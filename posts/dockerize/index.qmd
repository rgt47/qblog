---
title: "A simple seven step  process to get your  Shiny app online (securely). "
description: "This is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online."
subtitle: "Github, Docker-compose, EC2 version"
categories: [Docker, Shiny]
image: "img/rshiny.png"
editor: 
  markdown: 
    wrap: 72
#format:
#  pdf:
#    toc: true
#date: "2022-12-06"
#categories: [Neovim]
#image: "img/nvimlogo.png"
---

```{r init, include=FALSE}


options(dplyr.print_max = 1e9)
library(pacman)

p_load(jpeg, rmarkdown, tidyverse,  broom,  tidyr,  purrr,readr,knitr, 
       dplyr,  lubridate, zoo,  ggplot2, printr, lsmeans, ggthemes,  knitr,
       nlme, pwr)

opts_chunk$set(warning = F, message = F, echo=F, fig.width=3.2,
	       fig.height=3,  results='asis', dev='pdf',
	       opts_chunk$set(cache.path = "cache/"))
source('~/shr/zz.tools.R')
options(scipen = 1, digits = 2)
```

::: column-body
![under construction](img/crane.jpg)
:::

<font size="1"> Photo by
<a href="https://unsplash.com/@nathangwaters?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Nathan
Waters</a> on
<a href="https://unsplash.com/s/photos/construction?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
</font>

# Introduction

This is the first in a series of posts offering suggested strategies for
leveraging open source technologies to provide straight-forward
solutions to one of the central challenges in the practice of data
science, i.e. how to effectively communicate analysis results to clients
and collaborators. The list of open-source technologies (or software stack) we
suggest for employment is: linux, R, Shiny, Docker, Git, and Caddy. In
this post we'll make use of two cloud services Github and AWS. Further
posts will describe alternate constructions, e.g. using the low cost
cloud service: Hetzner.

Also described in other posts are strategies that avoid Github and
Amazon. 

This initial post provides a minimal, proof-of-concept example of how to
apply these technologies for hosting an interactive Shiny application.

In the following we start with a very simple, but hopefully still useful,
stand-alone Shiny app we've developed on our local workstation and  push it into
the cloud and after some straightforward interfacing with the Amazon web service
environment, end up with a secure (encrypted and authenticated) app running on a
website with a custom domain name. For pedagogic purposes the approach described
here is intentionally minimalist.

# Methods

To begin, lets assume we're just finished developing a new Shiny app,
named `power0` . (The methods described here apply generically to any
Shiny app, but we'll use one of our own for illustration). See the
`R/Shiny` code for our `power0` app (`power0.R`) [here](#appendix-1)
in appendix 1.

We can test the app locally by runnning it with the following command
issued from the `power0` directory. We can also think of the directory
as a project or a repository. The directory can be located anywhere on
your local system.

``` sh
R -e "library(shiny); runApp('power0.R', launch=T)"
```

This will in turn: run the R program, load the Shiny package, and launch
the app in your default browser.

Figure 1 below shows the Shiny app running locally in a browser on our
desktop, with a widget to select the sample size and provide a dynamic
visualization (2D plot) of the power as a function of the standardized
effect size:

::: column-body
![*Figure 1*](img/shinyapppower0.png)
:::

Once we determine our app is working as designed, we can move on to the
task of hosting the app on a (virtual) server to share with our
collaborators. There are many ways to accomplish this. Here we'll
demonstrate, a straightforward and efficient approach using mainstream
cloud services and open source tools. That is, we'll 'spin' up a server
on Amazon Web Service EC2 and in just a few steps through the
application of Docker, R, Shiny, and Caddy webserver functionality we'll
have a fully functional web app to share with colleagues.

# Hosting

::: column-body
![*Figure 2*](img/blogdockerizeflow.png)
:::

Figure 2 illustrates the tools we'll use and the flow of program and
configuration files. In order to host `power0` online we'll need the
following tasks:

1.  create a virtual server (connected via ssh) with firewall
2.  a static IP address (to identify the server online)
3.  a domain name (name for IP address)
4.  a webserver (tool to interact with https protocol requests and
    respond)
5.  an SSL certificate (to allow encrypted communication)
6.  an authentication method (password protection)
7.  a reverse proxy method (translate https (port 443) requests to Shiny
    (port 3838)

At first glance these 7 requirements can appear daunting, but on closer
inspection all can be met with relative ease and minimal or no cost.

This can be done at no cost if you have your own (self-hosted) server
with IP address, and domain name, or at minimal cost using a
cloud-hosting service (e.g. Amazon's EC2 or Digital Ocean) and a
"leased" domain name from, e.g. GoDaddy, or Amazon's Route 53.

# Select a hosting service (Steps 1,2 and 3)

There are a number of cloud based server options: Microsoft Azure,
Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean to name a few. Each
has their own approach to setting up a custom virtual server. Several
have free or low-cost service tiers available.

An overview of the process with EC2 is as follows. (Detailed
instructions for AWS EC2 are [here](#appendix-2) in appendix 2.)

Once the server is available connect via ssh and login, The only
necessary software to install is docker, docker-compose and git. Install
all 3 with the following command:

``` sh
sudo apt install -y git
sudo snap install docker
```

Once the host is set up and the requisite software installedh we'll have
a customized virtual server wtih a static IP address, and unique domain
name and firewall in place. In other words, items 1, 2, and 3 from our
list will be taken care of.

# Docker

We'll use docker to access both R/Shiny and Caddy, our webserver. The
first file is the dockerfile. In its simplest form it instructs Docker
to build a container based on a Rocker/Shiny image which is a ubuntu
image with R and Shiny installed then copy in the `power0.R` code and
launch Shiny on (default) port 3838.

::: column-body
![](img/docker1.jpg)
:::

<font size="1"> Photo by
<a href="https://unsplash.com/@carrier_lost?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Ian
Taylor</a> on
<a href="https://unsplash.com/?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
</font>

Here is our minimal dockerfile with comments:

```{r echo=T, eval=F}
#| code-fold: true
#| code-summary: "Show the code"
# Grab the latest rocker/Shiny image from Docker Hub to use as a base image.
FROM rocker/shiny
# Copy the Shiny code to the default location for shiny-server
# ?? not sure if need to change file name to app.R ??
COPY power0.R /srv/shiny-server/
# There is no non-root user on the image: shiny. Switch to user `shiny`
USER shiny
# Run the Shiny-server using the default app code
CMD ["/usr/bin/shiny-server"]

```

# Website

To configure the web server and containerize our app we need to add
three files to the server, to go along with our Shiny app in the
`power0` directory (in the home directory for default user `ubuntu`).

The easiest way to do this is to add the three files to the `power0`
directory on our workstation and then "push" a copy to github and from
there we can access them from our server.

Start by creating a repo for the app on github.

-   login to github (screenshot)

::: column-body
![](img/git1.png)
:::

-   click on `new` . Then in `repository name` field enter `power0`.
    (Make the
-   repo private, we only want to share with Bob at this point).
-   create repo. Click `Create repository` green button at the bottom of
    the page.
-   back on your laptop: clone the repo:

``` sh
git clone https://github.com/rgt47/power0.git
```

These three configuation files are:

-   a Caddy web server configuration file (default name `Caddyfile`)
-   a Docker configuration file (default name `Dockerfile`)
-   a Docker-compose configuration file (default name
    `docker-compose.yml`) (These are the default file names. If
    preferred, you can use custom names and point the program to the
    config file with command line options).

Lets discuss each. We'll use `Caddy` as our web server. Caddy is an
open-source tool that has the very useful feature of automating the
acquiring and installing of an SSL certificate. An SSL cert is required
by most browsers to use the encrypted communication protocol https.

Caddy is configured with a file named `Caddyfile`. We use the caddy
configuration file to specify three critical things.

1.  the site domain name.
2.  the authentication pair login/hash-password, for each user and
3.  the 'reverse proxy' map that redirects requests to port 443 (ssl
    port) to port 3838 (Shiny port).

Our barebones Caddyfile looks like this:

```{r echo=T, eval=F}
#| code-fold: true
#| code-summary: "Show the code"
rgtlab.org {
#auth credentials: bob/utter
basicauth * {
bob JDJhJDE0JElCQmRGaTA0ajY3bkZTLjRiWUZ4enVoZnVSQzVXVGVUMHlVcXJTaTRGYmpRQVFHLnYzN0tx
	}
	handle_path /power0/* {
		reverse_proxy power0:3838
	}
}

```

We can accomplish what we need for items 4, 5, 6 and 7 through the
Caddyfile.

Note:

-   power0.net is our domain name
-   basicauth provides user login information. In this case `bob` is the
    username and `thebunny` is the password.
-   `handle_path` maps all https requests to port 3838 where Shiny is
    listening.

Providing our servers domain name, `rgtlab.org` is sufficient to
initiate an exchange with `letsencrypt` to generates an SSL certificate.

And the third file is the docker compose file that containerizes our
Shiny app, pulls a caddy webserver image from Docker Hub and creates a
local network for the two containers to communicate in.

The docker-compose.yml file:

```{r echo=T, eval=F}
#| code-fold: true
#| code-summary: "Show the code"
version: "3.7"

services:
  power0:
    build: .
  caddy:
    image: caddy:2.3.0-alpine
    ports:
      - "443:443"
    volumes:
      - $PWD/Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
volumes:
    caddy_data:
```

# Github

Once in place on your laptop push the four files (power0.R, Dockerfile,
Caddyfile, docker-compose.yml) to github

``` sh
git push
```

and then ssh login to server and clone repo.

``` sh
git clone https://github.com/rgt47/power0.git
```

Lastly, cd to `power0` directory and run

``` sh
docker-compose up -d
```

and you're good to go!

The app `power0` can be accessed by 'bob' at the url

``` sh
https://rgtlab.org/power0
```

with password 'thebunny'

# Appendix-1

Consider an app that is a balance of simple and functional -- one that
calculates the power for a 2-sample t-test as a function of the
standardized effect size. re is our shiny app `power0.R`:

Consider the power0.R file:

``` sh

ui <- fluidPage(
titlePanel("Power Calculator for Two Group Parallel Designs"),
sliderInput("N", "Total Sample Size:", min = 0, max = 300, value = 100),
plotOutput("plot"),
verbatimTextOutput("eff"))

server <- function(input, output, session) {
  delta = seq(0, 1.5,.05)
  pow = reactive(sapply(delta, function(x) power.t.test(input$N, d=x)$power ))
  eff =  renderText(power.t.test(input$N, power=.8)$d)
  output$plot <- renderPlot({
  plot(delta, pow(), cex=1.5, ylab="power")
  abline(h = .8,  col = "red", lwd =2.5, lty = 4)
  abline(v = eff(), col = "blue",lwd =2.5, lty = 4)})  
  output$eff <- renderText(
    paste0("Std. effect detectable with power 80% = ", eff()) )
}
shinyApp(ui, server)
```

The app is designed to be maximally minimal. Using only base R
functions, with a minimum of reactive widgets and layout commands to
keep it simple while still performing a useful function.

# Appendix-2 {#appendix-2}

AWS is a reasonable choice for setting up a small custom server. AWS
offers a free set of servers for the first 12 months.

To start open the EC2 console.

``` sh
   https://aws.amazon.com/console
```

Choose regional service. For me its "N. California".

::: column-body
![](img/ec2a.png)
:::

Create an account or sign in and navigate to the EC2 dashboard. Next set
up a working environment. Specifically you'll want to set up four
components of the environment:

(https://portal.aws.amazon.com/billing/signup#/start/email)

Before selecting a server set up a working environment. This consists of
four main components: 1. ssh key-pair to allow you to remote login to
virtual server. 2. A firewall to restrict access to only secure
connections, 3. A static IP. This is required for maintaining the link
between the domain name and the server when rebooting. 4. A domain name,
say power0.net, or simplepower.org. Not strictly required but will
facilitate collaborator access.

1.  Ssh key pair

The first time you create an AWS account you need to exchange an SSH key
pair with AWS. You can generate the ssh key pair locally on you
workstation and upload the public key to EC2. To do this create a
directory to hold the keys. e.g. `~/.ssh`. From inside `.ssh` directory
you can generate the keys with the command

``` sh
ssh-keygen -m PEM
```

in the dialog that ensues name the key prefix something like `ssh-rsa`.

Back in the browser on EC2 select `security/keys`, A dialog starts and
asks for the location of the public key. Browse to the `.ssh` directory
and import the public key `ssh-rsa.pub`.

Or you can select `Create Key Pair` in EC2. Give the pair a name, say
power0ssh, and a pair of keys will be created and the private key
`power0ssh.pem` will be downloaded to you local machine. In my case to
the `~/Downloads` directory.

# Set up firewall

A very restrictive firewall is recommended. Only https and ssh packets
are needed. To construct the firewall click on: `Create Security Group`.
Add two incoming rules: 1. port 22 (ssh) for IPv4 packets. and 2. port
443 (https) for IPv4 packets. Thats it.

# Set up static IP address

Use "elastic IP" to get a static IP that can be assigned to the server.
Navigate to Network and Security again and select Allocate Elastic IP.
An IP will be assigned from the EC2 pool of IPv4 IP addresses. (there is
a small fee for use of the static IP).

Once you have created the instance come back to this Elastic IP dialog
and - click on elastic IP in left panel - select associate Elastic IP
13.57.139.31 choose an instance (power0) to associate with.

-   side panel, click "ec2"
-   side panel, click "Instances"
-   from top bar, click "Launch Instances"

# Get Domain Name

To obtain a dedicated domain name Go to godaddy.com or Amazon route 53
to associate a domain name with your Elastic IP.

(screenshot)

Once a domain name is aquired, eg power0.net, you want to associate it
with your static IP address. To associate domain name power0.net with
elastic IP do as follows.

in Route 53:

-   click on 'hosted zones' in side panel
-   click on power0.net in center panel
-   click on checkbox for power0.net type=A line
-   then click on edit record in right panel
-   change ip address to the Elastic IP (e.g. 13.57.139.31).

# Select and launch instance

2.  From "Quick Start" ine the EC2 dashboard click `Ubuntu` button.

-   Name the server, say power0
-   Choose an AMI (instance template, with a prefered operating system):

I'll suggest choosing "Ubuntu Server 22.04 LTS", but other linux
distributions can be utilized, e.g. Red Hat, or SUSE.

3.  Next choose an instance **type**, e.g. "t2-micro". (different
    instance types are mixtures of size, processors, memory, instance
    storage capacity, network performance)

4.  click "Next: Configure Instance Details"

5.  choose a Key pair (use power0.rsa from your environment) .

6.  Add security group, e.g. 'power0.firewall' allowing 22 (ssh), and
    443 (https).

7.  choose 30 GB of EBS General Purpose (SSD) or Magnetic storage

8.  click Launch Instance

# Access instance

Log into new instance with ssh from local

``` sh
ssh -i "~/Downloads/power0.rsa.pem" ubuntu@13.57.139.31
```

# Appendix 3 Tips and Tricks

## Tip 1.

For convenience, construct a `config` file in `~/.ssh` as:

``` sh
Host ec2
HostName 13.57.139.31 # static IP
User ubuntu # default user on ubuntu server
Port 22  # the default port ssh uses
IdentityFile ~/Downloads/power0.rsa
```

then you can ssh into the new server with

``` sh
sh> ssh ec2
```

## Tip 2: Add ubuntu to the docker group to allow docker to run without sudo.

## Tip 3:

Copy file contents to workstation without using editor with shell
commands. \* Copy file from blog \* Issue the following shell command \*
paste the file contents \* type EOF on a new line.

``` sh
cat << EOF > Dockerfile
```


# References
* [Setup Jupyter Notebook for R article](https://developers.refinitiv.com/en/article-catalog/article/setup-jupyter-notebook-r).


