[
  {
    "objectID": "posts/minimalist_edc_app/working_from_c060_a201/TODO.html",
    "href": "posts/minimalist_edc_app/working_from_c060_a201/TODO.html",
    "title": "Thomas Lab home page",
    "section": "",
    "text": "ReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  url = {https://focusonr.org/posts/minimalist_edc_app/working_from_c060_a201/TODO.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. n.d. https://focusonr.org/posts/minimalist_edc_app/working_from_c060_a201/TODO.html."
  },
  {
    "objectID": "posts/simpleS3/index.html",
    "href": "posts/simpleS3/index.html",
    "title": "Writing a simple R package in S3.",
    "section": "",
    "text": "S3 OOP in R\n\n\n\n1 Introduction\nIf you, like me, feel its time to expand your R programming armamentarium to include S3 methods. This blog may help.\nWhere to start?\nIn this post we’ll walk through an example of a simple “table 1” function using S3 methods.\nWe’ll start with the ‘raw’ data from a sample of the Penguins data set and return a dataframe with summary measures.\nS3 methods allow coders to write functions that perform differently for different classes of objects.\nIn our project we want to build a function that creates a row in the ‘Table 1’ table for each variable in the formula regardless of the class of the variable.\nNow reading Nick Tierney R journal paper.\n\nsource(\"~/shr/zz.tools.R\")\nlibrary(pacman)\n\np_load(tidyverse, dplyr, gapminder, thematic, palmerpenguins, tidyverse, knitr, lubridate, readxl)\nknitr::opts_chunk$set(collapse = T)\nset.seed(101)\ndat &lt;- palmerpenguins::penguins %&gt;%\n  fil(!is.na(sex))\ndat1  &lt;- slice_sample(dat, n=10) |&gt;\nsel(species, island, bill_length_mm)\n\n\n\n#' Table one summaries\n#'\n#' Summarizes baseline trial results by treatment\n#' @param data dataframe\n#' @param form formula y ~ x1 + x2\n#' @param ... extra parameters passed through to speciality functions\n#' @return a dataframe\n#' @examples\n#' table1(dat2, form = arm ~ sex + age, annot = FALSE)\n\n#' @export\ntable1 &lt;- function(form, data, ...) {\n  UseMethod(\"table1\")\n}\n\nrow_name &lt;- function(x, nm, ...) {\n  UseMethod(\"row_name\")\n}\n\nrow_name.character &lt;- function(x, nm, ...) {\n  # browser()\n  u &lt;- unique(x)\n  categs &lt;- paste(\"   \", u[!is.na(u)])\n  return(c(nm, categs))\n}\n\nrow_name.factor &lt;- row_name.character\n\nrow_name.logical &lt;- row_name.character\n\nrow_name.numeric &lt;- function(x, nm, ...) {\n  return(nm)\n}\n\nrow_summary &lt;- function(x) {\n  UseMethod(\"row_summary\")\n}\n\nrow_summary.character &lt;- function(x) {\n  # browser()\n  df &lt;- data.frame(x = x, y = dep) |&gt; na.omit()\n  t1 &lt;- df |&gt;\n    tabyl(x, y) |&gt;\n    adorn_percentages(\"col\") |&gt;\n    adorn_pct_formatting(digits = 0) |&gt;\n    adorn_ns(position = \"front\") |&gt;\n    select(-x)\n  # browser()\n  t1 &lt;- as_tibble(t1)\n  t2 &lt;- table(df$x, df$y) |&gt; as.data.frame.matrix()\n  rbind(\"\", t1)\n}\n\nrow_summary.factor &lt;- row_summary.character\nrow_summary.logical &lt;- row_summary.character\n\nrow_summary.numeric &lt;- function(x) {\n  sp &lt;- split(x, dep)\n  nms &lt;- names(sp)\n  mm &lt;- sp |&gt;\n    map_vec(mean, na.rm = TRUE) |&gt;\n    round(2) |&gt;\n    as.character() |&gt;\n    matrix(1)\n  ss &lt;- sp |&gt;\n    map_vec(sd, na.rm = TRUE) |&gt;\n    round(2) |&gt;\n    paste0(\"(\", x = _, \")\") |&gt;\n    matrix(1)\n  bb &lt;- paste(unlist(mm), unlist(ss)) |&gt; matrix(nrow = nrow(mm))\n  colnames(bb) &lt;- nms\n  bb &lt;- bb |&gt; as_tibble()\n  bb\n}\n\nrow_pv &lt;- function(x) {\n  UseMethod(\"row_pv\")\n}\n\nrow_pv.character &lt;- function(x) {\n  tab &lt;- data.frame(x = x, y = dep) |&gt;\n    na.omit() |&gt;\n    tabyl(x, y)\n  if (!(nrow(tab) &gt;= 2 & ncol(tab) &gt;= 2)) {\n    return(NA)\n  }\n  # browser()\n  pv &lt;- janitor::fisher.test(tab, simulate.p.value = TRUE)$p.value |&gt;\n    round(4)\n  return(c(pv, rep(\"\", nrow(tab))))\n}\n\nrow_pv.factor &lt;- row_pv.character\nrow_pv.logical &lt;- row_pv.character\n\nrow_pv.numeric &lt;- function(x) {\n  df &lt;- data.frame(x = x, y = dep)\n  tab &lt;- table(x, dep)\n  pv &lt;- ifelse((nrow(tab) &gt;= 2 & ncol(tab) &gt;= 2),\n    stats::fisher.test(tab, simulate.p.value = TRUE)$p.value, NA\n  ) |&gt;\n    round(4)\n  return(c(pv, rep(\"\", nrow(tab))))\n}\n\nrow_pv.factor &lt;- row_pv.character\nrow_pv.logical &lt;- row_pv.character\n\nrow_pv.numeric &lt;- function(x) {\n  df &lt;- data.frame(x = x, y = dep)\n  pv &lt;- tidy(anova(lm(x ~ y, data = df)))$p.value[1] |&gt;\n    round(4)\n  return(pv)\n}\n\n#' @export\n#' @describeIn table1 interprets formula and yields publication tables\ntable1.formula &lt;- function(form, data, ...) {\n  vars &lt;- all.vars(form)\n  # dep &lt;&lt;- data[[vars[1]]]\n  indep &lt;- data[vars[-1]]\n\n  y_var &lt;- deparse(form[[2]])\n  dep &lt;&lt;- data[y_var]\n  g_bar &lt;- form[[c(3, 1)]]\n  if (g_bar == \"|\") {\n    x_vars &lt;- all.vars(form[[c(3, 2)]])\n    g_vars &lt;- all.vars(form[[c(3, 3)]])\n    group &lt;- data[g_vars]\n  } else {\n    x_vars &lt;- all.vars(form)[-1]\n  }\n  indep &lt;- data[x_vars]\n  browser()\n  left &lt;- indep |&gt;\n    imap(row_name, ...) |&gt;\n    unlist() |&gt;\n    enframe(name = NULL) |&gt;\n    setNames(\"variable\")\n  right &lt;- indep |&gt;\n    map(row_pv) |&gt;\n    unlist() |&gt;\n    enframe(name = NULL) |&gt;\n    setNames(\"p-value\")\n  mid &lt;- indep |&gt;\n    map_dfr(row_summary) |&gt;\n    identity()\n  mid &lt;- bind_rows(mid)\n  # browser()\n  bind_cols(left, mid, right)\n}\n\n\n\np_load(palmerpenguins, dplyr)\np1 &lt;- sample_n(penguins, 300) |&gt;\n  dplyr::select(species, sex, body_mass_g, island)\n# p1 &lt;- pp |&gt; dplyr::mutate(sex1 = sex)\n# table1(species ~ sex + body_mass_g, data = p1)\n table1(species ~ sex + body_mass_g | island, data = p1)\n\n\n2 References\nAlso useful other references:\nIntroduction to Scientific Programming and Simulation using R. Jomes. Maillardet, Robinson.\n[1608.07161] A Simple Guide to S3 Methods https://arxiv.org/abs/1608.07161\nWhy your S3 method isn’t working | R-bloggers\nDealing with S3 methods in R with a simple example | R-bloggers\nVideo on S3 Classes in R by Dr Andrew Robinson | R-bloggers\nUnexported S3 Methods and R Packages | R-bloggers\nSimple Guide to S3 Methods | R-bloggers\nThe S3 OOP system | R-bloggers\nNick Tierney R journal paper.\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {{Writing} a Simple {R} Package in {S3.}},\n  date = {2024-02-10},\n  url = {https://focusonr.org/posts/simpleS3},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024.“Writing a Simple R Package in\nS3. .” February 10, 2024. https://focusonr.org/posts/simpleS3."
  },
  {
    "objectID": "posts/share_rmd_code_via_docker/index.html",
    "href": "posts/share_rmd_code_via_docker/index.html",
    "title": "Simple process for sharing Rmarkdown code via Docker",
    "section": "",
    "text": "1 Introduction\nLets assume you have an rmarkdown Rmd file, say peng.Rmd, that you’re written to analyze some data. You now want to share the code with a colleague, we’ll call him Joe. How to proceed?\nThe simplest option is simply to send Joe the “rmd” file containing the code via the most convenient method (e.g. email/text/slack/discord/github/USB drive etc.)\nThe next step will be for the Joe to ( attempt to ) load and run the code. Typically he would do this with either using Rstudio.app to open the file and knit it, render it from the command line with the command:\n&gt; R -e \"render('peng.Rmd')\"\nSometimes this approach works, and all is well. Joe can add comments or expand the code and reply to you. Frequently, however, this naive process will fail for any number of reasons. Ideally to facilitate reproducibility Joe will have as similar a computing environment as you, the original developer. This can be difficult to achieve, especially given the dynamic nature of open source software. For example Joe may have an outdated version of R installed on his workstation, or his R environment may be missing a necessary package. Additiional potential problems include: the required package may be present but its the wrong version, the program may need to source an additional file thats missing, or the program load some data that it can’t find on Joe’s machine.\nAll of these problems go away if instead of sending the program as a standalone text file you send it as a docker image. In this post we’ll walk through the process of dockerizing the R code.\nAssume a simple Rmd file like this:\n\n---\ntitle: \"Penguins analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r format(Sys.time(), '%B %d, %Y')`\"\nfontsize: 11pt\ngeometry: \"left=3cm,right=5cm,top=2cm,bottom=2cm\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\n      in_header: \"preamble.tex\"\n---\n\n```{r include=F, echo=F}\nlibrary(pacman)\np_load(palmerpenguins, tidyverse, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, results = \"asis\", dev = \"pdf\"\n)\n```\n\n# Introduction\n\nWe can work with the dataset `penguins` included in the package `palmerpenguins`.\n```{r }\nlibrary(palmerpenguins)\n```\nOne naive approach is to split the dataset and do three separate\nanalyses:\n\n```{r }\ndf1 &lt;- split(penguins, penguins$species)\n\nfoo &lt;- function(df, z) {\n  df |&gt; ggplot(aes(x = bill_length_mm, y = flipper_length_mm)) +\n    geom_point(aes(color = island), alpha = .5) +\n    geom_smooth() +\n    scale_color_manual(values = c(\"purple\", \"green\", \"red\")) +\n    theme_bw() +\n    labs(\n      title = paste(z, \" Penguin Anatomy Comparison\"), x = \"Flipper length\",\n      y = \"Bill length\", color = \"Island\"\n    )\n  plotfile_name &lt;- paste0(z, \".pdf\")\n  ggsave(plotfile_name)\n  cat(paste0(\"\\\\includegraphics[height=3cm]{\", plotfile_name, \"}\"), \"\\n\")\n  cat(\"\\\\vspace{1cm}\", \"\\n\")\n}\n\nbar &lt;- df1 |&gt; map2(names(df1), foo)\n```\nThe Rmd file runs cleanly on our machine and generates the the report on the following page. However, we note that the third plot needs additional examination and want to relay the program to our colleague Joe for further analyis.\n\n\n\nrendered page\n\n\n\n\n2 Share program code with Joe. Two approaches, Naive and Docker based.\nWhats the best way to accomplish this?\nWe start by simply emailing the file to him (rgthomas4747@gmail.com) and asking him to collaborate.\nJoe downloads the attachment. Opens a working directory and attempts to run the Rmd file\nwith the command\n&gt; R -e \"render('peng.Rmd')\"\nJoe has a linux mint desktop\n&gt; mkdir peng_collaboration\n&gt; cd peng_collaboration\n&gt; R -e \"render('peng.Rmd')\"\nLinux can’f find R\nJoe can fix this by installing R\n&gt; sudo apt install r-base-core\nNext R can not find the function render.\nJoe determines that render is a function in the package rmarkdown\nHe endeavors to installs rmarkdown with\n\nR -e \"install.packages('rmarkdown')\"\nThis fails due to inadequate permission on the directory /usr/lib/R/library\n\nsudo apt install libssl-dev libcurl4-openssl-dev unixodbc-dev libxml2-dev\\\nlibmariadb-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev\\\nlibfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\nAlso latex is not available\nOne more try… and the latex engine notes the absence of the file\n~/shr/preamble.tex\nSo, I need to relay the missing .tex file.\nAlso the .png (sudoku.png) logo file.\nFinally! success.\n\n\n3 Docker approach\nAlternatively, consider the “Docker” approach.\nBefore sending peng.Rmd to Joe we’ll dockerize it.\n\nPrepare a work directory: penguins. We want to send Joe a container that has R and all the preliminaries taken care of so that all he has to do is\n\nHere is the docker file\n\nFROM rocker/verse:4\nRUN apt update\nRUN apt install vim -y\nRUN R -e \"install.packages('pacman')\"\nRUN R -e \"install.packages('palmerpenguins')\"\nRUN R -e \"install.packages('tidyverse')\"\nRUN R -e \"install.packages('knitr')\"\nRUN R -e \"install.packages('rmarkdown')\"\nRUN tlmgr init-usertree\nRUN tlmgr update --self --all\nRUN  tlmgr install  fancyhdr adjustbox geometry titling\n\nRUN addgroup --system joe && adduser --system --ingroup joe joe\nRUN chmod -R 0777 '/usr/local/lib/R/site-library'\nRUN chown joe:joe -R /home/joe\nUSER joe\nWORKDIR /home/joe\nRUN mkdir -p /home/joe/shr\nRUN mkdir -p /home/joe/output\nCOPY /preamble.tex /home/joe/shr\n# COPY /.Rprofile /home/joe/shr\nCOPY sudoku.png /home/joe/shr\nCOPY peng.Rmd /home/joe/shr\nCMD [\"/bin/bash\"]\nrun docker\ndocker build -t rgt47/penguin_review --platform=linux/amd64 .\ndocker push rgt47/peng_review\nrelay image to Joe\ndocker push rgt47/peng_review\nor\ndocker save rgt47/peng_review | gzip &gt; peng_review_trans.tgz\ndocker load -i peng_review_trans.tgz\n&gt; docker pull rgt47/penguin_review\n\n&gt; droot=\"$PWD\"/output docker run -it --rm --platform linux/x86_64 \\\n-v $droot:/home/joe/output peng_review\n&gt; cd output\n&gt; library(rmarkdown); render('../shr/peng.Rmd')\nImportant to include the association between the /home/joe/output directory in the container with the output directory on the local workstation. Thats where the results of the analysis will be saved.\n&gt; R -e \"library(rmarkdown); render('peng.Rmd')\"\nand if he wants to edit peng.Rmd\n&gt; vim peng.Rmd\n\n\\usepackage[export]{adjustbox}\n\\usepackage{fancyhdr}\n\\usepackage{titling}\n\n\\pagestyle{fancy}\n\n\\pretitle{\n\\begin{flushright}\n\\includegraphics[width=3cm,valign=c]{sudoku.png}\\\\\n\\end{flushright}\n\\begin{flushleft} \\LARGE }\n\\posttitle{\\par\\end{flushleft}\\vskip 0.5em}\n\\predate{\\begin{flushleft}\\large}\n    \\postdate{\\par\\end{flushleft}}\n    \\preauthor{\\begin{flushleft}\\large}\n    \\postauthor{\\par\\end{flushleft}}\n\\fancyfoot[L]{\\currfilename} %put date in header\n\\fancyfoot[R]{\\includegraphics[width=.8cm]{sudoku.png}}\n\\fancyhead[L]{\\today} %put current file in footer\n\n\n4 REFERENCES\nRunning your R script in Docker\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Simple Process for Sharing {Rmarkdown} Code via {Docker}},\n  date = {2024-02-24},\n  url = {https://focusonr.org/posts/share_rmd_code_via_docker},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Simple Process for Sharing\nRmarkdown Code via Docker.” February 24, 2024. https://focusonr.org/posts/share_rmd_code_via_docker."
  },
  {
    "objectID": "posts/setupquarto/index.html",
    "href": "posts/setupquarto/index.html",
    "title": "Setting up Quarto",
    "section": "",
    "text": "quarto\n\n\n\n1 Introduction\nQuarto is an extension of the Rmarkdown ecosystem. It leverages the power of knitr and pandoc. It provides a number of useful additional tools for literate programming and blogging.\nI’m using quarto for my lab’s home page with an embedded blog. (focusonR).\nThis post will include some of the most useful and interesting quarto tools presented in the context of a Palmer Penguins data set analysis.\nTo start a blog, say qblog, begin by running the command quarto create-project at the ~/prj level\n❯ quarto create-project qblog --type website:blog\nThis generates a project folder ~/prj/qblog:\nNext steps:\n\ncd to `~/prj/qblog/posts/\nfor the first post, create a new directory, say setupquarto\ncd to ~/prj/qblog/posts/setupquarto\nedit the index.qmd file and add content. vim index.qmd\n\nThe framework for a quarto blog can be quite minimal. For example the following set of files is sufficient to start a useful blog:\n.\n|-- _quarto.yml\n|-- index.qmd\n`-- posts\n    |-- index.qmd\n    `-- setup_R_vimtex_ultisnips\n        |-- img\n        |   `-- vimR.png\n        `-- index.qmd\nwith file contents:\n\n\n\n_quarto.yml\n\nproject:\n  type: website\nwebsite:\n  title: \"Thomas Lab home page\"\n  site-url: https://focusonr.org\n  repo-url: https://github.com/rgt47/qblog\n  open-graph: true\n  navbar:\n    background: \"#182b49\"\n    foreground: \"#C69214\"\n    left:\n      - href: posts/index.qmd\n        text: Blog\n    right:\n      - icon: github\n        href: https://github.com/rgt47\n  page-footer:\n    left: \"Copyright 2023, Ronald G. Thomas\"\nformat:\n  html: \n    theme: cosmo\n\n\n\n\n\nindex.qmd\n\n---\ntitle: \"Minimal Blog\"\nlisting:\n  contents: posts\n---\n\n\n\n\n\nposts/index.qmd\n\n---\ntitle: \"Blog\"\ndescription: Posts on Data Science tools and R in particular.\nlisting:\n  contents: .\n  type: default\n---\n\n\n\nRefererences:\nUseful archive:\nmcanouil/awesome-quarto: A curated list of Quarto talks, tools, examples & articles\nConsider some ideas from\n\nRob Hyndman - Template of quarto website\nEric Ekholm - Modifying the Default Quarto Blog Structure\nAllison Hill - We don’t talk about Quarto\nNick Tierney - Notes on Changing from Rmarkdown/Bookdown to Quarto\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up {Quarto}},\n  date = {2024-02-24},\n  url = {https://focusonr.org/posts/setupquarto},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up Quarto.”\nFebruary 24, 2024. https://focusonr.org/posts/setupquarto."
  },
  {
    "objectID": "posts/setupneovim/index.html",
    "href": "posts/setupneovim/index.html",
    "title": "Setting up a minimal neovim environment for data science code development",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash \n\n1 Introduction\nNeovim (a fork of Vim) is a text editor that has several advantages for data science code development. One of its main attractions (besides being open source) is that it has a number of useful plugins to facilitate working on R, python, and julia code. Also, its modal, keyboard-centric system allows text and code manipulation at potentially far greater speed than conventional, mouse-centric, systems.\nIn this post we describe a minimal, yet functional setup to allow a quick start with neovim. We also describe a more extensive setup utilizing several of the neovim-only plugins that together allow neovim to provide IDE style code editing and REPL interaction for the three primary data science coding tools: R, Python, and Julia.\nOur presentation here is for a Macos environment. Appendix one contains required adjustments for a ubuntu linux environment.\n\n\n2 Install the latest stable version of neovim.\nWith minimal effort we can install both the terminal and GUI versions of neovim. The simplist approach is to use homebrew:\n&gt; brew install neovim neovim-qt\nSuggest set up convenience aliases in zsh.\n&gt; alias ng = \"nvim-qt\"\n&gt; alias nt = \"nvim\"\n(mnemonic: the t in nt is for terminal, the g in ng is for GUI)\n\n\n3 Configure neovim\nThe standard location for neovim configuration files on “unix-like” systems is ~/.config/nvim. The main config file is either init.vim (VimL) or init.lua (Lua). In this post we’ll focus on lua based configuration.\nHere is the file hierarchy we’ll construct. In fact all the code in the lua subdirectory could be bundled into the init.lua file, but this approach is clearer and cleaner.\n.\n|-- ginit.vim\n|-- init.lua\n|-- lazy-lock.json\n|-- lua\n|   |-- basics.lua\n|   |-- leap-config.lua\n|   |-- nvim-R-config.lua\n|   |-- nvim-cmp-config.lua\n|   |-- nvim-telescope-config.lua\n|   |-- nvim-tree-config.lua\n|   `-- treesitter-config.lua\n|-- my_snippets\n|   |-- all.snippets\n|   |-- tex\n|   |-- R\n|   |-- python\n|   |-- julia\n|   |-- giles.tex.snipppets\n|   |-- mail.snippets\n|   |-- r.snippets\n|   |-- rmd.snippets\n|   |-- snippets.snippets\n|   |-- tex.snippets\n|   |-- text.snippets\n|   `-- txt.snippets\n|-- spell\n|   |-- en.utf-8.add\n|   `-- en.utf-8.add.spl\nNeovim on its own is limited. We can add the functionality we need using plugins. To install one or more plugins we’ll need a plugin manager. There are several to choose from. We’ll use the Lazy plugin manager for this post. To install the Lazy plugin manager issue the following command at the shell prompt:\n&gt; git clone https://github.com/folke/lazy.nvim.git \\\n   ~/.local/share/nvim/lazy/lazy.nvim\nAdd the following code to init.lua list the plugins needed to be installed from github and “feed” them to Lazy for installation.\nNvim-R, Leap, UltiSnips, and vimtex need additional configuration. The required code is contained in bespoke files under the lua directory.\n\nvim.g.mapleader = \",\"\nvim.g.maplocalleader = \" \"\nvim.opt.rtp:prepend(\"~/.local/share/nvim/lazy/lazy.nvim\")\nrequire('plugins')\nrequire('basics')\nrequire('nvim-tree-config')\nrequire('nvim-R-config')\nrequire('nvim-telescope-config')\nrequire('leap').add_default_mappings()\nrequire('leap-config')\nrequire('lualine').setup()\nList of plugins\n\n\n\n\n\n\nrequire('lazy').setup({\n--\n--minimal data science setup\n--\n'jalvesaq/Nvim-R',\n'lervag/vimtex',\n'SirVer/ultisnips',\n'jalvesaq/vimcmdline',\n--\n--optional utilities\n--\n\"nvim-lualine/lualine.nvim\",\n\"bluz71/vim-moonfly-colors\",\n'junegunn/vim-peekaboo',\n'tpope/vim-commentary',\n'francoiscabrol/ranger.vim',\n'machakann/vim-highlightedyank',\n'tpope/vim-surround',\n'ggandor/leap.nvim',\n--\n--neovim specific\n'nvim-lua/plenary.nvim',\n'nvim-tree/nvim-web-devicons',\n'nvim-tree/nvim-tree.lua',\n'nvim-telescope/telescope.nvim',\n'nvim-treesitter/nvim-treesitter',\n'neovim/nvim-lspconfig',\n})\n\n\n\n4 plugin discussions\n\n\n# basics\n```sh\n\n\n\n\n\n\nlocal map = vim.keymap.set\nlocal opts = {noremap = true}\nvim.cmd([[\n\"    paste registers into terminal\ntnoremap &lt;expr&gt; &lt;C-R&gt; '&lt;C-\\&gt;&lt;C-N&gt;\"'.nr2char(getchar()).'pi'\nset background=dark\ncolorscheme moonfly\nlet $FZF_DEFAULT_COMMAND = 'rg --files --hidden'\nset completeopt=menu,menuone,noinsert,noselect\nset number relativenumber\nset textwidth=80\nset cursorline\nset clipboard=unnamed\nset iskeyword-=_\nset hlsearch\nset splitright\nset hidden\nset incsearch\nset noswapfile\nset showmatch\nset ignorecase\nset smartcase\nset gdefault\nfiletype plugin on\nset encoding=utf-8\nset nobackup\nset nowritebackup\nset updatetime=300\nset signcolumn=yes\nset colorcolumn=80\nset timeoutlen=1000 ttimeoutlen=10\nlet g:UltiSnipsSnippetDirectories = ['~/.config/nvim/my_snippets']\nlet g:UltiSnipsExpandTrigger=\"&lt;tab&gt;\"\nlet g:UltiSnipsJumpForwardTrigger=\"&lt;c-j&gt;\"\nlet g:UltiSnipsJumpBackwardTrigger=\"&lt;c-k&gt;\"\nnnoremap &lt;leader&gt;U &lt;Cmd&gt;call UltiSnips#RefreshSnippets()&lt;CR&gt;\n\nautocmd BufWinEnter,WinEnter term://* startinsert\n\"autocmd TermOpen * exec \"normal! i\"\n]])\nmap('n', ':', ';', opts)\nmap('n', ';', ':', opts)\nmap('n', '&lt;leader&gt;u',':UltiSnipsEdit&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;U','&lt;Cmd&gt;call UltiSnips#RefreshSnippets()&lt;cr&gt;', opts)\nmap('n', '&lt;localleader&gt;&lt;localleader&gt;','&lt;C-d&gt;', opts)\nmap('n', '-','$', opts)\nmap('n', '&lt;leader&gt;w','vipgq', opts)\nmap('n', '&lt;leader&gt;v',':edit ~/.config/nvim/init.lua&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;n',':edit ~/.config/nvim/lua/basics.lua&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;a','ggVG', opts)\nmap('n', '&lt;leader&gt;t',':tab split&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;y',':vert sb3&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;0',':ls!&lt;CR&gt;:b&lt;Space&gt;', opts)\nmap('n', '&lt;leader&gt;&lt;leader&gt;','&lt;C-w&gt;w', opts)\nmap('n', '&lt;leader&gt;1','&lt;C-w&gt;:b1&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;2','&lt;C-w&gt;:b2&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;3','&lt;C-w&gt;:b3&lt;cr&gt;', opts)\nmap('t',  'ZZ', \"q('yes')&lt;CR&gt;\", opts)\nmap('t',  'ZQ', \"q('no')&lt;CR&gt;\", opts)\nmap('v',  '-', '$', opts)\nmap('t',  '&lt;leader&gt;0','&lt;C-\\\\&gt;&lt;C-n&gt;&lt;C-w&gt;:ls!&lt;cr&gt;:b&lt;Space&gt;', opts)\nmap('t',  '&lt;Escape&gt;','&lt;C-\\\\&gt;&lt;C-n&gt;', opts)\nmap('t',  ',,','&lt;C-\\\\&gt;&lt;C-n&gt;&lt;C-w&gt;w', opts)\nmap('i',  '&lt;Esc&gt;', '&lt;Esc&gt;`^', opts)\n\n\n\n5 Set up R\n\n\n\n\n\n\nvim.cmd([[\niabb &lt;buffer&gt; x %&gt;%\niabb &lt;buffer&gt; z %in%\nlet R_auto_start = 2\nlet R_enable_comment = 1\nlet R_hl_term = 0\nlet R_clear_line = 1\nlet R_pdfviewer = \"zathura\"\nlet R_assign = 2\nlet R_latexcmd = ['xelatex']\naugroup rmarkdown\nautocmd!\nautocmd FileType rmd,r nnoremap &lt;buffer&gt; &lt;CR&gt;  :call SendLineToR(\"down\")&lt;CR&gt;\nautocmd FileType rmd,r nnoremap &lt;buffer&gt; &lt;space&gt;' :call RMakeRmd(\"default\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;i :call RAction(\"dim\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;h :call RAction(\"head\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;p :call RAction(\"print\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;q :call RAction(\"length\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;n :call RAction(\"nvim.names\")&lt;cr&gt;\nautocmd FileType rmd,r vmap &lt;buffer&gt; &lt;CR&gt; &lt;localleader&gt;sd\nautocmd FileType rmd,r nmap &lt;buffer&gt; &lt;space&gt;j &lt;localleader&gt;gn\nautocmd FileType rmd,r nmap &lt;buffer&gt; &lt;space&gt;k &lt;localleader&gt;gN\nautocmd FileType rmd,r nmap &lt;buffer&gt; &lt;space&gt;l &lt;localleader&gt;cd\naugroup END\n]])\n\n\n\n\n\n\n\n\n6 Appendix Ubuntu tweaks\n\n\n7 Appendix Isolate configuration files\ngit clone https://github.com/LazyVim/starter ~/.config/LazyVim\nNVIM_APPNAME=LazyVim nvim\n\n\n8 Appendix\nConsider using multiple config to evaluate:\nSwitching Configs in Neovim • Michael Uloth\n\n\n9 NB: study this init.vim with ALE for completion\nstudy this init.vim with ALE for completion\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up a Minimal Neovim Environment for Data Science Code\n    Development},\n  date = {2024-02-11},\n  url = {https://focusonr.org/posts/setupneovim},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up a Minimal Neovim\nEnvironment for Data Science Code Development.” February 11,\n2024. https://focusonr.org/posts/setupneovim."
  },
  {
    "objectID": "posts/setup_yabai/index.html",
    "href": "posts/setup_yabai/index.html",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "",
    "text": "quarto\n\n\n\n1 Introduction\nYabai is a tiling window manager for macOS.\nFrom the wiki Home · koekeishiya/yabai Wiki · GitHub\n“It automatically modifies your window layout using a binary space partitioning algorithm … . interface allows you to control and query windows, spaces and displays to enable powerful integration with tools like skhd to allow you to work more efficiently with macOS.”\nRequirements: (from the WIKI)\n\nIn the Desktop & Dock tab, inside the Mission Control pane, the setting “Displays have separate Spaces” must be enabled.\nSystem Settings (macOS 13.x, 14.x) In the Desktop & Dock tab, inside the Mission Control pane, the setting “Automatically rearrange Spaces based on most recent use” should be disabled for commands that rely on the ordering of spaces to work reliably.\nSystem Settings (macOS 14.x) In the Desktop & Dock tab, inside the Desktop & Stage Manager pane, the setting “Show Items On Desktop” should be enabled for display and space focus commands to work reliably in multi-display configurations.\nSystem Settings (macOS 14.x) In the Desktop & Dock tab, inside the Desktop & Stage Manager pane, the setting “Click wallpaper to reveal Desktop” should be set to “Only in Stage Manager” for display and space focus commands to work reliably.\n\nbrew install koekeishiya/formulae/yabai\n# start yabai\nyabai --start-service\nSample configuration files can be found in the ↗ examples directory. Refer to the ↗ documentation or the wiki for further information.\nKeyboard shortcuts can be defined with ↗ skhd or any other suitable software you may prefer. ## yabairc\n\n#!/usr/bin/env bash\nsudo yabai --load-sa\nyabai -m signal --add event=dock_did_restart action=\"sudo yabai --load-sa\"\nset -x\n\n# ====== Variables =============================\n\ndeclare -A gaps\ndeclare -A color\n\ngaps[\"top\"]=\"12\"\ngaps[\"bottom\"]=\"12\"\ngaps[\"left\"]=\"12\"\ngaps[\"right\"]=\"12\"\ngaps[\"inner\"]=\"12\"\n\ncolor[\"focused\"]=\"0xE0808080\"\ncolor[\"normal\"]=\"0x00010101\"\ncolor[\"preselect\"]=\"0xE02d74da\"\n\n\n# ===== Loading Scripting Additions ============\n\n# See: https://github.com/koekeishiya/yabai/wiki/Installing-yabai-(latest-release)#macos-big-sur---automatically-load-scripting-addition-on-startup\n# sudo yabai --load-sa\n# yabai -m signal --add event=dock_did_restart action=\"sudo yabai --load-sa\"\n\n# ===== Tiling setting =========================\n\nyabai -m config layout                      bsp\n\nyabai -m config top_padding                 \"${gaps[\"top\"]}\"\nyabai -m config bottom_padding              \"${gaps[\"bottom\"]}\"\nyabai -m config left_padding                \"${gaps[\"left\"]}\"\nyabai -m config right_padding               \"${gaps[\"right\"]}\"\nyabai -m config window_gap                  \"${gaps[\"inner\"]}\"\n\nyabai -m config mouse_follows_focus         on\nyabai -m config focus_follows_mouse         on\n\nyabai -m config window_topmost              off\nyabai -m config window_opacity              off\nyabai -m config window_shadow               float\n\nyabai -m config window_border               on\nyabai -m config window_border_width         2\nyabai -m config active_window_border_color  \"${color[\"focused\"]}\"\nyabai -m config normal_window_border_color  \"${color[\"normal\"]}\"\nyabai -m config insert_feedback_color       \"${color[\"preselect\"]}\"\n\nyabai -m config active_window_opacity       1.0\nyabai -m config normal_window_opacity       0.90\nyabai -m config split_ratio                 0.50\n\nyabai -m config auto_balance                on\n\nyabai -m config mouse_modifier              fn\nyabai -m config mouse_action1               move\nyabai -m config mouse_action2               resize\n\n\n\nset +x\nprintf \"yabai: configuration loaded...\\\\n\"\n\n\n2 skhd\n\n# experimental \n# # move window to display left and right\nshift + alt - s : yabai -m window --display west; yabai -m display --focus west;\nshift + alt - g : yabai -m window --display east; yabai -m display --focus east;\n# opens iTerm2\nalt - return : \"${HOME}\"/bin/open_iterm.sh\n\n\n# Navigation\nalt - h : yabai -m window --focus west\nalt - j : yabai -m window --focus south\nalt - k : yabai -m window --focus north\nalt - l : yabai -m window --focus east\n\n# Moving windows\nshift + alt - h : yabai -m window --warp west\nshift + alt - j : yabai -m window --warp south\nshift + alt - k : yabai -m window --warp north\nshift + alt - l : yabai -m window --warp east\n\n# Move focus container to workspace\nshift + alt - m : yabai -m window --space last; yabai -m space --focus last\nshift + alt - p : yabai -m window --space prev; yabai -m space --focus prev\nshift + alt - n : yabai -m window --space next; yabai -m space --focus next\nshift + alt - 1 : yabai -m window --space 1; yabai -m space --focus 1\nshift + alt - 2 : yabai -m window --space 2; yabai -m space --focus 2\nshift + alt - 3 : yabai -m window --space 3; yabai -m space --focus 3\nshift + alt - 4 : yabai -m window --space 4; yabai -m space --focus 4\n\n# Resize windows\nlctrl + alt - h : yabai -m window --resize left:-50:0; \\\n                  yabai -m window --resize right:-50:0\nlctrl + alt - j : yabai -m window --resize bottom:0:50; \\\n                  yabai -m window --resize top:0:50\nlctrl + alt - k : yabai -m window --resize top:0:-50; \\\n                  yabai -m window --resize bottom:0:-50\nlctrl + alt - l : yabai -m window --resize right:50:0; \\\n                  yabai -m window --resize left:50:0\n\n# Equalize size of windows\nlctrl + alt - e : yabai -m space --balance\n\n# Enable / Disable gaps in current workspace\nlctrl + alt - g : yabai -m space --toggle padding; yabai -m space --toggle gap\n\n# Rotate windows clockwise and anticlockwise\nalt - r         : yabai -m space --rotate 270\nshift + alt - r : yabai -m space --rotate 90\n\n# Rotate on X and Y Axis\nshift + alt - x : yabai -m space --mirror x-axis\nshift + alt - y : yabai -m space --mirror y-axis\n\n\n# Float / Unfloat window\nshift + alt - space : \\\n    yabai -m window --toggle float; \\\n    yabai -m window --toggle border\n\n# Restart Yabai\nshift + lctrl + alt - r : \\\n    /usr/bin/env osascript &lt;&lt;&lt; \\\n        \"display notification \\\"Restarting Yabai\\\" with title \\\"Yabai\\\"\"; \\\n    launchctl kickstart -k \"gui/${UID}/homebrew.mxcl.yabai\"\n\n# Make window native fullscreen\nalt - f         : yabai -m window --toggle zoom-fullscreen\nshift + alt - f : yabai -m window --toggle native-fullscreen\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Configure the Tiling Window Manager Yabai for Macos},\n  date = {2024-02-09},\n  url = {https://focusonr.org/posts/setup_yabai},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Configure the Tiling Window\nManager Yabai for Macos.” February 9, 2024. https://focusonr.org/posts/setup_yabai."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html",
    "href": "posts/server_setup_aws_console/index.html",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#select-a-hosting-service",
    "href": "posts/server_setup_aws_console/index.html#select-a-hosting-service",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "2.1 Select a hosting service",
    "text": "2.1 Select a hosting service\nThere are a number of cloud based server hosting options to choose from: for example Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean or Hetzner to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll provide a step-by-step description of a process using Amazon Web Services Elastic Compute Cloud (AWS EC2) infrastructure.\nAWS is, in our view, a reasonable choice for setting up a small custom server. Its not the cheapest option, but the system is well documented and, in our experience, reliable.\nThe first step is to get set up with AWS. To start, open the EC2 console by visiting the URL:\n   https://aws.amazon.com/console\n(see margin figure)\nIn the console window choose regional service. For us its “N. California”.\n\n\n\n\n\nAWS console\n\n\nNext create an account, or sign in. Once you’re logged in navigate to the EC2 dashboard. Its through this dashboard (aka console) that we’ll define the parameters for the type of server to launch and the mechanisms for communicating with it. We’ll refer to these as “Pre-Launch” tasks."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#overview",
    "href": "posts/server_setup_aws_console/index.html#overview",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nAlong with selecting a server we need to set up a working environment. We recommend setting up the working environment before launching the server, as it saves some back and forth with the console, but doing so is not required. The working environment consists of four main components:\n\nA security credential (RSA key-pair) to allow remote and secure login to the virtual server once its launched.\nA firewall, or security model, which restricts incoming server access. The purpose of the firewall is to close ofe all incoming packet traffic except through those ports specifically named.\nA static IP address, say 111.222.333.444. A static IP is required for maintaining the link between the domain name and the server when rebooting. (The default is for the instance/server to be assigned a new IP address each time its rebooted).\nA domain name, say rgtlab.org. A domain name is not required but will facilitate collaborator access by not requiring the use of the IP address directly.\n\nThese working environment components are not directly tied to any specific server. In fact, you can define multiple instances of each component. The only requirement is that you pick one of each to associate with each server."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#work-environment-details.",
    "href": "posts/server_setup_aws_console/index.html#work-environment-details.",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "3.2 Work Environment Details.",
    "text": "3.2 Work Environment Details.\n\n3.2.1 Ssh key pair\nIn order to securely communicate with the server we need to exchange an RSA key pair with AWS. The pair consists of a private key and a public key. We can define a key pair in one of two ways in EC2. Either, generate the pair locally, on our workstation and upload the public key to EC2, or have EC2 generate the key pair and download the private key. The EC2 based generation process will place the public key in the ~/.ssh/authorized_keys file on the server.\nFor the first option (local generation) we create a directory on our workstation to hold the keys and navigate to it, e.g. ~/.ssh. In the ~/.ssh directory generate the keys with the command\n&gt; ssh-keygen -m PEM\nPEM defines the key format. More information on public key authentication can be found (here). Also detailed instructions are available on AWS (here)\nIn the interactive dialog that follows name the key prefix something like power1_app.pem. The dialog will ask for a passphrase. You can enter a phrase for an additional level of security, but its not required. The ssh-keygen program will generate two files: power1_app.pem and power1_app.pem.pub\nTo complete the process return to the EC2 dashboard and select Network & Security/Keypair/Actions and then Import key pair in the left panel. Enter the name power1_app and select the Browse button. Navigate to the ~/.ssh/power1_app.pem.pub file and and select the Import key pair button at the bottom of the page.\nFor the second approach (EC2 generated) select Create key pair button in the upper right of the console page. A form will appears and ask for a name. Enter something like power1_app. Select RSA for key pair type and .pem for key file format. The keys will be created and the private key power1_app.pem will be offered for download to the local machine. We suggest placing it in the ~/.ssh directory. Lastly, change the permissions for the private key, so only you can access with the following command:\n&gt; sudo chmod 400 power1_app.pem\n\n\n3.2.2 Firewall\nTo create a firewall, click on Security groups under Network & Security settings in the left hand panel. Choose Create security group, and name the security group something like power1_app.\nUnder Inbound Rules select SSH and HTTPS from the Type dropdown menu. Select Anywhere IPv4 0.0.0.0/0 for both (??).\nThis will create a firewall that leaves open only ports 22 and 443, for ssh and https incoming traffic, respectively.\n\n\n3.2.3 Static IP address\nYou can use the EC2 elastic IP service to get a static IP. Navigate to Network and Security again and select Allocate Elastic IP. An IP will be assigned from the EC2 pool of available IPv4 IP addresses e.g. 13.57.139.31.\n\n\n3.2.4 Domain Name\nTo obtain a dedicated domain name, leave the EC2 dashboard and go to Amazon route 53 dashboard to select a domain name and associate it with our static IP (select Service at the top of the dashboard and search for Route 53).\nOnce a domain name is acquired, e.g. rgtlab.org, you can associate it with any IP address, static or dynamic. This can be done via the Route 53 service. For example, to associate domain name rgtlab.org with the elastic IP 111.2222.333.444 do the following in Route 53:\n\nclick on hosted zones in the side panel\nclick on rgtlab.org in center panel\nclick on checkbox for rgtlab.org type=A line\nthen click on edit record in right panel\nchange IP address to the assigned static 111.222.333.444 in “value”."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#access-server",
    "href": "posts/server_setup_aws_console/index.html#access-server",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "4.1 Access server",
    "text": "4.1 Access server\nOn your laptop log into server with\nssh -i \"~/.ssh/power1_app\" ubuntu@rgtlab.org"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html",
    "href": "posts/rct_validation_lang/index.html",
    "title": "RCT validation language",
    "section": "",
    "text": "1 Introduction\nConsider a simple programming language to capture the essence of clinical trial data base validation logic.\nSimilar in concept to Coffeescript (compiles to Lua) or Moonscript (compiles to Javascript).\nIdea is for trial design and initiation team to collaborate (say on gppgle docs) to develop the quality control validation logic and then translate that language into a series of snippets in Lua (using Lpeg)\nhttps://www.inf.puc-rio.br/~roberto/lpeg/\n\n1.0.1 consider matlab to R converter\nCRAN - Package matconv\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {RCT Validation Language},\n  date = {2024-02-11},\n  url = {https://focusonr.org/posts/rct_validation_lang},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “RCT Validation\nLanguage.” February 11, 2024. https://focusonr.org/posts/rct_validation_lang."
  },
  {
    "objectID": "posts/plots_from_purrr/index.html",
    "href": "posts/plots_from_purrr/index.html",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "",
    "text": "purrr\n\n\n\n1 Introduction\nConsider the problem of running a data analysis requiring a separate analysis for each of n strata. For example consider an effort to model the relationship between Bill length and Flipper length across three different species of penguins.\nWe can work with the dataset penguins included in the package palmerpenguins\nlibrary(palmerpenguins)\nOne naive approach is to split the dataset and do three separate analyses:\nThe R package purrr provides a straightforward method to conduct the analyses with a single command. Assume the set of data tables are contained in a list of dataframes. Also assume the analysis is a simple visualization of a potential linear association between two features,\n\n\n\n2 Plots for every variable and each species map inside map see ref 2 below\n\n\n3 combine plots in a upper triangular grid with correlation coefs\n\n\n4 Code\nlibrary(pacman)\np_load(grid, patchwork, rlang, purrr, palmerpenguins, tidyverse, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, fig.width = 8,\n  fig.height = 9, results = \"asis\", dev = \"pdf\"\n)\ndf0 &lt;- sample_n(penguins, 50) |&gt; na.omit()\n# nn = 50 ; df1 = sample_n(penguins, 50)\ndf1 &lt;- split(df0, df0$species)\n# df2 = penguins |&gt; group_by(species)\n\n\nct &lt;- names(df0)[3:6]\n# mm = expand.grid(names(df1[3:6]), names(df1[3:6]))\nnn &lt;- t(combn(ct, 2))\ncolnames(nn) &lt;- letters[1:2]\nnn2 &lt;- data.frame(nn) |&gt; cbind(g = \"sex\")\n\nzz.scatter &lt;- function(data, formula, ...) {\n  # function to take a dataframe, and a formula with potentially a '|' group\n  #     option and return scatterplot matrix with optional R^2, loess smooth,\n  #     or least squares line.\n}\n\nplt1 &lt;- function(a, b, g, spc, df_split) {\n  out_plot &lt;- df_split |&gt; ggplot(aes(x = .data[[a]], y = .data[[b]])) +\n    geom_point(aes(color = .data[[g]]), alpha = .5) +\n    geom_smooth() +\n    scale_color_manual(values = c(\"purple\", \"green\", \"red\")) +\n    theme_bw()\n  assign(paste0(spc, \"_\", a, \"_\", b), value = out_plot, envir = .GlobalEnv)\n  return(out_plot)\n}\n\n\ntemp &lt;- df1 |&gt; map2(names(df1), function(df_split, spc) {\n  nn2 |&gt; pmap(function(a, b, g) {\n    plt1(b, a, g, spc, df_split)\n  })\n})\n\ntemp2 = list_flatten(temp)\nX &lt;- grid::textGrob(\"Species 1\")\ntemp2[[2]] = plot_spacer()\ntemp2[[4]] = X\nwrap_plots(temp2, ncol=3, nrow=6) +\n  plot_layout(\n    guides = \"collect\",\n    axis_titles = \"collect\"\n  ) \nA &lt;- temp[[1]][[1]]\np2 &lt;- temp[[1]][[2]]\np3 &lt;- temp[[1]][[3]]\np4 &lt;- temp[[1]][[4]]\np5 &lt;- temp[[1]][[5]]\np6 &lt;- temp[[1]][[6]]\np7 &lt;- temp[[2]][[1]]\np8 &lt;- temp[[2]][[2]]\np9 &lt;- temp[[2]][[3]]\np10 &lt;- temp[[2]][[4]]\np11 &lt;- temp[[2]][[5]]\np12 &lt;- temp[[2]][[6]]\np13 &lt;- temp[[3]][[1]]\np14 &lt;- temp[[3]][[2]]\np15 &lt;- temp[[3]][[3]]\np16 &lt;- temp[[3]][[4]]\np17 &lt;- temp[[3]][[5]]\np18 &lt;- temp[[3]][[6]]\n# names(temp)\n\nlayout &lt;- \"\nX##\nABC\n#DE\n##F\nY##\nGHI\n#JK\n##L\nZ##\nMNO\n#PQ\n##R\n\"\nX &lt;- grid::textGrob(\"Species 1\")\nt2 &lt;- grid::textGrob(\"Species 2\")\nt3 &lt;- grid::textGrob(\"Species 3\")\n\nout &lt;- wrap_plots(\n  X , A, B = p2, C = p3, D = p4, E = p5, F = p6, Y = t2,\n  G = p7, H = p8, I = p9, J = p10, K = p11, L = p12, Z = t3,\n  M = p13, N = p14, O = p15, P = p16, Q = p17, R = p18,\n  design = layout\n) +\n  plot_layout(\n    guides = \"collect\",\n    axis_titles = \"collect\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.direction = \"horizontal\",\n    text = element_text(size = 8)\n  )\n\nout\n\n\n5 References\nprincipal components analysis\nAutomating exploratory plots with ggplot2 and purrr\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Working Example for Generating Multiple Plots Inside a Map2\n    Call},\n  date = {2024-02-23},\n  url = {https://focusonr.org/posts/plots_from_purrr},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Working Example for Generating\nMultiple Plots Inside a Map2 Call.” February 23, 2024. https://focusonr.org/posts/plots_from_purrr."
  },
  {
    "objectID": "posts/mimicsoftmood/index.html",
    "href": "posts/mimicsoftmood/index.html",
    "title": "Mimicing the softmood reddit post",
    "section": "",
    "text": "1 Introduction\n\n\n\n\n\nunder construction\n\n\nVery impressed with the reddit post of ykonstant\n[Cinnamon] Soft mood and latex workflow\nThis project is an attempt to mimic the various elements of the post, particularly the ultisnips portion.\nThe key elements to get started:\nThe list from the post:\n\nDE: Cinnamon\n\nTerminal emulator: iterm2 brew install iterm2\n\nWallpaper: Abstract geometry lofi coffee\n\n\n\n\n\n\nunder construction\n\n\n\nMusic mix credits: Loosen up your mind by Homework Radio\n\nRoot system animation: The Beauty of E8 by David Madore\n\nEye candy: cli-visualiser, cmatrix, neofetch, pipes.sh\n\nReference Management System: Zotero\n\nBrowser: qutebrowser with zotero connector\n\nVim Colorscheme: habiLight modified\n\nStatus Bar: airline with custom theme, adapted from gruvbox code.\n\nVim plugins: vimtex, ultisnips, vim-surround.\n\nbrew install neofetch\n\n\n\n\n\nunder construction\n\n\n\n\n2 Using qutebrowser\n\n\n3 Using Zotero\nstarts at 2:50 on video\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Mimicing the Softmood Reddit Post},\n  date = {2024-01-23},\n  url = {https://focusonr.org/posts/mimicsoftmood},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Mimicing the Softmood Reddit\nPost.” January 23, 2024. https://focusonr.org/posts/mimicsoftmood."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSimple process for sharing R code via Docker\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSimple process for sharing Rmarkdown code via Docker\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSimple process for sharing R code via Docker\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nA Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.\n\n\ngitlab, Docker-compose, EC2 version\n\n\n\nAWS\n\n\nDocker\n\n\nShiny\n\n\ndocker-compose\n\n\n\nThis is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online.” \n\n\n\n\n\nFeb 24, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up Quarto\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConstructing a medium complexity shiny app for power analysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up git for (solo) data science workflow\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nWorking example for generating multiple plots inside a map2 call\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConfigure the command line for data science development\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nMinimal EDC in Shiny\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the AWS command line interface to launch an EC2 server\n\n\n\n\n\n\nAWS\n\n\n\nBatch programs to setup a virtual server to host a Shiny app\n\n\n\n\n\nFeb 12, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nRCT validation language\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a minimal neovim environment for data science code development\n\n\nA neovim IDE for R, Python, and Julia\n\n\n\nNeovim\n\n\nVim\n\n\n\nThis is the first in a series of posts offering suggested strategies for setting up key tools for data science code development\n\n\n\n\n\nFeb 11, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nWriting a simple R package in S3.\n\n\n\n\n\n\nAWS\n\n\n\nGetting started with S3 OO programming in R\n\n\n\n\n\nFeb 10, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up R, vimtex and Ultisnips in vim on a Mac\n\n\n\n\n\n\nvim\n\n\nR\n\n\nTex\n\n\nUltisnips\n\n\n\nDetailed configuration for optimal interaction and efficiency\n\n\n\n\n\nFeb 10, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConfigure the tiling window manager yabai for macos\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nInstall Linux Mint on a Macbook Pro\n\n\nA set of tips for installation and post install\n\n\n\nMint\n\n\nR\n\n\nPython\n\n\nJulia\n\n\n\nstep by step description of howto install and customize a Mint instance for data science workflow\n\n\n\n\n\nFeb 1, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up OBS for webcasting\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nExtend Shiny power app to five tabs\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSet up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)\n\n\n\n\n\n\nAWS\n\n\n\nDetailed steps for setting up a lightweight server on AWS. \n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nA simple vim package for interfacing with a REPL\n\n\n\n\n\n\nR\n\n\nvim\n\n\n\nAn alternative to Nvim-R and vim-slime\n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nA simple process to get your Shiny app online (securely).\n\n\n\n\n\n\nDocker\n\n\nShiny\n\n\n\nThis is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online.\n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nMimicing the softmood reddit post\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\nNo matching items\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Blog},\n  url = {https://focusonr.org/posts},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. n.d. “Blog.” https://focusonr.org/posts."
  },
  {
    "objectID": "posts/dockerize_simple/index.html",
    "href": "posts/dockerize_simple/index.html",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#pre-launch-tasks",
    "href": "posts/dockerize_simple/index.html#pre-launch-tasks",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.1 Pre-launch tasks",
    "text": "3.1 Pre-launch tasks\nSelect a hosting service\nThere are a number of cloud based server options: Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean and Hetzner to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nAn overview of the process with AWS EC2 follows. (Detailed instructions for setting up a virtual server on EC2 both through the EC2 console and the command line interface were described in earlier posts: here and here.\nThe first step is to create an AWS account or sign in to an existing account and navigate to the EC2 dashboard.\nBefore launching the server instance itself we need to define a working environment within EC2. That is, we need to do the following:\n\ngenerate secure shell (ssh) key-pair\nconfigure a firewall.\nobtain a static IP.\nobtain a domain name.\n\nThe configuration has three components:\n\nselect an instance operating system (ubuntu) and\nselect an instance type (t2-micro)\ndetermine the size of the storage space.\n\nOnce the environment and configuration is set up we can launch the server.\nWhen the server is available we can connect via ssh.\nLastly associate the IP address with the domain name.\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nor using the config setup described in Tip 1 at the end of this post.\nssh rgtlab.org\nThe only software tools necessary to install are Docker and Caddy. If you followed the CLI or console based instructions to set up a virtual server here or here Docker and Caddy will be pre-installed.\nOtherwise you can install them with the following commands:\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\nAt this point we have a customized virtual server with a static IP address, unique domain name and a firewall in place. In other words, items 1, 2, 3, and 4 from our ‘hosting’ list above are taken care of."
  },
  {
    "objectID": "posts/dockerize_simple/index.html#post-launch-steps-on-local-workstation",
    "href": "posts/dockerize_simple/index.html#post-launch-steps-on-local-workstation",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.2 Post-Launch steps on local workstation",
    "text": "3.2 Post-Launch steps on local workstation\nTo run and host our Shiny app online we need to add a few configuration files to our power1_app development directory."
  },
  {
    "objectID": "posts/dockerize_simple/index.html#we-want-to-containerize-our-app.",
    "href": "posts/dockerize_simple/index.html#we-want-to-containerize-our-app.",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.3 We want to containerize our app.",
    "text": "3.3 We want to containerize our app.\nBy dockerizing the Shiny app we can assure that whenever its run all the required software and the right versions are ava\nThe first configuation file is:"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#docker",
    "href": "posts/dockerize_simple/index.html#docker",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.4 Docker",
    "text": "3.4 Docker\n\na Docker configuration file (default name Dockerfile)\n\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access R and Shiny. Here is our minimal dockerfile:\n\nDockerfile: Show the code\nFROM rocker/shiny:4.2.0\n# there are a bunch of files in /srv/shiny-server. delete them\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\n# rocker/shiny adds a user named shiny\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis file in just a few lines instructs Docker to build a new container based on a Rocker/Shiny image (which is a ubuntu image with R and Shiny installed) and layered with the addition of our Shiny code launch Shiny server listening on (default) port 3838.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquiring and installing of an SSL certificate. (An SSL cert is required by most browsers to use the encrypted communication protocol https.)\nTo configure the web server we need to add a Caddy configuration file (default name Caddyfile) to the power1_app directory.\nThe Caddy configuration file specifies three critical things.\n\nthe site domain name.\nthe authentication pair login/hash-password, for each user and\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) onto port 3838 (Shiny port) in the docker container.\n\nOur barebones Caddyfile looks like this:\n\nCaddyfile: Show the code\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, 6 and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nthe basicauth directive specifies login credentials for user bob (password: vanilla47)\nhandle_path maps all https requests to port 3838 where Shiny is listening.\nroot directive tells Caddy where to look for the index.html file.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generate an SSL certificate.\nLastly, we need an index.html file to provide a launch page for the app.\n\nindex.html: Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nOnce the config files, the index.html file and the Shiny code directory are in place copy we the entire power1_app directory to the server rgtlab.org with the secure copy command:\nscp -i \"~/.ssh/power1_app.pem\" -r ~/prj/power1_app/  ubuntu@rgtlab.org:~"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#post-launch-steps-on-remote-server",
    "href": "posts/dockerize_simple/index.html#post-launch-steps-on-remote-server",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.5 Post-Launch steps on remote server",
    "text": "3.5 Post-Launch steps on remote server\nUse ssh to login to the server and cd to power1_app directory\nBuild and run the Docker container (using the docker approach allows us to avoid installing both R and Shiny on the virtual server rgtlab.org).\ndocker build -t power1_image .\nrun container\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\nNext copy the Caddyfile to the location caddy expects to find it in the /etc/caddy directory\nsudo cp ./Caddyfile /etc/caddy/\ncopy index.html to location Caddy expects to find it in the /var/www/html directory\ncp  ./index.html /var/www/html/\nLastly, run the following command to restart Caddy\nsudo systemctl reload caddy\nThe App launch page will now be available at https://rgtlab.org.\nand you’re good to go!"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#tip-construct-ssh-config-file.",
    "href": "posts/dockerize_simple/index.html#tip-construct-ssh-config-file.",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.6 Tip construct ssh config file.",
    "text": "3.6 Tip construct ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nStrictHostKeyChecking no  #avoid known host file error message\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/config_term/index.html",
    "href": "posts/config_term/index.html",
    "title": "Configure the command line for data science development",
    "section": "",
    "text": "iterm2"
  },
  {
    "objectID": "posts/config_term/index.html#configzsh.zsh_aliases",
    "href": "posts/config_term/index.html#configzsh.zsh_aliases",
    "title": "Configure the command line for data science development",
    "section": "3.1 ~/.config/zsh/.zsh_aliases",
    "text": "3.1 ~/.config/zsh/.zsh_aliases\n\nalias mm='mutt'\nalias sk='open -a Skim'\nalias vc='vim ~/.vimrc'\nalias vz='vim ~/.zshrc'\nalias sz='source ~/.zshrc'\nalias p2='enscript -C -2 -r -j --media=Letter'\nalias p1='enscript  -j --media=Letter'\nalias yr=\"yabai --restart-service\"\nalias lt='eza -lrFha -sold'\nalias mvim=\"/Applications/MacVim.app/Contents/bin/mvim\"\nalias tp='trash-put -v'\nalias rm='echo \"This is not the command you are looking for.\"; false'\nalias s='scd'\nalias ZZ='exit'\nalias r=\"radian\"\nalias nt=\"nvim\"\nalias -g ...='../..'\nalias -g ....='../../..'\nalias -g .....='../../../..'\nalias -g ......='../../../../..'\n\nalias -- -='cd -'\nalias 1='cd -1'\nalias 2='cd -2'\nalias 3='cd -3'\nalias 4='cd -4'\nalias 5='cd -5'\nalias 6='cd -6'\nalias 7='cd -7'\nalias 8='cd -8'\nalias 9='cd -9'\n\nalias md='mkdir -p'\nalias rd=rmdir\n\n# List directory contents\nalias lsa='ls -lah'\nalias l='ls -lah'\nalias ll='ls -lh'\nalias la='ls -lAh'\n\n# search for directory and cd to it\nalias sd=\"cd ~ && cd \\$(find * -type d -not -path '*/Library/*' | fzf)\""
  },
  {
    "objectID": "posts/config_term/index.html#configzsh.zsh_exports",
    "href": "posts/config_term/index.html#configzsh.zsh_exports",
    "title": "Configure the command line for data science development",
    "section": "3.2 ~/.config/zsh/.zsh_exports",
    "text": "3.2 ~/.config/zsh/.zsh_exports\n\nexport EDITOR=\"vim\"\nexport TEXINPUTS='.:/Users/zenn/shr/images:/Users/zenn/shr:'\nexport PATH=\".:.local/bin:/opt/homebrew/sbin:/opt/homebrew/bin:$PATH:$HOME/bin\"\nexport vpc_id=\"vpc-14814b73\"\nexport subnet_id=\"subnet-f02c90ab\"\nexport ami_id=\"ami-014d05e6b24240371\"\nexport keypair_name=\"rebecca_app\"\nexport proj_name=\"rebecca_app\"\nexport instance_type=\"t2.micro\"\nexport storage_size=\"30\"\nexport ami_id=\"ami-014d05e6b24240371\"\nexport security_grp=\"sg-008cace70d32f6267\"\nexport static_ip='13.56.101.209'\n\nif type rg &&gt; /dev/null; then\n  export FZF_DEFAULT_COMMAND='rg --files --hidden --no-ignore-vcs'\n  export FZF_DEFAULT_OPTS='-m --height 50% --border'\nfi\n\nexport ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=\"fg=011,bg=black,bold,underline\"\nLS_COLORS+='pi=01;33:so=01;33:do=01;33:bd=01;33:cd=01;33:su=01;35:sg=01;35:ca=01;35:ex=01;32'\nexport LSCOLORS='ExGxDxDxCxDxDxFxFxexEx'"
  },
  {
    "objectID": "posts/config_term/index.html#configzsh.zsh_functions",
    "href": "posts/config_term/index.html#configzsh.zsh_functions",
    "title": "Configure the command line for data science development",
    "section": "3.3 ~/.config/zsh/.zsh_functions",
    "text": "3.3 ~/.config/zsh/.zsh_functions\n\nfunction d () {\n  if [[ -n $1 ]]; then\n    dirs \"$@\"\n  else\n    dirs -v | head -n 10\n  fi\n}\n\nmma () { /Applications/Mathematica.app/Contents/MacOS/WolframKernel -script $1 }\nfunction gz() {\n    git add .\n    git commit -a -m \"$1\"\n    git push\n}"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Thomas Lab",
    "section": "",
    "text": "twitter\n  \n  \n    \n     Github\n  \n\n      \nThe Thomas Lab in the the Herbert Wertheim School of Public Health and Human Longevity Science at UC San Diego focuses on developing data science methodology and educational materials."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas lab",
    "section": "",
    "text": "Director: Professor Ronald G. Thomas School of Public Health UC, San Diego La Jolla, California\nFocused on new and interesting data science technologies."
  },
  {
    "objectID": "posts/dockerize_compose/index.html",
    "href": "posts/dockerize_compose/index.html",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#hosting",
    "href": "posts/dockerize_compose/index.html#hosting",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 illustrates the tools we’ll use and the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with static IP address) from a domain registration provider.\nInstall and configure a webserver ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838 requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nThere are a number of cloud based server options we can choose from: Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts ( here ) and ( here ).\nStep 0. Create an account or sign in to the AWS EC2 dashboard.\nStep 1. Set up an working environment with AWS server. This entails:\n\ndefine an ssh key-pair.\nconfigure a firewall.\nobtain a static IP.\nobtain a domain name.\nselect an instance (AMI, type and disk size), generate and launch server.\n\nOnce the server is available, connect via ssh, and login,\nThe only software necessary to install is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\nOnce the host is set up and docker installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, with a unique domain name and firewall are in place."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker",
    "href": "posts/dockerize_compose/index.html#docker",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838. We placed the power1_app/app.R code in the default location /srv/shiny-server we only need to start the server and it will find the shiny program.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#caddy",
    "href": "posts/dockerize_compose/index.html#caddy",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.2 Caddy",
    "text": "3.2 Caddy\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. An SSL cert is required by most browsers to use the encrypted communication protocol https.\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generates an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker-compose",
    "href": "posts/dockerize_compose/index.html#docker-compose",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#landing-page",
    "href": "posts/dockerize_compose/index.html#landing-page",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html",
    "href": "posts/extend_shiny_app/index.html",
    "title": "Extend Shiny power app to five tabs",
    "section": "",
    "text": "Shiny"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#modules",
    "href": "posts/extend_shiny_app/index.html#modules",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.1 Modules",
    "text": "2.1 Modules"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#golem",
    "href": "posts/extend_shiny_app/index.html#golem",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.2 Golem",
    "text": "2.2 Golem"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#package",
    "href": "posts/extend_shiny_app/index.html#package",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.3 Package",
    "text": "2.3 Package"
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html",
    "href": "posts/install_mint_on_macbook/index.html",
    "title": "Install Linux Mint on a Macbook Pro",
    "section": "",
    "text": "1 Introduction\nTo get started we want to download the latest Linux Mint “iso” file and “burn” it onto a USB drive. One way to accomplish this is to use a “mac” laptop with macos installed. Wifi or ethernet internet connectivity is required, and at least one external port.\nNB: as of 1/4/24 not working are: * wifi broadband * audio * touch bar ## Install Mint on a macbook pro\nThe specific goal of this “DIY” project is to refurbish a seven year old macbook pro laptop with a modern linux operating system. The OS we’ll focus on for this post is Linux Mint 21.3. Why Mint? Well, as its been, “since the beginning” of the linux era (circa 1993) the main challenge to installing a linux distribution on almost any PC or mac is wrestling with the hardware drivers: notably video, audio, trackpad and power management drivers. The Mint distro provides a solution the drivers needed for our target macbook pro, making the install much, much more straightforward.\nThe target machine is a 2016 13-inch MacBook Pro with four Thunderbolt 3 Ports.\nTo start the process download an iso file from the Mint website. The current “Virginia” version of Mint iso file is 3.07 GB in size. The “Cinnamon” edition is recommended.\nOnce downloaded also download the associated sha256sum.txt file.\nTo check the integrity of your local ISO file, generate its SHA256 checksum and compare it to the content of the sha256sum.txt file:\n&gt; sha256sum -b linuxmint-21.3-cinnamon-64bit.iso\nWe can transfer the iso file to a USB flash drive using one of several methods. On macos we suggest using the app balanaEtcher. You can download balanaEtcher here\nInsert the bootable USB flash drive into the target macbook and reboot. Hold the ALT key while the machine reboots and you’ll be presented with a screen offering boot drive options. Select the icon for the USB drive. A grub menu will appear.\n\n\nGNU GRand Unified Bootloader (GRUB). “When your Linux operating system starts up, GRUB is the first program that runs. It loads the kernel of the operating system, and then the kernel loads the rest of the operating system, including the shell, the desktop environment, and other operating system features.”  codecademy.com \nFrom the Grub menu choose Start Linux Mint 21.2 Cinnamon 64-bit. and the Mint install program will start.\nA linux mint desktop will appear allowing you to “test drive” Mint or to continue the install by clicking the icon labeled “install Linux Mint”.\nA setup dialog will start. Select, in sequence\n\nLanguage (English for us),\nNetwork (suggest skip),\ncodexes (suggest skip),\noptions for a “fresh install” or “something else” (choose fresh to devote full hard drive to Mint).\nLocation (Pacific region for us),\nname a user who will have administrator privilidges, a hostname, and assign a password.\n\nThe install process will proceed. When complete connect the target machine to the Internet. If you have ethernet connectivity plug the cable directly into the target macbook and Mint should connect automatically to the internet. For wireless wifi access use a supported modem e.g. Panda Wireless modem. Panda is supported since Mint 21.2 has Ralink RT5372 drivers installed. (see appendix for Broadcom install instructions)\nThe final hardware related step is to add a second monitor, if available, via HDMI.\nThats it. Reboot and login with the admin username and password you provided earlier.\n\n\n2 Setup configuration\nAfter logging in for the first time start by configuring the displays, the keyboard, the touchpad and the backup software.\n\nOpen Display menu (press command key to open menu and search for “display”). Select Primary monitor with 2560x1440 as the resolution for both monitors. Set Monitor scale at 200% to increase default font size in apps. Second monitor should be set at 3840x2160 (200%)\nTurn on the pre-installed backup program, Timeshift, to provide hourly snapshots.\nSet keyboard and trackpad preferences:\n\nOpen Mouse and Touchpad in settings. Turn on Tap to click and Reverse scroll.\nOpen Keyboard &gt; Layouts &gt; Options &gt; Caps Lock behavior and select Swap Esc and Caps-Lock\n\nUpdate base pre-installed software.\n\n&gt; sudo apt update\n&gt; sudo apt upgrade\n\n\n3 Additional Software setup\n\nInstall basic utilities ssh, git, wget, curl, zsh, vim, as well as major applications tex, qutebrowser, firefox and zathura with one command:\n\nsudo apt install  ssh zsh  curl git texlive-full\n dropbox vim zathura  qutebrowser firefox\nr-base-core\n-y\n\nInstall Zotero and Dropbox. The easiest way to install Zotero and Dropbox is with the Mint Software    Manager aka Flatpak.\nInstall oh-my-zsh and oh-my-zsh plugins z and z-autosuggestions\n\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\ngit clone https://github.com/zsh-users/zsh-autosuggestions \\\n   ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\ngit clone https://github.com/agkozak/zsh-z \\\n   ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-z\nDon’t forget to edit .zshrc to include z and z-autosuggestions in the plugins list.\nRun bash shell script ~/Dropbox/dotfiles/set_up_links.sh to set up symbolic links (e.g. ln -s ~/Dropbox/prj ~/prj). See Appendix 1 below for details.\n\n\n4 Appendix 1. Script to set up links from local Home to Dropbox\nset_up_links.sh\n#!/bin/zsh\nff=(\".zshrc\" \".vimrc\" \".local\" \".vim\" \".config\")\nfor P in \"${ff[@]}\"\ndo\necho \"create  a link for Dropbox/dotfiles version of $P in Home\"\n    ln -v -s \"$HOME/Dropbox/dotfiles/$P\" \"$HOME/$P\"\ndone\n\ndd=(\"sbx\" \"bin\" \"docs\" \"prj\" \"work\" \"shr\")\nfor P in \"${dd[@]}\"\ndo\n    echo \"create  a link for Dropbox working directories  $P in Home\"\n    ln -v -s \"$HOME/Dropbox/$P\" \"$HOME/$P\"\ndone\n\n\n5 Appendix 2. Copy files to new Mint machine\nConnect to new machine via ssh from mac laptop\nFirst on the new machine (zz)\nzz&gt; sudo apt install ssh\nzz&gt; ifconfig\nget IP for target, say 10.0.1.196\nEither shell in to linux mint machine, or secure copy files over.\nmac&gt; ssh z@10.0.1.196\nmac&gt; scp .vimrc z@10.0.1.196:~\n\n\n6 Practice\nInstall docker and run R code from Docker Hub.\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Install {Linux} {Mint} on a {Macbook} {Pro}},\n  date = {2024-02-01},\n  url = {https://focusonr.org/posts/install_mint_on_macbook},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Install Linux Mint on a Macbook\nPro.” February 1, 2024. https://focusonr.org/posts/install_mint_on_macbook."
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html",
    "href": "posts/minimalist_edc_app/index.html",
    "title": "Minimal EDC in Shiny",
    "section": "",
    "text": "1 Introduction\nOne of the essential tools for the conduct of a randomized clinical trial (or any scientific experiment involving the collection of data) is the availability of a high quality electronic data capture (EDC) system.\nNumerous software systems have been developed over the past 30 plus years, both commercial and open-source, that provide a platform for scientific data capture e.g. the RedCap system Harris, Taylor, and Thielke (2009), or the Lorris system Das et al. (2011). These systems vary in design, and complexity and require different levels of professional support for development and maintenance. The system presented here is targeted at academic research groups without dedicated IT support staff, who typically require a customizable, easily managed, affordable and secure system.\nThe design goals for the system are as follows:\n\nAllow rapid project setup (Require minimum to no programming for setup and maintainance. i.e. must be able to be managed by teams without dedicated programming staff)\nBuilt with open-source tools\nRapid project close-out and data export\nIntegrated reporting\nCustomizable validation definition (via google sheets or similar collaboration software)\nAllow configurable access (user role setting)\nAuthentication\nAuditable\nCFR 21 Part 11 compliance capable.\n\nThe open-source tools employed for this system are:\n\nR\nshiny\nsqllite\nrmarkdown\n\nAlso, the system makes use of the propriatary but free to use tools from google:\n\ngoogle docs\ngoogle sheets\nConsider each of the above design goals in turn.\n\nRapid setup.\nICH guidelines compliant 1. Secure. EDC systems require flexible multilayer security. ideally at the part 11 level. This includes encryption and authentication as well as the use of secure servers.\n\n\n2 Methods\nStart in working directory /Users/zenn/prj/qblog/posts/minimalist_edc_app/working_from_c060_a201\nInterface looks like this:\n\n\n\n3 Results\n\n\n4 References\n\n\n5 Appendix\nArchive directories\n~/sandbox/edc47\n~/prj/c060/a32\n~/prj/c060/a201\n\n\n\n\n\nReferences\n\nDas, Samir, Alex P Zijdenbos, Jonathan Harlap, Dario Vins, and Alan C Evans. 2011. “LORIS: a web-based data management system for multi-center studies.” Frontiers in Neuroinformatics 5 (January): 37. https://doi.org/10.3389/fninf.2011.00037.\n\n\nHarris, PA, R Taylor, and R Thielke. 2009. “Research electronic data capture (REDCap)—a metadata-driven methodology and workflow process for providing translational research informatics support.” Journal of Biomedical …. http://www.sciencedirect.com/science/article/pii/S1532046408001226.\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Minimal {EDC} in {Shiny}},\n  date = {2024-02-22},\n  url = {https://focusonr.org/posts/minimalist_edc_app},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Minimal EDC in Shiny.”\nFebruary 22, 2024. https://focusonr.org/posts/minimalist_edc_app."
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#user-interface",
    "href": "posts/power_analysis_shiny_app/index.html#user-interface",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.1 User interface",
    "text": "2.1 User interface"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#parameters",
    "href": "posts/power_analysis_shiny_app/index.html#parameters",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.2 Parameters",
    "text": "2.2 Parameters"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#visualization",
    "href": "posts/power_analysis_shiny_app/index.html#visualization",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.3 Visualization",
    "text": "2.3 Visualization"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#reporting-formats",
    "href": "posts/power_analysis_shiny_app/index.html#reporting-formats",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.4 Reporting formats",
    "text": "2.4 Reporting formats"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#specifying-effect-size",
    "href": "posts/power_analysis_shiny_app/index.html#specifying-effect-size",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.5 Specifying effect size",
    "text": "2.5 Specifying effect size"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#itt-and-completers",
    "href": "posts/power_analysis_shiny_app/index.html#itt-and-completers",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.6 Itt and completers",
    "text": "2.6 Itt and completers"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#create-security-group-script",
    "href": "posts/server_setup_aws_cli/index.html#create-security-group-script",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.1 Create security group script",
    "text": "2.1 Create security group script\nGenerate security group: `\nExample:\n&gt; aws_create_security_group.sh -s $proj_name -g -k\nThis version of the script creates a security group with options to open ports: 22, 80, 3838, 443, 9000, and 9001 with flags -g, -i, -j, -k, -l, -m respectively.\nThe default, i.e. no flags set, is to open 22 and 443 only. the security group name is set as the base directory name.\n\n#!/usr/bin/env bash\nHelp()\n{\necho  The script generates a new security group\necho  the group name is given with the -n flag.\necho  ports are specificed with the -p flag. Any number of ports can be listed\necho  Anticipated incoming ports are 22 ssh, 80 http, 3838 shiny and 443 https.\necho  Script will fail if group name is already in use on EC2.\necho  reads vpc_id from the environment variables set in .zshrc\necho  example usage for ports 22, 80 and 443:\necho  aws_create_security_group.sh -n power1_app  -p 22 -p 80 -p 443\n}\nsg_grp_name=`basename $PWD`\nwhile getopts \":hp:n:\" opt; do\n    case $opt in\n        p ) ports+=(\"$OPTARG\") ;; # use the split+glob operator\n        n ) sg_grp_name=$OPTARG ;;\n        h ) Help\n            exit ;;\n        * ) echo 'error in command line parsing. Expect options n and p' &gt;&2\n            exit 1\n    esac\ndone\necho \"sg group name = $sg_grp_name\"\n\naws ec2 create-security-group \\\n    --group-name $sg_grp_name \\\n    --description \"security group\" \\\n    --tag-specifications \\\n    \"ResourceType=security-group,Tags=[{Key=Name,Value=$sg_grp_name}]\" \\\n    --vpc-id $vpc_id  &gt; temp.txt\nwait\nsecurity_grp=`jq -r .GroupId temp.txt`\nwait\necho \"security group ID = $security_grp\"\n\n for i in \"${ports[@]}\"\n do\n   aws ec2 authorize-security-group-ingress \\\n    --group-id $security_grp \\\n    --protocol tcp \\\n    --port ${i} \\\n    --cidr \"0.0.0.0/0\" &gt; /dev/null\n done"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#create-new-key-pair-with-a-project-name-flag",
    "href": "posts/server_setup_aws_cli/index.html#create-new-key-pair-with-a-project-name-flag",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.2 Create new key pair with a project name flag",
    "text": "2.2 Create new key pair with a project name flag\nExample usage: Note run with one parameter for optional keypair name.\n&gt; aws_create_keypair.sh -k $keypair_name\n\n#!/usr/bin/env bash\nHelp()\n{\necho  The script generates a new keypair\necho  the keypair name is given with the -k flag.\necho  Script will fail if pair name is already in use on EC2.\necho  aws_create_keypair.sh -k power1_app\n}\nwhile getopts 'hk:' flag; do\n  case \"${flag}\" in\n    h) Help\n      exit;;\n    k) key_pair_name=${OPTARG};;\n  esac\ndone\nbase=`basename $PWD`\nif [ -z \"$key_pair_name\" ]\nthen\n  key_pair_name=$base\nfi\necho \"key_pair_name is $key_pair_name\"\n\ncd ~/.ssh\nrm -f  ~/.ssh/$key_pair_name.pem\naws ec2 create-key-pair  --key-name  $key_pair_name \\\n   --query 'KeyMaterial' --output text &gt; ~/.ssh/$key_pair_name.pem\n\nwait\nchmod 400 ~/.ssh/$key_pair_name.pem"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#generate-instance",
    "href": "posts/server_setup_aws_cli/index.html#generate-instance",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.3 Generate instance",
    "text": "2.3 Generate instance\nstart up script. &gt; aws_create_instance.sh -p power1_app\n\n\n#!/usr/bin/env bash\nHelp()\n{\necho \"Notes on currect parameters:\"\necho \"security group should be in place already. check on EC2.  If not,\nrun ./awscli_create_security.sh.  \"\necho \"Key pair should be in place. check on EC2 and in ~/.ssh.\nIf not run ./create_keypair.sh. \"\necho \"ami id is for ubuntu linux 22.04 LTS.\nIf not what is desired check EC2 list of instances.\"\necho \"Check static IP: nslookup IPaddress.\nShould point to the domain name e.g.  rgtlab.org \"\necho  Usage: &gt;aws_create_instance.sh -p power1_app\necho \"\"\necho \"Review parameters: \"\necho \"---\"\necho \"proj_name is $proj_name\"\necho \"keypair_name is $keypair_name\"\necho \"vpc_id: $vpc_id\";\necho \"subnet_id: $subnet_id\";\necho \"ami_id: $ami_id\";\necho \"security_grp: $security_grp\";\necho \"static_ip: $static_ip\";\necho \"type: $type\";\necho \"size: $size\";\n}\nwhile getopts 'hp:' flag; do\n  case \"${flag}\" in\n    h) Help\n      exit;;\n    p) proj_name=${OPTARG};;\n  esac\ndone\nbase=`basename $PWD`\nif [ -z \"$proj_name\" ]\nthen\n  proj_name=$base\nfi\n\naws ec2 run-instances \\\n--image-id $ami_id \\\n--count 1 \\\n--instance-type $instance_type \\\n--key-name $keypair_name \\\n--security-group-ids $security_grp \\\n--subnet-id $subnet_id \\\n--block-device-mappings \"[{\\\"DeviceName\\\":\\\"/dev/sda1\\\",\\\"Ebs\\\":{\\\"VolumeSize\\\":$storage_size}}]\" \\\n--tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=$proj_name}]\"  \\\n--user-data file://~/Dropbox/prj/c060/aws_startup_code.sh\n iid0=`aws ec2 describe-instances --filters \"Name=tag:Name,Values=$proj_name\" | \\\n    jq -r '.Reservations[].Instances[].InstanceId'`\necho $iid0\nread -p \"enter instance id:\" iid\necho \"instance id: $iid\"\naws ec2 associate-address --public-ip $static_ip --instance-id $iid\naws_startup.sh\n\n#!/bin/bash\napt update\n# Add Docker and Docker Compose support to the Ubuntu's packages list\napt-get install curl -y\napt-get install gnupg -y\napt-get install ca-certificates -y\napt-get install lsb-release -y\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\necho \"deb [arch=\"$(dpkg --print-architecture)\" \\\nsigned-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n\"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\nsudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\napt-get update\napt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\nsu ubuntu -\nusermod -aG docker ubuntu\n\n\n\n\n\n\nTip 1.\n\n\n\nFor convenience, construct a config file in ~/.ssh as:\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen we can ssh into the new server with\nsh&gt; ssh rgtlab.org\n\n\nChange the access permissions: sudo chmod 600 power1ssh.pem to be more restrictive."
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#appendix-1",
    "href": "posts/server_setup_aws_cli/index.html#appendix-1",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.4 Appendix 1 Set up AWS IAM",
    "text": "2.4 Appendix 1 Set up AWS IAM\nThis appendix provides details on how to initiate batch processing via the AWS CLI desktop application. Start by launching the aws configure program.\nFrom aws web site:\n\n\n\n\n\nIAM description\n\n\nLog into the AWS console.\nSearch for IAM service. Navigate to IAM dashboard.\nSelect User groups. Create a user group based on the Power User profile.\nCall it admin. Include ryy_iam in the admin group.\nSelect Users in left hand panel.\nThen select Create User button (in upper right).\nThen enter a User name in the form, say zenn. Click Next (lower right)\nThen Create User.\nClick on the user name\nIn the page that comes up. Select Security Credentials tab (center of page).\nUnder Access Keys panel click Create access key (left side or bottom of panel).\nClick Command Line Interface CLI\nand at the bottom of the page click the checkbox “I understand…”.\nFinally select Create access key and\nchoose Download .csv file (lower right).\nNavigate Download screen to local ~/.aws directory.(may need shift-cmd-. on mac)\nClick Done\nNow in the terminal on your workstation, configure the aws cli app via the command.\n\n\n“AWS Identity and Access Management (IAM) is a web service that helps you securely control access to AWS resources.”\n&gt; aws configure\nUsing cut and paste enter info from the credentials file just downloaded. After entering the AWS Access Key ID and AWS Secret Access Key information you are asked for a Region, (my region is us-west-1), and an output format (suggested output format is JSON)."
  },
  {
    "objectID": "posts/setup_R_vimtex_ultisnips/index.html",
    "href": "posts/setup_R_vimtex_ultisnips/index.html",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "",
    "text": "vim setup"
  },
  {
    "objectID": "posts/setup_R_vimtex_ultisnips/index.html#yaml-header",
    "href": "posts/setup_R_vimtex_ultisnips/index.html#yaml-header",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "8.1 YAML header",
    "text": "8.1 YAML header\nThe RMD file contains a YAML metadata header delineated with the lines “—” above and below. For this example we want to generate a pdf formatted output file.\nThe YAML can be as simple as one line specifying the output as pdf.\n---\noutput: pdf_document\n---\nWhich results in a simple output file as follows:\nNB. to invoke file completion in vim for the rmd (or quarto) change the vim filetype using the command:\n:set filetype=tex\nthen enter, e.g., \\includegraphics{ or \\input{ followed by C-x C-o. and a pop-up menu with possible completions with appear.\n\n---\ntitle: \"Penguins data analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r Sys.Date()`\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\nheader-includes:\n    - \\usepackage{lipsum, fancyhdr, titling, currfile}\n    - \\usepackage[export]{adjustbox}\n    - \\pagestyle{fancy}\n    - \\pretitle{\n    - \\begin{flushright} \\includegraphics[width=3cm,valign=c]{sudoku.pdf}\n    - \\end{flushright}\n    - \\noindent\\rule{\\linewidth}{2pt}\\begin{flushleft}\\LARGE}\n    - \\posttitle{\\end{flushleft}\\noindent\\rule{\\linewidth}{2pt}}\n---"
  },
  {
    "objectID": "posts/setupgit/index.html",
    "href": "posts/setupgit/index.html",
    "title": "Setting up git for (solo) data science workflow",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/setupgit/index.html#invite-a-colleague-to-collaborate-on-a-github-repository",
    "href": "posts/setupgit/index.html#invite-a-colleague-to-collaborate-on-a-github-repository",
    "title": "Setting up git for (solo) data science workflow",
    "section": "2.1 Invite a colleague to collaborate on a github repository",
    "text": "2.1 Invite a colleague to collaborate on a github repository\nStart by logging into Github and navigating to the repository to be shared, say x24. Select settings (in top row of tabs) and then the collaborators tab (in the left panel)\nSelect green “add people” button, then “invite collaborator”, then “add rgt4748 to this repository”, in the center of the page.\nEnter the github user name (rgt4748) and select “Add rgt4748” t Now rgt4748 should login and accept invitation:\nclick “message” icon in upper right corner.\nSelect “Invitation to join rgt47/x23 from rgt47”, then “Accept Invitation” green button in center of page.\nThey’ll be taken to the rgt47/x24 repo.\nNow on their workstation they can clone repository with the following code:\n&gt; git clone https://github.com/rgt4748/x24.git\n&gt; cd x24\n&gt; git branch myedits\n&gt; git checkout myedits\n&gt; vim x24.Rmd\nmodify title: \"R2\" to title: \"changed R2\" and save edits.\n&gt; git add .\n&gt; git commit -m \"sample edit\"\n&gt; git push origin myedits #(?)\n&gt; git checkout master\n&gt; git merge myedits\n&gt; git branch -d myedits #(delete branch)\nClick contribute button, then open pull request, create pull request, enter title and description.\nlogin as rgt47. you’ll see one notification. check files changed"
  },
  {
    "objectID": "posts/setupobs/index.html",
    "href": "posts/setupobs/index.html",
    "title": "Setting up OBS for webcasting",
    "section": "",
    "text": "1 Introduction\nWebcasting for biostatistics is the challenge.\nLets take it one step at a time.\nStart with the open source project OBS.\nWelcome | OBS\nSteps to get started. Work with youtube video.\n(How to Use OBS Studio)[https://www.youtube.com/watch?v=-puA85ciDEM]\n\n\n2 Sections TBD\n\n\n3 Youtube channel\n\n\n4 Background blur\n\n\n5 Keycastr\n\n\n6 High contrast colorscheme\n\n\n7 hotkeys\n\n\n8 audio setup\n\n\n9 video setup\n\n\n10 format ?\n\n\n11 scenes\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up {OBS} for Webcasting},\n  date = {2024-01-24},\n  url = {https://focusonr.org/posts/setupobs},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up OBS for\nWebcasting.” January 24, 2024. https://focusonr.org/posts/setupobs."
  },
  {
    "objectID": "posts/share_R_code_via_docker/index.html",
    "href": "posts/share_R_code_via_docker/index.html",
    "title": "Simple process for sharing R code via Docker",
    "section": "",
    "text": "1 Introduction\nThings that can differ between team members the version of R, the operating system, packages, libraries, environment variables… !\nLets assume you have an R code program, say peng.R, that you’re written to analyze some data. You now want to share the code with a colleague, we’ll call him Joe. How to proceed?\nThe simplest option is simply to send Joe the “R” file containing the code via the most convenient method (e.g. email/text/slack/discord/github/USB drive etc.)\nThe next step will be for Joe to ( attempt to ) load and run the code. Typically he would do this either using the IDE Rstudio.app to open the file and knit it, or run it from the command line with the command:\n&gt; R -e \"source('fig.R)\"\nSometimes this approach works. Joe can add comments or expand the code and reply to you, and all is well. Frequently, however, this naive process will fail for any number of reasons. Even when it runs its not guaranteed that Joe will get the same results you did. Issues such as package versioning, the version of R, the compiler settings when R was compiled, .Rprofile settings can all impact results.\nIdeally to facilitate reproducibility Joe will have as similar a computing environment as you, the original developer. This can be difficult to achieve, especially given the dynamic nature of open source software. For example Joe may have an outdated version of R installed on his workstation, or his R environment may be missing a necessary package. Additiional potential problems include: the required package may be present but its the wrong version, the program may need to source an additional file thats missing, or the program load some data that it can’t find on Joe’s machine.\nAll of these problems go away if instead of sending the program as a standalone text file you send it as a docker image. In this post we’ll walk through the process of dockerizing the R code.\nAssume a simple Rmd file like this:\n\nzz.sum.max &lt;- function(x, extra = F) {\n  if (!is.numeric(x)) {\n    cat(\"Error: Numeric arrays required.\")\n    return(1)\n  }\n  x &lt;- x[!is.na(x)]\n  N &lt;- length(x)\n  options(digits = 4)\n  if (!N) {\n    return(c(0))\n  }\n  Mean &lt;- mean(x)\n  V &lt;- var(x)\n  SD &lt;- V^.5\n  SE &lt;- V^.5 / (N^.5)\n  Min &lt;- min(x)\n  Median &lt;- quantile(x, probs = c(.5), names = F)\n  Max &lt;- max(x)\n  errmin2 &lt;- Mean - 1.96 * SE\n  errmax2 &lt;- Mean + 1.96 * SE\n  errmin1 &lt;- Mean - SE\n  errmax1 &lt;- Mean + SE\n  if (extra) {\n    return(c(N = round(N), Mean = Mean, SE = SE, ERRMN1 = errmin1, ERRMX1 = errmax1, ERRMN2 = errmin2, ERRMX2 = errmax2, SD = SD, min = Min, max = Max))\n  } else {\n    return(c(N = round(N), Mean = Mean, Median = Median, SE = SE, SD = SD, min = Min, max = Max))\n  }\n}\n\ndat1 &lt;- read.csv(\"orth.csv\")\nout &lt;- zz.sum.max(dat1$age)\nprint(out)\n\n\n2 Share program code with Joe. Two approaches, Naive and Docker based.\nWhats the best way to accomplish this?\nWe start by simply emailing the file to him (rgthomas4747@gmail.com) and asking him to collaborate.\nJoe downloads the attachment. Opens a working directory and attempts to run the Rmd file\nwith the command\n&gt; R -e \"source('fig.R')\"\nJoe has a linux mint desktop\n&gt; mkdir fig_collaboration\n&gt; cd fig_collaboration\n&gt; R -e \"source('fig.R')\"\nLinux can’f find R\nJoe can fix this by installing R\n&gt; sudo apt install r-base-core\nNext R can not find the function render.\nJoe determines that render is a function in the package rmarkdown\nHe endeavors to installs rmarkdown with\n\nR -e \"install.packages('rmarkdown')\"\nThis fails due to inadequate permission on the directory /usr/lib/R/library\n\nsudo apt install libssl-dev libcurl4-openssl-dev unixodbc-dev libxml2-dev\\\nlibmariadb-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev\\\nlibfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\nAlso latex is not available\nOne more try… and the latex engine notes the absence of the file\n~/shr/preamble.tex\nSo, I need to relay the missing .tex file.\nAlso the .png (sudoku.png) logo file.\nFinally! success.\n\n\n3 Docker approach\nAlternatively, consider the “Docker” approach.\nBefore sending peng.Rmd to Joe we’ll dockerize it.\n\nPrepare a work directory: penguins. We want to send Joe a container that has R and all the preliminaries taken care of so that all he has to do is\n\nHere is the docker file\n\nFROM rhub/r-minimal\nENV MRAN_BUILD_DATE=2024-02-01 # Install Basic Utility R Packages\nRUN installr -r https://cran.microsoft.com/snapshot/${MRAN_BUILD_DATE} \\\n    --error  -d  -t \"zlib-dev\"  shiny\nRUN addgroup --system joe && adduser --system --ingroup joe joe\nRUN chown joe:joe -R /home/joe\nUSER joe\nWORKDIR /home/joe\nRUN mkdir -p /home/joe/shr\nRUN mkdir -p /home/joe/output\nCOPY fig.R /home/joe/shr\nCOPY orth.csv /home/joe/shr\nCMD [\"/bin/bash\"]\nrun docker\ndocker build -t rgt47/penguin_review --platform=linux/amd64 .\ndocker push rgt47/peng_review\nrelay image to Joe\ndocker push rgt47/peng_review\nor\ndocker save rgt47/peng_review | gzip &gt; peng_review_trans.tgz\ndocker load -i peng_review_trans.tgz\n&gt; docker pull rgt47/penguin_review\n\n&gt; droot=\"$PWD\"/output docker run -it --rm --platform linux/x86_64 \\\n-v $droot:/home/joe/output peng_review\n&gt; cd output\n&gt; library(rmarkdown); render('../shr/peng.Rmd')\nImportant to include the association between the /home/joe/output directory in the container with the output directory on the local workstation. Thats where the results of the analysis will be saved.\n&gt; R -e \"library(rmarkdown); render('peng.Rmd')\"\nand if he wants to edit peng.Rmd\n&gt; vim peng.Rmd\n\n\\usepackage[export]{adjustbox}\n\\usepackage{fancyhdr}\n\\usepackage{titling}\n\n\\pagestyle{fancy}\n\n\\pretitle{\n\\begin{flushright}\n\\includegraphics[width=3cm,valign=c]{sudoku.png}\\\\\n\\end{flushright}\n\\begin{flushleft} \\LARGE }\n\\posttitle{\\par\\end{flushleft}\\vskip 0.5em}\n\\predate{\\begin{flushleft}\\large}\n    \\postdate{\\par\\end{flushleft}}\n    \\preauthor{\\begin{flushleft}\\large}\n    \\postauthor{\\par\\end{flushleft}}\n\\fancyfoot[L]{\\currfilename} %put date in header\n\\fancyfoot[R]{\\includegraphics[width=.8cm]{sudoku.png}}\n\\fancyhead[L]{\\today} %put current file in footer\n\n\n4 REFERENCES\nRunning your R script in Docker\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Simple Process for Sharing {R} Code via {Docker}},\n  date = {2024-02-24},\n  url = {https://focusonr.org/posts/share_R_code_via_docker},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Simple Process for Sharing R\nCode via Docker.” February 24, 2024. https://focusonr.org/posts/share_R_code_via_docker."
  },
  {
    "objectID": "posts/share_shiny_code_via_docker/index.html",
    "href": "posts/share_shiny_code_via_docker/index.html",
    "title": "Simple process for sharing R code via Docker",
    "section": "",
    "text": "1 Introduction\nLets assume you have an rmarkdown Rmd file, say peng.Rmd, that you’re written to analyze some data. You now want to share the code with a colleague, we’ll call him Joe. How to proceed?\nThe simplest option is simply to send Joe the “rmd” file containing the code via the most convenient method (e.g. email/text/slack/discord/github/USB drive etc.)\nThe next step will be for the Joe to ( attempt to ) load and run the code. Typically he would do this with either using Rstudio.app to open the file and knit it, render it from the command line with the command:\n&gt; R -e \"render('peng.Rmd')\"\nSometimes this approach works, and all is well. Joe can add comments or expand the code and reply to you. Frequently, however, this naive process will fail for any number of reasons. Ideally to facilitate reproducibility Joe will have as similar a computing environment as you, the original developer. This can be difficult to achieve, especially given the dynamic nature of open source software. For example Joe may have an outdated version of R installed on his workstation, or his R environment may be missing a necessary package. Additiional potential problems include: the required package may be present but its the wrong version, the program may need to source an additional file thats missing, or the program load some data that it can’t find on Joe’s machine.\nAll of these problems go away if instead of sending the program as a standalone text file you send it as a docker image. In this post we’ll walk through the process of dockerizing the R code.\nAssume a simple Rmd file like this:\n\n---\ntitle: \"Penguins analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r format(Sys.time(), '%B %d, %Y')`\"\nfontsize: 11pt\ngeometry: \"left=3cm,right=5cm,top=2cm,bottom=2cm\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\n      in_header: \"preamble.tex\"\n---\n\n```{r include=F, echo=F}\nlibrary(pacman)\np_load(palmerpenguins, tidyverse, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, results = \"asis\", dev = \"pdf\"\n)\n```\n\n# Introduction\n\nWe can work with the dataset `penguins` included in the package `palmerpenguins`.\n```{r }\nlibrary(palmerpenguins)\n```\nOne naive approach is to split the dataset and do three separate\nanalyses:\n\n```{r }\ndf1 &lt;- split(penguins, penguins$species)\n\nfoo &lt;- function(df, z) {\n  df |&gt; ggplot(aes(x = bill_length_mm, y = flipper_length_mm)) +\n    geom_point(aes(color = island), alpha = .5) +\n    geom_smooth() +\n    scale_color_manual(values = c(\"purple\", \"green\", \"red\")) +\n    theme_bw() +\n    labs(\n      title = paste(z, \" Penguin Anatomy Comparison\"), x = \"Flipper length\",\n      y = \"Bill length\", color = \"Island\"\n    )\n  plotfile_name &lt;- paste0(z, \".pdf\")\n  ggsave(plotfile_name)\n  cat(paste0(\"\\\\includegraphics[height=3cm]{\", plotfile_name, \"}\"), \"\\n\")\n  cat(\"\\\\vspace{1cm}\", \"\\n\")\n}\n\nbar &lt;- df1 |&gt; map2(names(df1), foo)\n```\nThe Rmd file runs cleanly on our machine and generates the the report on the following page. However, we note that the third plot needs additional examination and want to relay the program to our colleague Joe for further analyis.\n\n\n\nrendered page\n\n\n\n\n2 Share program code with Joe. Two approaches, Naive and Docker based.\nWhats the best way to accomplish this?\nWe start by simply emailing the file to him (rgthomas4747@gmail.com) and asking him to collaborate.\nJoe downloads the attachment. Opens a working directory and attempts to run the Rmd file\nwith the command\n&gt; R -e \"render('peng.Rmd')\"\nJoe has a linux mint desktop\n&gt; mkdir peng_collaboration\n&gt; cd peng_collaboration\n&gt; R -e \"render('peng.Rmd')\"\nLinux can’f find R\nJoe can fix this by installing R\n&gt; sudo apt install r-base-core\nNext R can not find the function render.\nJoe determines that render is a function in the package rmarkdown\nHe endeavors to installs rmarkdown with\n\nR -e \"install.packages('rmarkdown')\"\nThis fails due to inadequate permission on the directory /usr/lib/R/library\n\nsudo apt install libssl-dev libcurl4-openssl-dev unixodbc-dev libxml2-dev\\\nlibmariadb-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev\\\nlibfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\nAlso latex is not available\nOne more try… and the latex engine notes the absence of the file\n~/shr/preamble.tex\nSo, I need to relay the missing .tex file.\nAlso the .png (sudoku.png) logo file.\nFinally! success.\n\n\n3 Docker approach\nAlternatively, consider the “Docker” approach.\nBefore sending peng.Rmd to Joe we’ll dockerize it.\n\nPrepare a work directory: penguins. We want to send Joe a container that has R and all the preliminaries taken care of so that all he has to do is\n\nHere is the docker file\n\nFROM rocker/verse:4\nRUN apt update\nRUN apt install vim -y\nRUN R -e \"install.packages('pacman')\"\nRUN R -e \"install.packages('palmerpenguins')\"\nRUN R -e \"install.packages('tidyverse')\"\nRUN R -e \"install.packages('knitr')\"\nRUN R -e \"install.packages('rmarkdown')\"\nRUN tlmgr init-usertree\nRUN tlmgr update --self --all\nRUN  tlmgr install  fancyhdr adjustbox geometry titling\n\nRUN addgroup --system joe && adduser --system --ingroup joe joe\nRUN chmod -R 0777 '/usr/local/lib/R/site-library'\nRUN chown joe:joe -R /home/joe\nUSER joe\nWORKDIR /home/joe\nRUN mkdir -p /home/joe/shr\nRUN mkdir -p /home/joe/output\nCOPY /preamble.tex /home/joe/shr\n# COPY /.Rprofile /home/joe/shr\nCOPY sudoku.png /home/joe/shr\nCOPY peng.Rmd /home/joe/shr\nCMD [\"/bin/bash\"]\nrun docker\ndocker build -t rgt47/penguin_review --platform=linux/amd64 .\ndocker push rgt47/peng_review\nrelay image to Joe\ndocker push rgt47/peng_review\nor\ndocker save rgt47/peng_review | gzip &gt; peng_review_trans.tgz\ndocker load -i peng_review_trans.tgz\n&gt; docker pull rgt47/penguin_review\n\n&gt; droot=\"$PWD\"/output docker run -it --rm --platform linux/x86_64 \\\n-v $droot:/home/joe/output peng_review\n&gt; cd output\n&gt; library(rmarkdown); render('../shr/peng.Rmd')\nImportant to include the association between the /home/joe/output directory in the container with the output directory on the local workstation. Thats where the results of the analysis will be saved.\n&gt; R -e \"library(rmarkdown); render('peng.Rmd')\"\nand if he wants to edit peng.Rmd\n&gt; vim peng.Rmd\n\n\\usepackage[export]{adjustbox}\n\\usepackage{fancyhdr}\n\\usepackage{titling}\n\n\\pagestyle{fancy}\n\n\\pretitle{\n\\begin{flushright}\n\\includegraphics[width=3cm,valign=c]{sudoku.png}\\\\\n\\end{flushright}\n\\begin{flushleft} \\LARGE }\n\\posttitle{\\par\\end{flushleft}\\vskip 0.5em}\n\\predate{\\begin{flushleft}\\large}\n    \\postdate{\\par\\end{flushleft}}\n    \\preauthor{\\begin{flushleft}\\large}\n    \\postauthor{\\par\\end{flushleft}}\n\\fancyfoot[L]{\\currfilename} %put date in header\n\\fancyfoot[R]{\\includegraphics[width=.8cm]{sudoku.png}}\n\\fancyhead[L]{\\today} %put current file in footer\n\n\n4 REFERENCES\nRunning your R script in Docker\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Simple Process for Sharing {R} Code via {Docker}},\n  date = {2024-02-24},\n  url = {https://focusonr.org/posts/share_shiny_code_via_docker},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Simple Process for Sharing R\nCode via Docker.” February 24, 2024. https://focusonr.org/posts/share_shiny_code_via_docker."
  },
  {
    "objectID": "posts/vim_R_package/index.html#notes",
    "href": "posts/vim_R_package/index.html#notes",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "1.1 Notes",
    "text": "1.1 Notes\n2023-08-03 17:37:04\n\ncan’t handle logical variables yet\ncategorical values should be indented\nadd option to change continuous summary to median IQR\nreview atable, furniture, and tableone for features.\nmaybe a “style” option for NEJM, JAMA, lancet"
  }
]