[
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html",
    "href": "posts/setupquarto/quarto-blog-template.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#introduction",
    "href": "posts/setupquarto/quarto-blog-template.html#introduction",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#required-packages-and-setup",
    "href": "posts/setupquarto/quarto-blog-template.html#required-packages-and-setup",
    "title": "Your Technical Blog Post Title",
    "section": "2 Required Packages and Setup",
    "text": "2 Required Packages and Setup\n\n# List the packages readers will need\nlibrary(tidyverse)\n# Add other packages\n\nBrief explanation of why these packages were chosen and any setup requirements."
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#the-problemdata",
    "href": "posts/setupquarto/quarto-blog-template.html#the-problemdata",
    "title": "Your Technical Blog Post Title",
    "section": "3 The Problem/Data",
    "text": "3 The Problem/Data\n\n# Data loading and initial preparation\n# Load sample dataset\ndata &lt;- mtcars\nglimpse(data)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\nDescribe your data source\nExplain the problem you’re addressing\nShare any initial data preparation steps"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#analysistutorial-steps",
    "href": "posts/setupquarto/quarto-blog-template.html#analysistutorial-steps",
    "title": "Your Technical Blog Post Title",
    "section": "4 Analysis/Tutorial Steps",
    "text": "4 Analysis/Tutorial Steps\n\n4.1 Step 1: Initial Data Exploration\n\n# Your analysis code here\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\nggplot(mtcars, aes(x=cyl, y=mpg)) +\n  geom_point()\n\n\n\n\nDescription of your visualization\n\n\n\n  # Your visualization\n\nExplain what you found and why it’s interesting.\n\n\n4.2 Step 2: Main Analysis\n\n# Core analysis code\n\nWalk through your analysis, explaining: - Why you chose this approach - What the code does - What the results mean\n\n\n4.3 Step 3: Results and Visualization\n\n# Create compelling visualizations\n\nInterpret your results and explain their significance."
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#key-takeaways",
    "href": "posts/setupquarto/quarto-blog-template.html#key-takeaways",
    "title": "Your Technical Blog Post Title",
    "section": "5 Key Takeaways",
    "text": "5 Key Takeaways\n\nBullet point summary of main findings\nPractical applications\nImportant insights"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#reproducibility",
    "href": "posts/setupquarto/quarto-blog-template.html#reproducibility",
    "title": "Your Technical Blog Post Title",
    "section": "6 Reproducibility",
    "text": "6 Reproducibility\n\n# Print session info for reproducibility\nsessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1      lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.0     tidyselect_1.2.1  \n [5] scales_1.4.0       yaml_2.3.10        fastmap_1.2.0      R6_2.6.1          \n [9] labeling_0.4.3     generics_0.1.4     knitr_1.50         htmlwidgets_1.6.4 \n[13] rprojroot_2.0.4    pillar_1.10.2      RColorBrewer_1.1-3 tzdb_0.5.0        \n[17] rlang_1.1.6        stringi_1.8.7      xfun_0.52          timechange_0.3.0  \n[21] cli_3.6.5          withr_3.0.2        magrittr_2.0.3     digest_0.6.37     \n[25] grid_4.5.0         hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5       \n[29] evaluate_1.0.3     glue_1.8.0         farver_2.1.2       rmarkdown_2.29    \n[33] tools_4.5.0        pkgconfig_2.0.3    htmltools_0.5.8.1"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#next-steps",
    "href": "posts/setupquarto/quarto-blog-template.html#next-steps",
    "title": "Your Technical Blog Post Title",
    "section": "7 Next Steps",
    "text": "7 Next Steps\n\nSuggest areas for further exploration\nMention potential improvements\nInvite reader engagement"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#references",
    "href": "posts/setupquarto/quarto-blog-template.html#references",
    "title": "Your Technical Blog Post Title",
    "section": "8 References",
    "text": "8 References\n\nCite your sources\nLink to relevant documentation\nCredit other contributors"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#hosting",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#hosting",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 illustrates the tools we’ll use and the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with static IP address) from a domain registration provider.\nInstall and configure a webserver ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838 requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#select-a-hosting-service",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nThere are a number of cloud based server options we can choose from: Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts ( here ) and ( here ).\nStep 0. Create an account or sign in to the AWS EC2 dashboard.\nStep 1. Set up an working environment with AWS server. This entails:\n\ndefine an ssh key-pair.\nconfigure a firewall.\nobtain a static IP.\nobtain a domain name.\nselect an instance (AMI, type and disk size), generate and launch server.\n\nOnce the server is available, connect via ssh, and login,\nThe only software necessary to install is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\nOnce the host is set up and docker installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, with a unique domain name and firewall are in place."
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838. We placed the power1_app/app.R code in the default location /srv/shiny-server we only need to start the server and it will find the shiny program.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#caddy",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#caddy",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.2 Caddy",
    "text": "3.2 Caddy\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. An SSL cert is required by most browsers to use the encrypted communication protocol https.\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generates an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker-compose",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker-compose",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#landing-page",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#landing-page",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-1.-docker-on-m1-macbook.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-2-add-user-to-docker-group-on-server.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-3-ssh-config-file.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/dockerize_simple/index.html",
    "href": "posts/dockerize_simple/index.html",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#introduction",
    "href": "posts/dockerize_simple/index.html#introduction",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis guide demonstrates how to deploy a Shiny application from your local workstation to a secure web environment. We’ll use a stack of open-source technologies including Linux, R, Shiny, Docker, and Caddy, deployed on AWS EC2. While we focus on AWS here, the principles apply to other cloud providers like Hetzner, which we’ll cover in future posts."
  },
  {
    "objectID": "posts/dockerize_simple/index.html#prerequisites",
    "href": "posts/dockerize_simple/index.html#prerequisites",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore beginning this tutorial, you’ll need:\n\nA working Shiny application on your local machine\nAn AWS account with permissions to create EC2 instances\nBasic familiarity with the Linux command line\nGit (optional, for version control)"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#the-example-application",
    "href": "posts/dockerize_simple/index.html#the-example-application",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "3 The Example Application",
    "text": "3 The Example Application\nLet’s start with a simple but practical example: hosting a shiny web application that provides a power calculator for two-sample t-tests. While straightforward, this application demonstrates all the key deployment concepts.\nHere is the code for the Shiny app (The app is intentionally minimal, using only base R functions, with a minimum of reactive widgets and layout commands.):\n\nPower Calculator Shiny App Code (power1_shiny/app.R)\nui &lt;- fluidPage(\n  titlePanel(\"Power Calculator for Two Group Parallel Designs\"),\n  sliderInput(\"N\", \"Total Sample Size:\", min = 0, max = 300, value = 100),\n  plotOutput(\"plot\"),\n  verbatimTextOutput(\"eff\"))\n\nserver &lt;- function(input, output, session) {\n  delta = seq(0, 1.5,.05)\n  pow = reactive(sapply(delta, function(x) power.t.test(input$N, d=x)$power ))\n  eff =  renderText(power.t.test(input$N, power=.8)$d)\n  output$plot &lt;- renderPlot({\n    plot(delta, pow(), cex=1.5, ylab=\"power\")\n    abline(h = .8,  col = \"red\", lwd =2.5, lty = 4)\n    abline(v = eff(), col = \"blue\",lwd =2.5, lty = 4)})\n  output$eff &lt;- renderText(\n    paste0(\"Std. effect detectable with power 80% = \", eff()) )\n}\nshinyApp(ui, server)\n\n\n\n\n\n\nShiny app interface"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#step-by-step-implementation",
    "href": "posts/dockerize_simple/index.html#step-by-step-implementation",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "4 Step-by-Step Implementation",
    "text": "4 Step-by-Step Implementation\n\n4.1 Deployment Checklist\nAs an overview, to host our Shiny app securely online, we need to:\n\nObtain a static IP address\nRegister a domain name\nConfigure a firewall\nSet up the virtual server\nInstall and configure a web server\nImplement SSL encryption\nSet up user authentication\nConfigure reverse proxy routing\n\nWhile this might seem complex, we’ll break it down into manageable steps.\nDetailed instructions for setting up a virtual server (items 1 through 4 above) on EC2 both through the EC2 console and the command line interface can be found: here and here\n\n\n4.2 Step 1: Server Setup\nFirst, we’ll prepare our AWS EC2 environment: In the course of setting up your server, you’ll need to: 1. Create or access your AWS account 2. Generate SSH key-pair, named for example, power1_app.pem 3. Configure firewall settings, allowing SSH (port 22), HTTP (port 80) traffic and HTTPS (port 443) traffic. 4. Obtain static IP, e.g., 13.57.139.31 5. Register domain name, e.g. rgtlab.org 6. Launch Ubuntu instance (t2-micro is sufficient)\n\n\n4.3 Step 2: Installing Required Software\nconnect to your server via SSH:\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nOn your server, install Docker and Caddy (a modern web server with automatic HTTPS) using the following commands.\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\n\n\n4.4 Step 3: Containerizing the Application\nCreate a Dockerfile in your app directory:\n\nDockerfile Configuration\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\n\n\n4.5 Step 4: Configuring the Web Server\nCreate a Caddyfile:\n\nCaddy Server Configuration\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nCreate an index.html:\n\nLanding Page HTML\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n4.6 Step 5: Deployment\n\nCopy files to server:\n\nscp -r ~/prj/power1_app/ ubuntu@rgtlab.org:~\n\nBuild and run Docker container:\n\ndocker build -t power1_image .\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\n\nConfigure Caddy:\n\nsudo cp ./Caddyfile /etc/caddy/\ncp ./index.html /var/www/html/\nsudo systemctl reload caddy\nYour app should now be available at https://rgtlab.org!"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#advanced-tips",
    "href": "posts/dockerize_simple/index.html#advanced-tips",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "5 Advanced Tips",
    "text": "5 Advanced Tips\nFor easier SSH access, create a ~/.ssh/config file:\nHost rgtlab.org\nHostName 13.57.139.31\nStrictHostKeyChecking no\nUser ubuntu\nPort 22\nIdentityFile ~/.ssh/power1_app.pem\nThis enables simple SSH access:\nssh rgtlab.org"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#key-takeaways",
    "href": "posts/dockerize_simple/index.html#key-takeaways",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "6 Key Takeaways",
    "text": "6 Key Takeaways\n\nDocker containers provide isolation and reproducibility for your Shiny applications\nCaddy web server automatically handles SSL certificates and security\nBasic authentication provides a simple access control mechanism\nAWS EC2 offers a reliable platform for hosting web applications\nThe entire deployment can be automated for continuous delivery workflows"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#further-reading",
    "href": "posts/dockerize_simple/index.html#further-reading",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "7 Further Reading",
    "text": "7 Further Reading\n\nShiny Server documentation\nDocker documentation\nCaddy Web Server documentation\nAWS EC2 documentation"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#step-by-step-implementation-1",
    "href": "posts/dockerize_simple/index.html#step-by-step-implementation-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "8 Step-by-Step Implementation",
    "text": "8 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#key-takeaways-1",
    "href": "posts/dockerize_simple/index.html#key-takeaways-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "9 Key Takeaways",
    "text": "9 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#further-reading-1",
    "href": "posts/dockerize_simple/index.html#further-reading-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "10 Further Reading",
    "text": "10 Further Reading\nIn development"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "A collection of technical articles, tutorials, and explorations covering R programming, data science methodologies, and research computing workflows.\n\n  2025\n\n\n  2024\n\n\n  2023\n\n\n  Earlier\n\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nDescription\n\n\nCategories\n\n\n\n\n\n\n \n\n\nDraft Posts\n\n\nWork-in-progress articles and posts under development\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nBest practices for parsing a formula in R programming\n\n\n\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nAdd python code as an ultisnip snippet\n\n\n\n\n\nultisnips, python\n\n\n\n\nJuly 1, 2025\n\n\nSimple process for sharing Rmarkdown code via Docker\n\n\n\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nSimple process for sharing R code via Docker\n\n\n\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nSetting up an R development environment on github\n\n\nStep by step guide to setting up an R development environment on github.\n\n\nR, Analysis, Tutorial\n\n\n\n\nJuly 1, 2025\n\n\nSetting up a minimal Quarto blog\n\n\nGetting started with technical blogging using Quarto is straightforward. This post will guide you through, step by step, the setting up a minimal Quarto blog. \n\n\nR, Analysis, Tutorial\n\n\n\n\nJuly 1, 2025\n\n\nSetting Up a Comprehensive Research Backup System on macOS\n\n\n\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nWriting a Simple R Package in S3\n\n\nGetting started with S3 object-oriented programming in R\n\n\nProgramming-Development, R\n\n\n\n\nJuly 1, 2025\n\n\nSetting up rrtools R Data Analysis Project Framework\n\n\nA comprehensive guide to creating reproducible R projects using the rrtools package framework for better collaboration and reproducibility\n\n\nProgramming-Development, R\n\n\n\n\nJuly 1, 2025\n\n\nSetting up Git for Solo Data Science Workflow\n\n\nA comprehensive guide to configuring Git for individual data science projects and research workflows\n\n\nDevelopment-Environment, Programming-Development\n\n\n\n\nJuly 1, 2025\n\n\nSetting Up a Vim Environment for Data Science Work\n\n\n\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nExtend Shiny power app to five tabs\n\n\n\n\n\n \n\n\n\n\nJuly 1, 2025\n\n\nResearch Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy\n\n\nThis white paper presents an approach to achieving reproducibility in R workflows by combining three tools: zzrrtools for creating structured research compendia, renv for R package management, and Docker for containerizing the computing environment. The zzrrtools framework provides a standardized research compendium structure, renv manages package dependencies, and Docker ensures consistent execution environments. Together, these tools create self-contained research compendia that run identically across different systems. The paper includes a practical case study demonstrating multi-developer collaborative workflows with clear governance roles, where a project maintainer manages the technical infrastructure while multiple contributors extend the research analysis. \n\n\n \n\n\n\n\nMay 23, 2025\n\n\nUpdate R package development process\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nA Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.\n\n\nThis is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online.” \n\n\nAWS, Docker, Shiny, docker-compose\n\n\n\n\nMay 13, 2025\n\n\nMaking optimal use of ChatGPT and other chatbots for data science\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\ncoding with genAI\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nConfigure the command line for data science development\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nSetting up a vim environment for R data science code development\n\n\nThis is another in a series of posts offering suggested strategies for setting up key tools for data science code development\n\n\nVim\n\n\n\n\nMay 13, 2025\n\n\nAdding Windows as a Second OS on Thinkpad\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nRCT validation language\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nMac Workflow for Tracking Daily Research Progress\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nSetting up OBS for webcasting\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nConfigure the tiling window manager yabai for macos\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nConverting R data.frames to pdf for better placement control in latex pdf report\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nUsing the AWS command line interface to launch an EC2 server\n\n\nBatch programs to setup a virtual server to host a Shiny app\n\n\nAWS\n\n\n\n\nMay 13, 2025\n\n\nSet up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)\n\n\nDetailed steps for setting up a lightweight server on AWS. \n\n\nAWS\n\n\n\n\nMay 13, 2025\n\n\nSetting up a neovim environment for data science code development\n\n\nThis is the first in a series of posts offering suggested strategies for setting up key tools for data science code development\n\n\nNeovim, Vim\n\n\n\n\nMay 13, 2025\n\n\nA simple vim package for interfacing with a REPL\n\n\nAn alternative to Nvim-R and vim-slime\n\n\nR, vim\n\n\n\n\nMay 13, 2025\n\n\nInstall Arch Linux on a Macbook Air\n\n\nstep by step description of howto install and customize an Arch instance for data science workflow\n\n\nMint, linux, R, Python, Julia\n\n\n\n\nMay 13, 2025\n\n\nWorking example for generating multiple plots inside a map2 call\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nMimicing the softmood reddit post\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nConstructing a medium complexity shiny app for power analysis\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nSetting up R, vimtex and Ultisnips in vim on a Mac\n\n\nDetailed configuration for optimal interaction and efficiency\n\n\nvim, R, Tex, Ultisnips\n\n\n\n\nMay 13, 2025\n\n\nA simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nInstall Linux Mint on a Macbook Air\n\n\nstep by step description of howto install and customize a Mint instance for data science workflow\n\n\nMint, linux, R, Python, Julia\n\n\n\n\nMay 13, 2025\n\n\nSet Names to Lowercase for Multiple Dataframes in R\n\n\n\n\n\nData Analysis & Visualization\n\n\n\n\nMay 13, 2025\n\n\nMinimal EDC in Shiny\n\n\n\n\n\n \n\n\n\n\nMay 13, 2025\n\n\nSecurely Deploying Your Shiny App Online: A Step-by-Step Guide\n\n\nA practical guide for data scientists on how to deploy R Shiny applications securely using open-source technologies.\n\n\nDeployment & Operations\n\n\n\n\nDecember 22, 2024\n\n\nYour Technical Blog Post Title\n\n\nA brief, engaging description of your post (appears in previews and social sharing). Keep it under 2-3 sentences. \n\n\nR, Analysis, Tutorial\n\n\n\n\nJuly 17, 2024\n\n\nInstall Arch Linux on a Macbook Air\n\n\nstep by step description of howto install and customize an Arch instance for data science workflow\n\n\nMint, linux, R, Python, Julia\n\n\n\n\nJuly 17, 2024\n\n\nA Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.\n\n\nThis is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online.” \n\n\nAWS, Docker, Shiny, docker-compose\n\n\n\n\n\nNo matching items\n\n\n  \n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Blog},\n  url = {https://focusonr.org/posts/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. n.d. “Blog.” https://focusonr.org/posts/."
  },
  {
    "objectID": "posts/plots_from_purrr/index.html",
    "href": "posts/plots_from_purrr/index.html",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/plots_from_purrr/index.html#prerequisites",
    "href": "posts/plots_from_purrr/index.html#prerequisites",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/plots_from_purrr/index.html#step-by-step-implementation",
    "href": "posts/plots_from_purrr/index.html#step-by-step-implementation",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "5.2 Step-by-Step Implementation",
    "text": "5.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/plots_from_purrr/index.html#key-takeaways",
    "href": "posts/plots_from_purrr/index.html#key-takeaways",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "5.3 Key Takeaways",
    "text": "5.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/plots_from_purrr/index.html#further-reading",
    "href": "posts/plots_from_purrr/index.html#further-reading",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "5.4 Further Reading",
    "text": "5.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#connect-to-target-machine-with-ssh",
    "href": "posts/install_arch_on_macbook/index.html#connect-to-target-machine-with-ssh",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "4.1 Connect to target machine with ssh",
    "text": "4.1 Connect to target machine with ssh\nconfigure WIFI\n\nbash&gt; iwctl\n\nidw&gt; device list (optional) (assume device is wlan0)\nidw&gt; station wlan0 scan (optional)\nidw&gt; station wlan0 connect rgtnet2\npassphrase for rgtnet2\nidw&gt; exit\n(assume the local IP address is 10.0.1.176)\nSet a password for root user. You’ll need it to log in.\nbash&gt; passwd\n  (enter `z` password)\nNew password: z\nRetype new password: z\n\nNow switch over to the mac.\n ssh  root@10.0.1.176"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#begin-install-process",
    "href": "posts/install_arch_on_macbook/index.html#begin-install-process",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "4.2 Begin install process",
    "text": "4.2 Begin install process\nFirst step:\n\npartition harddisk:\n\nbash&gt; cfdisk /dev/nvme0n1\nUse interface to create two partitions:\n\nEFI type of size 1gb\nroot of size entire rest of disk.\nwrite partition to disk\n\ncheck the partition:\n\nFormat the partitions.\n\nEFI disk is fat32\nRoot is ext4\n\n\n# run in three parts\n# part 1\nmkfs.fat -F32 /dev/nvme0n1p1\nmkfs.ext4 /dev/nvme0n1p2\nloadkeys mac-us\ntimedatectl set-ntp true\nmount /dev/nvme0n1p2 /mnt\nreflector -p https  --save /etc/pacman.d/mirrorlist --country US --latest 15\\\n    --sort rate \npacman -Sy\npacstrap /mnt base  linux linux-firmware sudo\ngenfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n\n# part 2\narch-chroot /mnt\n\n# part 3\nln -sf /usr/share/zoneinfo/America/Los\\_Angeles /etc/localtime\nsed -i.bak 's/#en_US\\.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen\nlocale-gen\necho zz &gt;&gt; /etc/hostname\necho LANG=en_US.UTF-8  &gt;&gt; locale.conf\npacman -S  --noconfirm networkmanager intel-ucode grub efibootmgr \\\n  docker xorg-server xf86-video-intel gnome cinnamon vim sudo openssh \\\n  zsh base-devel  pandoc r firefox git fzf ripgrep zathura\n\nsystemctl enable NetworkManager gdm sshd docker\nmkdir /boot/efi\nmount /dev/nvme0n1p1 /boot/efi\ngrub-install --target=x86_64-efi --bootloader-id=GRUB --efi-directory=/boot/efi\ngrub-mkconfig -o /boot/grub/grub.cfg\n\n# next items are interactive\n#### in sudoers uncomment # %wheel ALL=(ALL) ALL\n\nvim /etc/sudoers\nuseradd -m -G wheel -s /bin/bash z\npasswd z\n# password for root\npasswd\nexit\numount -l /mnt\nThats it. The base system is ready to go. Reboot and login with the admin username and password you provided earlier. To choose the Cinnamon desktop environment, select z as the user and then click on the selection wheel. The default desktop is Gnome, but an option to switch to Cinnamon is offered."
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#setup-yay",
    "href": "posts/install_arch_on_macbook/index.html#setup-yay",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "6.1 setup YAY",
    "text": "6.1 setup YAY\n sudo git clone https://aur.archlinux.org/yay-git.git  \n sudo chown -R z:z ./yay-git\n cd yay-git\n makepkg -si\n yay -Syu \n yay -S autojump\n yay -S zsh-autosuggestions-git\n yay -S zotero\nMake zsh the default shell.\n&gt; chsh -s $(which zsh)\nStart Dropbox to transfer working environment\nyay -S dropbox\ndropbox \n# builtin autostart from preferences 8/12/24\nDropbox startup process will launch a “Sign in” web page. Login with Dropbox credentials through web page.\nNext\nRun bash shell script ~/Dropbox/dotfiles/set_up_links.sh to set up symbolic links (e.g. ln -s ~/Dropbox/prj ~/prj). See Appendix 1 below for details.\nSet up the shell (zsh) per the post [link to set up terminal post]\nInstall zotero using software manager and set up syncing (login: rgthomas)\nadd vimium extension to firefox"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#prerequisites",
    "href": "posts/install_arch_on_macbook/index.html#prerequisites",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "8.1 Prerequisites",
    "text": "8.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#step-by-step-implementation",
    "href": "posts/install_arch_on_macbook/index.html#step-by-step-implementation",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "8.2 Step-by-Step Implementation",
    "text": "8.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#key-takeaways",
    "href": "posts/install_arch_on_macbook/index.html#key-takeaways",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "8.3 Key Takeaways",
    "text": "8.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#further-reading",
    "href": "posts/install_arch_on_macbook/index.html#further-reading",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "8.4 Further Reading",
    "text": "8.4 Further Reading\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html",
    "href": "tutorials/git-setup-guide/index.html",
    "title": "Setting up git for (solo) data science workflow",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#prerequisites",
    "href": "tutorials/git-setup-guide/index.html#prerequisites",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "href": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#key-takeaways",
    "href": "tutorials/git-setup-guide/index.html#key-takeaways",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#further-reading",
    "href": "tutorials/git-setup-guide/index.html#further-reading",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#title-add-the-normal-mode-mapping-zy-for-quarto-files.",
    "href": "posts/simple_vim_plugin/index.html#title-add-the-normal-mode-mapping-zy-for-quarto-files.",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "2.1 Title: Add the normal mode mapping ZY for quarto files.",
    "text": "2.1 Title: Add the normal mode mapping ZY for quarto files."
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#introduction-1",
    "href": "posts/simple_vim_plugin/index.html#introduction-1",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "2.2 Introduction:",
    "text": "2.2 Introduction:\nThe goal is to allow quarto filetypes to render to pdf using a mapping called from the qmd file.\n\nstart by constructing a mapping in .vimrc: (easier to develop there) map ZY to a shell escape and call to quarto_render. ( use ZT map in rgt-R.vim as a template).\ntest using any index.qmd file in posts. e.g. ~/config_ultisnips/index.qmd.\nonce the mapping works then move it to the plugin and add a autocommand that only adds the mapping for quarto filetype files.\nopen ~/prj/qblog/posts/vim_plugin_zz.tools.vim-R/rgt-R/plugin/rgt-R.vim\ncopy ZT mapping to ZY\nmodify ZY to render quarto files with render_quarto command."
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#prerequisites",
    "href": "posts/simple_vim_plugin/index.html#prerequisites",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#step-by-step-implementation",
    "href": "posts/simple_vim_plugin/index.html#step-by-step-implementation",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "3.2 Step-by-Step Implementation",
    "text": "3.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#key-takeaways",
    "href": "posts/simple_vim_plugin/index.html#key-takeaways",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "3.3 Key Takeaways",
    "text": "3.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#further-reading",
    "href": "posts/simple_vim_plugin/index.html#further-reading",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "3.4 Further Reading",
    "text": "3.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/share_rmd_code_via_docker/index.html#prerequisites",
    "href": "posts/share_rmd_code_via_docker/index.html#prerequisites",
    "title": "Simple process for sharing Rmarkdown code via Docker",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/share_rmd_code_via_docker/index.html#step-by-step-implementation",
    "href": "posts/share_rmd_code_via_docker/index.html#step-by-step-implementation",
    "title": "Simple process for sharing Rmarkdown code via Docker",
    "section": "5.2 Step-by-Step Implementation",
    "text": "5.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/share_rmd_code_via_docker/index.html#key-takeaways",
    "href": "posts/share_rmd_code_via_docker/index.html#key-takeaways",
    "title": "Simple process for sharing Rmarkdown code via Docker",
    "section": "5.3 Key Takeaways",
    "text": "5.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/share_rmd_code_via_docker/index.html#further-reading",
    "href": "posts/share_rmd_code_via_docker/index.html#further-reading",
    "title": "Simple process for sharing Rmarkdown code via Docker",
    "section": "5.4 Further Reading",
    "text": "5.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/setupgit/index.html",
    "href": "posts/setupgit/index.html",
    "title": "Setting up Git for Solo Data Science Workflow",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/setupgit/index.html#prerequisites",
    "href": "posts/setupgit/index.html#prerequisites",
    "title": "Setting up Git for Solo Data Science Workflow",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setupgit/index.html#step-by-step-implementation",
    "href": "posts/setupgit/index.html#step-by-step-implementation",
    "title": "Setting up Git for Solo Data Science Workflow",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setupgit/index.html#key-takeaways",
    "href": "posts/setupgit/index.html#key-takeaways",
    "title": "Setting up Git for Solo Data Science Workflow",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setupgit/index.html#further-reading",
    "href": "posts/setupgit/index.html#further-reading",
    "title": "Setting up Git for Solo Data Science Workflow",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#create-security-group-script",
    "href": "posts/server_setup_aws_cli/index.html#create-security-group-script",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.1 Create security group script",
    "text": "2.1 Create security group script\nGenerate security group: `\nExample:\n&gt; aws_create_security_group.sh -s $proj_name -g -k\nThis version of the script creates a security group with options to open ports: 22, 80, 3838, 443, 9000, and 9001 with flags -g, -i, -j, -k, -l, -m respectively.\nThe default, i.e. no flags set, is to open 22 and 443 only. the security group name is set as the base directory name.\n\n#!/usr/bin/env bash\nHelp()\n{\necho  The script generates a new security group\necho  the group name is given with the -n flag.\necho  ports are specificed with the -p flag. Any number of ports can be listed\necho  Anticipated incoming ports are 22 ssh, 80 http, 3838 shiny and 443 https.\necho  Script will fail if group name is already in use on EC2.\necho  reads vpc_id from the environment variables set in .zshrc\necho  example usage for ports 22, 80 and 443:\necho  aws_create_security_group.sh -n power1_app  -p 22 -p 80 -p 443\n}\nsg_grp_name=`basename $PWD`\nwhile getopts \":hp:n:\" opt; do\n    case $opt in\n        p ) ports+=(\"$OPTARG\") ;; # use the split+glob operator\n        n ) sg_grp_name=$OPTARG ;;\n        h ) Help\n            exit ;;\n        * ) echo 'error in command line parsing. Expect options n and p' &gt;&2\n            exit 1\n    esac\ndone\necho \"sg group name = $sg_grp_name\"\n\naws ec2 create-security-group \\\n    --group-name $sg_grp_name \\\n    --description \"security group\" \\\n    --tag-specifications \\\n    \"ResourceType=security-group,Tags=[{Key=Name,Value=$sg_grp_name}]\" \\\n    --vpc-id $vpc_id  &gt; temp.txt\nwait\nsecurity_grp=`jq -r .GroupId temp.txt`\nwait\necho \"security group ID = $security_grp\"\n\n for i in \"${ports[@]}\"\n do\n   aws ec2 authorize-security-group-ingress \\\n    --group-id $security_grp \\\n    --protocol tcp \\\n    --port ${i} \\\n    --cidr \"0.0.0.0/0\" &gt; /dev/null\n done"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#create-new-key-pair-with-a-project-name-flag",
    "href": "posts/server_setup_aws_cli/index.html#create-new-key-pair-with-a-project-name-flag",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.2 Create new key pair with a project name flag",
    "text": "2.2 Create new key pair with a project name flag\nExample usage: Note run with one parameter for optional keypair name.\n&gt; aws_create_keypair.sh -k $keypair_name\n\n#!/usr/bin/env bash\nHelp()\n{\necho  The script generates a new keypair\necho  the keypair name is given with the -k flag.\necho  Script will fail if pair name is already in use on EC2.\necho  aws_create_keypair.sh -k power1_app\n}\nwhile getopts 'hk:' flag; do\n  case \"${flag}\" in\n    h) Help\n      exit;;\n    k) key_pair_name=${OPTARG};;\n  esac\ndone\nbase=`basename $PWD`\nif [ -z \"$key_pair_name\" ]\nthen\n  key_pair_name=$base\nfi\necho \"key_pair_name is $key_pair_name\"\n\ncd ~/.ssh\nrm -f  ~/.ssh/$key_pair_name.pem\naws ec2 create-key-pair  --key-name  $key_pair_name \\\n   --query 'KeyMaterial' --output text &gt; ~/.ssh/$key_pair_name.pem\n\nwait\nchmod 400 ~/.ssh/$key_pair_name.pem"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#generate-instance",
    "href": "posts/server_setup_aws_cli/index.html#generate-instance",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.3 Generate instance",
    "text": "2.3 Generate instance\nstart up script. &gt; aws_create_instance.sh -p power1_app\n\n\n#!/usr/bin/env bash\nHelp()\n{\necho \"Notes on currect parameters:\"\necho \"security group should be in place already. check on EC2.  If not,\nrun ./awscli_create_security.sh.  \"\necho \"Key pair should be in place. check on EC2 and in ~/.ssh.\nIf not run ./create_keypair.sh. \"\necho \"ami id is for ubuntu linux 22.04 LTS.\nIf not what is desired check EC2 list of instances.\"\necho \"Check static IP: nslookup IPaddress.\nShould point to the domain name e.g.  rgtlab.org \"\necho  Usage: &gt;aws_create_instance.sh -p power1_app\necho \"\"\necho \"Review parameters: \"\necho \"---\"\necho \"proj_name is $proj_name\"\necho \"keypair_name is $keypair_name\"\necho \"vpc_id: $vpc_id\";\necho \"subnet_id: $subnet_id\";\necho \"ami_id: $ami_id\";\necho \"security_grp: $security_grp\";\necho \"static_ip: $static_ip\";\necho \"type: $type\";\necho \"size: $size\";\n}\nwhile getopts 'hp:' flag; do\n  case \"${flag}\" in\n    h) Help\n      exit;;\n    p) proj_name=${OPTARG};;\n  esac\ndone\nbase=`basename $PWD`\nif [ -z \"$proj_name\" ]\nthen\n  proj_name=$base\nfi\n\naws ec2 run-instances \\\n--image-id $ami_id \\\n--count 1 \\\n--instance-type $instance_type \\\n--key-name $keypair_name \\\n--security-group-ids $security_grp \\\n--subnet-id $subnet_id \\\n--block-device-mappings \"[{\\\"DeviceName\\\":\\\"/dev/sda1\\\",\\\"Ebs\\\":{\\\"VolumeSize\\\":$storage_size}}]\" \\\n--tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=$proj_name}]\"  \\\n--user-data file://~/Dropbox/prj/c060/aws_startup_code.sh\n iid0=`aws ec2 describe-instances --filters \"Name=tag:Name,Values=$proj_name\" | \\\n    jq -r '.Reservations[].Instances[].InstanceId'`\necho $iid0\nread -p \"enter instance id:\" iid\necho \"instance id: $iid\"\naws ec2 associate-address --public-ip $static_ip --instance-id $iid\naws_startup.sh\n\n#!/bin/bash\napt update\n# Add Docker and Docker Compose support to the Ubuntu's packages list\napt-get install curl -y\napt-get install gnupg -y\napt-get install ca-certificates -y\napt-get install lsb-release -y\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\necho \"deb [arch=\"$(dpkg --print-architecture)\" \\\nsigned-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n\"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\nsudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\napt-get update\napt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\nsu ubuntu -\nusermod -aG docker ubuntu\n\n\n\n\n\n\nTip 1.\n\n\n\nFor convenience, construct a config file in ~/.ssh as:\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen we can ssh into the new server with\nsh&gt; ssh rgtlab.org\n\n\nChange the access permissions: sudo chmod 600 power1ssh.pem to be more restrictive."
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#prerequisites",
    "href": "posts/server_setup_aws_cli/index.html#prerequisites",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#step-by-step-implementation",
    "href": "posts/server_setup_aws_cli/index.html#step-by-step-implementation",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "5.2 Step-by-Step Implementation",
    "text": "5.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#key-takeaways",
    "href": "posts/server_setup_aws_cli/index.html#key-takeaways",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "5.3 Key Takeaways",
    "text": "5.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#further-reading",
    "href": "posts/server_setup_aws_cli/index.html#further-reading",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "5.4 Further Reading",
    "text": "5.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html",
    "href": "posts/lowercasing_dataframes/index.html",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "",
    "text": "R"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#introduction",
    "href": "posts/lowercasing_dataframes/index.html#introduction",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "1 Introduction",
    "text": "1 Introduction\nFrequent task in R is to set names of dataframes to lowercase.\nAssume a data space with many objects. Several of which are data frames We want to idenify all the dataframes by surveying their classes and conver the column names to lowercase no matter what case format they currently have."
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#prerequisites",
    "href": "posts/lowercasing_dataframes/index.html#prerequisites",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nTo follow along with this tutorial, you’ll need:\n\nBasic knowledge of R programming\nR installed on your system\nThe purrr package for functional programming"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#step-by-step-implementation",
    "href": "posts/lowercasing_dataframes/index.html#step-by-step-implementation",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "3 Step-by-Step Implementation",
    "text": "3 Step-by-Step Implementation\n\n3.1 Setting up the Environment\nFirst, let’s load required packages and clean our environment:\nlibrary(purrr)\nrm(list = ls())\n\n\n3.2 Creating Test Data\nConstruct a few objects. Two of them dataframes:\naa = data.frame(COL_1 = letters[6:4], COL_2 = 1:3)\nbb = data.frame(COL_1 = letters[6:8], COL_2 = 1:3)\nbb = as_tibble(bb)\ncc = 1:10\ndd = letters[1:4]\n\n\n3.3 Finding and Converting Dataframes\nStart by creating a list of all the dataframes in the workspace:\n# test each object in environment to see if it is a dataframe.\n# keep a list of the data frames in df1\ndf0 = eapply(.GlobalEnv, \\(x) if (is.data.frame(x)) return(x) )\ndf1 &lt;- l1[!sapply(l1,is.null)]\n# process dataframes in df1 and lower the case of the names\ndf2 = lapply(df1, \\(x) {names(x) = tolower(names(x))\n  return(x) })\n # move the processed dataframes in df3 out to global env\nlist2env(df2, .GlobalEnv)\n\n\n3.4 Alternative Approach\nAn alternative method from How to get the list of available data frames in R environment?:\ndf1 = names(which(unlist(eapply(.GlobalEnv,is.data.frame))))"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#key-takeaways",
    "href": "posts/lowercasing_dataframes/index.html#key-takeaways",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "4 Key Takeaways",
    "text": "4 Key Takeaways\n\nUsing eapply() allows us to check all objects in the environment efficiently\nWe can filter for dataframes and process them in batch operations\nThe list2env() function is useful for updating global environment objects\nThis approach works even for objects with multiple classes (like tibbles)"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#additional-implementation-notes",
    "href": "posts/lowercasing_dataframes/index.html#additional-implementation-notes",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "5 Additional Implementation Notes",
    "text": "5 Additional Implementation Notes"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#further-reading",
    "href": "posts/lowercasing_dataframes/index.html#further-reading",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "6 Further Reading",
    "text": "6 Further Reading\n\nAdvanced R: Environments\npurrr documentation\nIn development"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#step-by-step-implementation-1",
    "href": "posts/lowercasing_dataframes/index.html#step-by-step-implementation-1",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "7 Step-by-Step Implementation",
    "text": "7 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#key-takeaways-1",
    "href": "posts/lowercasing_dataframes/index.html#key-takeaways-1",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "8 Key Takeaways",
    "text": "8 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/lowercasing_dataframes/index.html#further-reading-1",
    "href": "posts/lowercasing_dataframes/index.html#further-reading-1",
    "title": "Set Names to Lowercase for Multiple Dataframes in R",
    "section": "9 Further Reading",
    "text": "9 Further Reading\nIn development"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#connect-to-target-machine-with-ssh",
    "href": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#connect-to-target-machine-with-ssh",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "3.1 Connect to target machine with ssh",
    "text": "3.1 Connect to target machine with ssh\nconfigure WIFI\n\nbash&gt; iwctl\n\niwd&gt; device list (assume device is wlan0)\nidw&gt; station wlan0 scan\nidw&gt; station wlan0 connect rgtnet2\npassphrase for rgtnet2\nidw&gt; exit\nstart ssh and determine target machine IP address\n\n*  bash&gt; systemctl enable sshd\n*  bash&gt; systemctl start sshd\n*  bash&gt; ip route | grep default\n\n(assume the local IP address is 10.0.1.176)\nSet a password for root user. You’ll need it to log in.\nbash&gt; passwd\n  (enter `z` password)\nNew password: z\nRetype new password: z\n\nNow switch over to the mac\n* zsh&gt;   ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no root@10.0.1.176\n* ssh&gt; root@10.0.1.176's password: \n* z\n\nssh returns prompt on arch target machine\n\nroot@archiso ~ &gt;"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#begin-install-process",
    "href": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#begin-install-process",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "3.2 Begin install process",
    "text": "3.2 Begin install process\nFirst step:\n\npartition harddisk:\n\nbash&gt; cfdisk /dev/nvme0n1\nUse interface to create two partitions:\n\nEFI type of size 1gb\nroot of size entire rest of disk.\nwrite partition to disk\n\ncheck the partition:\n\nbash&gt; fdisk /dev/nvme0n1 -l\nFormat the partitions.\n\nEFI disk is fat32\nRoot is ext4\n\nbash&gt; mkfs.fat -F32 /dev/nvme0n1p1\nbash&gt; mkfs.ext4 /dev/nvme0n1p2\nset the keymap to mac us\n\nbash&gt; loadkeys mac-us\n\nSet system time and date\nbash&gt; timedatectl set-ntp true\n\n“The /mnt mount point in Linux is for mounting a storage device temporarily. As we only need to mount the partition for installing Arch Linux on it, the /mnt mount point is perfect.” The Arch Linux Handbook – Learn Arch Linux for Beginners\n\nbash&gt; mount /dev/nvme0n1p2 /mnt\nbash&gt; mount –mkdir /dev/efi_system_partition /mnt/boot\nFind best mirror:\n\nbash&gt; reflector –download-timeout 5 –country “United States” –age 12 –protocol https –sort rate –save /etc/pacman.d/mirrorlist\n\nbash&gt; pacstrap /mnt base base-devel linux linux-firmware sudo networkmanager\nbash&gt; genfstab -U /mnt &gt;&gt; /mnt/etc/fstab\nbash&gt; arch-chroot /mnt\nbash&gt; ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\nedit /etc/local.gen to set locale\nsearch for en_US and uncomment first row\nbash&gt; vim /etc/locale.gen\nbash&gt; locale.gen\nbash&gt; vim /etc/locale.conf\npacman -S networkmanager\nAvahi provides local hostname resolution using a “hostname.local” naming scheme. To enable it, install the nss-mdns package and start/enable avahi-daemon.service.\npacman -S nss-mdns\nsystemctl start avahi-daemon.service\nsystemctl enable NetworkManager (add root passwd)\npasswd\n\nuseradd -m -G wheel zenn\npasswd zenn\n\n4 for intel processors\npacman -S intel-ucode\n\npacman -S grub efibootmgr\n\nmkdir /boot/efi\nmount /dev/nvme0n1p1 /boot/efi\ngrub-install –target=x86_64-efi –bootloader-id=grub\ngrub-mkconfig -o /boot/grub/grub.cfg\n\npacman -S xorg-server\ncheck on what type of video card is in place on target\nlspci -v | grep -A1 -e VGA -e 3D\n\npacman -S xf86-video-intel\n\npacman -S gnome\n\npacman -S cinnamon\n\nsystemctl enable gdm\n\nexit\n\nroot@archiso ~ # umount -R /mnt\n\nPut the whole thing together for post disk partitioning …\nmkfs.fat -F32 /dev/nvme0n1p1\nmkfs.ext4 /dev/nvme0n1p2\nmount /dev/nvme0n1p2 /mnt\nreflector --download-timeout 5 --country \"United States\"  --age 12 --protocol https --sort rate --save /etc/pacman.d/mirrorlist\npacman -Sy\npacstrap /mnt base base-devel linux linux-firmware sudo networkmanager\ngenfstab -U /mnt &gt;&gt; /mnt/etc/fstab\narch-chroot /mnt\n\npasswd    \nuseradd -m -G wheel z\npasswd z\npacman -S vim\nvim /etc/sudoers\nuncomment # %wheel ALL=(ALL) ALL\nln -sf /usr/share/zoneinfo/America/Los\\_Angeles /etc/localtime\nvim /etc/locale.gen\n            uncomment en_US line\nlocale-gen\nvim /etc/locale.conf\n            LANG=en_US.UTF-8\nvim /etc/hostname\n            enter zz\npacman -S networkmanager\nsystemctl enable NetworkManager\npacman -S intel-ucode\npacman -S grub efibootmgr\nmkdir /boot/efi\nmount /dev/nvme0n1p1 /boot/efi\ngrub-install --target=x86_64-efi --bootloader-id=grub\ngrub-mkconfig -o /boot/grub/grub.cfg\npacman -S --noconfirm xorg-server\npacman -S --noconfirm xf86-video-intel\npacman -S --noconfirm gnome\npacman -S --noconfirm cinnamon\nsystemctl enable gdm\nexit\numount -R /mnt\n    \nThe final hardware related step is to add a second monitor, if available, via HDMI or “USB-C”.\nThats it. The base system is ready to go. Reboot and login with the admin username and password you provided earlier."
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "",
    "text": "Setting up a working repo can be time consuming and error-prone. This document presents a solution to this problem by providing a step-by-step guide to creating a reproducible R project using the rrtools package. The guide includes instructions for generating a project structure, creating a README file, And generating a Dockerfile for containerization. The goal is to provide a"
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#executive-summary",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#executive-summary",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "",
    "text": "Setting up a working repo can be time consuming and error-prone. This document presents a solution to this problem by providing a step-by-step guide to creating a reproducible R project using the rrtools package. The guide includes instructions for generating a project structure, creating a README file, And generating a Dockerfile for containerization. The goal is to provide a"
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#motivation",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#motivation",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "2 Motivation",
    "text": "2 Motivation\nImagine you’ve written code that you want to share with a colleague. At first glance, this may seem like a straightforward task—simply send the R files via email. However, ensuring that your colleague can run the code without errors and obtain the same results is often much more challenging than anticipated.\nWhen sharing R code, several potential problems can arise:\n\nDifferent versions of R installed on each machine\nMismatched R package versions\nMissing system dependencies (like pandoc or LaTeX)\nMissing supplemental files referenced by the program (bibliography files, LaTeX preambles, datasets, images)\nDifferent R startup configurations (.Rprofile or .Renviron)\n\nA real-world scenario often unfolds like this:\n\nYou email your R Markdown file to your colleague, Joe\nJoe attempts to run it with R -e \"source('peng1.Rmd')\"\nR isn’t installed on Joe’s system\nAfter installing R, Joe gets an error: “could not find function ‘render’”\nJoe installs the rmarkdown package\nNow pandoc is missing\nAfter installing pandoc, a required package is missing\nAfter installing the package, external files are missing (bibliography, images)\nAnd so on…"
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#conclusion",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#conclusion",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "3 Conclusion",
    "text": "3 Conclusion\nAchieving full reproducibility in R requires addressing both package dependencies and system-level consistency, while ensuring code quality through testing. By combining renv for R package management, Docker for environment containerization, and automated testing for code validation, data scientists and researchers can create truly portable, reproducible, and reliable workflows.\nThe comprehensive approach presented in this white paper ensures that the common frustration of “it works on my machine” becomes a thing of the past. Instead, R Markdown projects become easy to share and fully reproducible. A collaborator or reviewer can launch the Docker container and get identical results, without worrying about package versions or system setup.\nThe case study demonstrates how two developers can effectively collaborate on an analysis while maintaining reproducibility and code quality throughout the project lifecycle. By integrating testing into the workflow, the team can be confident that their analysis is not only reproducible but also correct.\nThis strategy represents a best practice for long-term reproducibility in R, meeting the high standards required for professional data science and research documentation. By adopting this comprehensive approach, the R community can make significant strides toward the goal of fully reproducible and reliable research and analysis."
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#references",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#references",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "4 References",
    "text": "4 References\n\nThomas, R.G. “Docker and renv strategy.”\n“Palmer Penguins Analysis.”\nThe Rocker Project. https://www.rocker-project.org/\nrenv documentation. https://rstudio.github.io/renv/\ntestthat documentation. https://testthat.r-lib.org/\nHorst, A.M., Hill, A.P., & Gorman, K.B. (2022). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R Journal."
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#prerequisites",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#prerequisites",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "5 Prerequisites",
    "text": "5 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#step-by-step-implementation",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#step-by-step-implementation",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "6 Step-by-Step Implementation",
    "text": "6 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#key-takeaways",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#key-takeaways",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "7 Key Takeaways",
    "text": "7 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#further-reading",
    "href": "posts/setup_or_modifyto_rrtools_analysis_repo_p33/index.html#further-reading",
    "title": "Setting up rrtools R Data Analysis Project Framework",
    "section": "8 Further Reading",
    "text": "8 Further Reading\nIn development\nSession Summary\nIn this session, we worked on refactoring a shell script to convert a generic R research project to follow the rrtools framework for reproducible research. Here’s what we accomplished:\nMain Achievements\n\nAnalyzed the existing adjust_to_rtools.sh script that was designed for an MCI analysis project\nRefactored the script to work with generic research repositories like x19\nEnhanced the script to align more closely with Ben Marwick’s rrtools framework\nAdded proper directory structure, documentation templates, and reproducibility features\n\nKey Script Developed\nThe main deliverable was a comprehensive shell script that: - Creates the standard rrtools directory structure - Organizes R functions, analysis scripts, and Rmd files - Sets up proper testing infrastructure - Creates documentation files (README, CONTRIBUTING, CONDUCT) - Configures Docker and Binder support - Establishes dependency management with renv - Creates symbolic links for easier navigation\nNotable Features\n\nBacks up the original project structure before making changes\nDetects package name from DESCRIPTION file\nIntelligently sorts existing files into appropriate directories\nCreates templates for R Markdown manuscripts using bookdown\nSets up Docker containers for reproducibility\nConfigures Binder for browser-based analysis\nAdds comprehensive documentation following rrtools standards\n\nThis refactored script provides a solid foundation for converting existing R research projects to follow best practices for reproducible research using the rrtools framework."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html",
    "href": "tutorials/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#learning-objectives",
    "href": "tutorials/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#prerequisites",
    "href": "tutorials/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "href": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "href": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-5-testing",
    "href": "tutorials/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "href": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#next-steps",
    "href": "tutorials/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#resources",
    "href": "tutorials/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "test_copy.html",
    "href": "test_copy.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "This is a test."
  },
  {
    "objectID": "test_copy.html#test",
    "href": "test_copy.html#test",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "This is a test."
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#current-courses",
    "href": "teaching/index.html#current-courses",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#workshops-and-training",
    "href": "teaching/index.html#workshops-and-training",
    "title": "Teaching",
    "section": "2 Workshops and Training",
    "text": "2 Workshops and Training\n\n2.1 Professional Development\n\nR package development workshops\nReproducible research training\nStatistical consulting methodology\nAcademic writing for statisticians\n\n\n\n2.2 Conference Presentations\n\nInvited talks on statistical methods\nSoftware demonstrations\nMethodology tutorials\nBest practices sessions"
  },
  {
    "objectID": "teaching/index.html#educational-resources",
    "href": "teaching/index.html#educational-resources",
    "title": "Teaching",
    "section": "3 Educational Resources",
    "text": "3 Educational Resources\n\n3.1 Course Materials\n\nLecture slides and notes\nLab exercises and solutions\nAssignment templates\nAssessment rubrics\n\n\n\n3.2 Open Educational Content\n\nOnline tutorials and guides\nVideo lectures and demonstrations\nInteractive learning materials\nStudent project examples\n\n\nThis section will feature detailed course descriptions, syllabi, teaching materials, and educational resources developed for statistics and data science instruction."
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "333 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\n\n\n\n\nNote\n\n\n\nFilter by Topic: Click any badge below to filter publications by research area.\nMedical/Clinical Military/Defense Neuroimaging/Technical COVID/Healthcare General Research\n\nClear All Filters\n\n\n\n\n\n\nGalasko, Douglas, Farlow, Martin R, Lucey, Brendan P, et al., “A multicenter, randomized, double-blind, placebo-controlled ascending dose study to evaluate the safety, tolerability, pharmacokinetics (PK) and pharmacodynamic (PD) effects of Posiphen in subjects with Early Alzheimer’s Disease”, Alzheimer’s Research & Therapy, (2024)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nMcEvoy, Cory, Crabtree, Adam, Case, John, et al., “Cumulative blast impulse is predictive for changes in chronic neurobehavioral symptoms following low level blast exposure during military training”, Military medicine, (2024)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kathleen F, Muzi, Mark, et al., “Increased [18F] Fluorodeoxyglucose Uptake in the Left Pallidum in Military Veterans with Blast-Related Mild Traumatic Brain Injury: Potential as an Imaging Biomarker and Mediation with Executive Dysfunction and Cognitive Impairment”, Journal of Neurotrauma, (2024)\nMedical/Clinical Traumatic brain injury Military health Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\n\n\n\nReiman, Eric M, Pruzin, Jeremy J, Rios-Romenets, Silvia, et al., “A public resource of baseline data from the Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nRaskind, Murray A, Williams, Tammy, Holmes, Hollie, et al., “A randomized controlled clinical trial of prazosin for alcohol use disorder in active duty soldiers: Predictive effects of elevated cardiovascular parameters”, Alcoholism: Clinical and Experimental Research, (2023)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kati, Muzi, Mark, et al., “FDG-PET as a Clinical Diagnostic Biomarker for Repetitive Blast Mild Traumatic Brain Injury”, NEUROPSYCHOPHARMACOLOGY, (2023)\nMilitary/Defense Traumatic brain injury Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Su, Yi, et al., “Impact of reference region on longitudinal florbetapir PET SUVR changes from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2023)\nNeuroimaging/Technical Neuroimaging\n\n🔗 Article\n\n\n\nKeil, Samantha A, Schindler, Abigail G, Wang, Marie X, et al., “Longitudinal Sleep Patterns and Cognitive Impairment in Older Adults”, JAMA Network Open, (2023)\nMedical/Clinical Sleep disorders\n\n🔗 Article\n\n\n\nMeabon, James S, Schindler, Abigail G, Murray, Daniel R, et al., “Pontine pathology mediates common symptoms of blast-induced chronic mild traumatic brain injury”, medRxiv, (2023)\nMilitary/Defense Traumatic brain injury\n\n🔗 Article\n\n\n\nQiu, Yuqi, Messer, Karen, Jacobs, Diane M, et al., “Prognostic value of plasma biomarkers in a clinical trial of mild-to-moderate Alzheimer’s Disease”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, McCall, Catherine A, Rosser, Aaron F, et al., “The relative contribution of COVID-19 infection versus COVID-19 related occupational stressors to insomnia in healthcare workers”, Sleep medicine: X, (2023)\nCOVID/Healthcare COVID-19 Sleep disorders\n\n🔗 Article\n\n\n\n\n\n\nJansson, Deidre, Wang, Marie, Thomas, Ronald G., et al., “Markers of Cerebrovascular Injury, Inflammation, and Plasma Lipids Are Associated with Alzheimer’s Disease Cerebrospinal Fluid Biomarkers in Cognitively Normal Persons”, Journal of Alzheimer’s Disease, (2022)\nMedical/Clinical Alzheimer’s disease Biomarkers\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, et al., “Sex differences in cognitive resilience in preclinical autosomal-dominant Alzheimer’s disease carriers and non-carriers: baseline findings from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2022)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nShadyab, Aladdin H, LaCroix, Andrea Z, Matthews, Genevieve, et al., “T2 Protect AD: Achieving a rapid recruitment timeline in a multisite clinical trial for individuals with mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2022)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Slevin, Rois', “The impact of the COVID-19 pandemic on mental health, occupational functioning, and professional retention among health care workers and first responders”, Journal of general internal medicine, (2022)\nCOVID/Healthcare COVID-19\n\n🔗 Article\n\n\n\n\n\n\nSalloway, Stephen, Farlow, Martin, McDade, Eric, et al., “A trial of gantenerumab or solanezumab in dominantly inherited Alzheimer’s disease”, Nature Medicine, (2021), doi: 10.1038/s41591-021-01369-8\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article • 📄 PDF\n\n\n\nBinette, Alexa Pichet, Vachon-Presseau, Etienne, Morris, John, et al., “Amyloid and tau pathology associations with personality traits, neuropsychiatric symptoms, and cognitive lifestyle in the preclinical phases of sporadic and autosomal dominant Alzheimer’s disease”, Biological psychiatry, (2021)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, et al., “Optimizing aggregated N-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Creating Evidence from Real World Patient Digital Data, (2021)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nHu, Nan, Mackey, Howard, Thomas, Ronald, “Power and sample size for random coefficient regression models in randomized experiments with monotone missing data”, Biometrical Journal, (2021)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nMatthews, Dawn C, Ritter, Aaron, Thomas, Ronald G, et al., “Rasagiline effects on glucose metabolism, cognition, and tau in Alzheimer’s dementia”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2021)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nShadyab, Aladdin, others, “Recruitment of a multi-site randomized controlled trial of aerobic exercise for older adults with amnestic mild cognitive impairment: the EXERT trial”, Alzheimer’s & Dementia, (2021)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Slevin, Rois', “The Impact of the COVID-19 Pandemic on Mental Health, Occupational Functioning, and Professional Retention Among Health Care Workers and First Responders”, Journal of general internal medicine, (2021)\nCOVID/Healthcare COVID-19\n\n🔗 Article\n\n\n\n\n\n\nRios-Romenets, Silvia, Lopera, Francisco, Sink, Kaycee M, et al., “Baseline demographic, clinical, and cognitive characteristics of the Alzheimer’s Prevention Initiative (API) Autosomal-Dominant Alzheimer’s Disease Colombia Trial”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, et al., “Development of a novel cognitive composite outcome to assess therapeutic effects of exercise in the EXERT trial for adults with MCI: The ADAS-Cog-Exec”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2020)\nMedical/Clinical\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, et al., “Optimizing aggregated n-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Frontiers in Digital Health, (2020)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Goradia, Dhruman D, et al., “PET evidence of preclinical cerebellar amyloid plaque deposition in autosomal dominant Alzheimer’s disease”, 2020 Alzheimer’s Association International Conference, (2020)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, et al., “Sex differences in neurodegeneration and memory performance in preclinical autosomal dominant Alzheimer’s disease: Baseline findings from the API ADAD trial: Intersections of sex/gender and race/ethnicity in cognitive aging and Alzheimer’s disease trajectories”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLangbaum, Jessica B, Ellison, Noel N, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative Composite Cognitive Test: a practical measure for tracking cognitive decline in preclinical Alzheimer’s disease”, Alzheimer’s Research & Therapy, (2020)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMatthews, Dawn, Ritter, Aaron, Thomas, Ronald G, et al., “The Effects of Rasagiline on Glucose Metabolism and Cognition and Their Relationship to Tau Burden in a Double-Blind, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia”, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia (2/21/2020), (2020)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nSano, Mary, Zhu, Carolyn W, Kaye, Jeffrey, et al., “A randomized clinical trial to evaluate home-based assessment of people over 75 years old”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Sink, Kaycee, et al., “F4-04-01: TRIAL DESIGN, DATA SHARING RISK MITIGATION, AND BASELINE CLINICAL AND COGNITIVE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nAcosta-Baena, Natalia, Rios-Romenets, Silvia, Munoz, Claudia, et al., “F4-04-02: AGE-RELATED CHANGES IN BASELINE COGNITIVE MEASURES IN UNIMPAIRED PSEN1 E280A MUTATION CARRIERS AND NON-CARRIERS IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSu, Yi, Rios-Romenets, Silvia, Tariot, Pierre N, et al., “F4-04-03: RELATIONSHIPS BETWEEN BASELINE BRAIN IMAGING BIOMARKER MEASUREMENTS AND AGE IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nQuiroz, Yakeel T, Tariot, Pierre N, Sink, Kaycee, et al., “F4-04-04: ASSOCIATION BETWEEN CEREBRAL AMYLOIDOSIS AND WORSE COGNITIVE PERFORMANCE IN PRECLINICAL AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE: BASELINE FINDINGS FROM THE API COLOMBIA AUTOSOMAL DOMINANT AD TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, Lon S, Geffen, Yona, Rabinowitz, Jonathan, et al., “Low-dose ladostigil for mild cognitive impairment: A phase 2 placebo-controlled clinical trial”, Neurology, (2019)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nHuisa, Branko N, Thomas, Ronald G, Jin, Shelia, et al., “Memantine and acetylcholinesterase inhibitor use in Alzheimer’s disease clinical trials: Potential for confounding by indication”, Journal of Alzheimer’s Disease, (2019)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKilian, Hett, Vinh-Thong, Ta, Gwenaelle, Catheline, et al., “Multimodal Hippocampal Subfield Grading For Alzheimer’s Disease Classification”, Scientific Reports (Nature Publisher Group), (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLiu, Jiao, Zhang, Binlong, Wilson, Georgia, et al., “New Perspective for Non-invasive Brain Stimulation Site Selection in Mild Cognitive Impairment: Based on Meta-and Functional Connectivity Analyses”, Frontiers in aging neuroscience, (2019)\nMedical/Clinical\n\n🔗 Article\n\n\n\nGupta, Yubraj, Lama, Ramesh Kumar, Kwon, Goo-Rak, et al., “Prediction and classification of Alzheimer’s disease based on combined features from apolipoprotein-E genotype, cerebrospinal fluid, MR, and FDG-PET imaging biomarkers”, Frontiers in computational neuroscience, (2019)\nMedical/Clinical Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nZhao, Qian, Liu, Min, Ha, Lingxia, et al., “Quantitative 18F-AV1451 brain tau PET imaging in cognitively normal older adults, mild cognitive impairment, and Alzheimer’s disease patients”, Frontiers in neurology, (2019)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, et al., “Safety and efficacy of edonerpic maleate for patients with mild to moderate Alzheimer disease: a phase 2 randomized clinical trial”, JAMA neurology, (2019)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBorowsky, Beth, Lopez, Cristina Lopez, Tariot, Pierre, et al., “The Alzheimer Prevention Initiative Generation Program: Evaluation of CNP520 in Preclinical Alzheimer’s Disease (P4. 1-005)”, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLopez, Cristina Lopez, Tariot, Pierre N, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative Generation Program: study design of two randomized controlled trials for individuals at risk for clinical onset of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2019)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nKlinger, Rebecca Y, James, Olga G, Borges-Neto, Salvador, et al., “18F-florbetapir Positron Emission Tomography–determined Cerebral beta-Amyloid Deposition and Neurocognitive Performance after Cardiac Surgery”, Anesthesiology, (2018)\nMedical/Clinical\n\n🔗 Article\n\n\n\nRafii, Michael S, Tuszynski, Mark H, Thomas, Ronald G, et al., “Adeno-associated viral vector (serotype 2)–nerve growth factor for patients with alzheimer disease: a randomized clinical trial”, JAMA neurology, (2018)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHuisa, Branko, Thomas, Ronald, Jin, Shelia, et al., “Memantine and Cholinesterase Inhibitor Use in Alzheimer Disease Trials: Potential for Confounding by Indication (P6. 178)”, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, et al., “P3-032: SCREENING-TO-BASELINE COGNITIVE VARIABILITY DOES NOT PREDICT RATE OF DECLINE IN A CLINICAL TRIAL OF MILD-TO-MODERATE AD”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nReiman, Eric M, Sink, Kaycee M, Hu, Nan, et al., “P4-209: A PUBLIC RESOURCE OF BASELINE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nVerfaillie, Sander CJ, Binette, Alexa Pichet, Vachon-Presseau, Etienne, et al., “Subjective cognitive decline is associated with altered default mode network connectivity in individuals with a family history of Alzheimer’s disease”, Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Langbaum, Jessica B, et al., “The Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial: A study of crenezumab versus placebo in preclinical PSEN1 E280A mutation carriers to evaluate efficacy and safety in the treatment of autosomal-dominant Alzheimer’s disease, including a placebo-treated noncarrier cohort”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nRelkin, Norman R, Thomas, Ronald G, Rissman, Robert A, et al., “A phase 3 trial of IV immunoglobulin for Alzheimer disease”, Neurology, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLim, Yen Ying, Mormino, Elizabeth C, Alzheimer’s Disease Neuroimaging Initiative, et al., “APOE genotype and early beta-amyloid accumulation in older adults without dementia”, Neurology, (2017)\nMedical/Clinical\n\n🔗 Article\n\n\n\nRusso, Mar', “Adding recognition discriminability index to the delayed recall is useful to predict conversion from mild cognitive impairment to Alzheimer’s disease in the Alzheimer’s disease neuroimaging initiative”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nRisacher, Shannon L, Anderson, Wesley H, Charil, Arnaud, et al., “Alzheimer disease brain atrophy subtypes are associated with cognition and rate of decline”, Neurology, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMunilla, Jorge, Ortiz, Andres, Gorriz, Juan M, et al., “Construction and analysis of weighted brain networks from sice for the study of Alzheimer’s disease”, Frontiers in neuroinformatics, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGuo, Shengwen, Lai, Chunren, Wu, Congling, et al., “Conversion discriminative analysis on mild cognitive impairment using multiple cortical features from MR images”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Aisen, Paul S, et al., “Randomized controlled trials in mild cognitive impairment: sources of variability”, Neurology, (2017)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nPark, Jong-Yun, Na, Han Kyu, Kim, Sungsoo, et al., “Robust identification of Alzheimer’s disease subtypes based on cortical atrophy patterns”, Scientific reports, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre, Lopez-Lopez, Cristina, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative (API) Generation Program: Evaluating the Efficacy of the BACE-1 Inhibitor CNP520 in Preclinical Alzheimer’s Disease”, NEUROPSYCHOPHARMACOLOGY, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLopez, C Lopez, Caputo, A, Liu, F, et al., “The Alzheimer’s Prevention Initiative Generation Program: evaluating CNP520 efficacy in the prevention of Alzheimer’s disease”, J Prev Alzheimers Dis, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nCaputo, Angelika, Racine, Amy, Paule, Ines, et al., “[O5–01–02]: RATIONALE FOR SELECTION OF PRIMARY ENDPOINTS IN THE ALZHEIMER PREVENTION INITIATIVE GENERATION STUDY IN COGNITIVELY HEALTHY APOE4 HOMOZYGOTES”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, et al., “[P4–573]: A PHASE 2 MULTICENTER, RANDOMIZED, PLACEBO-CONTROLLED TRIAL TO EVALUATE THE EFFICACY AND SAFETY OF EDONERPIC (T-817) IN PATIENTS WITH MILD TO MODERATE ALZHEIMER’s DISEASE”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nLiu, Haochen, Zhou, Xiaoting, Jiang, Hao, et al., “A semi-mechanism approach based on MRI and proteomics for prediction of conversion from mild cognitive impairment to Alzheimer’s disease”, Scientific reports, (2016)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nGelmont, David, Thomas, Ronald G, Britt, Jonathan, et al., “Demonstration of safety of intravenous immunoglobulin in geriatric patients in a long-term, placebo-controlled study of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2016)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDeming, Yuetiva, Xia, Jian, Cai, Yefei, et al., “Genetic studies of plasma analytes identify novel potential biomarkers for several complex traits”, Scientific Reports, (2016)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nThomas, Ronald G, Albert, Marilyn, Petersen, Ronald C, et al., “Longitudinal decline in mild-to-moderate Alzheimer’s disease: analyses of placebo data from clinical trials”, Alzheimer’s & Dementia, (2016)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre, Langbaum, Jessica, Schneider, Lon, et al., “The Alzheimer’s Prevention Initiative Generation Study: A Preclinical Trial in APOE4 Homozygotes”, NEUROPSYCHOPHARMACOLOGY, (2016)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nTurner, R Scott, Thomas, Ronald G, Craft, Suzanne, et al., “A randomized, double-blind, placebo-controlled trial of resveratrol for Alzheimer disease”, Neurology, (2015)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nChen, Chi-Hua, Peng, Qian, Schork, Andrew J, et al., “Large-scale genomics unveil polygenic architecture of human cortical surface area”, Nature communications, (2015)\nGeneral Research\n\n🔗 Article\n\n\n\nDonohue, Michael C, Moghadam, Setareh H, Roe, Allyson D, et al., “Longitudinal plasma amyloid beta in Alzheimer’s disease clinical trials”, Alzheimer’s & Dementia, (2015)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Raman, Rema, Sperling, Reisa A, et al., “Peripheral and central effects of \\\\gamma-secretase inhibition by semagacestat in Alzheimer’s disease”, Alzheimer’s research & therapy, (2015)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTurner, R, Thomas, Ronald, Craft, Suzanne, et al., “Resveratrol is safe and well-tolerated in individuals with mild-moderate dementia due to Alzheimer’s disease.(S33. 009)”, (2015)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGelmont, D, Thomas, RG, Dyck-Jones, JA, et al., “Safety of Intravenous Immunoglobulin Therapy in Patients with Probable Alzheimer’s Disease: A Randomized, Placebo-Controlled Clinical Study”, ANNALS OF ALLERGY ASTHMA & IMMUNOLOGY, (2015)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nOrban, Pierre, Madjar, C'e, “Test-retest resting-state fMRI in healthy elderly persons with a family history of Alzheimer’s disease”, Scientific data, (2015)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nNewman, Rhian C, Ellis, Tim, Davison, Phil I, et al., “Using novel methodologies to examine the impact of artificial light at night on the cortisol stress response in dispersing Atlantic salmon (Salmo salar L.) fry”, Conservation physiology, (2015)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nDoody, RS, Thomas, RG, Farlow, M, et al., “Alzheimer’s Disease Cooperative Study Steering Committee; Solanezumab study group. Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, MC, Sperling, RA, Salmon, DP, et al., “Australian imaging, biomarkers, and lifestyle flagship study of ageing; Alzheimer’s disease neuroimaging initiative; Alzheimer’s disease cooperative study. The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA Neurol, (2014)\nMedical/Clinical Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nChen, Yun-Fei, Mohs, Richard, Ding, Ying, et al., “Bayesian Longitudinal Modeling on Placebo Data from Alzheimer’s Disease Clinical Studies (P1. 010)”, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bell, Joanne, Mancuso, Jessica Y, et al., “Clinical trial of an inhibitor of RAGE-A beta interactions in Alzheimer disease”, Neurology, (2014)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Jacqmin-Gadda, Hene, Le Goff, Melanie, et al., “Estimating long-term multivariate progression from short-term data”, Alzheimer’s & Dementia, (2014)\nGeneral Research\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, Anthony, Jack, Clifford, et al., “F3-02-02: MODELING LONG-TERM DISEASE PROGRESSION WITH COVARIATES”, Alzheimer’s & Dementia, (2014)\nGeneral Research\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo Adolfo, Thomas, Ronald G, Qiu, Hongmei, et al., “P1-357: ADCS EDC: INVESTIGATIONAL PRODUCT MANAGEMENT SYSTEM”, Alzheimer’s & Dementia, (2014)\nGeneral Research\n\n🔗 Article\n\n\n\nLaske, Christoph, “Phase 3 trials of solanezumab and bapineuzumab for Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Thomas, Ronald G, Farlow, Martin, et al., “Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, New England Journal of Medicine, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, Michael C, Sperling, Reisa A, Salmon, David P, et al., “The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA neurology, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nDoody, Rachelle S, Raman, Rema, Farlow, Martin, et al., “A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, New England Journal of Medicine, (2013)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSalmon, David P, Ferris, Steven H, Thomas, Ronald G, et al., “Age and apolipoprotein E genotype influence rate of cognitive decline in nondemented elderly.”, Neuropsychology, (2013)\nMedical/Clinical\n\n🔗 Article\n\n\n\nDoody, RS, Raman, R, Farlow, M, et al., “Alzheimer’s Disease Cooperative Study Steering Committee, Siemers E, Sethuraman G, Mohs R, Semagacestat Study Group. A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, N Engl J Med, (2013)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nPosner, Holly B, Cano, Stefan, Carrillo, Maria C, et al., “Establishing the psychometric underpinning of cognition measures for clinical trials of Alzheimer’s disease and its precursors: a new approach”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBurstein, Aaron, Galasko, Douglas, Aisen, Paul, et al., “P1–332: Evaluation of the relationship between TTP488 plasma concentrations and changes in ADAS-cog relative to placebo”, Alzheimer’s & Dementia, (2013)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald, Petersen, Ronald, Siuciak, Judith, et al., “P3–295: The Placebo Data Analysis in Alzheimer’s Disease (AD) and Mild Cognitive Impairment (MCI) Clinical Trials Project: Overview of progress in trial data collection, and key findings from the pooled Alzheimer’s disease trial datasets”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Bruschi, Stefania, et al., “P4–157: Adcs electronic data capture: Collaborative development and management of clinical trial databases”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nMills, Sarah M, Mallmann, J, Santacruz, Anna M, et al., “Preclinical trials in autosomal dominant AD: implementation of the DIAN-TU trial”, Revue neurologique, (2013)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nHobart, Jeremy, Cano, Stefan, Posner, Holly, et al., “Putting the Alzheimer’s cognitive test to the test II: Rasch Measurement Theory”, Alzheimer’s & dementia, (2013)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nAustin, David, Thomas, Rob, “A Garden before the Garden: Landscape, History and the National Botanic Garden of Wales”, Landscapes, (2012)\nGeneral Research\n\n🔗 Article\n\n\n\nGalasko, DR, Peskind, E, Clark, CM, et al., “Alzheimer’s Disease Cooperative Study. Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Arch Neurol, (2012)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nVellas, B, Hampel, H, Roug'e, “Alzheimer’s disease therapeutic trials: EU/US Task Force report on recruitment, retention, and methodology”, The journal of nutrition, health & aging, (2012)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas R, Peskind, Elaine, Clark, Christopher M, et al., “Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Archives of neurology, (2012)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Jin, Shelia, He, Feng, et al., “Incidence of new-onset seizures in mild to moderate Alzheimer disease”, Archives of neurology, (2012)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nRelkin, Norman, Gessert, Devon, Stokes, Karen, et al., “O3-13-05: The Gammaglobulin Alzheimer Partnership Study (GAP): Design, screening, enrollment and futility analysis results”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Hong, Phuoc, et al., “P3-364: ADCS EDC”, Alzheimer’s & Dementia, (2012)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald, Jimenez, Gustavo, Brewer, James, et al., “P3-383: ADCS data sharing”, Alzheimer’s & Dementia, (2012)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, Paul, Thomas, Ronald, Carrillo, Maria, et al., “P3-384: The placebo data analysis in Alzheimer’s disease and mild cognitive impairment (MCI) clinical trials project: Overview of progress in trial data collection, and key findings from the pooled MCI trial datasets”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nRafii, MS, Walsh, S, Little, JT, et al., “A phase II trial of huperzine A in mild to moderate Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Bell, KL, Galasko, D, et al., “A randomized, double-blind, placebo-controlled trial of simvastatin to treat Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Raman, Rema, Emond, Jennifer, et al., “Adding delayed recall to the Alzheimer Disease Assessment Scale is useful in studies of mild cognitive impairment but not Alzheimer disease”, Alzheimer disease and associated disorders, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Schneider, Lon S, Cummings, Jeffrey, et al., “Chronic divalproex sodium to attenuate agitation and clinical progression of Alzheimer disease”, Archives of General Psychiatry, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nFleisher, AS, Truran, D, Mai, JT, et al., “Chronic divalproex sodium use and brain atrophy in Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMockus, Danyte S, Macera, Caroline A, Wingard, Deborah L, et al., “Dietary self-monitoring and its impact on weight loss in overweight children”, International Journal of Pediatric Obesity, (2011)\nGeneral Research\n\n🔗 Article\n\n\n\nQuinn, JF, Raman, R, Thomas, RG, et al., “Omega-3 Fatty Acids for Alzheimer’s Disease. What a Pill Can Tell Us about Eating Fish”, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMessick, Viviana, Donohue, Michael, Raman, Rema, et al., “P3-406: Role of caregiver in subject’s compliance with treatment”, Alzheimer’s & Dementia, (2011)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSmart, N, George, A, Khan, D, et al., “Radiological follow up of perineal repair with cross-linked acellular porcine dermal collagen following extralevator abdominoperineal excision for low rectal cancer: P115”, Colorectal Disease, (2011)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, PS, Andrieu, S, Sampaio, C, et al., “Report of the task force on designing clinical trials in early (predementia) AD”, Neurology, (2011)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, AC, Thomas, RG, et al., “The relative efficiency of time-to-threshold and rate of change in longitudinal data”, Contemporary clinical trials, (2011)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nAisen, Paul S, Petersen, Ronald C, Donohue, Michael C, et al., “Clinical Core of the Alzheimer’s Disease Neuroimaging Initiative: progress and plans”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, et al., “Docosahexaenoic acid supplementation and cognitive decline in Alzheimer disease: a randomized trial”, Jama, (2010)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael, Gamst, Anthony, Thomas, Ron, et al., “O3-01-07: Rate of decline in ADNI normal controls with evidence of amyloid burden”, Alzheimer’s & Dementia, (2010)\nGeneral Research\n\n🔗 Article\n\n\n\nFleisher, Adam S, Jack Jr, Clifford R, Weiner, Michael W, et al., “P1-433: Brain volume changes with divalproex sodium in Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Thomas, Ronald, Raman, Rema, et al., “P1-447: Cerebrospinal fluid biomarker outcomes in a trial of docosahexaenoic acid (DHA) for Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Alzheimer’s disease Biomarkers\n\n🔗 Article\n\n\n\n\n\n\nRaman, Rema, Thomas, Ronald G, Weiner, Michael W, et al., “MRI substudy participation in Alzheimer disease (AD) clinical trials: baseline comparability of a substudy sample to entire study population”, Alzheimer disease and associated disorders, (2009)\nMedical/Clinical Alzheimer’s disease Clinical trials Neuroimaging\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, et al., “O1-04-02: A clinical trial of docosahexanoic acid (DHA) for the treatment of Alzheimer’s disease”, Alzheimer’s & Dementia, (2009)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Aisen, Paul, Cummings, Jeffrey, et al., “O1-04-03: The ADCS valproate neuroprotection trial: Primary efficacy and safety results”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nCano, Stefan, Posner, Holly, Aisen, Paul, et al., “O4-04-07: The ADAS-cog’s performance as a measure—lessons from the ADNI study: Part 2-evaluation using modern psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nPosner, Holly, Cano, Stefan, Aisen, Paul, et al., “P1-269: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 1-evaluation using traditional psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nHobart, Jeremy, Posner, Holly, Aisen, Paul, et al., “P1-270: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 3-do the scale modifications add value?”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Raman, Rema, Schwarzschild, Michael A, et al., “Plasma urate and progression of mild cognitive impairment”, Neurodegenerative Diseases, (2009)\nMedical/Clinical\n\n🔗 Article\n\n\n\nMachado, C, Leisman, G, Koch, P, et al., “REVIEWS IN THE NEUROSCIENCES”, NEUROSCIENCES, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nPasner, Holly, Cano, Stefan J, Aisen, Paul, et al., “The ADAS-cog’s Performance as a Measure Lessons from the ADNI Study: Part 1-Evaluation Using Traditional Psychometric Methods”, Neurology, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nKhachaturian, Zaven S, Petersen, Ronald C, Gauthier, Serge, et al., “A roadmap for the prevention of dementia: the inaugural Leon Thal Symposium”, Alzheimer’s & dementia: the journal of the Alzheimer’s Association, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\nAisen, PS, Schneider, LS, Sano, M, et al., “Alzheimer Disease Cooperative Study. High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nRoch-Levecq, Anne-Catherine, Brody, Barbara L, Thomas, Ronald G, et al., “Ametropia, preschoolers’ cognitive abilities, and effects of spectacle correction”, Archives of ophthalmology, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\nDoody, RS, Gavrilova, SI, Sano, M, et al., “Dimebon investigators: Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, Lancet, (2008)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, et al., “Dual Task Test Could Help Diagnose Dementia”, JAMA, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana I, Sano, Mary, et al., “Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, The Lancet, (2008)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMeyer, Brett C, Raman, Rema, Hemmen, Thomas, et al., “Efficacy of site-independent telemedicine in the STRokE DOC trial: a randomised, blinded, prospective study”, The Lancet Neurology, (2008)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, et al., “High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Peskind, Elaine, Clark, Christopher M, et al., “O2-04–06: Randomized clinical trial of antioxidant treatment in Alzheimer’s disease with CSF biomarker measures”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Thomas, Ronald, et al., “P4-337: Dimebon improves cognition, function, and behavior in mild and moderate Alzheimer’s disease: Results by severity of a one-year, double-blind, placebo-controlled study”, Alzheimer’’s and Dementia, (2008)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald, et al., “P4-343: Omega 3 fatty acids and Alzheimer’s disease: Trial design and baseline study population characteristics in a clinical trial of docosahexanoic acid for Alzheimer’s disease”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nRaman, Rema, Emond, Jennifer, Thomas, Ronald G, et al., “P4-387: Adding delayed recall to the Alzheimer’s disease assessment scale-cognitive subscale (ADAS-cog): Sensitivity in a clinical trial for Alzheimer’s disease and mild cognitive impairment”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDoody, Rachelle, Seely, Lynn, Thomas, Ronald, et al., “Statistical treatment of withdrawal in trials of anti-dementia drugs–Authors’ reply”, The Lancet, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\n\n\n\nDoody, Rochelle, Gavrilova, Svetlana, Sano, Mary, et al., “Dimebon improves cognition, function, and behavior in patients with mild-moderate Alzheimer’s disease: Results of a randomized, double-blind, placebo-controlled study”, Neurology, (2007)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Kaye, Jeffrey, Ferris, Steven, et al., “P-081: The ACDS home assessment instrument: A pilot study”, Alzheimer’s & Dementia, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nTHOMAS, RONALD J, CLARK, CHRISTOPHER A, “Population Dynamics of Meloidogyne incognita and RotylenchulusTenchulus reniformis Alone and in Combination, and Their Effects on Sweet Potato1”, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nMay, Susanne, Gilman, Sid, Sowell, B Brooke, et al., “Potential outcome measures and trial design issues for multiple system atrophy”, Movement disorders, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, Paul S, Jin, Shelia, Thomas, Ronald G, et al., “S3–02–01: ADCS homocysteine trial”, Alzheimer’s & Dementia, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Sano, Mary, et al., “S3–02–03: Results of a one-year randomized, placebo-controlled trial of dimebon for the treatment of mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia, (2007)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nSano, Mary, Zhu, Carolyn W, Whitehouse, Peter J, et al., “ADCS Prevention Instrument Project: pharmacoeconomics: assessing health-related resource use among healthy elderly”, Alzheimer disease and associated disorders, (2006)\nGeneral Research\n\n🔗 Article\n\n\n\nPetersen, Ronald, Thomas, Ronald, Grundman, Michael, et al., “Cognitive Changes in the Treatment of Mild Cognitive Impairment with Donepezil and Vitamin E: P02. 187”, Neurology, (2006)\nMedical/Clinical\n\n🔗 Article\n\n\n\n\n\n\nKrajewska, Maryla, Kim, Hoguen, Kim, Chul, et al., “Analysis of apoptosis protein expression in early-stage colorectal cancer suggests opportunities for new prognostic biomarkers”, Clinical Cancer Research, (2005)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nPfeiffer, E, Petersen, RC, Thomas, RG, et al., “Cognition in the treatment of mild cognitive impairment with donepezil and vitamin E”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nRoch–Levecq, A–C, Brody, B, Thomas, RG, et al., “Cognitive Outcomes of Corrective Lenses on Low Income Preschoolers With Hyperopia/Astimgatism: A Longitudinal Pilot Study”, Investigative Ophthalmology & Visual Science, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nGalasko, D, Schmitt, F, Thomas, R, et al., “Detailed assessment of activities of daily living in moderate to severe Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Raman, Rema, Jakimovich, Laura, et al., “Divalproex sodium in nursing home residents with possible or probable Alzheimer disease complicated by agitation: a randomized, controlled trial”, The American journal of geriatric psychiatry, (2005)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nPeskind, Elaine R, Tsuang, Debby W, Bonner, Lauren T, et al., “Propranolol for disruptive behaviors in nursing home residents with probable or possible Alzheimer disease: a placebo-controlled study”, Alzheimer Disease & Associated Disorders, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nEdland, SD, May, S, Emond, JA, et al., “Sample size considerations in dementia prevention trials: Data from the Alzheimer’s disease Cooperative Study MCI Trial”, NEUROLOGY, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nBrody, Barbara L, Roch-Levecq, Anne-Catherine, Thomas, Ronald G, et al., “Self-management of age-related macular degeneration at the 6-month follow-up: a randomized controlled trial”, Archives of Ophthalmology, (2005)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Grundman, M, et al., “Treatment of MCI with cholinesterase inhibitors: current data”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, et al., “Vitamin E and donepezil for the treatment of mild cognitive impairment”, New England Journal of Medicine, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, et al., “[O1-04-04]: Operational criteria for patient recruitment in trials of mild cognitive impairment”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Grundman, Michael, et al., “[O2-01-01]: Donepezil and vitamin E in the progression of mild cognitive impairment to Alzheimer’s disease: A hazard-ratio analysis”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nHamilton, Joanne M, Salmon, David P, Galasko, Douglas, et al., “A comparison of episodic memory deficits in neuropathologically-confirmed Dementia with Lewy bodies and Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2004)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nThomas, Ronald G, Aisen, Paul S, Shoulson, Ira, et al., “Distinguished From Alzheimer Disease and Normal Aging for Clinical Trials Michael Grundman, MD, MPH; Ronald C. Petersen, PhD, MD; Steven H. Ferris, PhD”, (2004)\nMedical/Clinical Alzheimer’s disease Clinical trials Neuroimaging\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Thal, L, “Donepezil and vitamin E for mild cognitive impairment”, 9th International Congress on Alzheimer’s Disease. Philadelphia, (2004)\nMedical/Clinical\n\n🔗 Article\n\n\n\nArgent, R, Thomas, R, Boughan, P, et al., “MAP kinase inhibitors reduce Helicobacter pylori-induced interleukin-8 secretion and the phosphorylation of I\\\\kappaB\\\\\\\\alpha”, Helicobacter, (2004)\nGeneral Research\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Ferris, Steven H, et al., “Mild cognitive impairment can be distinguished from Alzheimer disease and normal aging for clinical trials”, Archives of neurology, (2004)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, et al., “P1-003 ADCS Prevention instrument project: assessment of activities of daily living (ADL)”, Neurobiology of Aging, (2004)\nGeneral Research\n\n🔗 Article\n\n\n\nTariot, Pierre N, Thal, Leon, Jakimovich, Laura, et al., “P1-322 A multicenter, randomized, double-blind, placebo-controlled trial of valproate for agitation associated with dementia”, Neurobiology of Aging, (2004)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Tractenberg, Rochelle E, Sano, Mary, et al., “Reliability of monitoring the clinical dementia rating in multicenter clinical trials”, Alzheimer disease and associated disorders, (2004)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon, “S5-03-02 Prevention trials in Alzheimer’s disease: design issues”, Neurobiology of Aging, (2004)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nSinger, Clifford, Tractenberg, Rochelle E, Kaye, Jeffrey, et al., “A multicenter, placebo-controlled trial of melatonin for sleep disturbance in Alzheimer’s disease”, Sleep, (2003)\nMedical/Clinical Alzheimer’s disease Sleep disorders\n\n🔗 Article\n\n\n\nGrundman, M, Capparelli, E, Kim, HT, et al., “A multicenter, randomized, placebo controlled, multiple-dose, safety and pharmacokinetic study of AIT-082 (Neotrofin™) in mild Alzheimer’s disease patients”, Life sciences, (2003)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, PS, Schafer, KA, Grundman, M, et al., “Alzheimer’s Disease Cooperative Study. Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly A, Grundman, Michael, et al., “Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Mulnard, Ruth, et al., “Estrogen levels do not correlate with improvement in cognition”, Archives of Neurology, (2003)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RG, Choudhury, RK, Mohanty, AK, et al., “Fission fragment angular distributions: A probe to study heavy-ion fusion dynamics”, Physical Review C, (2003)\nGeneral Research\n\n🔗 Article\n\n\n\nGrundman, Michael, Jack, Clifford R, Petersen, Ronald C, et al., “Hippocampal volume is associated with memory but not nonmemory cognitive performance in patients with mild cognitive impairment”, Journal of Molecular Neuroscience, (2003)\nMedical/Clinical\n\n🔗 Article\n\n\n\nThal, LJ, Grundman, M, Berg, J, et al., “Idebenone treatment fails to slow cognitive decline in Alzheimer’s disease”, Neurology, (2003)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly, Grundman, Michael, et al., “NSAIDs and hypertension”, Archives of internal medicine, (2003)\nGeneral Research\n\n🔗 Article\n\n\n\nRaskind, Murray A, Peskind, Elaine R, Kanter, Evan D, et al., “Reduction of nightmares and other PTSD symptoms in combat veterans by prazosin: a placebo-controlled study”, American Journal of Psychiatry, (2003)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nBrody, BL, Roch-Levecq, AC, Thomas, RG, et al., “Self-Management of Age-Related Macular Degeneration and Quality of Life at 6 Months Follow-Up: A Randomized Controlled Trial”, Investigative Ophthalmology & Visual Science, (2003)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nAisen, PS, Berg, JD, Craft, S, et al., “Steroid-induced elevation of glucose in Alzheimer’s disease: relationship to gender, apolipoprotein E genotype and cognition”, Psychoneuroendocrinology, (2003)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nGrundman, Michael, Farlow, Martin, Peavy, Guerry, et al., “A phase I study of AIT-082 in healthy elderly volunteers”, Journal of Molecular Neuroscience, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nPierce, John P, Faerber, Susan, Wright, Fred A, et al., “A randomized trial of the effect of a plant-based dietary pattern on additional breast cancer events and survival:: the Women’s Healthy Eating and Living (WHEL) Study”, Controlled clinical trials, (2002)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nSalmon, David P, Thomas, RG, Pay, MM, et al., “Alzheimer’s disease can be accurately diagnosed in very mildly impaired individuals”, Neurology, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Jin, Shelia, et al., “Assessing Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory: scoring and clinical implications”, Journal of psychiatric research, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, Clifford R, et al., “Brain MRI hippocampal volume and prediction of clinical status in a mild cognitive impairment trial”, Journal of Molecular Neuroscience, (2002)\nMedical/Clinical Neuroimaging\n\n🔗 Article\n\n\n\nGrundman, M, Kim, HT, Schultz, AN, et al., “Clinical correlates of hippocampal atrophy in patients with mild cognitive impairment”, NEUROBIOLOGY OF AGING, (2002)\nMedical/Clinical\n\n🔗 Article\n\n\n\nHamilton, JM, Corey-Bloom, J, Thomas, RG, et al., “Correlates of weight change in Huntington’s disease”, NEUROLOGY, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nLange, Kelly L, Bondi, Mark W, Salmon, David P, et al., “Decline in verbal memory during preclinical Alzheimer’s disease: examination of the effect of APOE genotype”, Journal of the International Neuropsychological Society: JINS, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJames, MW, Argent, RH, Thomas, R, et al., “Indomethacin reduces Helicobacter pylori-induced interleukin-8 (IL-8) production by the gastric epithelial cell line, AGS.”, GASTROENTEROLOGY, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Gamst, Anthony, Thomas, Ronald G, et al., “Investigating emergent symptomatology as an outcome measure in a behavioral study of Alzheimer’s disease”, The Journal of neuropsychiatry and clinical neurosciences, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Sano, Mary, et al., “No long-term effect of behavioral treatment on psychotropic drug use for agitation in Alzheimer’s disease patients”, Journal of geriatric psychiatry and neurology, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGoldberg, DE, Roch-Levecq, AC, Maclean, KK, et al., “Psychosocial and Functional Parameters in Patients with Age Related Macular Degeneration and Choroidal Neovascularization with and without Photodynamic Therapy”, Investigative Ophthalmology & Visual Science, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, P, Schafer, K, Grundman, M, et al., “Results of a multicenter trial of rofecoxib and naproxen in Alzheimer’s disease”, Neurobiology of Aging, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSinger, C, Colling, E, Tractenberg, R, et al., “The ADCS clinical trial of melatonin for the sleep disturbance of alzheimer’s disease: Case report of an unusual sleep/wake cycle and response to melatonin.”, AMERICAN JOURNAL OF GERIATRIC PSYCHIATRY, (2002)\nMedical/Clinical Alzheimer’s disease Sleep disorders Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nTractenberg, Rochelle E, Gamst, Anthony, Weiner, Myron F, et al., “Frequency of behavioral symptoms characterizes agitation in Alzheimer’s disease”, International journal of geriatric psychiatry, (2001)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Thomas, RG, et al., “Incidence and persistence of psychosis in Alzheimer’s disease”, Neurology, (2001)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLindblad, Ulf, Langer, Robert D, Wingard, Deborah L, et al., “Metabolic syndrome and ischemic heart disease in elderly men and women”, American journal of epidemiology, (2001)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nAisen, Paul S, Davis, KL, Berg, JD, et al., “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKoch, HJ, Szecsey, A, “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThomas, Ronald G, Berg, Julie D, Sano, Mary, et al., “Analysis of longitudinal data in an Alzheimer’s disease clinical trial”, Statistics in medicine, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBayley, Peter J, Salmon, David P, Bondi, Mark W, et al., “Comparison of the serial position effect in very mild Alzheimer’s disease, mild Alzheimer’s disease, and amnesia associated with electroconvulsive therapy”, Journal of the International Neuropsychological Society, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGamst, A, Thomas, RG, Patterson, M, et al., “Description of behaviors emerging in community-dwelling persons with Alzheimer’s disease over 12 months”, ANNALS OF NEUROLOGY, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTHOMAS, R, MICHAEL, J, “Disorder among Veterans with Substance Abuse”, THE JOURNaL OF NERvOUs AND MEntal Disease, (2000)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nMulnard, Ruth A, Cotman, Carl W, Kawas, Claudia, et al., “Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, Jama, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nPaulsen, Jane S, Salmon, DP, Thal, Leon J, et al., “Incidence of and risk factors for hallucinations and delusions in patients with probable AD”, Neurology, (2000)\nGeneral Research\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Knopman, D, et al., “Predicting nursing home placement with change on cognitive measures in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Patterson, Marian, Weiner, Myron F, et al., “Prevalence of symptoms on the CERAD behavior rating scale for dementia in normal elderly subjects and Alzheimer’s disease patients”, The Journal of neuropsychiatry and clinical neurosciences, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Jin, Shelia, Patterson, Marian, et al., “Qualifying change: a method for defining clinically meaningful outcomes of change score computation”, Journal of the American Geriatrics Society, (2000)\nGeneral Research\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle, Teri, Linda, et al., “Quantifying behavioral disturbance in Alzheimer’s disease patients”, Journal of Psychiatric Research, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTeri, Linda, Logsdon, RG, Peskind, E, et al., “Treatment of agitation in AD: a randomized, placebo-controlled clinical trial”, Neurology, (2000)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, CR, et al., “Use of brain MRI volumetric analysis in a mild cognitive impairment trial to delay the diagnosis of Alzheimer’s disease”, Drug discovery and development for Alzheimer’s disease, (2000)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nMulnard, RA, Cotman, CW, Kawas, C, et al., “for the Alzheimer’s Disease Cooperative Study: Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, JAMA, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nLineweaver, Tara T, Bondi, Mark W, Thomas, Ronald G, et al., “A normative study of Nelson’s (1976) modified version of the Wisconsin Card Sorting Test in healthy older adults”, The Clinical Neuropsychologist, (1999)\nGeneral Research\n\n🔗 Article\n\n\n\nBrody, Barbara L, Williams, Rebecca A, Thomas, Ronald G, et al., “Age-related macular degeneration: a randomized clinical trial of a self-management intervention”, Annals of Behavioral Medicine, (1999)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, et al., “Assessment of agitation in Alzheimer’s disease: the agitated behavior in dementia scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, et al., “Brief Methodological Reports-Assessment of Agitation in Alzheimer’s Disease: The Agitated Behavior in Dementia Scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nOlin, JT, Papka, M, Jin, S, et al., “Clinical symptoms of dementia with Lewy bodies: Secondary analyses of the Alzheimer’s disease cooperative study selegiline and vitamin E clinical trial”, European Neuropsychopharmacology, (1999)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBell, Karen, Sano, Mary, Jin, Shelia, et al., “Ethnic differences in clinical measures among participants in Alzheimer’s disease clinical trials”, Neurology, (1999)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHohl, Ursula, Grundman, Michael, Salmon, David P, et al., “Mini-mental state examination and Mattis Dementia Rating Scale performance differs in Hispanic and non-Hispanic Alzheimer’s disease patients”, Journal of the International Neuropsychological Society, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSabbagh, Marwan N, Corey-Bloom, Jody, Tiraboschi, Pietro, et al., “Neurochemical markers do not correlate with cognitive decline in the Lewy body variant of Alzheimer disease”, Archives of neurology, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nBondi, Mark W, Salmon, David P, Galasko, Douglas, et al., “Neuropsychological function and apolipoprotein E genotype in the preclinical detection of Alzheimer’s disease.”, Psychology and aging, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKnopman, David S, Berg, JD, Thomas, R, et al., “Nursing home placement is related to dementia progression: experience from a clinical trial”, Neurology, (1999)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Sano, Mary, Berg, Julie, et al., “The Beneficial Effects of Vitamin E and Selegiline in a Controlled Trial in Alzheimer’s Disease Are Independent of the Apolipoprotein E e4 Allele”, Neurology, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nChambers, Christina D, Anderson, Philip O, Thomas, Ronald G, et al., “Weight gain in infants breastfed by mothers who take fluoxetine”, Pediatrics, (1999)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nWeiner, Myron F, Koss, Elisabeth, Patterson, Marian, et al., “A comparison of the Cohen-Mansfield agitation inventory with the cerad behavioral rating scale for dementia in community-dwelling persons with Alzheimers disease”, Journal of psychiatric research, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle, Schafer, Kimberly, Thomas, Ron, et al., “Agreement on CDR ratings by committee”, Controlled Clinical Trials, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nTanaka, S, Chen, X, Xia, Y, et al., “Association of CYP2D microsatellite polymorphism with Lewy body variant of Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nPeavy, GM, Salmon, DP, Thomas, RG, “Cognitive and functional abilities in severely demented Alzheimer’s patients”, CLINICAL NEUROPSYCHOLOGIST, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nFerry, David R, O’Rourke, Robert A, Blaustein, Alvin S, et al., “Design and baseline characteristics of the veterans affairs non-Q-wave infarction strategies in-hospital (VANQWISH) trial”, Journal of the American College of Cardiology, (1998)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nJin, Shelia, Thomas, Ronald G, Galasko, Douglas, et al., “Dynamic measurement scale development for clinical trials in targeted populations”, Controlled Clinical Trials, (1998)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGalasko, D, Chang, L, Motter, R, et al., “High cerebrospinal fluid tau and low amyloid beta42 levels in the clinical diagnosis of Alzheimer disease and relation to apolipoprotein E genotype”, Archives of neurology, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKatzman, R, Kang, D, Thomas, R, “Interaction of apolipoprotein E 4 with other genetic and non-genetic risk factors in late onset Alzheimer disease: problems facing the investigator”, Neurochemical research, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nBerg, Julie D, Thomas, Ronald G, Thal, Leon J, et al., “Measuring cognitive progression in Alzheimer’s disease”, Controlled Clinical Trials, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKean, Yin M, Thomas, Ronald G, Thal, Leon J, “Power calculation for randomized start design”, Controlled Clinical Trials, (1998)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nLineweaver, TT, Bondi, MW, Thomas, RG, “Practice effects on the modified Wisconsin card sorting test in normally aging adults”, Archives of Clinical Neuropsychology, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nFroelicher, Victor F, Lehmann, Kenneth G, Thomas, Ronald, et al., “The electrocardiographic exercise test in a population with reduced workup bias: diagnostic performance, computerized interpretation, and multivariable prediction”, Annals of internal medicine, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nWilliams, Rebecca A, Brody, Barbara L, Thomas, Ronald G, et al., “The psychosocial impact of macular degeneration”, Archives of ophthalmology, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nKnopman, David, Sano, Mary, Berg, Julie, et al., “The relationship between Nursing home placement and measures of change in Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Welty, Greg, Thomas, Ronald G, “Use of the world wide web in data dissemination to central review committees”, Controlled Clinical Trials, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nKeane, Terence M, Kolb, Lawrence C, Kaloupek, Danny G, et al., “Utility of psychophysiological measurement in the diagnosis of posttraumatic stress disorder: results from a Department of Veterans Affairs Cooperative Study.”, Journal of consulting and clinical psychology, (1998)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\n\n\n\nJeong, Jong-Hyeon, Klauber, Melville R, Thomas, Ronald G, et al., “53 Power comparisons among different number of categories under ordered polytomous logistic regression model”, Controlled Clinical Trials, (1997)\nGeneral Research\n\n🔗 Article\n\n\n\nWhitehouse, Peter J, Schmitt, HFrederick A, Sano, Mary, et al., “A Multicenter Evaluation of New Treatment Efficacy”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Thomas, Ronald G, et al., “A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease”, New England Journal of Medicine, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nPatterson, Marian B, Mack, James L, Mackell, Joan A, et al., “A longitudinal study of behavioral pathology across five levels of dementia severity in Alzheimer’s disease: The CERAD Behavior Rating Scale for Dementia.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, Mary, Thomas, Ronald G, Thal, Leon J, “Alpha-tocopherol and Alzheimer’s disease”, The New England Journal of Medicine, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, et al., “An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSeubert, PA, Motter, RN, Schenk, DB, et al., “ApoE genotype influences the CSF level of A \\\\beta 42 in Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKoss, Elisabeth, Weiner, Myron, Ernesto, Christopher, et al., “Assessing patterns of agitation in Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory. The Alzheimer’s Disease Cooperative Study.”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Seubert, P, Motter, R, et al., “CSF levels of A beta 432 and tau as aids to diagnosing Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nRoch, J-M, Sundsmo, M, Otero, D, et al., “Defective Neurite Extension Is Caused by a Mutation in Amyloid /A4 (A ) Protein Precursor Found in Familial Alzheimer’s Disease”, JOURNAL OF NEUROBIOLOGY, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLi, Hai Ling, Roch, Jean-Marc, Sundsmo, Mary, et al., “Defective neurite extension is caused by a mutation in amyloid beta protein precursor found in familial Alzheimer’s disease”, Journal of neurobiology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nHohl, U, CoreyBloom, J, Hansen, LA, et al., “Diagnostic accuracy of dementia with Lewy bodies: A prospective evaluation”, Neurology, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, et al., “Effects of Selegiline and alpha-Tocopherol on cognitive and functional outcome measures in moderately impaired patients with Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKatzman, R, Zhang, M-Y, Chen, PJ, et al., “Effects of apolipoprotein E on dementia and aging in the Shanghai Survey of Dementia”, Neurology, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nBarrett-Connor, Elizabeth, Thomas, Ronald G, “Estrogen, apolipoprotein E, and dementia”, Journal of women’s health, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nKang, DE, Saitoh, T, Chen, X, et al., “Genetic association of the low-density lipoprotein receptor-related protein gene (LRP), and apolipoprotein E receptor, with late-onset Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald G, Welty, Greg, et al., “P23 use of the world wide web for clinical monitoring in multicenter clinical trials”, Controlled Clinical Trials, (1997)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nWilliams, RA, Brody, BL, Kaplan, RM, et al., “Quality of life among elderly adults with macular degeneration”, INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE, (1997)\nGeneral Research\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Sano, Mary, “Tacrine and nursing home placement”, Neurology, (1997)\nGeneral Research\n\n🔗 Article\n\n\n\nSano, M, Mackell, JA, Ponton, M, et al., “The Spanish Instrument Protocol: Design and implementation of a study to evaluate treatment efficacy instruments for Spanish-speaking patients with Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, et al., “Validity and reliability of the Alzheimer’s Disease Cooperative Study-Clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, et al., “for the members of the Alzheimer’s Disease Cooperative Study”, A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease. N Engl J Med, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, LS, Olin, JT, Doody, RS, et al., “the Alzheimer’s Disease Cooperative Study. Validity and reliability of the Alzheimer’s disease cooperative study-clinical global impression of change”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Sano, M, et al., “the Alzheimer’s Disease Cooperative Study. An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nThomas, Ronald G, Schafer, Kimberly, Woodbury, Peter, et al., “A32 computer-aided clinical monitoring: Results of a controlled experiment”, Controlled Clinical Trials, (1996)\nGeneral Research\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Ernesto, Christopher, Sano, Mary, et al., “A34 Clinical monitoring of rating scales in multicenter clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nChen, X, Xia, Y, Gresham, LS, et al., “ApoE and CYP2D6 polymorphism with and without parkinsonism-dementia complex in the people of Chamorro, Guam”, Neurology, (1996)\nMedical/Clinical\n\n🔗 Article\n\n\n\nKatzman, R, Galasko, DR, Saitoh, T, et al., “Apolipoprotein-epsilon4 and head trauma: Synergistic or additive risks?”, Neurology, (1996)\nGeneral Research\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Ernesto, C, et al., “Development of a pool of items to assess activities of daily living in clinical trials for Alzheimer’s disease”, Neurology, (1996)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, M, Growdon, J, Thomas, R, et al., “Evaluation of efficacy measures in clinical trials for Alzheimer’s disease: Does psychometric test performance predict clinically relevant outcomes?”, Neurology, (1996)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nWright, Fred A, Thomas, Ronald G, “Familial melanoma and pancreatic cancer”, The New England journal of medicine, (1996)\nGeneral Research\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald, Galasko, Douglas, et al., “P63 Informed consent issues when including genetic testing in clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Morris, JC, et al., “Rate of dementia of the Alzheimer type (DAT) in subjects with mild cognitive impairment”, Neurology, (1996)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Klauber, Melville R, et al., “Rationale and design of a multicenter study of selegiline and alpha-tocopherol in the treatment of Alzheimer disease using novel clinical outcomes. Alzheimer’s Disease Cooperative Study.”, Alzheimer disease and associated disorders, (1996)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSeidner, Andrea L, Burling, Thomas A, Gaither, David E, et al., “Substance-dependent inpatients who accept smoking treatment”, Journal of Substance Abuse, (1996)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, et al., “Validity and reliability of the Alzheimers disease cooperative study-clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease Springer, (1996)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nLi, Dominic, German, Donald, Lulla, Sulochina, et al., “Prospective study of hospitalization for asthma: a preliminary risk factor model”, American journal of respiratory and critical care medicine, (1995)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RG, Jin, S, Schafer, K, et al., “The Spanish Instrument Protocol: a Study to Evaluate Treatment Efficacy Instruments for Spanish-Speaking Patients with Alzheimer’s Disease”, Alzheimer Disease and Associated Disorders, (1995)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nAstion, Michael L, Wener, Mark H, Thomas, Ronald G, et al., “Application of neural networks to the classification of giant cell arteritis”, Arthritis & Rheumatism: Official Journal of the American College of Rheumatology, (1994)\nGeneral Research\n\n🔗 Article\n\n\n\nIrving, Lori M, Seidner, Andrea L, Burling, Thomas A, et al., “Drug and alcohol abuse inpatients’ attitudes about smoking cessation”, Journal of Substance Abuse, (1994)\nMedical/Clinical\n\n🔗 Article\n\n\n\nThomas, Ralf, “Zweibaryonensysteme mit Strangeness und die Antikaon-Deuteron Streuung”, (1994)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nWilson, Sandra R, Scamagas, Peter, German, Donald F, et al., “A controlled trial of two forms of self-management education for adults with asthma”, The American journal of medicine, (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nConlon, Michael, Thomas, Ronald G, “Algorithm AS 280: the power function for Fisher’s exact test”, Journal of the Royal Statistical Society. Series C (Applied Statistics), (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nAstion, ML, Wener, MH, Thomas, RG, et al., “Overtraining in neural networks that interpret clinical data”, Clinical chemistry, (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nMorrow, Kiernan, Morris, Charles K, Froelicher, Victor F, et al., “Prediction of cardiovascular death in men undergoing noninvasive evaluation for coronary artery disease”, Annals of Internal Medicine, (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nWard, TT, Thomas, RG, Fye, CL, et al., “Trimethoprim-sulfamethoxazole prophylaxis in granulocytopenic patients with acute leukemia: evaluation of serum antibiotic levels in a randomized, double-blind, placebo-controlled Department of Veterans Affairs Cooperative Study”, Clinical infectious diseases, (1993)\nMilitary/Defense Clinical trials Military health\n\n🔗 Article\n\n\n\n\n\n\nThomas, Ronald G, Conlon, Michael, “An algorithm for the rapid evaluation of the power function for Fisher’s Exact Test”, Journal of statistical computation and simulation, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nBeuschel, T, Feldkeller, B, Fuchs, M, et al., “Calculation of observables in the pion-deuteron system. Berechnung von Observablen im Pion Deuteron-System”, Verhandlungen der Deutschen Physikalischen Gesellschaft;(Germany), (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nKerns, David L, Ritter, Mary L, Thomas, Ronald G, “Concave hymenal variations in suspected child sexual abuse victims”, Pediatrics, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nRAYNAULD, JP, THOMAS, RG, BLOCH, DA, “PROGRESSION OF FUNCTIONAL DISABILITY IN RHEUMATOID-ARTHRITIS”, ARTHRITIS AND RHEUMATISM, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald G, Conlon, Michael, “Sample size determination based on Fisher’s exact test for use in 2 x 2 comparative trials with low event rates”, Controlled clinical trials, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nFuchs, M, Huber, MG, Metsch, BC, et al., “Two-baryon systems with strangeness S=-1 and S=-2”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nSheridan, Lenore, Thomas, Ronald G, “An analysis of methods of communication in clinical trials”, Controlled Clinical Trials, (1991)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGordon, DE, Thomas, R, Shedrow, CB, et al., “Integration of statutory provisions of NEPA, RCRA, and CERCLA at the Savannah River site. Revision 1”, (1991)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nConlon, Michael, Thomas, Ronald G, “A new confidence interval for the difference of two binomial proportions”, Computational Statistics & Data Analysis, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Data monitoring through stochastic curtailing when the outcome proportions are small: An exact approach”, Controlled Clinical Trials, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, R, Empl, E, Kilian, K, et al., “Development of an active target for scattering of neutral baryons”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nDecker, G, Kilian, K, Lippert, C, et al., “Test measurements of an asymmetric induction drift chamber with flash ADC’s”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nTyrell, Doris, Cline, Dorothy R, Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nLee, Kelvin K, Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nHale, William E, May, Franklin E, Thomas, Ronald G, et al., “Effect of zinc supplementation on the development of cardiovascular disease in the elderly”, Journal of Nutrition for the Elderly, (1989)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Exact sample size calculations for 2x2 comparative trials when the outcome proportions are small”, Controlled Clinical Trials, (1989)\nGeneral Research\n\n🔗 Article\n\n\n\nEllis, Stephen G, Shaw, Richard E, Gershony, Gary, et al., “Risk factors, time course and treatment effect for restenosis after successful percutaneous transluminal coronary angioplasty of chronic total occlusion”, The American journal of cardiology, (1989)\nMedical/Clinical\n\n🔗 Article\n\n\n\n\n\n\nEllis, SG, Roubin, GS, King 3rd, SB, et al., “Angiographic and clinical predictors of acute closure after native vessel coronary angioplasty.”, Circulation, (1988)\nGeneral Research\n\n🔗 Article\n\n\n\nMELLEN, BG, THOMAS, RG, CASTANO, D, “FORMS INVENTORY SYSTEM FOR A COMPLEX CLINICAL-TRIAL”, CONTROLLED CLINICAL TRIALS, (1988)\nGeneral Research\n\n🔗 Article\n\n\n\nRoubin, Gary S, Douglas Jr, John S, King 3rd, SB, et al., “Influence of balloon size on initial success, acute complications, and restenosis after percutaneous transluminal coronary angioplasty. A prospective randomized study.”, Circulation, (1988)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nMufson, LGAR, Roubin, GS, Black, A, et al., “A comparison of single lesion dilatation in single vessel and multivessel disease”, Circulation, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nMcGlynn, F Dudley, LeCompte, E Joseph, Thomas, Ronald G, et al., “Effects of behavioral self-management on oral hygiene adherence among orthodontic patients”, American Journal of Orthodontics and Dentofacial Orthopedics, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nSherertz, Robert J, Belani, Anusha, Kramer, Barnett S, et al., “Impact of air filtration on nosocomial Aspergillus infections: unique risk of bone marrow transplant recipients”, The American journal of medicine, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nShcrertz, RJ, Belani, A, Kramer, BS, et al., “Impact of air filtration on nosocomial aspergillus infections”, Am J Med, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RG, Black, A, Lin, S, et al., “Is there dependence between sites for continued success or restenosis after successful multisite coronary angioplasty”, Circulation, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nRoubin, GS, Sutor, C, Lembo, NJ, et al., “PROGNOSIS AFTER MULTIPLE VESSEL ANGIOPLASTY (PTCA) IN PATIENTS WITH CORONARY-ARTERY DISEASE”, Circulation, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThal, Leon J, Grundman, Michael, Golden, Robert, “Alzheimer’s disease: a correlational analysis of the Blessed Information-Memory-Concentration test and the Mini-Mental State Exam”, Neurology, (1986)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nHUWS, DA, FAN, TP, THOMAS, RU, “ELUTION OF PROSTAGLANDIN-E2 FROM FILTER-PAPER STRIPS-EFFICIENCY AND REPRODUCIBILITY”, JOURNAL OF DENTAL RESEARCH, (1985)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nSchubert, Mark M, Guttu, Ronald L, Hunter, Letha H, et al., “Changes in shoulder and leg strength in athletes wearing mandibular orthopedic repositioning appliances”, The Journal of the American Dental Association, (1984)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nPepe, Paul E, Thomas, Ronald G, Stager, Marie Anne, et al., “Early prediction of the adult respiratory distress syndrome by a simple scoring method”, Annals of emergency medicine, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald J, Clark, Christopher A, “Effects of concomitant development on reproduction of Meloidogyne incognita and Rotylenchulus reniformis on sweet potato”, Journal of Nematology, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald J, Clark, Christopher A, “Population dynamics of Meloidogyne incognita and Rotylenchulus reniformis alone and in combination, and their effects on sweet potato”, Journal of Nematology, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\nSchubert, M, Guttu, R, Hunter, L, et al., “THE EFFECT OF MANDIBULAR ORTHOPEDIC REPOSITIONING APPLIANCES ON BODY STRENGTH”, JOURNAL OF DENTAL RESEARCH, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nTHOMAS, RJ, CA, CLARK, “CONCOMITANT REPRODUCTION AND POPULATION DYNAMICS OF MELOIDOGYNE INCOGNITA AND ROTYLENCHULUS RENIFORMIS ON SWEET POTATO”, (1982)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald James, “Interactions of Rotylenchulus Reniformis and Meloidogyne Incognita on Sweet Potato.”, (1982)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nGordon, D, Nouri, AM, Thomas, RU, “Selective inhibition of thromboxane biosynthesis in human blood mononuclear cells and the effects of mitogen-stimulated lymphocyte proliferation.”, British journal of pharmacology, (1981)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nGordon, D, Nouri, AME, Thomas, RU, “Dissociation of the proliferative response of mitogen-stimulated human lymphocytes from the release of lymphokine (S) that stimulate prostaglandin (PG) production by isolated rheumatoid adherent synovial cells (RASC)”, International Journal of Immunopharmacology, (1980)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nStotter, David A, Thomas, R David, Wilson, Michael T, “Reductive dechlorination of DDT by haem proteins”, Bioinorganic chemistry, (1977)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThomas, RU, Whittle, BJ, “Prostaglandins and the release of histamine from rat peritoneal mast cells [proceedings].”, British journal of pharmacology, (1976)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nDix, C, Thomas, RT, “A conductive mode amplifier for the scanning electron microscope”, Journal of Physics E: Scientific Instruments, (1972)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nGratze, SC, Thomas, RT, “Observations on epitaxial gallium arsenide varactor diodes using the scanning electron microscope”, Microelectronics Reliability, (1970)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RT, “Time dependence of the electrical conductivity of BaTiO3 single crystals heated in oxygen”, Journal of Physics D: Applied Physics, (1970)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThomas, Reid, “Essays on the Intellectual Powers of Man”, (1901)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nReid, Thomas, “Essays on the Powers of the Human Mind: To which are Prefixed an Essay on Quantity, and an Analysis of Aristotle’s Logic”, (1819)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThomas, Reid, “An Inquiry into the Human Mind on the Principles of Common Sense”, (1764)\nGeneral Research\n\n🔗 Article"
  },
  {
    "objectID": "research/index.html#publications",
    "href": "research/index.html#publications",
    "title": "Research",
    "section": "",
    "text": "333 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\n\n\n\n\nNote\n\n\n\nFilter by Topic: Click any badge below to filter publications by research area.\nMedical/Clinical Military/Defense Neuroimaging/Technical COVID/Healthcare General Research\n\nClear All Filters\n\n\n\n\n\n\nGalasko, Douglas, Farlow, Martin R, Lucey, Brendan P, et al., “A multicenter, randomized, double-blind, placebo-controlled ascending dose study to evaluate the safety, tolerability, pharmacokinetics (PK) and pharmacodynamic (PD) effects of Posiphen in subjects with Early Alzheimer’s Disease”, Alzheimer’s Research & Therapy, (2024)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nMcEvoy, Cory, Crabtree, Adam, Case, John, et al., “Cumulative blast impulse is predictive for changes in chronic neurobehavioral symptoms following low level blast exposure during military training”, Military medicine, (2024)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kathleen F, Muzi, Mark, et al., “Increased [18F] Fluorodeoxyglucose Uptake in the Left Pallidum in Military Veterans with Blast-Related Mild Traumatic Brain Injury: Potential as an Imaging Biomarker and Mediation with Executive Dysfunction and Cognitive Impairment”, Journal of Neurotrauma, (2024)\nMedical/Clinical Traumatic brain injury Military health Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\n\n\n\nReiman, Eric M, Pruzin, Jeremy J, Rios-Romenets, Silvia, et al., “A public resource of baseline data from the Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nRaskind, Murray A, Williams, Tammy, Holmes, Hollie, et al., “A randomized controlled clinical trial of prazosin for alcohol use disorder in active duty soldiers: Predictive effects of elevated cardiovascular parameters”, Alcoholism: Clinical and Experimental Research, (2023)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kati, Muzi, Mark, et al., “FDG-PET as a Clinical Diagnostic Biomarker for Repetitive Blast Mild Traumatic Brain Injury”, NEUROPSYCHOPHARMACOLOGY, (2023)\nMilitary/Defense Traumatic brain injury Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Su, Yi, et al., “Impact of reference region on longitudinal florbetapir PET SUVR changes from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2023)\nNeuroimaging/Technical Neuroimaging\n\n🔗 Article\n\n\n\nKeil, Samantha A, Schindler, Abigail G, Wang, Marie X, et al., “Longitudinal Sleep Patterns and Cognitive Impairment in Older Adults”, JAMA Network Open, (2023)\nMedical/Clinical Sleep disorders\n\n🔗 Article\n\n\n\nMeabon, James S, Schindler, Abigail G, Murray, Daniel R, et al., “Pontine pathology mediates common symptoms of blast-induced chronic mild traumatic brain injury”, medRxiv, (2023)\nMilitary/Defense Traumatic brain injury\n\n🔗 Article\n\n\n\nQiu, Yuqi, Messer, Karen, Jacobs, Diane M, et al., “Prognostic value of plasma biomarkers in a clinical trial of mild-to-moderate Alzheimer’s Disease”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, McCall, Catherine A, Rosser, Aaron F, et al., “The relative contribution of COVID-19 infection versus COVID-19 related occupational stressors to insomnia in healthcare workers”, Sleep medicine: X, (2023)\nCOVID/Healthcare COVID-19 Sleep disorders\n\n🔗 Article\n\n\n\n\n\n\nJansson, Deidre, Wang, Marie, Thomas, Ronald G., et al., “Markers of Cerebrovascular Injury, Inflammation, and Plasma Lipids Are Associated with Alzheimer’s Disease Cerebrospinal Fluid Biomarkers in Cognitively Normal Persons”, Journal of Alzheimer’s Disease, (2022)\nMedical/Clinical Alzheimer’s disease Biomarkers\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, et al., “Sex differences in cognitive resilience in preclinical autosomal-dominant Alzheimer’s disease carriers and non-carriers: baseline findings from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2022)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nShadyab, Aladdin H, LaCroix, Andrea Z, Matthews, Genevieve, et al., “T2 Protect AD: Achieving a rapid recruitment timeline in a multisite clinical trial for individuals with mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2022)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Slevin, Rois', “The impact of the COVID-19 pandemic on mental health, occupational functioning, and professional retention among health care workers and first responders”, Journal of general internal medicine, (2022)\nCOVID/Healthcare COVID-19\n\n🔗 Article\n\n\n\n\n\n\nSalloway, Stephen, Farlow, Martin, McDade, Eric, et al., “A trial of gantenerumab or solanezumab in dominantly inherited Alzheimer’s disease”, Nature Medicine, (2021), doi: 10.1038/s41591-021-01369-8\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article • 📄 PDF\n\n\n\nBinette, Alexa Pichet, Vachon-Presseau, Etienne, Morris, John, et al., “Amyloid and tau pathology associations with personality traits, neuropsychiatric symptoms, and cognitive lifestyle in the preclinical phases of sporadic and autosomal dominant Alzheimer’s disease”, Biological psychiatry, (2021)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, et al., “Optimizing aggregated N-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Creating Evidence from Real World Patient Digital Data, (2021)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nHu, Nan, Mackey, Howard, Thomas, Ronald, “Power and sample size for random coefficient regression models in randomized experiments with monotone missing data”, Biometrical Journal, (2021)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nMatthews, Dawn C, Ritter, Aaron, Thomas, Ronald G, et al., “Rasagiline effects on glucose metabolism, cognition, and tau in Alzheimer’s dementia”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2021)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nShadyab, Aladdin, others, “Recruitment of a multi-site randomized controlled trial of aerobic exercise for older adults with amnestic mild cognitive impairment: the EXERT trial”, Alzheimer’s & Dementia, (2021)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Slevin, Rois', “The Impact of the COVID-19 Pandemic on Mental Health, Occupational Functioning, and Professional Retention Among Health Care Workers and First Responders”, Journal of general internal medicine, (2021)\nCOVID/Healthcare COVID-19\n\n🔗 Article\n\n\n\n\n\n\nRios-Romenets, Silvia, Lopera, Francisco, Sink, Kaycee M, et al., “Baseline demographic, clinical, and cognitive characteristics of the Alzheimer’s Prevention Initiative (API) Autosomal-Dominant Alzheimer’s Disease Colombia Trial”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, et al., “Development of a novel cognitive composite outcome to assess therapeutic effects of exercise in the EXERT trial for adults with MCI: The ADAS-Cog-Exec”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2020)\nMedical/Clinical\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, et al., “Optimizing aggregated n-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Frontiers in Digital Health, (2020)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Goradia, Dhruman D, et al., “PET evidence of preclinical cerebellar amyloid plaque deposition in autosomal dominant Alzheimer’s disease”, 2020 Alzheimer’s Association International Conference, (2020)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, et al., “Sex differences in neurodegeneration and memory performance in preclinical autosomal dominant Alzheimer’s disease: Baseline findings from the API ADAD trial: Intersections of sex/gender and race/ethnicity in cognitive aging and Alzheimer’s disease trajectories”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLangbaum, Jessica B, Ellison, Noel N, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative Composite Cognitive Test: a practical measure for tracking cognitive decline in preclinical Alzheimer’s disease”, Alzheimer’s Research & Therapy, (2020)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMatthews, Dawn, Ritter, Aaron, Thomas, Ronald G, et al., “The Effects of Rasagiline on Glucose Metabolism and Cognition and Their Relationship to Tau Burden in a Double-Blind, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia”, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia (2/21/2020), (2020)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nSano, Mary, Zhu, Carolyn W, Kaye, Jeffrey, et al., “A randomized clinical trial to evaluate home-based assessment of people over 75 years old”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Sink, Kaycee, et al., “F4-04-01: TRIAL DESIGN, DATA SHARING RISK MITIGATION, AND BASELINE CLINICAL AND COGNITIVE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nAcosta-Baena, Natalia, Rios-Romenets, Silvia, Munoz, Claudia, et al., “F4-04-02: AGE-RELATED CHANGES IN BASELINE COGNITIVE MEASURES IN UNIMPAIRED PSEN1 E280A MUTATION CARRIERS AND NON-CARRIERS IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSu, Yi, Rios-Romenets, Silvia, Tariot, Pierre N, et al., “F4-04-03: RELATIONSHIPS BETWEEN BASELINE BRAIN IMAGING BIOMARKER MEASUREMENTS AND AGE IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nQuiroz, Yakeel T, Tariot, Pierre N, Sink, Kaycee, et al., “F4-04-04: ASSOCIATION BETWEEN CEREBRAL AMYLOIDOSIS AND WORSE COGNITIVE PERFORMANCE IN PRECLINICAL AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE: BASELINE FINDINGS FROM THE API COLOMBIA AUTOSOMAL DOMINANT AD TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, Lon S, Geffen, Yona, Rabinowitz, Jonathan, et al., “Low-dose ladostigil for mild cognitive impairment: A phase 2 placebo-controlled clinical trial”, Neurology, (2019)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nHuisa, Branko N, Thomas, Ronald G, Jin, Shelia, et al., “Memantine and acetylcholinesterase inhibitor use in Alzheimer’s disease clinical trials: Potential for confounding by indication”, Journal of Alzheimer’s Disease, (2019)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKilian, Hett, Vinh-Thong, Ta, Gwenaelle, Catheline, et al., “Multimodal Hippocampal Subfield Grading For Alzheimer’s Disease Classification”, Scientific Reports (Nature Publisher Group), (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLiu, Jiao, Zhang, Binlong, Wilson, Georgia, et al., “New Perspective for Non-invasive Brain Stimulation Site Selection in Mild Cognitive Impairment: Based on Meta-and Functional Connectivity Analyses”, Frontiers in aging neuroscience, (2019)\nMedical/Clinical\n\n🔗 Article\n\n\n\nGupta, Yubraj, Lama, Ramesh Kumar, Kwon, Goo-Rak, et al., “Prediction and classification of Alzheimer’s disease based on combined features from apolipoprotein-E genotype, cerebrospinal fluid, MR, and FDG-PET imaging biomarkers”, Frontiers in computational neuroscience, (2019)\nMedical/Clinical Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nZhao, Qian, Liu, Min, Ha, Lingxia, et al., “Quantitative 18F-AV1451 brain tau PET imaging in cognitively normal older adults, mild cognitive impairment, and Alzheimer’s disease patients”, Frontiers in neurology, (2019)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, et al., “Safety and efficacy of edonerpic maleate for patients with mild to moderate Alzheimer disease: a phase 2 randomized clinical trial”, JAMA neurology, (2019)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBorowsky, Beth, Lopez, Cristina Lopez, Tariot, Pierre, et al., “The Alzheimer Prevention Initiative Generation Program: Evaluation of CNP520 in Preclinical Alzheimer’s Disease (P4. 1-005)”, (2019)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLopez, Cristina Lopez, Tariot, Pierre N, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative Generation Program: study design of two randomized controlled trials for individuals at risk for clinical onset of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2019)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nKlinger, Rebecca Y, James, Olga G, Borges-Neto, Salvador, et al., “18F-florbetapir Positron Emission Tomography–determined Cerebral beta-Amyloid Deposition and Neurocognitive Performance after Cardiac Surgery”, Anesthesiology, (2018)\nMedical/Clinical\n\n🔗 Article\n\n\n\nRafii, Michael S, Tuszynski, Mark H, Thomas, Ronald G, et al., “Adeno-associated viral vector (serotype 2)–nerve growth factor for patients with alzheimer disease: a randomized clinical trial”, JAMA neurology, (2018)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHuisa, Branko, Thomas, Ronald, Jin, Shelia, et al., “Memantine and Cholinesterase Inhibitor Use in Alzheimer Disease Trials: Potential for Confounding by Indication (P6. 178)”, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, et al., “P3-032: SCREENING-TO-BASELINE COGNITIVE VARIABILITY DOES NOT PREDICT RATE OF DECLINE IN A CLINICAL TRIAL OF MILD-TO-MODERATE AD”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nReiman, Eric M, Sink, Kaycee M, Hu, Nan, et al., “P4-209: A PUBLIC RESOURCE OF BASELINE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nVerfaillie, Sander CJ, Binette, Alexa Pichet, Vachon-Presseau, Etienne, et al., “Subjective cognitive decline is associated with altered default mode network connectivity in individuals with a family history of Alzheimer’s disease”, Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Langbaum, Jessica B, et al., “The Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial: A study of crenezumab versus placebo in preclinical PSEN1 E280A mutation carriers to evaluate efficacy and safety in the treatment of autosomal-dominant Alzheimer’s disease, including a placebo-treated noncarrier cohort”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2018)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nRelkin, Norman R, Thomas, Ronald G, Rissman, Robert A, et al., “A phase 3 trial of IV immunoglobulin for Alzheimer disease”, Neurology, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLim, Yen Ying, Mormino, Elizabeth C, Alzheimer’s Disease Neuroimaging Initiative, et al., “APOE genotype and early beta-amyloid accumulation in older adults without dementia”, Neurology, (2017)\nMedical/Clinical\n\n🔗 Article\n\n\n\nRusso, Mar', “Adding recognition discriminability index to the delayed recall is useful to predict conversion from mild cognitive impairment to Alzheimer’s disease in the Alzheimer’s disease neuroimaging initiative”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nRisacher, Shannon L, Anderson, Wesley H, Charil, Arnaud, et al., “Alzheimer disease brain atrophy subtypes are associated with cognition and rate of decline”, Neurology, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMunilla, Jorge, Ortiz, Andres, Gorriz, Juan M, et al., “Construction and analysis of weighted brain networks from sice for the study of Alzheimer’s disease”, Frontiers in neuroinformatics, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGuo, Shengwen, Lai, Chunren, Wu, Congling, et al., “Conversion discriminative analysis on mild cognitive impairment using multiple cortical features from MR images”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Aisen, Paul S, et al., “Randomized controlled trials in mild cognitive impairment: sources of variability”, Neurology, (2017)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nPark, Jong-Yun, Na, Han Kyu, Kim, Sungsoo, et al., “Robust identification of Alzheimer’s disease subtypes based on cortical atrophy patterns”, Scientific reports, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre, Lopez-Lopez, Cristina, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative (API) Generation Program: Evaluating the Efficacy of the BACE-1 Inhibitor CNP520 in Preclinical Alzheimer’s Disease”, NEUROPSYCHOPHARMACOLOGY, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLopez, C Lopez, Caputo, A, Liu, F, et al., “The Alzheimer’s Prevention Initiative Generation Program: evaluating CNP520 efficacy in the prevention of Alzheimer’s disease”, J Prev Alzheimers Dis, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nCaputo, Angelika, Racine, Amy, Paule, Ines, et al., “[O5–01–02]: RATIONALE FOR SELECTION OF PRIMARY ENDPOINTS IN THE ALZHEIMER PREVENTION INITIATIVE GENERATION STUDY IN COGNITIVELY HEALTHY APOE4 HOMOZYGOTES”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, et al., “[P4–573]: A PHASE 2 MULTICENTER, RANDOMIZED, PLACEBO-CONTROLLED TRIAL TO EVALUATE THE EFFICACY AND SAFETY OF EDONERPIC (T-817) IN PATIENTS WITH MILD TO MODERATE ALZHEIMER’s DISEASE”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nLiu, Haochen, Zhou, Xiaoting, Jiang, Hao, et al., “A semi-mechanism approach based on MRI and proteomics for prediction of conversion from mild cognitive impairment to Alzheimer’s disease”, Scientific reports, (2016)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nGelmont, David, Thomas, Ronald G, Britt, Jonathan, et al., “Demonstration of safety of intravenous immunoglobulin in geriatric patients in a long-term, placebo-controlled study of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2016)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDeming, Yuetiva, Xia, Jian, Cai, Yefei, et al., “Genetic studies of plasma analytes identify novel potential biomarkers for several complex traits”, Scientific Reports, (2016)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nThomas, Ronald G, Albert, Marilyn, Petersen, Ronald C, et al., “Longitudinal decline in mild-to-moderate Alzheimer’s disease: analyses of placebo data from clinical trials”, Alzheimer’s & Dementia, (2016)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre, Langbaum, Jessica, Schneider, Lon, et al., “The Alzheimer’s Prevention Initiative Generation Study: A Preclinical Trial in APOE4 Homozygotes”, NEUROPSYCHOPHARMACOLOGY, (2016)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nTurner, R Scott, Thomas, Ronald G, Craft, Suzanne, et al., “A randomized, double-blind, placebo-controlled trial of resveratrol for Alzheimer disease”, Neurology, (2015)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nChen, Chi-Hua, Peng, Qian, Schork, Andrew J, et al., “Large-scale genomics unveil polygenic architecture of human cortical surface area”, Nature communications, (2015)\nGeneral Research\n\n🔗 Article\n\n\n\nDonohue, Michael C, Moghadam, Setareh H, Roe, Allyson D, et al., “Longitudinal plasma amyloid beta in Alzheimer’s disease clinical trials”, Alzheimer’s & Dementia, (2015)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Raman, Rema, Sperling, Reisa A, et al., “Peripheral and central effects of \\\\gamma-secretase inhibition by semagacestat in Alzheimer’s disease”, Alzheimer’s research & therapy, (2015)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTurner, R, Thomas, Ronald, Craft, Suzanne, et al., “Resveratrol is safe and well-tolerated in individuals with mild-moderate dementia due to Alzheimer’s disease.(S33. 009)”, (2015)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGelmont, D, Thomas, RG, Dyck-Jones, JA, et al., “Safety of Intravenous Immunoglobulin Therapy in Patients with Probable Alzheimer’s Disease: A Randomized, Placebo-Controlled Clinical Study”, ANNALS OF ALLERGY ASTHMA & IMMUNOLOGY, (2015)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nOrban, Pierre, Madjar, C'e, “Test-retest resting-state fMRI in healthy elderly persons with a family history of Alzheimer’s disease”, Scientific data, (2015)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nNewman, Rhian C, Ellis, Tim, Davison, Phil I, et al., “Using novel methodologies to examine the impact of artificial light at night on the cortisol stress response in dispersing Atlantic salmon (Salmo salar L.) fry”, Conservation physiology, (2015)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nDoody, RS, Thomas, RG, Farlow, M, et al., “Alzheimer’s Disease Cooperative Study Steering Committee; Solanezumab study group. Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, MC, Sperling, RA, Salmon, DP, et al., “Australian imaging, biomarkers, and lifestyle flagship study of ageing; Alzheimer’s disease neuroimaging initiative; Alzheimer’s disease cooperative study. The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA Neurol, (2014)\nMedical/Clinical Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nChen, Yun-Fei, Mohs, Richard, Ding, Ying, et al., “Bayesian Longitudinal Modeling on Placebo Data from Alzheimer’s Disease Clinical Studies (P1. 010)”, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bell, Joanne, Mancuso, Jessica Y, et al., “Clinical trial of an inhibitor of RAGE-A beta interactions in Alzheimer disease”, Neurology, (2014)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Jacqmin-Gadda, Hene, Le Goff, Melanie, et al., “Estimating long-term multivariate progression from short-term data”, Alzheimer’s & Dementia, (2014)\nGeneral Research\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, Anthony, Jack, Clifford, et al., “F3-02-02: MODELING LONG-TERM DISEASE PROGRESSION WITH COVARIATES”, Alzheimer’s & Dementia, (2014)\nGeneral Research\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo Adolfo, Thomas, Ronald G, Qiu, Hongmei, et al., “P1-357: ADCS EDC: INVESTIGATIONAL PRODUCT MANAGEMENT SYSTEM”, Alzheimer’s & Dementia, (2014)\nGeneral Research\n\n🔗 Article\n\n\n\nLaske, Christoph, “Phase 3 trials of solanezumab and bapineuzumab for Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Thomas, Ronald G, Farlow, Martin, et al., “Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, New England Journal of Medicine, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, Michael C, Sperling, Reisa A, Salmon, David P, et al., “The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA neurology, (2014)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nDoody, Rachelle S, Raman, Rema, Farlow, Martin, et al., “A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, New England Journal of Medicine, (2013)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSalmon, David P, Ferris, Steven H, Thomas, Ronald G, et al., “Age and apolipoprotein E genotype influence rate of cognitive decline in nondemented elderly.”, Neuropsychology, (2013)\nMedical/Clinical\n\n🔗 Article\n\n\n\nDoody, RS, Raman, R, Farlow, M, et al., “Alzheimer’s Disease Cooperative Study Steering Committee, Siemers E, Sethuraman G, Mohs R, Semagacestat Study Group. A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, N Engl J Med, (2013)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nPosner, Holly B, Cano, Stefan, Carrillo, Maria C, et al., “Establishing the psychometric underpinning of cognition measures for clinical trials of Alzheimer’s disease and its precursors: a new approach”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBurstein, Aaron, Galasko, Douglas, Aisen, Paul, et al., “P1–332: Evaluation of the relationship between TTP488 plasma concentrations and changes in ADAS-cog relative to placebo”, Alzheimer’s & Dementia, (2013)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald, Petersen, Ronald, Siuciak, Judith, et al., “P3–295: The Placebo Data Analysis in Alzheimer’s Disease (AD) and Mild Cognitive Impairment (MCI) Clinical Trials Project: Overview of progress in trial data collection, and key findings from the pooled Alzheimer’s disease trial datasets”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Bruschi, Stefania, et al., “P4–157: Adcs electronic data capture: Collaborative development and management of clinical trial databases”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nMills, Sarah M, Mallmann, J, Santacruz, Anna M, et al., “Preclinical trials in autosomal dominant AD: implementation of the DIAN-TU trial”, Revue neurologique, (2013)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nHobart, Jeremy, Cano, Stefan, Posner, Holly, et al., “Putting the Alzheimer’s cognitive test to the test II: Rasch Measurement Theory”, Alzheimer’s & dementia, (2013)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nAustin, David, Thomas, Rob, “A Garden before the Garden: Landscape, History and the National Botanic Garden of Wales”, Landscapes, (2012)\nGeneral Research\n\n🔗 Article\n\n\n\nGalasko, DR, Peskind, E, Clark, CM, et al., “Alzheimer’s Disease Cooperative Study. Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Arch Neurol, (2012)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nVellas, B, Hampel, H, Roug'e, “Alzheimer’s disease therapeutic trials: EU/US Task Force report on recruitment, retention, and methodology”, The journal of nutrition, health & aging, (2012)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas R, Peskind, Elaine, Clark, Christopher M, et al., “Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Archives of neurology, (2012)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Jin, Shelia, He, Feng, et al., “Incidence of new-onset seizures in mild to moderate Alzheimer disease”, Archives of neurology, (2012)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nRelkin, Norman, Gessert, Devon, Stokes, Karen, et al., “O3-13-05: The Gammaglobulin Alzheimer Partnership Study (GAP): Design, screening, enrollment and futility analysis results”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Hong, Phuoc, et al., “P3-364: ADCS EDC”, Alzheimer’s & Dementia, (2012)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald, Jimenez, Gustavo, Brewer, James, et al., “P3-383: ADCS data sharing”, Alzheimer’s & Dementia, (2012)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, Paul, Thomas, Ronald, Carrillo, Maria, et al., “P3-384: The placebo data analysis in Alzheimer’s disease and mild cognitive impairment (MCI) clinical trials project: Overview of progress in trial data collection, and key findings from the pooled MCI trial datasets”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nRafii, MS, Walsh, S, Little, JT, et al., “A phase II trial of huperzine A in mild to moderate Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Bell, KL, Galasko, D, et al., “A randomized, double-blind, placebo-controlled trial of simvastatin to treat Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Raman, Rema, Emond, Jennifer, et al., “Adding delayed recall to the Alzheimer Disease Assessment Scale is useful in studies of mild cognitive impairment but not Alzheimer disease”, Alzheimer disease and associated disorders, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Schneider, Lon S, Cummings, Jeffrey, et al., “Chronic divalproex sodium to attenuate agitation and clinical progression of Alzheimer disease”, Archives of General Psychiatry, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nFleisher, AS, Truran, D, Mai, JT, et al., “Chronic divalproex sodium use and brain atrophy in Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMockus, Danyte S, Macera, Caroline A, Wingard, Deborah L, et al., “Dietary self-monitoring and its impact on weight loss in overweight children”, International Journal of Pediatric Obesity, (2011)\nGeneral Research\n\n🔗 Article\n\n\n\nQuinn, JF, Raman, R, Thomas, RG, et al., “Omega-3 Fatty Acids for Alzheimer’s Disease. What a Pill Can Tell Us about Eating Fish”, (2011)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMessick, Viviana, Donohue, Michael, Raman, Rema, et al., “P3-406: Role of caregiver in subject’s compliance with treatment”, Alzheimer’s & Dementia, (2011)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSmart, N, George, A, Khan, D, et al., “Radiological follow up of perineal repair with cross-linked acellular porcine dermal collagen following extralevator abdominoperineal excision for low rectal cancer: P115”, Colorectal Disease, (2011)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, PS, Andrieu, S, Sampaio, C, et al., “Report of the task force on designing clinical trials in early (predementia) AD”, Neurology, (2011)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, AC, Thomas, RG, et al., “The relative efficiency of time-to-threshold and rate of change in longitudinal data”, Contemporary clinical trials, (2011)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nAisen, Paul S, Petersen, Ronald C, Donohue, Michael C, et al., “Clinical Core of the Alzheimer’s Disease Neuroimaging Initiative: progress and plans”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, et al., “Docosahexaenoic acid supplementation and cognitive decline in Alzheimer disease: a randomized trial”, Jama, (2010)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael, Gamst, Anthony, Thomas, Ron, et al., “O3-01-07: Rate of decline in ADNI normal controls with evidence of amyloid burden”, Alzheimer’s & Dementia, (2010)\nGeneral Research\n\n🔗 Article\n\n\n\nFleisher, Adam S, Jack Jr, Clifford R, Weiner, Michael W, et al., “P1-433: Brain volume changes with divalproex sodium in Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Thomas, Ronald, Raman, Rema, et al., “P1-447: Cerebrospinal fluid biomarker outcomes in a trial of docosahexaenoic acid (DHA) for Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Alzheimer’s disease Biomarkers\n\n🔗 Article\n\n\n\n\n\n\nRaman, Rema, Thomas, Ronald G, Weiner, Michael W, et al., “MRI substudy participation in Alzheimer disease (AD) clinical trials: baseline comparability of a substudy sample to entire study population”, Alzheimer disease and associated disorders, (2009)\nMedical/Clinical Alzheimer’s disease Clinical trials Neuroimaging\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, et al., “O1-04-02: A clinical trial of docosahexanoic acid (DHA) for the treatment of Alzheimer’s disease”, Alzheimer’s & Dementia, (2009)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Aisen, Paul, Cummings, Jeffrey, et al., “O1-04-03: The ADCS valproate neuroprotection trial: Primary efficacy and safety results”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nCano, Stefan, Posner, Holly, Aisen, Paul, et al., “O4-04-07: The ADAS-cog’s performance as a measure—lessons from the ADNI study: Part 2-evaluation using modern psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nPosner, Holly, Cano, Stefan, Aisen, Paul, et al., “P1-269: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 1-evaluation using traditional psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nHobart, Jeremy, Posner, Holly, Aisen, Paul, et al., “P1-270: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 3-do the scale modifications add value?”, Alzheimer’s & Dementia, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Raman, Rema, Schwarzschild, Michael A, et al., “Plasma urate and progression of mild cognitive impairment”, Neurodegenerative Diseases, (2009)\nMedical/Clinical\n\n🔗 Article\n\n\n\nMachado, C, Leisman, G, Koch, P, et al., “REVIEWS IN THE NEUROSCIENCES”, NEUROSCIENCES, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\nPasner, Holly, Cano, Stefan J, Aisen, Paul, et al., “The ADAS-cog’s Performance as a Measure Lessons from the ADNI Study: Part 1-Evaluation Using Traditional Psychometric Methods”, Neurology, (2009)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nKhachaturian, Zaven S, Petersen, Ronald C, Gauthier, Serge, et al., “A roadmap for the prevention of dementia: the inaugural Leon Thal Symposium”, Alzheimer’s & dementia: the journal of the Alzheimer’s Association, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\nAisen, PS, Schneider, LS, Sano, M, et al., “Alzheimer Disease Cooperative Study. High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nRoch-Levecq, Anne-Catherine, Brody, Barbara L, Thomas, Ronald G, et al., “Ametropia, preschoolers’ cognitive abilities, and effects of spectacle correction”, Archives of ophthalmology, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\nDoody, RS, Gavrilova, SI, Sano, M, et al., “Dimebon investigators: Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, Lancet, (2008)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, et al., “Dual Task Test Could Help Diagnose Dementia”, JAMA, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana I, Sano, Mary, et al., “Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, The Lancet, (2008)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nMeyer, Brett C, Raman, Rema, Hemmen, Thomas, et al., “Efficacy of site-independent telemedicine in the STRokE DOC trial: a randomised, blinded, prospective study”, The Lancet Neurology, (2008)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, et al., “High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Peskind, Elaine, Clark, Christopher M, et al., “O2-04–06: Randomized clinical trial of antioxidant treatment in Alzheimer’s disease with CSF biomarker measures”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Thomas, Ronald, et al., “P4-337: Dimebon improves cognition, function, and behavior in mild and moderate Alzheimer’s disease: Results by severity of a one-year, double-blind, placebo-controlled study”, Alzheimer’’s and Dementia, (2008)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald, et al., “P4-343: Omega 3 fatty acids and Alzheimer’s disease: Trial design and baseline study population characteristics in a clinical trial of docosahexanoic acid for Alzheimer’s disease”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nRaman, Rema, Emond, Jennifer, Thomas, Ronald G, et al., “P4-387: Adding delayed recall to the Alzheimer’s disease assessment scale-cognitive subscale (ADAS-cog): Sensitivity in a clinical trial for Alzheimer’s disease and mild cognitive impairment”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDoody, Rachelle, Seely, Lynn, Thomas, Ronald, et al., “Statistical treatment of withdrawal in trials of anti-dementia drugs–Authors’ reply”, The Lancet, (2008)\nMedical/Clinical\n\n🔗 Article\n\n\n\n\n\n\nDoody, Rochelle, Gavrilova, Svetlana, Sano, Mary, et al., “Dimebon improves cognition, function, and behavior in patients with mild-moderate Alzheimer’s disease: Results of a randomized, double-blind, placebo-controlled study”, Neurology, (2007)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Kaye, Jeffrey, Ferris, Steven, et al., “P-081: The ACDS home assessment instrument: A pilot study”, Alzheimer’s & Dementia, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nTHOMAS, RONALD J, CLARK, CHRISTOPHER A, “Population Dynamics of Meloidogyne incognita and RotylenchulusTenchulus reniformis Alone and in Combination, and Their Effects on Sweet Potato1”, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nMay, Susanne, Gilman, Sid, Sowell, B Brooke, et al., “Potential outcome measures and trial design issues for multiple system atrophy”, Movement disorders, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, Paul S, Jin, Shelia, Thomas, Ronald G, et al., “S3–02–01: ADCS homocysteine trial”, Alzheimer’s & Dementia, (2007)\nGeneral Research\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Sano, Mary, et al., “S3–02–03: Results of a one-year randomized, placebo-controlled trial of dimebon for the treatment of mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia, (2007)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nSano, Mary, Zhu, Carolyn W, Whitehouse, Peter J, et al., “ADCS Prevention Instrument Project: pharmacoeconomics: assessing health-related resource use among healthy elderly”, Alzheimer disease and associated disorders, (2006)\nGeneral Research\n\n🔗 Article\n\n\n\nPetersen, Ronald, Thomas, Ronald, Grundman, Michael, et al., “Cognitive Changes in the Treatment of Mild Cognitive Impairment with Donepezil and Vitamin E: P02. 187”, Neurology, (2006)\nMedical/Clinical\n\n🔗 Article\n\n\n\n\n\n\nKrajewska, Maryla, Kim, Hoguen, Kim, Chul, et al., “Analysis of apoptosis protein expression in early-stage colorectal cancer suggests opportunities for new prognostic biomarkers”, Clinical Cancer Research, (2005)\nNeuroimaging/Technical Biomarkers\n\n🔗 Article\n\n\n\nPfeiffer, E, Petersen, RC, Thomas, RG, et al., “Cognition in the treatment of mild cognitive impairment with donepezil and vitamin E”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nRoch–Levecq, A–C, Brody, B, Thomas, RG, et al., “Cognitive Outcomes of Corrective Lenses on Low Income Preschoolers With Hyperopia/Astimgatism: A Longitudinal Pilot Study”, Investigative Ophthalmology & Visual Science, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nGalasko, D, Schmitt, F, Thomas, R, et al., “Detailed assessment of activities of daily living in moderate to severe Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Raman, Rema, Jakimovich, Laura, et al., “Divalproex sodium in nursing home residents with possible or probable Alzheimer disease complicated by agitation: a randomized, controlled trial”, The American journal of geriatric psychiatry, (2005)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nPeskind, Elaine R, Tsuang, Debby W, Bonner, Lauren T, et al., “Propranolol for disruptive behaviors in nursing home residents with probable or possible Alzheimer disease: a placebo-controlled study”, Alzheimer Disease & Associated Disorders, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nEdland, SD, May, S, Emond, JA, et al., “Sample size considerations in dementia prevention trials: Data from the Alzheimer’s disease Cooperative Study MCI Trial”, NEUROLOGY, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nBrody, Barbara L, Roch-Levecq, Anne-Catherine, Thomas, Ronald G, et al., “Self-management of age-related macular degeneration at the 6-month follow-up: a randomized controlled trial”, Archives of Ophthalmology, (2005)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Grundman, M, et al., “Treatment of MCI with cholinesterase inhibitors: current data”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, et al., “Vitamin E and donepezil for the treatment of mild cognitive impairment”, New England Journal of Medicine, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, et al., “[O1-04-04]: Operational criteria for patient recruitment in trials of mild cognitive impairment”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Grundman, Michael, et al., “[O2-01-01]: Donepezil and vitamin E in the progression of mild cognitive impairment to Alzheimer’s disease: A hazard-ratio analysis”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nHamilton, Joanne M, Salmon, David P, Galasko, Douglas, et al., “A comparison of episodic memory deficits in neuropathologically-confirmed Dementia with Lewy bodies and Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2004)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nThomas, Ronald G, Aisen, Paul S, Shoulson, Ira, et al., “Distinguished From Alzheimer Disease and Normal Aging for Clinical Trials Michael Grundman, MD, MPH; Ronald C. Petersen, PhD, MD; Steven H. Ferris, PhD”, (2004)\nMedical/Clinical Alzheimer’s disease Clinical trials Neuroimaging\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Thal, L, “Donepezil and vitamin E for mild cognitive impairment”, 9th International Congress on Alzheimer’s Disease. Philadelphia, (2004)\nMedical/Clinical\n\n🔗 Article\n\n\n\nArgent, R, Thomas, R, Boughan, P, et al., “MAP kinase inhibitors reduce Helicobacter pylori-induced interleukin-8 secretion and the phosphorylation of I\\\\kappaB\\\\\\\\alpha”, Helicobacter, (2004)\nGeneral Research\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Ferris, Steven H, et al., “Mild cognitive impairment can be distinguished from Alzheimer disease and normal aging for clinical trials”, Archives of neurology, (2004)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, et al., “P1-003 ADCS Prevention instrument project: assessment of activities of daily living (ADL)”, Neurobiology of Aging, (2004)\nGeneral Research\n\n🔗 Article\n\n\n\nTariot, Pierre N, Thal, Leon, Jakimovich, Laura, et al., “P1-322 A multicenter, randomized, double-blind, placebo-controlled trial of valproate for agitation associated with dementia”, Neurobiology of Aging, (2004)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Tractenberg, Rochelle E, Sano, Mary, et al., “Reliability of monitoring the clinical dementia rating in multicenter clinical trials”, Alzheimer disease and associated disorders, (2004)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon, “S5-03-02 Prevention trials in Alzheimer’s disease: design issues”, Neurobiology of Aging, (2004)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nSinger, Clifford, Tractenberg, Rochelle E, Kaye, Jeffrey, et al., “A multicenter, placebo-controlled trial of melatonin for sleep disturbance in Alzheimer’s disease”, Sleep, (2003)\nMedical/Clinical Alzheimer’s disease Sleep disorders\n\n🔗 Article\n\n\n\nGrundman, M, Capparelli, E, Kim, HT, et al., “A multicenter, randomized, placebo controlled, multiple-dose, safety and pharmacokinetic study of AIT-082 (Neotrofin™) in mild Alzheimer’s disease patients”, Life sciences, (2003)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, PS, Schafer, KA, Grundman, M, et al., “Alzheimer’s Disease Cooperative Study. Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly A, Grundman, Michael, et al., “Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Mulnard, Ruth, et al., “Estrogen levels do not correlate with improvement in cognition”, Archives of Neurology, (2003)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RG, Choudhury, RK, Mohanty, AK, et al., “Fission fragment angular distributions: A probe to study heavy-ion fusion dynamics”, Physical Review C, (2003)\nGeneral Research\n\n🔗 Article\n\n\n\nGrundman, Michael, Jack, Clifford R, Petersen, Ronald C, et al., “Hippocampal volume is associated with memory but not nonmemory cognitive performance in patients with mild cognitive impairment”, Journal of Molecular Neuroscience, (2003)\nMedical/Clinical\n\n🔗 Article\n\n\n\nThal, LJ, Grundman, M, Berg, J, et al., “Idebenone treatment fails to slow cognitive decline in Alzheimer’s disease”, Neurology, (2003)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly, Grundman, Michael, et al., “NSAIDs and hypertension”, Archives of internal medicine, (2003)\nGeneral Research\n\n🔗 Article\n\n\n\nRaskind, Murray A, Peskind, Elaine R, Kanter, Evan D, et al., “Reduction of nightmares and other PTSD symptoms in combat veterans by prazosin: a placebo-controlled study”, American Journal of Psychiatry, (2003)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nBrody, BL, Roch-Levecq, AC, Thomas, RG, et al., “Self-Management of Age-Related Macular Degeneration and Quality of Life at 6 Months Follow-Up: A Randomized Controlled Trial”, Investigative Ophthalmology & Visual Science, (2003)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nAisen, PS, Berg, JD, Craft, S, et al., “Steroid-induced elevation of glucose in Alzheimer’s disease: relationship to gender, apolipoprotein E genotype and cognition”, Psychoneuroendocrinology, (2003)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nGrundman, Michael, Farlow, Martin, Peavy, Guerry, et al., “A phase I study of AIT-082 in healthy elderly volunteers”, Journal of Molecular Neuroscience, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nPierce, John P, Faerber, Susan, Wright, Fred A, et al., “A randomized trial of the effect of a plant-based dietary pattern on additional breast cancer events and survival:: the Women’s Healthy Eating and Living (WHEL) Study”, Controlled clinical trials, (2002)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nSalmon, David P, Thomas, RG, Pay, MM, et al., “Alzheimer’s disease can be accurately diagnosed in very mildly impaired individuals”, Neurology, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Jin, Shelia, et al., “Assessing Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory: scoring and clinical implications”, Journal of psychiatric research, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, Clifford R, et al., “Brain MRI hippocampal volume and prediction of clinical status in a mild cognitive impairment trial”, Journal of Molecular Neuroscience, (2002)\nMedical/Clinical Neuroimaging\n\n🔗 Article\n\n\n\nGrundman, M, Kim, HT, Schultz, AN, et al., “Clinical correlates of hippocampal atrophy in patients with mild cognitive impairment”, NEUROBIOLOGY OF AGING, (2002)\nMedical/Clinical\n\n🔗 Article\n\n\n\nHamilton, JM, Corey-Bloom, J, Thomas, RG, et al., “Correlates of weight change in Huntington’s disease”, NEUROLOGY, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nLange, Kelly L, Bondi, Mark W, Salmon, David P, et al., “Decline in verbal memory during preclinical Alzheimer’s disease: examination of the effect of APOE genotype”, Journal of the International Neuropsychological Society: JINS, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nJames, MW, Argent, RH, Thomas, R, et al., “Indomethacin reduces Helicobacter pylori-induced interleukin-8 (IL-8) production by the gastric epithelial cell line, AGS.”, GASTROENTEROLOGY, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Gamst, Anthony, Thomas, Ronald G, et al., “Investigating emergent symptomatology as an outcome measure in a behavioral study of Alzheimer’s disease”, The Journal of neuropsychiatry and clinical neurosciences, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Sano, Mary, et al., “No long-term effect of behavioral treatment on psychotropic drug use for agitation in Alzheimer’s disease patients”, Journal of geriatric psychiatry and neurology, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGoldberg, DE, Roch-Levecq, AC, Maclean, KK, et al., “Psychosocial and Functional Parameters in Patients with Age Related Macular Degeneration and Choroidal Neovascularization with and without Photodynamic Therapy”, Investigative Ophthalmology & Visual Science, (2002)\nGeneral Research\n\n🔗 Article\n\n\n\nAisen, P, Schafer, K, Grundman, M, et al., “Results of a multicenter trial of rofecoxib and naproxen in Alzheimer’s disease”, Neurobiology of Aging, (2002)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSinger, C, Colling, E, Tractenberg, R, et al., “The ADCS clinical trial of melatonin for the sleep disturbance of alzheimer’s disease: Case report of an unusual sleep/wake cycle and response to melatonin.”, AMERICAN JOURNAL OF GERIATRIC PSYCHIATRY, (2002)\nMedical/Clinical Alzheimer’s disease Sleep disorders Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nTractenberg, Rochelle E, Gamst, Anthony, Weiner, Myron F, et al., “Frequency of behavioral symptoms characterizes agitation in Alzheimer’s disease”, International journal of geriatric psychiatry, (2001)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Thomas, RG, et al., “Incidence and persistence of psychosis in Alzheimer’s disease”, Neurology, (2001)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLindblad, Ulf, Langer, Robert D, Wingard, Deborah L, et al., “Metabolic syndrome and ischemic heart disease in elderly men and women”, American journal of epidemiology, (2001)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nAisen, Paul S, Davis, KL, Berg, JD, et al., “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKoch, HJ, Szecsey, A, “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThomas, Ronald G, Berg, Julie D, Sano, Mary, et al., “Analysis of longitudinal data in an Alzheimer’s disease clinical trial”, Statistics in medicine, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBayley, Peter J, Salmon, David P, Bondi, Mark W, et al., “Comparison of the serial position effect in very mild Alzheimer’s disease, mild Alzheimer’s disease, and amnesia associated with electroconvulsive therapy”, Journal of the International Neuropsychological Society, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGamst, A, Thomas, RG, Patterson, M, et al., “Description of behaviors emerging in community-dwelling persons with Alzheimer’s disease over 12 months”, ANNALS OF NEUROLOGY, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTHOMAS, R, MICHAEL, J, “Disorder among Veterans with Substance Abuse”, THE JOURNaL OF NERvOUs AND MEntal Disease, (2000)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nMulnard, Ruth A, Cotman, Carl W, Kawas, Claudia, et al., “Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, Jama, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nPaulsen, Jane S, Salmon, DP, Thal, Leon J, et al., “Incidence of and risk factors for hallucinations and delusions in patients with probable AD”, Neurology, (2000)\nGeneral Research\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Knopman, D, et al., “Predicting nursing home placement with change on cognitive measures in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Patterson, Marian, Weiner, Myron F, et al., “Prevalence of symptoms on the CERAD behavior rating scale for dementia in normal elderly subjects and Alzheimer’s disease patients”, The Journal of neuropsychiatry and clinical neurosciences, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Jin, Shelia, Patterson, Marian, et al., “Qualifying change: a method for defining clinically meaningful outcomes of change score computation”, Journal of the American Geriatrics Society, (2000)\nGeneral Research\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle, Teri, Linda, et al., “Quantifying behavioral disturbance in Alzheimer’s disease patients”, Journal of Psychiatric Research, (2000)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTeri, Linda, Logsdon, RG, Peskind, E, et al., “Treatment of agitation in AD: a randomized, placebo-controlled clinical trial”, Neurology, (2000)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, CR, et al., “Use of brain MRI volumetric analysis in a mild cognitive impairment trial to delay the diagnosis of Alzheimer’s disease”, Drug discovery and development for Alzheimer’s disease, (2000)\nMedical/Clinical Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nMulnard, RA, Cotman, CW, Kawas, C, et al., “for the Alzheimer’s Disease Cooperative Study: Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, JAMA, (2000)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nLineweaver, Tara T, Bondi, Mark W, Thomas, Ronald G, et al., “A normative study of Nelson’s (1976) modified version of the Wisconsin Card Sorting Test in healthy older adults”, The Clinical Neuropsychologist, (1999)\nGeneral Research\n\n🔗 Article\n\n\n\nBrody, Barbara L, Williams, Rebecca A, Thomas, Ronald G, et al., “Age-related macular degeneration: a randomized clinical trial of a self-management intervention”, Annals of Behavioral Medicine, (1999)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, et al., “Assessment of agitation in Alzheimer’s disease: the agitated behavior in dementia scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, et al., “Brief Methodological Reports-Assessment of Agitation in Alzheimer’s Disease: The Agitated Behavior in Dementia Scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nOlin, JT, Papka, M, Jin, S, et al., “Clinical symptoms of dementia with Lewy bodies: Secondary analyses of the Alzheimer’s disease cooperative study selegiline and vitamin E clinical trial”, European Neuropsychopharmacology, (1999)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBell, Karen, Sano, Mary, Jin, Shelia, et al., “Ethnic differences in clinical measures among participants in Alzheimer’s disease clinical trials”, Neurology, (1999)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHohl, Ursula, Grundman, Michael, Salmon, David P, et al., “Mini-mental state examination and Mattis Dementia Rating Scale performance differs in Hispanic and non-Hispanic Alzheimer’s disease patients”, Journal of the International Neuropsychological Society, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSabbagh, Marwan N, Corey-Bloom, Jody, Tiraboschi, Pietro, et al., “Neurochemical markers do not correlate with cognitive decline in the Lewy body variant of Alzheimer disease”, Archives of neurology, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nBondi, Mark W, Salmon, David P, Galasko, Douglas, et al., “Neuropsychological function and apolipoprotein E genotype in the preclinical detection of Alzheimer’s disease.”, Psychology and aging, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKnopman, David S, Berg, JD, Thomas, R, et al., “Nursing home placement is related to dementia progression: experience from a clinical trial”, Neurology, (1999)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Sano, Mary, Berg, Julie, et al., “The Beneficial Effects of Vitamin E and Selegiline in a Controlled Trial in Alzheimer’s Disease Are Independent of the Apolipoprotein E e4 Allele”, Neurology, (1999)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nChambers, Christina D, Anderson, Philip O, Thomas, Ronald G, et al., “Weight gain in infants breastfed by mothers who take fluoxetine”, Pediatrics, (1999)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nWeiner, Myron F, Koss, Elisabeth, Patterson, Marian, et al., “A comparison of the Cohen-Mansfield agitation inventory with the cerad behavioral rating scale for dementia in community-dwelling persons with Alzheimers disease”, Journal of psychiatric research, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle, Schafer, Kimberly, Thomas, Ron, et al., “Agreement on CDR ratings by committee”, Controlled Clinical Trials, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nTanaka, S, Chen, X, Xia, Y, et al., “Association of CYP2D microsatellite polymorphism with Lewy body variant of Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nPeavy, GM, Salmon, DP, Thomas, RG, “Cognitive and functional abilities in severely demented Alzheimer’s patients”, CLINICAL NEUROPSYCHOLOGIST, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nFerry, David R, O’Rourke, Robert A, Blaustein, Alvin S, et al., “Design and baseline characteristics of the veterans affairs non-Q-wave infarction strategies in-hospital (VANQWISH) trial”, Journal of the American College of Cardiology, (1998)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\nJin, Shelia, Thomas, Ronald G, Galasko, Douglas, et al., “Dynamic measurement scale development for clinical trials in targeted populations”, Controlled Clinical Trials, (1998)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGalasko, D, Chang, L, Motter, R, et al., “High cerebrospinal fluid tau and low amyloid beta42 levels in the clinical diagnosis of Alzheimer disease and relation to apolipoprotein E genotype”, Archives of neurology, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKatzman, R, Kang, D, Thomas, R, “Interaction of apolipoprotein E 4 with other genetic and non-genetic risk factors in late onset Alzheimer disease: problems facing the investigator”, Neurochemical research, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nBerg, Julie D, Thomas, Ronald G, Thal, Leon J, et al., “Measuring cognitive progression in Alzheimer’s disease”, Controlled Clinical Trials, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKean, Yin M, Thomas, Ronald G, Thal, Leon J, “Power calculation for randomized start design”, Controlled Clinical Trials, (1998)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\nLineweaver, TT, Bondi, MW, Thomas, RG, “Practice effects on the modified Wisconsin card sorting test in normally aging adults”, Archives of Clinical Neuropsychology, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nFroelicher, Victor F, Lehmann, Kenneth G, Thomas, Ronald, et al., “The electrocardiographic exercise test in a population with reduced workup bias: diagnostic performance, computerized interpretation, and multivariable prediction”, Annals of internal medicine, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nWilliams, Rebecca A, Brody, Barbara L, Thomas, Ronald G, et al., “The psychosocial impact of macular degeneration”, Archives of ophthalmology, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nKnopman, David, Sano, Mary, Berg, Julie, et al., “The relationship between Nursing home placement and measures of change in Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Welty, Greg, Thomas, Ronald G, “Use of the world wide web in data dissemination to central review committees”, Controlled Clinical Trials, (1998)\nGeneral Research\n\n🔗 Article\n\n\n\nKeane, Terence M, Kolb, Lawrence C, Kaloupek, Danny G, et al., “Utility of psychophysiological measurement in the diagnosis of posttraumatic stress disorder: results from a Department of Veterans Affairs Cooperative Study.”, Journal of consulting and clinical psychology, (1998)\nMilitary/Defense Military health\n\n🔗 Article\n\n\n\n\n\n\nJeong, Jong-Hyeon, Klauber, Melville R, Thomas, Ronald G, et al., “53 Power comparisons among different number of categories under ordered polytomous logistic regression model”, Controlled Clinical Trials, (1997)\nGeneral Research\n\n🔗 Article\n\n\n\nWhitehouse, Peter J, Schmitt, HFrederick A, Sano, Mary, et al., “A Multicenter Evaluation of New Treatment Efficacy”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Thomas, Ronald G, et al., “A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease”, New England Journal of Medicine, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nPatterson, Marian B, Mack, James L, Mackell, Joan A, et al., “A longitudinal study of behavioral pathology across five levels of dementia severity in Alzheimer’s disease: The CERAD Behavior Rating Scale for Dementia.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, Mary, Thomas, Ronald G, Thal, Leon J, “Alpha-tocopherol and Alzheimer’s disease”, The New England Journal of Medicine, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, et al., “An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSeubert, PA, Motter, RN, Schenk, DB, et al., “ApoE genotype influences the CSF level of A \\\\beta 42 in Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKoss, Elisabeth, Weiner, Myron, Ernesto, Christopher, et al., “Assessing patterns of agitation in Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory. The Alzheimer’s Disease Cooperative Study.”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Seubert, P, Motter, R, et al., “CSF levels of A beta 432 and tau as aids to diagnosing Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nRoch, J-M, Sundsmo, M, Otero, D, et al., “Defective Neurite Extension Is Caused by a Mutation in Amyloid /A4 (A ) Protein Precursor Found in Familial Alzheimer’s Disease”, JOURNAL OF NEUROBIOLOGY, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nLi, Hai Ling, Roch, Jean-Marc, Sundsmo, Mary, et al., “Defective neurite extension is caused by a mutation in amyloid beta protein precursor found in familial Alzheimer’s disease”, Journal of neurobiology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nHohl, U, CoreyBloom, J, Hansen, LA, et al., “Diagnostic accuracy of dementia with Lewy bodies: A prospective evaluation”, Neurology, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, et al., “Effects of Selegiline and alpha-Tocopherol on cognitive and functional outcome measures in moderately impaired patients with Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nKatzman, R, Zhang, M-Y, Chen, PJ, et al., “Effects of apolipoprotein E on dementia and aging in the Shanghai Survey of Dementia”, Neurology, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nBarrett-Connor, Elizabeth, Thomas, Ronald G, “Estrogen, apolipoprotein E, and dementia”, Journal of women’s health, (1997)\nMedical/Clinical\n\n🔗 Article\n\n\n\nKang, DE, Saitoh, T, Chen, X, et al., “Genetic association of the low-density lipoprotein receptor-related protein gene (LRP), and apolipoprotein E receptor, with late-onset Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald G, Welty, Greg, et al., “P23 use of the world wide web for clinical monitoring in multicenter clinical trials”, Controlled Clinical Trials, (1997)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nWilliams, RA, Brody, BL, Kaplan, RM, et al., “Quality of life among elderly adults with macular degeneration”, INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE, (1997)\nGeneral Research\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Sano, Mary, “Tacrine and nursing home placement”, Neurology, (1997)\nGeneral Research\n\n🔗 Article\n\n\n\nSano, M, Mackell, JA, Ponton, M, et al., “The Spanish Instrument Protocol: Design and implementation of a study to evaluate treatment efficacy instruments for Spanish-speaking patients with Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, et al., “Validity and reliability of the Alzheimer’s Disease Cooperative Study-Clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, et al., “for the members of the Alzheimer’s Disease Cooperative Study”, A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease. N Engl J Med, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, LS, Olin, JT, Doody, RS, et al., “the Alzheimer’s Disease Cooperative Study. Validity and reliability of the Alzheimer’s disease cooperative study-clinical global impression of change”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Sano, M, et al., “the Alzheimer’s Disease Cooperative Study. An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nThomas, Ronald G, Schafer, Kimberly, Woodbury, Peter, et al., “A32 computer-aided clinical monitoring: Results of a controlled experiment”, Controlled Clinical Trials, (1996)\nGeneral Research\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Ernesto, Christopher, Sano, Mary, et al., “A34 Clinical monitoring of rating scales in multicenter clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nChen, X, Xia, Y, Gresham, LS, et al., “ApoE and CYP2D6 polymorphism with and without parkinsonism-dementia complex in the people of Chamorro, Guam”, Neurology, (1996)\nMedical/Clinical\n\n🔗 Article\n\n\n\nKatzman, R, Galasko, DR, Saitoh, T, et al., “Apolipoprotein-epsilon4 and head trauma: Synergistic or additive risks?”, Neurology, (1996)\nGeneral Research\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Ernesto, C, et al., “Development of a pool of items to assess activities of daily living in clinical trials for Alzheimer’s disease”, Neurology, (1996)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, M, Growdon, J, Thomas, R, et al., “Evaluation of efficacy measures in clinical trials for Alzheimer’s disease: Does psychometric test performance predict clinically relevant outcomes?”, Neurology, (1996)\nMedical/Clinical Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nWright, Fred A, Thomas, Ronald G, “Familial melanoma and pancreatic cancer”, The New England journal of medicine, (1996)\nGeneral Research\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald, Galasko, Douglas, et al., “P63 Informed consent issues when including genetic testing in clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Morris, JC, et al., “Rate of dementia of the Alzheimer type (DAT) in subjects with mild cognitive impairment”, Neurology, (1996)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Klauber, Melville R, et al., “Rationale and design of a multicenter study of selegiline and alpha-tocopherol in the treatment of Alzheimer disease using novel clinical outcomes. Alzheimer’s Disease Cooperative Study.”, Alzheimer disease and associated disorders, (1996)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\nSeidner, Andrea L, Burling, Thomas A, Gaither, David E, et al., “Substance-dependent inpatients who accept smoking treatment”, Journal of Substance Abuse, (1996)\nMedical/Clinical\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, et al., “Validity and reliability of the Alzheimers disease cooperative study-clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease Springer, (1996)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nLi, Dominic, German, Donald, Lulla, Sulochina, et al., “Prospective study of hospitalization for asthma: a preliminary risk factor model”, American journal of respiratory and critical care medicine, (1995)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RG, Jin, S, Schafer, K, et al., “The Spanish Instrument Protocol: a Study to Evaluate Treatment Efficacy Instruments for Spanish-Speaking Patients with Alzheimer’s Disease”, Alzheimer Disease and Associated Disorders, (1995)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nAstion, Michael L, Wener, Mark H, Thomas, Ronald G, et al., “Application of neural networks to the classification of giant cell arteritis”, Arthritis & Rheumatism: Official Journal of the American College of Rheumatology, (1994)\nGeneral Research\n\n🔗 Article\n\n\n\nIrving, Lori M, Seidner, Andrea L, Burling, Thomas A, et al., “Drug and alcohol abuse inpatients’ attitudes about smoking cessation”, Journal of Substance Abuse, (1994)\nMedical/Clinical\n\n🔗 Article\n\n\n\nThomas, Ralf, “Zweibaryonensysteme mit Strangeness und die Antikaon-Deuteron Streuung”, (1994)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nWilson, Sandra R, Scamagas, Peter, German, Donald F, et al., “A controlled trial of two forms of self-management education for adults with asthma”, The American journal of medicine, (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nConlon, Michael, Thomas, Ronald G, “Algorithm AS 280: the power function for Fisher’s exact test”, Journal of the Royal Statistical Society. Series C (Applied Statistics), (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nAstion, ML, Wener, MH, Thomas, RG, et al., “Overtraining in neural networks that interpret clinical data”, Clinical chemistry, (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nMorrow, Kiernan, Morris, Charles K, Froelicher, Victor F, et al., “Prediction of cardiovascular death in men undergoing noninvasive evaluation for coronary artery disease”, Annals of Internal Medicine, (1993)\nGeneral Research\n\n🔗 Article\n\n\n\nWard, TT, Thomas, RG, Fye, CL, et al., “Trimethoprim-sulfamethoxazole prophylaxis in granulocytopenic patients with acute leukemia: evaluation of serum antibiotic levels in a randomized, double-blind, placebo-controlled Department of Veterans Affairs Cooperative Study”, Clinical infectious diseases, (1993)\nMilitary/Defense Clinical trials Military health\n\n🔗 Article\n\n\n\n\n\n\nThomas, Ronald G, Conlon, Michael, “An algorithm for the rapid evaluation of the power function for Fisher’s Exact Test”, Journal of statistical computation and simulation, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nBeuschel, T, Feldkeller, B, Fuchs, M, et al., “Calculation of observables in the pion-deuteron system. Berechnung von Observablen im Pion Deuteron-System”, Verhandlungen der Deutschen Physikalischen Gesellschaft;(Germany), (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nKerns, David L, Ritter, Mary L, Thomas, Ronald G, “Concave hymenal variations in suspected child sexual abuse victims”, Pediatrics, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nRAYNAULD, JP, THOMAS, RG, BLOCH, DA, “PROGRESSION OF FUNCTIONAL DISABILITY IN RHEUMATOID-ARTHRITIS”, ARTHRITIS AND RHEUMATISM, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald G, Conlon, Michael, “Sample size determination based on Fisher’s exact test for use in 2 x 2 comparative trials with low event rates”, Controlled clinical trials, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\nFuchs, M, Huber, MG, Metsch, BC, et al., “Two-baryon systems with strangeness S=-1 and S=-2”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1992)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nSheridan, Lenore, Thomas, Ronald G, “An analysis of methods of communication in clinical trials”, Controlled Clinical Trials, (1991)\nMedical/Clinical Clinical trials\n\n🔗 Article\n\n\n\nGordon, DE, Thomas, R, Shedrow, CB, et al., “Integration of statutory provisions of NEPA, RCRA, and CERCLA at the Savannah River site. Revision 1”, (1991)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nConlon, Michael, Thomas, Ronald G, “A new confidence interval for the difference of two binomial proportions”, Computational Statistics & Data Analysis, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Data monitoring through stochastic curtailing when the outcome proportions are small: An exact approach”, Controlled Clinical Trials, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, R, Empl, E, Kilian, K, et al., “Development of an active target for scattering of neutral baryons”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nDecker, G, Kilian, K, Lippert, C, et al., “Test measurements of an asymmetric induction drift chamber with flash ADC’s”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nTyrell, Doris, Cline, Dorothy R, Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\nLee, Kelvin K, Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nHale, William E, May, Franklin E, Thomas, Ronald G, et al., “Effect of zinc supplementation on the development of cardiovascular disease in the elderly”, Journal of Nutrition for the Elderly, (1989)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Exact sample size calculations for 2x2 comparative trials when the outcome proportions are small”, Controlled Clinical Trials, (1989)\nGeneral Research\n\n🔗 Article\n\n\n\nEllis, Stephen G, Shaw, Richard E, Gershony, Gary, et al., “Risk factors, time course and treatment effect for restenosis after successful percutaneous transluminal coronary angioplasty of chronic total occlusion”, The American journal of cardiology, (1989)\nMedical/Clinical\n\n🔗 Article\n\n\n\n\n\n\nEllis, SG, Roubin, GS, King 3rd, SB, et al., “Angiographic and clinical predictors of acute closure after native vessel coronary angioplasty.”, Circulation, (1988)\nGeneral Research\n\n🔗 Article\n\n\n\nMELLEN, BG, THOMAS, RG, CASTANO, D, “FORMS INVENTORY SYSTEM FOR A COMPLEX CLINICAL-TRIAL”, CONTROLLED CLINICAL TRIALS, (1988)\nGeneral Research\n\n🔗 Article\n\n\n\nRoubin, Gary S, Douglas Jr, John S, King 3rd, SB, et al., “Influence of balloon size on initial success, acute complications, and restenosis after percutaneous transluminal coronary angioplasty. A prospective randomized study.”, Circulation, (1988)\nGeneral Research Clinical trials\n\n🔗 Article\n\n\n\n\n\n\nMufson, LGAR, Roubin, GS, Black, A, et al., “A comparison of single lesion dilatation in single vessel and multivessel disease”, Circulation, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nMcGlynn, F Dudley, LeCompte, E Joseph, Thomas, Ronald G, et al., “Effects of behavioral self-management on oral hygiene adherence among orthodontic patients”, American Journal of Orthodontics and Dentofacial Orthopedics, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nSherertz, Robert J, Belani, Anusha, Kramer, Barnett S, et al., “Impact of air filtration on nosocomial Aspergillus infections: unique risk of bone marrow transplant recipients”, The American journal of medicine, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nShcrertz, RJ, Belani, A, Kramer, BS, et al., “Impact of air filtration on nosocomial aspergillus infections”, Am J Med, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RG, Black, A, Lin, S, et al., “Is there dependence between sites for continued success or restenosis after successful multisite coronary angioplasty”, Circulation, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\nRoubin, GS, Sutor, C, Lembo, NJ, et al., “PROGNOSIS AFTER MULTIPLE VESSEL ANGIOPLASTY (PTCA) IN PATIENTS WITH CORONARY-ARTERY DISEASE”, Circulation, (1987)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThal, Leon J, Grundman, Michael, Golden, Robert, “Alzheimer’s disease: a correlational analysis of the Blessed Information-Memory-Concentration test and the Mini-Mental State Exam”, Neurology, (1986)\nMedical/Clinical Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n\n\nHUWS, DA, FAN, TP, THOMAS, RU, “ELUTION OF PROSTAGLANDIN-E2 FROM FILTER-PAPER STRIPS-EFFICIENCY AND REPRODUCIBILITY”, JOURNAL OF DENTAL RESEARCH, (1985)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nSchubert, Mark M, Guttu, Ronald L, Hunter, Letha H, et al., “Changes in shoulder and leg strength in athletes wearing mandibular orthopedic repositioning appliances”, The Journal of the American Dental Association, (1984)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nPepe, Paul E, Thomas, Ronald G, Stager, Marie Anne, et al., “Early prediction of the adult respiratory distress syndrome by a simple scoring method”, Annals of emergency medicine, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald J, Clark, Christopher A, “Effects of concomitant development on reproduction of Meloidogyne incognita and Rotylenchulus reniformis on sweet potato”, Journal of Nematology, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald J, Clark, Christopher A, “Population dynamics of Meloidogyne incognita and Rotylenchulus reniformis alone and in combination, and their effects on sweet potato”, Journal of Nematology, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\nSchubert, M, Guttu, R, Hunter, L, et al., “THE EFFECT OF MANDIBULAR ORTHOPEDIC REPOSITIONING APPLIANCES ON BODY STRENGTH”, JOURNAL OF DENTAL RESEARCH, (1983)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nTHOMAS, RJ, CA, CLARK, “CONCOMITANT REPRODUCTION AND POPULATION DYNAMICS OF MELOIDOGYNE INCOGNITA AND ROTYLENCHULUS RENIFORMIS ON SWEET POTATO”, (1982)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, Ronald James, “Interactions of Rotylenchulus Reniformis and Meloidogyne Incognita on Sweet Potato.”, (1982)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nGordon, D, Nouri, AM, Thomas, RU, “Selective inhibition of thromboxane biosynthesis in human blood mononuclear cells and the effects of mitogen-stimulated lymphocyte proliferation.”, British journal of pharmacology, (1981)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nGordon, D, Nouri, AME, Thomas, RU, “Dissociation of the proliferative response of mitogen-stimulated human lymphocytes from the release of lymphokine (S) that stimulate prostaglandin (PG) production by isolated rheumatoid adherent synovial cells (RASC)”, International Journal of Immunopharmacology, (1980)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nStotter, David A, Thomas, R David, Wilson, Michael T, “Reductive dechlorination of DDT by haem proteins”, Bioinorganic chemistry, (1977)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThomas, RU, Whittle, BJ, “Prostaglandins and the release of histamine from rat peritoneal mast cells [proceedings].”, British journal of pharmacology, (1976)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nDix, C, Thomas, RT, “A conductive mode amplifier for the scanning electron microscope”, Journal of Physics E: Scientific Instruments, (1972)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nGratze, SC, Thomas, RT, “Observations on epitaxial gallium arsenide varactor diodes using the scanning electron microscope”, Microelectronics Reliability, (1970)\nGeneral Research\n\n🔗 Article\n\n\n\nThomas, RT, “Time dependence of the electrical conductivity of BaTiO3 single crystals heated in oxygen”, Journal of Physics D: Applied Physics, (1970)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThomas, Reid, “Essays on the Intellectual Powers of Man”, (1901)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nReid, Thomas, “Essays on the Powers of the Human Mind: To which are Prefixed an Essay on Quantity, and an Analysis of Aristotle’s Logic”, (1819)\nGeneral Research\n\n🔗 Article\n\n\n\n\n\n\nThomas, Reid, “An Inquiry into the Human Mind on the Principles of Common Sense”, (1764)\nGeneral Research\n\n🔗 Article"
  },
  {
    "objectID": "research/index.html#current-projects",
    "href": "research/index.html#current-projects",
    "title": "Research",
    "section": "2 Current Projects",
    "text": "2 Current Projects\n\n2.1 Statistical Methods Development\n\nNovel approaches to clinical trial design\nBayesian methods for biomarker analysis\nReproducible research workflows\n\n\n\n2.2 Collaborative Research\n\nMulti-institutional studies\nOpen science initiatives\nMethodological consulting"
  },
  {
    "objectID": "research/index.html#data-and-code",
    "href": "research/index.html#data-and-code",
    "title": "Research",
    "section": "3 Data and Code",
    "text": "3 Data and Code\nReproducible research materials, datasets, and computational resources supporting published work.\n\n3.1 Open Science Contributions\n\nR packages for statistical analysis\nData analysis pipelines\nMethodology implementations"
  },
  {
    "objectID": "research/index.html#comprehensive-tag-collection",
    "href": "research/index.html#comprehensive-tag-collection",
    "title": "Research",
    "section": "4 Comprehensive Tag Collection",
    "text": "4 Comprehensive Tag Collection\nBased on analysis of 300+ recent posts from R-bloggers and leading biostatistics blogs, here are the most relevant and frequently used tags for data science and biostatistics:\n\n4.1 Core R & Programming (8 tags)\nR Programming • Data Science • ggplot2 • Shiny • Python • Data Visualization • Statistical Computing • R Packages\n\n\n4.2 Statistical Methods (10 tags)\nMachine Learning • Bayesian Methods • Time Series Analysis • PCA (Principal Component Analysis) • Statistical Learning • Forecasting • Dimensionality Reduction • Neural Networks • ARIMA/GARCH Models • Correlation Analysis\n\n\n4.3 Biostatistics & Medical (8 tags)\nBiostatistics • Clinical Trials • Survival Analysis • Epidemiology • Healthcare Analytics • Medical Research • Drug Development • Prevention Trials\n\n\n4.4 Domain Applications (7 tags)\nFinancial Analysis • Spatial Analysis • Environmental Statistics • Genomics • Neuroimaging • Ecological Statistics • Computational Methods\n\n\n4.5 Emerging Technologies (5 tags)\nLarge Language Models • AI/Machine Learning • Open Science • Predictive Modeling • Simulation\n\n\n4.6 Specialized Research Areas (7 tags)\nMilitary Health • Healthcare • COVID-19 • Alzheimer’s Disease • Sleep Research • Cognitive Assessment • Pharmacokinetics\nTotal: 45 curated tags based on current R/biostatistics community trends and your research focus"
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "References",
    "section": "",
    "text": "Quick reference materials for when you need answers fast. These living documents are continuously updated and expanded based on real-world usage.\nFind: - Command cheat sheets - Configuration templates - Common patterns and snippets - Troubleshooting checklists - Best practices summaries\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nCategories\n\n\nDescription\n\n\n\n\n\n\nR Commands Quick Reference\n\n\nR, reference, cheatsheet\n\n\nQuick lookup table of commonly used R commands for data manipulation, visualization, and analysis.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html",
    "href": "posts/table_placement_rmarkdown/index.html",
    "title": "Converting R data.frames to pdf for better placement control in latex pdf report",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "href": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "title": "Converting R data.frames to pdf for better placement control in latex pdf report",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "href": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "title": "Converting R data.frames to pdf for better placement control in latex pdf report",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "href": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "title": "Converting R data.frames to pdf for better placement control in latex pdf report",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#further-reading",
    "href": "posts/table_placement_rmarkdown/index.html#further-reading",
    "title": "Converting R data.frames to pdf for better placement control in latex pdf report",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html",
    "href": "posts/share_R_code_via_docker_p25/index.html",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "",
    "text": "Reproducibility is key to conducting data analysis, yet in practice, achieving it consistently with R workflows can be quite challenging. R projects frequently break when transferred between computers due to mismatched R versions, package dependencies, or inconsistent project organization. This white paper describes an approach to solving this problem by combining three tools: zzrrtools for creating structured research compendia, renv for R package management, and Docker for containerizing the computing environment. Together, these tools ensure that an R workflow runs identically across different computers by providing standardized project structure, identical R packages and versions, consistent R versions, and the same operating system libraries as the original setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "href": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "1.1 The Challenge of Reproducibility in R",
    "text": "1.1 The Challenge of Reproducibility in R\nR has become a standard tool for data science and statistical analysis across numerous scientific disciplines. However, as R projects grow in complexity, they often develop complex webs of dependencies that can make sharing and reproducing analyses difficult. Some common challenges include:\n\nDifferent R versions across machines\nIncompatible package versions\nMissing system-level dependencies\nOperating system differences (macOS vs. Windows vs. Linux)\nConflicts with other installed packages\nR startup files (.Rprofile, .Renviron, .RData) that can affect code behavior\n\nThese challenges often manifest as the frustrating “it works on my machine” problem, where analysis code runs perfectly for the original author but fails when others attempt to use it. This undermines the scientific and collaborative potential of R-based analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "href": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "1.2 A Three-Level Solution",
    "text": "1.2 A Three-Level Solution\nTo address these challenges, we need to tackle reproducibility at three distinct levels:\n\nProject-level reproducibility: Ensuring consistent project structure and organization using research compendium standards\nPackage-level reproducibility: Ensuring exact package versions and dependencies are maintained\nSystem-level reproducibility: Guaranteeing consistent R versions, operating system, and system libraries\n\nThe strategy presented in this white paper leverages zzrrtools for project-level structure, renv for package-level consistency, and Docker for system-level consistency. When combined, they provide a framework for end-to-end reproducible R workflows with proper research compendium organization.\nWith this three-level framework established, we can now examine how each tool addresses its specific layer of reproducibility. We begin with zzrrtools, which tackles the foundational challenge of project-level organization and provides the structural framework upon which package and system-level reproducibility can be built."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "2.1 What is zzrrtools?",
    "text": "2.1 What is zzrrtools?\nzzrrtools is a Docker-first framework that creates reproducible research compendia with containerized development workflows. The framework extends the research compendium concept introduced by Ben Marwick’s rrtools, adding container-based development and automated dependency validation. Team members install zzrrtools once on their system, then can create or join any zzrrtools-based project using the same framework. A research compendium organizes digital research materials to enable others to inspect, reproduce, and extend the research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "2.2 Key Features of zzrrtools",
    "text": "2.2 Key Features of zzrrtools\nzzrrtools creates containerized research compendia with these key features:\n\nDocker-first development: All workflows operate within containers, eliminating “works on my machine” issues\nCentralized framework: One-time zzrrtools installation enables consistent project creation and team collaboration\nMulti-service architecture: Provides specialized Docker environments for interactive R sessions, shell development, and paper rendering\nFlexible base images: Choice of minimal (rocker/r-ver) or pre-packaged (rgt47/r-pluspackages) Docker templates with common R packages\nAdvanced dependency validation: Automated renv consistency checking with CRAN verification and pre-commit validation\nShell-based workflows: Optimized for command-line development with rich automation via Make targets\nTeam collaboration focus: Designed for multi-developer teams working on shared research projects"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-self-replicating-collaboration",
    "href": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-self-replicating-collaboration",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "2.3 zzrrtools Workflow: Self-Replicating Collaboration",
    "text": "2.3 zzrrtools Workflow: Self-Replicating Collaboration\nThe zzrrtools workflow is designed for team collaboration:\n# Project creator initializes the research compendium\n~/prj/zzrrtools/zzrrtools.sh [OPTIONS]\n\n# Available options:\n#   --dotfiles DIR       Copy personal dotfiles (with leading dots)\n#   --dotfiles-nodot DIR Copy dotfiles (without leading dots) \n#   --base-image NAME    Use custom Docker base image (default: rocker/r-ver)\n#                        Popular options: rgt47/r-pluspackages (includes tidyverse)\n#   --no-docker          Skip Docker image build\n#   --next-steps         Show workflow guidance\nThis creates a Docker-first research compendium with:\n\nFramework-based setup using centrally installed zzrrtools for consistent project creation\nMulti-service Docker architecture for interactive R, shell, and rendering\nAdvanced renv validation with CRAN verification and pre-commit checking\nDual-track automation supporting both native R and Docker workflows\nNavigation shortcuts via symbolic links (a→data, p→paper, s→scripts)\nDeveloper environment integration with personal dotfiles support\nTeam synchronization via automated dependency validation\n\nTeam members can collaborate after one-time zzrrtools installation:\n# One-time zzrrtools installation\ngit clone zzrrtools-repo ~/prj/zzrrtools\ncd ~/prj/zzrrtools && ./install.sh  # Creates zzrrtools command in PATH\n\n# Per-project workflow\ngit clone project-repo && cd project-repo\nzzrrtools  # Set up project environment (command available anywhere)\nmake docker-r   # Start interactive R session\n\n2.3.1 Integrated renv Consistency Checking\nThe workflow includes advanced renv management through the check_renv_for_commit.R script, which provides automated dependency validation and team conflict prevention. This script:\n\nScans multiple directories (R/, scripts/, analysis/) for package dependencies\nValidates against CRAN to ensure packages exist and are properly named\n\nSynchronizes dependencies across code files, DESCRIPTION, and renv.lock\nProvides automated fixes to maintain team environment consistency\nIntegrates with CI/CD for fail-fast validation workflows\n\nUsage examples:\n# Interactive dependency checking (development)\nRscript check_renv_for_commit.R\n\n# Auto-fix dependency issues\nRscript check_renv_for_commit.R --fix\n\n# CI/CD validation with fail-fast\nRscript check_renv_for_commit.R --fix --fail-on-issues --quiet\n\n# Via Make targets (recommended)\nmake check-renv          # Check dependencies\nmake check-renv-fix      # Fix dependency issues\nmake docker-check-renv-fix  # Fix in container\nThis approach ensures collaborators can reliably reproduce package environments and CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "href": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "2.4 Research Compendium Structure",
    "text": "2.4 Research Compendium Structure\nThe zzrrtools setup creates a directory structure that follows research compendium best practices. The structure includes organized data folders, analysis directories, testing frameworks, and workflows.\nKey organizational principles:\n\nData management: Separate folders for raw, derived, and external data with proper documentation\nAnalysis workflow: Dedicated spaces for papers, figures, tables, and working scripts\n\nPackage structure: R package organization with documentation and testing\nIntegration support: Works with Docker, GitHub Actions, and build systems\n\nThis organizational framework provides the foundation for reproducible research while supporting team collaboration and automated workflows."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "2.5 Iterative Development Workflow",
    "text": "2.5 Iterative Development Workflow\nFor collaborative analysis development, the research compendium structure supports a phased approach that balances rapid iteration with publication-quality outputs:\n\n2.5.1 Phase 1: Exploration & Development (scripts/)\nDuring active analysis development, team members should work primarily in the scripts/ directory:\nscripts/\n├── 01_data_exploration.R\n├── 02_penguin_correlations.R  \n├── 03_species_analysis.R\n├── 04_body_mass_analysis.R    # Additional analysis\n└── 05_visualization_experiments.R\nBenefits of script-based development: - Fast iteration: No need to knit/render documents during development - Interactive debugging: Can run code line-by-line in R console - Version control friendly: Pure R files produce clean diffs in Git - Easy collaboration: Contributors can add numbered script files - Flexible experimentation: Quick to test ideas and approaches\n\n\n2.5.2 Phase 2: Function Extraction (R/)\nAs analysis patterns emerge, extract reusable functions to the R/ directory:\n# R/penguin_utils.R\ncalculate_species_correlation &lt;- function(data, x_var, y_var, \n                                          species_filter = NULL) {\n  # Reusable function extracted from scripts\n  if (!is.null(species_filter)) {\n    data &lt;- data[data$species == species_filter, ]\n  }\n  cor(data[[x_var]], data[[y_var]], use = \"complete.obs\")\n}\n\ncreate_species_plot &lt;- function(data, x_var, y_var) {\n  # Standardized plotting function\n  ggplot(data, aes_string(x = x_var, y = y_var, \n                          color = \"species\")) +\n    geom_point() +\n    theme_minimal()\n}\n\n\n2.5.3 Phase 3: Publication Integration (analysis/paper/)\nOnce analysis approaches stabilize, integrate polished results into the manuscript:\n# In analysis/paper/paper.Rmd\n# Option 1: Source complete scripts\nsource(\"../../scripts/02_penguin_correlations.R\")\nsource(\"../../scripts/04_body_mass_analysis.R\")\n\n# Option 2: Use extracted functions\nlibrary(here)\nsource(here(\"R\", \"penguin_utils.R\"))\n\ncorrelation_result &lt;- calculate_species_correlation(\n  penguins, \"flipper_length_mm\", \"bill_length_mm\"\n)\n\n\n2.5.4 Recommended Collaborative Workflow:\n\nProject initialization: Project maintainer runs zzrrtools.sh to create project structure\nImmediate containerization: Build Docker container and switch to container-based development from day one\nInitial development: Create exploratory scripts in scripts/ directory inside the container\nCollaborative iteration: Team members clone repo, build identical container, add additional script files through pull requests from within the container\nCode review in scripts: Both developers refine analysis logic in script files while working in identical Docker environments\nFunction extraction: Move stable, reusable code to R/ directory\nPaper integration: Source scripts or use functions in analysis/paper/paper.Rmd\nContinuous validation: All development and testing occurs within the containerized environment\n\nWhy this container-first approach works:\n\nReproducibility: Eliminates “works on my machine” problems from day one\nIdentical environments: All collaborators work in exactly the same computational environment\nNo environment drift: Cannot occur when everyone develops within containers\nSpeed: Script development is faster than R Markdown knitting\nModularity: Each script can focus on a specific analysis aspect\nTestability: Functions in R/ can be easily unit tested in the same environment they’ll run in production\nSimple collaboration: Environment setup becomes a one-time docker build command for all contributors\nDevelopment-production parity: The development environment IS the production environment\n\nThis container-first, phased approach gives collaborators the speed of script-based development during exploration while maintaining the reproducibility and narrative flow of literate programming for final outputs. Most importantly, it ensures that all development occurs within the exact computational environment that will be used for final analysis and publication.\nWhile zzrrtools establishes the organizational foundation for reproducible research, it relies on consistent R package environments to function effectively across different systems. The directory structure and R package framework created by zzrrtools becomes most useful when combined with precise dependency management. This is where renv becomes essential, providing the package-level consistency that complements zzrrtools’ structural approach."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "3.1 What is renv?",
    "text": "3.1 What is renv?\nrenv (Reproducible Environment) is an R package designed to create isolated, project-specific library environments. Instead of relying on a shared system-wide R library that might change over time, renv gives each project its own separate collection of packages with specific versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "3.2 Key Features of renv",
    "text": "3.2 Key Features of renv\n\nIsolated project library: renv creates a project-specific library (typically in renv/library) containing only the packages used by that project. This isolation ensures that updates or changes to packages in one project won’t affect others.\nLockfile for dependencies: When you finish installing or updating packages, renv::snapshot() produces a renv.lock file - a JSON document listing each package and its exact version and source. This lockfile is designed to be committed to version control and shared.\nEnvironment restoration: On a new machine (or when reproducing past results), renv::restore() installs the exact versions of packages specified in the lockfile. This creates an R package environment identical to the one that created the lockfile, provided the same R version is available. The R version is important since critical components of the R system, such as random number generation, and default factor handling policy vary between versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "3.3 Basic renv Workflow",
    "text": "3.3 Basic renv Workflow\nThe typical workflow with renv involves:\n# One-time installation of renv\ninstall.packages(\"renv\")\n\n# Initialize renv for the project\nrenv::init()  # Creates renv infrastructure\n\n# Install project-specific packages\n# ...\n\n# Save the package state to renv.lock\nrenv::snapshot()\n\n# Later or on another system...\nrenv::restore()  # Restore packages from renv.lock\nWhile renv successfully addresses package-level reproducibility by ensuring identical R package versions across environments, even perfect package consistency cannot prevent analyses from failing or producing different results due to variations in R versions, operating systems, or system-level dependencies. A complete reproducibility solution requires addressing these system-level differences, which is where Docker containerization becomes essential."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "4.1 What is Docker?",
    "text": "4.1 What is Docker?\nDocker is a platform that allows you to package software into standardized units called containers. A Docker container is like a lightweight virtual machine that includes everything needed to run an application: the code, runtime, system tools, libraries, and settings."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "href": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "4.2 Docker’s Role in Reproducibility",
    "text": "4.2 Docker’s Role in Reproducibility\nWhile renv handles R packages, Docker ensures consistency for:\n\nOperating system: The specific Linux distribution or OS version\nR interpreter: The exact R version\nSystem libraries: Required C/C++ libraries and other dependencies\nComputational environment: Memory limits, CPU configuration, etc.\nExternal tools: pandoc, LaTeX, and other utilities needed for R Markdown\n\nBy running an R Markdown project in Docker, you eliminate differences in OS or R installation as potential sources of irreproducibility. Any machine running Docker will execute the container in an identical environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#docker-components-for-r-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#docker-components-for-r-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "4.3 Docker Components for R Workflows",
    "text": "4.3 Docker Components for R Workflows\nFor R-based projects, a typical Docker approach involves:\n\nBase image: Starting from a pre-configured R image (e.g., from the Rocker project)\nDependencies: Adding system and R package dependencies\nConfiguration: Setting working directories and environment variables\nContent: Adding project files\nExecution: Defining how the project should run\n\nThe zzrrtools setup uses a streamlined Dockerfile based on rocker/r-ver with TinyTeX for LaTeX support. The R version is matched to the renv.lock file:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Prevent interactive prompts\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install minimal system dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    pandoc \\\n    vim \\\n    git \\\n    curl \\\n    fonts-dejavu \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/bash ${USERNAME}\n\n# Set user R library path\nENV R_LIBS_USER=/home/${USERNAME}/R/library\n\n# Create user R library directory and assign permissions\nRUN mkdir -p /home/${USERNAME}/R/library && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/R\n\n# Set working directory\nWORKDIR /home/${USERNAME}\n\n# Copy renv files with correct ownership\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R ./renv/\n\n# Switch to non-root user\nUSER ${USERNAME}\n\n# Install base R packages to user library\nRUN Rscript -e '.libPaths(Sys.getenv(\"R_LIBS_USER\")); \\\n    install.packages(c(\"tinytex\", \"rmarkdown\", \"renv\"), \\\n    repos = \"https://cloud.r-project.org\")'\n\n# Install TinyTeX in user directory\nRUN Rscript -e 'tinytex::install_tinytex()'\n\n# Add TinyTeX binaries to PATH\nENV PATH=/home/${USERNAME}/.TinyTeX/bin/x86_64-linux:$PATH\n\n# Restore R packages via renv\nRUN Rscript -e '.libPaths(Sys.getenv(\"R_LIBS_USER\")); \\\n    renv::restore()'\n\n# Default to interactive shell\nCMD [\"/bin/bash\"]\nThis configuration provides a minimal R installation with LaTeX support for PDF rendering and secure non-root user execution.\nDocker Compose Integration:\nThe setup also includes a docker-compose.yml that provides multiple development environments:\n# Multiple services for different workflows\nservices:\n  r-session:   # Interactive R session  \n  bash:        # Bash shell access\n  research:    # Automated paper rendering\n  test:        # Package testing\n  check:       # Package checking\nThis allows developers to choose their preferred development environment while maintaining identical package dependencies and system configuration."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "href": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "5.1 Why Use All Three?",
    "text": "5.1 Why Use All Three?\nUsing any single tool improves reproducibility, but combining all three provides the most complete solution:\n\nzzrrtools provides standardized project structure and research compendium organization\nrenv guarantees the R packages and their versions\nDocker guarantees the OS and R version\nTogether they achieve end-to-end reproducibility from project organization through package dependencies to operating system consistency\n\nThis approach creates a fully portable, well-organized research compendium that can be shared and will produce identical results across different computers while following established research best practices."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-governance-model",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-governance-model",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "5.2 Integration Strategy with Governance Model",
    "text": "5.2 Integration Strategy with Governance Model\nThe workflow integrates zzrrtools, renv, and Docker with a clear governance structure suitable for multi-developer research teams:\nProject Maintainer Role: - Creates and maintains the research compendium structure - Manages renv environment and package dependencies using consistency checking - Updates and maintains Docker images - Reviews and approves contributor changes - Runs renv validation before accepting pull requests\nContributor Role (Other Developers): - Access the private research compendium as invited collaborators - Add analysis content, papers, and documentation using feature branches - Propose new package dependencies through contributions - Submit changes via pull requests from feature branches\nWorkflow Steps:\n\nInitialize Research Compendium (Maintainer):\n\nCreate standardized project structure using zzrrtools framework\nSet up analysis directories with data organization\nInitialize renv environment with renv::init()\nCreate Dockerfile with container configuration\n\nEstablish Development Environment (Maintainer):\n\nInstall required packages and develop initial analysis\nCreate tests for analytical functions\nUse the renv consistency checker to validate and create initial lockfile:\n# Validate dependencies and create snapshot\nRscript check_renv_for_commit.R --fix\nBuild and test Docker image locally\n\nMaintain Infrastructure (Maintainer):\n\nReview contributor pull requests for package additions\nUse renv consistency checker to validate and update dependencies:\n# Validate contributor's package requirements\nRscript check_renv_for_commit.R --fail-on-issues\n\n# If validation passes, update environment\nRscript check_renv_for_commit.R --fix\nUpdate renv.lock by selectively incorporating new dependencies\nRebuild Docker images when system dependencies change\nPush updated images to container registry (Docker Hub, GitHub Container Registry)\n\nCollaborative Development (All Developers):\nResearch Compendium Files in GitHub Repository:\n\nProject Structure: DESCRIPTION, LICENSE, README.qmd (zzrrtools-generated)\nAnalysis Content: Files in analysis/paper/ directory (R Markdown manuscripts)\nDependencies: renv.lock (managed by maintainer), renv/activate.R\nInfrastructure: Dockerfile (maintained by project maintainer)\nCode: R/ directory (utility functions), tests/ directory\nDocumentation: Generated README files and project documentation\nConfiguration: .gitignore, .github/ (CI/CD workflows)\n\nSharing the Docker image using Docker Hub:\nDocker Hub provides public image hosting that enables reproducible research by sharing computational environments while protecting private research code in GitHub.\nDocker Hub (Recommended for Reproducible Research)\n# Build the image with GitHub Container Registry URL\ndocker build -t ghcr.io/username/penguins_analysis:v1.0 .\n\n# Login to GitHub Container Registry (using GitHub Personal Access Token)\necho $GITHUB_TOKEN | docker login ghcr.io -u username \\\n  --password-stdin\n\n# Push to GitHub Container Registry (automatically private)\ndocker push ghcr.io/username/penguins_analysis:v1.0\nSetting up GitHub Personal Access Token:\nCreate a Personal Access Token with the required permissions for container registry operations. The token must include write:packages and read:packages scopes, plus repo access for private repositories.\nFor detailed step-by-step instructions, see Appendix A: GitHub Personal Access Token Setup.\n# Export token as environment variable (replace with your actual token)\nexport GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n# Login and push\necho $GITHUB_TOKEN | docker login ghcr.io -u username \\\n  --password-stdin\ndocker build -t ghcr.io/username/penguins_analysis:v1.0 .\ndocker push ghcr.io/username/penguins_analysis:v1.0\nNote: If you get a “permission_denied” error when pushing, ensure your token includes the correct scopes (see Appendix A for details).\nGitHub Container Registry Benefits:\n\nFree tier: 0.5GB storage included, no billing currently active\nAutomatic access control: Inherits repository permissions\nIntegrated with GitHub Actions: Direct authentication in CI/CD\nSimple team sharing: Repository collaborators automatically have access\nPackage management: Integrated with GitHub Packages ecosystem\n\nDocker Workflow:\nThe zzrrtools setup provides multiple approaches for working with containers, from simple Make commands to direct Docker execution. Make commands offer simplicity:\n# Build and run with Make (recommended)\nmake docker-build    # Build the container\nmake docker-r        # Interactive R session\nmake docker-render   # Render research paper\nFor Docker workflow options including Docker Compose and direct commands, see Appendix D: Docker Workflow Options.\nExecute consistently:\n\nRun analyses in the Docker container for guaranteed reproducibility\nUse volume mounts to access local files while maintaining environment consistency\nRun tests within the container to verify functionality\n\n\nThis strategy ensures that your R Markdown documents and analyses will run identically for anyone who has access to your Docker container, regardless of their local setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "href": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "6.1 Project Scenario",
    "text": "6.1 Project Scenario\nA team of data scientists collaborates on Palmer Penguins analysis using zzrrtools’ Docker-first workflow that eliminates environment setup friction:\n\nJoe (joe): Project maintainer who initializes the repository\nSam (sam): Contributor who extends the analysis\n\nAdditional team members: Can join without any local R installation\n\nThe collaboration model emphasizes zero-setup team onboarding through self-replicating project distribution and containerized development environments.\n\nCollaboration Philosophy: - Self-contained projects: Each repository includes its own setup script - Container-first development: All work happens in identical Docker environments - Automated dependency validation: Pre-commit checks prevent conflicts - Shell-based workflows: Command-line tools for maximum flexibility\n\nKey Workflow Principles: - Joe initializes with zzrrtools and commits the setup script to the repository - Team members run the included script - no separate installation required - All development occurs in containers for perfect environment consistency - Dependency changes are validated before commits to prevent team conflicts - Each developer works in identical environments regardless of host system"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "href": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "6.2 Implementation Example",
    "text": "6.2 Implementation Example\n\n6.2.1 Project Maintainer Setup (Joe)\nJoe initializes a private GitHub repository and creates the containerized research environment:\n# Create repository and initialize zzrrtools\ngit clone https://github.com/joe/penguins_analysis.git\ncd penguins_analysis\n~/prj/zzrrtools/zzrrtools.sh --dotfiles ~/.config/shell \\\n                             --base-image rgt47/r-pluspackages\nThis creates: - Research compendium directory structure - Docker container configuration - renv dependency management - Automated validation scripts - GitHub Actions workflows\nFor a detailed view of the complete directory structure created by zzrrtools, see Appendix C: Directory Structure.\nJoe completes the setup and begins development:\n# Validate dependencies and build container\nmake check-renv\nmake docker-build\n\n# Start container-based development\nmake docker-r\nFor detailed information on renv dependency validation, troubleshooting, and team collaboration workflows, see Appendix G: renv Management and Validation.\nThe validation script ensures package environment consistency by verifying dependencies across code files, DESCRIPTION, and renv.lock, preventing common collaboration issues where team members have mismatched environments.\nStep 4: Create Initial Analysis Paper\nJoe creates an initial analysis examining flipper length vs. bill length relationships in the Palmer Penguins dataset, implementing basic visualization and statistical exploration within the research compendium structure.\nStep 5: Create Tests for Analysis Functions\nJoe implements testing to ensure reproducible research through data validation, error detection, and environment verification. Testing provides collaboration confidence and supports publication standards by validating data integrity, statistical relationships, and pipeline functionality.\nJoe sets up the testing framework and creates basic data validation tests to verify dataset availability, dimensions, and required columns. These tests ensure the analysis environment is correctly configured and catch data-related issues early in the development process.\nFor a complete test suite with data validation, statistical tests, and integration tests, see Appendix B: Test Suite.\nStep 6: Create a .gitignore file\nJoe configures version control to track source code and dependencies while excluding generated outputs and temporary files. The principle: track the “recipe” (code + dependencies), not the “meal” (outputs).\nJoe creates a .gitignore file excluding renv libraries, generated outputs, temporary files, and system artifacts. This keeps the repository lightweight while ensuring collaborators can recreate the complete environment from tracked dependencies.\nStep 7: Create a Dockerfile\nzzrrtools generates a Dockerfile with multiple template options. The standard template uses rocker/r-ver, while the pluspackages template includes common R packages like tidyverse. Both provide:\n\nR version consistency: Matches exact R version specified in renv.lock\nDevelopment environment: Includes zsh, vim, tmux, Node.js for plugin support\nSecurity: Non-root user execution with proper file permissions\nTinyTeX integration: LaTeX support for PDF rendering (pluspackages template)\nPre-installed packages: Common packages like tidyverse, DT, testthat (pluspackages template)\n\nThe generated Dockerfile includes development tools and optimizations:\nARG R_VERSION=latest\nFROM rocker/r-ver:${R_VERSION}\n\n# Install comprehensive development environment\nRUN apt-get update && apt-get install -y \\\n    git ssh curl wget vim tmux zsh build-essential \\\n    libcurl4-openssl-dev libssl-dev libxml2-dev \\\n    libfontconfig1-dev libharfbuzz-dev libfribidi-dev \\\n    libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev \\\n    man-db pandoc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Node.js for vim plugins\nRUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \\\n    apt-get install -y nodejs\n\n# Create non-root user with zsh shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set up R environment with renv\nWORKDIR /home/${USERNAME}/project\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nUSER ${USERNAME}\nRUN R -e \"install.packages('renv'); renv::restore()\"\n\n# Copy project files and install\nCOPY --chown=${USERNAME}:${USERNAME} . .\nRUN R -e \"devtools::install('.')\"\n\nCMD [\"/bin/zsh\"]\nAlternative: Pre-packaged Template\nFor projects using common packages, the pluspackages template includes TinyTeX and popular R packages:\n# Install TinyTeX for PDF rendering\nRUN R -e \"install.packages('tinytex')\" && \\\n    R -e \"tinytex::install_tinytex()\" && \\\n    /root/.TinyTeX/bin/*/tlmgr path add\n\n# Install common R packages (cached layer)\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', \\\n    'testthat', 'naniar', 'DT', 'conflicted', 'ggthemes', \\\n    'datapasta', 'janitor', 'kableExtra', 'tidytuesdayR', \\\n    'tidyverse'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Give user write permissions to R library\nRUN chown -R ${USERNAME}:${USERNAME} /usr/local/lib/R/site-library\nFor production Dockerfiles with development environment configuration (zsh, vim plugins, dotfiles integration), see Appendix F: Docker Configuration Examples.\nR Version Synchronization:\nThe Dockerfile uses a build argument to ensure the R version exactly matches what’s specified in renv.lock. This eliminates potential issues from R version mismatches between the package environment and the underlying R interpreter. The build command extracts the R version from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/joe/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment.\nStep 8: Container-Based Development\nJoe performs all development work inside the Docker container, ensuring consistent environments and immediate visibility of changes to the host system through volume mounting. The container provides a complete development environment with package management, editing tools, and validation utilities.\nStep 9: Update and Share Environment\nWhen package dependencies change, GitHub Actions automatically rebuilds the Docker image with updated renv.lock specifications and pushes the updated environment to Docker Hub for team access. This ensures collaborators have access to the identical development environment.\nStep 10: Prepare for Team Handoff\nBefore handing off to team members, Joe must complete several critical steps:\n# 1. Validate all dependencies are properly captured\nmake check-renv-fix\n\n# 2. Run complete test suite to ensure everything works\nmake docker-test\n\n# 3. Render paper to verify end-to-end workflow\nmake docker-render\n\n# 4. Build and tag the Docker image\nmake docker-build\ndocker tag penguins_analysis ghcr.io/joe/penguins_analysis:v1.0\n\n# 5. Push Docker image to Docker Hub for team access\necho $GITHUB_TOKEN | docker login ghcr.io -u joe --password-stdin\ndocker push ghcr.io/joe/penguins_analysis:v1.0\n\n# 6. Commit all setup files and push to repository\ngit add .\ngit commit -m \"Initial research compendium setup with Docker environment\"\ngit push origin main\nStep 11: Enable Team Access\nJoe configures repository permissions for team collaboration:\n\nRepository Settings → Collaborators → Add team members\nGrant “Write” access to enable forking and pull requests\nShare repository URL and Docker Hub image name with team\nDocument onboarding process in README or team communication\n\nAt this point, Joe has established a reproducible research framework ready for collaborative development. The containerized environment is available via the registry, and team members can join with zero local setup requirements.\n\n\n6.2.2 Team Member Onboarding (Sam)\nWhat Sam Receives from Joe: - Repository URL: https://github.com/joe/penguins_analysis - Container registry access (GitHub Personal Access Token) - Brief project overview and development guidelines\nSam’s Onboarding Process:\n# 1. Clone the zzrrtools framework\ngit clone https://github.com/username/zzrrtools.git ~/prj/zzrrtools\ncd ~/prj/zzrrtools\n./install.sh  # Creates zzrrtools command in PATH\n\n# 2. Fork and clone the project repository\ngit clone https://github.com/sam/penguins_analysis.git  # Sam's fork\ncd penguins_analysis\n\n# 3. Run zzrrtools setup with personal preferences\nzzrrtools --dotfiles ~/.config/shell  # Customize with personal dotfiles\n# Or use other options:\n# zzrrtools --base-image rgt47/r-pluspackages  # Use pre-packaged template\n# zzrrtools --no-docker                       # Skip Docker build\n# zzrrtools --next-steps                      # Show workflow guidance\n\n# 4. Pull the pre-built Docker environment\ndocker pull ghcr.io/joe/penguins_analysis:v1.0\n\n# 5. Start development in identical environment\nmake docker-r\nKey Advantage: After one-time zzrrtools installation, Sam has access to the framework for all future projects. The development environment setup becomes a simple script execution.\nSam develops new analysis components within the same containerized environment, ensuring identical results across team members.\nStep 5: Paper Integration and Testing\nSam integrates the new analysis into the research paper, combining Joe’s original visualizations with the new body mass analysis. Sam also creates tests to validate the new functionality and ensure package dependencies are properly documented.\nStep 6: Validation and Quality Assurance\nSam creates tests for the new body mass analysis, validates data integrity and statistical relationships, then runs the complete test suite and verifies paper rendering to ensure no regressions before submission.\nStep 7: Contribution Submission\nWhen Sam completes the analysis iteration, the submission process follows these steps:\n\nValidate dependencies: Run make docker-check-renv-fix to ensure package consistency\nRun complete test suite: Execute make docker-test to verify all tests pass\nVerify paper rendering: Run make docker-render to confirm analysis integrates properly\nCommit changes:\ngit add .\ngit commit -m \"Add body mass analysis and associated tests\"\ngit push origin feature/body-mass-analysis\nCreate pull request: Submit pull request from Sam’s fork to Joe’s original repository\nNotify Joe: Alert project maintainer about new packages or Docker changes needed\n\nNote: Only Joe (project maintainer) can accept pull requests. The official Docker image is automatically rebuilt and pushed to Docker Hub by GitHub Actions when package dependencies change.\nCI Feedback Loop: If the CI workflow fails (e.g., renv validation issues), Sam receives automatic GitHub notifications and can view detailed failure logs to fix the issues before Joe reviews the PR.\nSam commits the completed analysis, tests, and documentation to their feature branch and creates a cross-repository pull request to the original repository. This ensures proper code review and governance while maintaining clear attribution of contributions.\nAt this point, Sam has successfully contributed new analysis through the collaborative workflow. Joe reviews the pull request, tests the changes in the containerized environment, and merges the contribution while maintaining project governance and quality standards."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "href": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "6.3 Complete Handoff Workflow Summary",
    "text": "6.3 Complete Handoff Workflow Summary\nInitiating Developer (Joe) Responsibilities: 1. Run zzrrtools.sh to create research compendium 2. Develop initial analysis and create tests 3. Validate dependencies with make check-renv-fix\n4. Build initial Docker image and configure automated rebuilds via GitHub Actions 5. Push team Docker image to Docker Hub (public registry for reproducibility) 6. Commit all files and push to repository 7. Grant team member repository access\n8. Share repository URL and Docker Hub image name\nJoining Developer (Sam) Process: 1. Receive repository URL and Docker Hub image name from Joe 2. Clone zzrrtools framework: git clone zzrrtools ~/prj/zzrrtools 3. Install zzrrtools: cd ~/prj/zzrrtools && ./install.sh (creates zzrrtools command in PATH) 4. Fork and clone project repository 5. Pull pre-built team Docker image: docker pull [TEAM]/project:latest (from Docker Hub) 6. Start development immediately: make docker-r (no local setup needed) 7. Submit contributions via pull requests to private repository\nKey Success Factor: The containerized environment and centralized zzrrtools framework eliminate project-specific configuration requirements for team members after one-time framework installation."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "href": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "6.4 Collaboration Results",
    "text": "6.4 Collaboration Results\nThis workflow achieves: - Identical development environments across team members - Dependency validation preventing conflicts - Standardized project structure - Automated testing and CI/CD integration\nFor GitHub Actions setup instructions, workflow examples, and CI/CD configuration, see Appendix E: GitHub Actions CI/CD Setup.\nThe collaborative workflow demonstrated above illustrates the power of combining zzrrtools, renv, and Docker for reproducible research. However, successful implementation of this approach requires understanding both when it’s most beneficial and how to apply it effectively. The following best practices and considerations provide guidance for teams considering this strategy."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "7.1 When to Use This Approach",
    "text": "7.1 When to Use This Approach\nThe zzrrtools + renv + Docker approach with testing is particularly valuable for:\n\nLong-term research projects where reproducibility over time is crucial\nCollaborative analyses with multiple contributors on different systems\nProduction analytical pipelines that need to run consistently\nAcademic publications where methods must be reproducible\nTeaching and education to ensure consistent student experiences\nComplex analyses that require testing to validate results"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "href": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "7.2 Tips for Efficient Implementation",
    "text": "7.2 Tips for Efficient Implementation\n\nKeep Docker images minimal: Include only what’s necessary for reproducibility.\nUse specific version tags: For both R packages and Docker base images, specify exact versions.\nDocument system requirements: Include notes on RAM and storage requirements.\nLeverage bind mounts: Mount local directories to containers for easier development.\nWrite meaningful tests: Focus on validating both data integrity and analytical results.\nTest regularly: Use CI/CD pipelines to run tests on every change.\nConsider computational requirements: Particularly for resource-intensive analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "href": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "7.3 Testing Strategies for R Analyses",
    "text": "7.3 Testing Strategies for R Analyses\nTesting data analysis code differs from traditional software testing but provides crucial value for reproducible research:\n\nData Validation Tests: Ensure data has the expected structure, types, and values.\nFunction Tests: Verify that custom functions work as expected with known inputs and outputs.\nEdge Case Tests: Check how code handles missing values, outliers, or unexpected inputs.\nIntegration Tests: Confirm that different parts of the analysis work correctly together.\nRegression Tests: Make sure new changes don’t break existing functionality.\nOutput Validation: Verify that final results match expected patterns or benchmarks.\n\nWhile uncommon in traditional data analysis, these tests catch silent errors, validate assumptions, and provide confidence that analyses remain correct as code and data evolve."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "href": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "7.4 Potential Challenges",
    "text": "7.4 Potential Challenges\nSome challenges to be aware of:\n\nDocker image size: Images with many packages can become large\nLearning curve: Docker, renv, and testing frameworks require some initial learning\nSystem-specific features: Some analyses may rely on hardware features\nPerformance considerations: Containers may have different performance characteristics\nTest maintenance: Tests need to be updated as the analysis evolves"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "7.5 Troubleshooting Common Issues",
    "text": "7.5 Troubleshooting Common Issues\nDocker Build Failures: - Try: export DOCKER_BUILDKIT=0 (disable BuildKit) - Check Docker has sufficient memory/disk space - Ensure Docker is running and up to date\nPlatform Warnings on ARM64/Apple Silicon: - Use updated Makefile with --platform linux/amd64 flags - Or set: export DOCKER_DEFAULT_PLATFORM=linux/amd64\nPermission Errors in Container: - Rebuild image after copying dotfiles - Check file ownership in project directory\nPackage Name Errors: - Ensure directory name contains only letters/numbers/periods - Avoid underscores and special characters\nMissing Dotfiles in Container: - Use --dotfiles or --dotfiles-nodot flag during setup - Rebuild Docker image after adding dotfiles\nDespite these challenges, the benefits of reproducible research outweigh the implementation costs, particularly for collaborative and long-term projects. The approach described in this white paper provides a foundation for achieving reproducibility that meets the standards expected in data science and academic research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.1 Step-by-Step Token Creation",
    "text": "9.1 Step-by-Step Token Creation\n1. Navigate to GitHub Settings: - Go to GitHub.com and sign in - Click your profile picture (top right) → Settings - In the left sidebar: Developer settings → Personal access tokens\nNote: GitHub now offers two token types: - Fine-grained personal access tokens (recommended for new projects) - Personal access tokens (classic) (for broader compatibility)\n2. Create New Token: - Click “Generate new token” and select the appropriate type - Add a descriptive note (e.g., “Docker Container Registry Access”) - Set expiration (recommended: 90 days for security)\n3. Select Required Scopes (check these boxes): - ✅ repo (Full control of private repositories) - Required for private repos - ✅ write:packages (Upload Docker images to GitHub Container Registry) - Required for project maintainer - ✅ read:packages (Download Docker images from GitHub Container Registry) - Required for all team members - ✅ delete:packages (Delete packages from GitHub Package Registry) - Optional but recommended\nNote: Team members only need read:packages and repo, but the project maintainer needs all container permissions to push Docker images.\nToken Type Recommendation: Use fine-grained personal access tokens for new projects as they provide better security and more precise permissions.\n4. Generate and Copy Token: - Click “Generate token” at the bottom - Important: Copy the token immediately - you won’t see it again - Store it securely (see security practices below)"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "href": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.2 Token Security Best Practices",
    "text": "9.2 Token Security Best Practices\n\nNever commit tokens to repositories - Use .gitignore to exclude files containing tokens\nUse environment variables - Store tokens in shell environment variables\nSet reasonable expiration dates - Use 30-90 day expiration for security\nRevoke unused tokens - Clean up tokens when no longer needed\nConsider GitHub CLI - Use gh auth login for easier management\nMonitor token usage - Check GitHub Settings → Developer settings → Personal access tokens for activity"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "href": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.3 Alternative: Using GitHub CLI",
    "text": "9.3 Alternative: Using GitHub CLI\nFor simpler token management, consider using GitHub CLI instead of manual tokens:\n# Install and authenticate (handles tokens)\ngh auth login --scopes write:packages,read:packages,repo\n\n# Login to container registry (works with gh auth)\necho $(gh auth token) | docker login ghcr.io \\\n  -u $(gh api user --jq .login) --password-stdin"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.4 Troubleshooting Common Issues",
    "text": "9.4 Troubleshooting Common Issues\n“permission_denied: The token provided does not match expected scopes” - Verify your token includes write:packages and read:packages scopes - For private repositories, ensure repo scope is also selected - Create a new token with correct permissions if needed\nToken not recognized: - Ensure token is properly exported: export GITHUB_TOKEN=your_token_here - Verify token hasn’t expired - Check that you’re using the full token (starts with ghp_) 6. Horst, A.M., Hill, A.P., & Gorman, K.B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ 7. Marwick, B. (2016). Computational reproducibility in archaeological research: Basic principles and a case study of their implementation. Journal of Archaeological Method and Theory, 24(2), 424-473."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R",
    "text": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R\nlibrary(testthat)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\n# Test 1: Data Availability and Basic Structure\n# Generic application: Verify your primary dataset loads correctly and has \n# expected dimensions\n# Catches: Package loading issues, file path problems, corrupted data files\ntest_that(\"Palmer Penguins dataset is available and has correct structure\", \n          {\n  expect_true(exists(\"penguins\", where = \"package:palmerpenguins\"))\n  expect_s3_class(palmerpenguins::penguins, \"data.frame\")\n  expect_equal(ncol(palmerpenguins::penguins), 8)  # Adapt: Set expected \n                                                    # column count\n  expect_gt(nrow(palmerpenguins::penguins), 300)   # Adapt: Set minimum \n                                                    # row threshold\n  expect_equal(nrow(palmerpenguins::penguins), 344)  # Adapt: Set exact \n                                                      # expected count \n                                                      # if known\n})\n\n# Test 2: Required Columns Exist with Correct Types\n# Generic application: Ensure your analysis depends on columns that \n# actually \n# exist with correct types\n# Catches: Column name changes, type coercion issues, CSV import problems\ntest_that(\"Dataset contains required columns with expected data types\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Check column existence - Adapt: List columns your analysis requires\n  required_cols &lt;- c(\"species\", \"island\", \"bill_length_mm\", \n                     \"bill_depth_mm\", \"flipper_length_mm\", \n                     \"body_mass_g\", \"sex\", \"year\")\n  expect_true(all(required_cols %in% names(df)))\n  \n  # Check data types - Adapt: Verify types match your analysis \n  # expectations\n  expect_type(df$species, \"integer\")  # Factor stored as integer\n  expect_type(df$bill_length_mm, \"double\")  # Continuous measurements\n  expect_type(df$flipper_length_mm, \"integer\")  # Discrete measurements\n  expect_type(df$body_mass_g, \"integer\")  # Integer measurements\n})\n\n# Test 3: Categorical Variables Have Expected Levels\n# Generic application: Verify factor levels for categorical variables used\n# in \n# analysis\n# Catches: Missing categories, typos in factor levels, data encoding issues\ntest_that(\"Species factor has expected levels\", {\n  species_levels &lt;- levels(palmerpenguins::penguins$species)\n  expected_species &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")  # Adapt: Your \n                                                          # expected \n                                                          # categories\n  expect_equal(sort(species_levels), sort(expected_species))\n  expect_equal(length(species_levels), 3)  # Adapt: Expected number of \n                                           # categories\n  # For other datasets: Test treatment groups, regions, product types, etc.\n})\n\n# Test 4: Data Value Ranges are Domain-Reasonable\n# Generic application: Verify numeric values fall within realistic ranges\n# for \n# your domain\n# Catches: Data entry errors, unit conversion mistakes, outliers from \n# measurement errors\ntest_that(\"Measurement values fall within reasonable biological ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Bill length - Adapt: Set realistic bounds for your numeric variables\n  bill_lengths &lt;- df$bill_length_mm[!is.na(df$bill_length_mm)]\n  expect_true(all(bill_lengths &gt;= 30 & bill_lengths &lt;= 70))  # Penguin-\n                                                              # specific \n                                                              # range\n  \n  # Flipper length - Examples for other domains:\n  flipper_lengths &lt;- df$flipper_length_mm[!is.na(df$flipper_length_mm)]\n  expect_true(all(flipper_lengths &gt;= 150 & flipper_lengths &lt;= 250))\n  # Finance: stock prices &gt; 0, percentages 0-100\n  # Health: age 0-120, BMI 10-80, blood pressure 50-300\n  # Engineering: temperatures -273+°C, pressures &gt; 0\n  \n  # Body mass\n  body_masses &lt;- df$body_mass_g[!is.na(df$body_mass_g)]\n  expect_true(all(body_masses &gt;= 2000 & body_masses &lt;= 7000))\n})\n\n# Test 5: Missing Data Patterns are as Expected\n# Generic application: Verify missingness patterns match your data \n# collection \n# expectations\n# Catches: Unexpected data loss, systematic missingness, data pipeline \n# failures\ntest_that(\"Missing data follows expected patterns\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Total missing values should be manageable\n  total_na &lt;- sum(is.na(df))\n  expect_lt(total_na, nrow(df))  # Adapt: Set acceptable threshold for \n                                 # missing \n                                 # data\n  \n  # Some variables may have expected missingness\n  expect_gt(sum(is.na(df$sex)), 0)  # Sex determination sometimes difficult\n  # Adapt examples: Optional survey questions, historical data gaps, sensor \n  # failures\n  \n  # Critical variables should be complete\n  expect_equal(sum(is.na(df$species)), 0)  # Primary identifier must be \n                                           # complete\n  # Adapt: ID columns, primary keys, required fields should have no NAs\n})\n\n# Test 6: Expected Statistical Relationships Hold\n# Generic application: Test known relationships between variables in your \n# domain\n# Catches: Data corruption, encoding errors, units mix-ups that break known \n# patterns\ntest_that(\"Expected correlations between measurements exist\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test strong expected relationships\n  correlation &lt;- cor(df$flipper_length_mm, df$body_mass_g, \n                     use = \"complete.obs\")\n  expect_gt(correlation, 0.8)  # Strong positive correlation expected\n  # Adapt examples: height vs weight, price vs quality, experience vs salary\n  \n  # Test weaker but expected relationships\n  bill_cor &lt;- cor(df$bill_length_mm, df$bill_depth_mm, use = \"complete.obs\")\n  expect_gt(abs(bill_cor), 0.1)  # Some relationship should exist\n  # Adapt: Education vs income, advertising vs sales, temperature vs \n  # energy use\n})\n\n# Test 7: Visualization Functions Work Correctly\n# Generic application: Ensure your key plots and visualizations can be \n# generated\n# Catches: Missing aesthetic mappings, incompatible data types, package \n# conflicts\ntest_that(\"Basic plots can be generated without errors\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test basic plot creation without errors\n  expect_no_error({\n    p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      theme_minimal()\n  })\n  # Adapt: Test your key plot types - histograms, boxplots, time series,\n  # etc.\n  \n  # Test that plot object is properly created\n  p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n    geom_point()\n  expect_s3_class(p1, \"ggplot\")  # Adapt: Check for your plotting \n                                   # framework objects\n})\n\n# Test 8: Data Filtering and Subsetting Work Correctly\n# Generic application: Verify data manipulation operations produce expected\n# results\n# Catches: Logic errors in filtering, unexpected factor behaviors, \n# indexing mistakes\ntest_that(\"Data can be properly filtered and subsetted\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test categorical filtering\n  adelie_penguins &lt;- df[df$species == \"Adelie\" & !is.na(df$species), ]\n  expect_gt(nrow(adelie_penguins), 100)  # Adapt: Expected subset size\n  expect_true(all(adelie_penguins$species == \"Adelie\", na.rm = TRUE))\n  # Adapt: Filter by treatment groups, regions, time periods, etc.\n  \n  # Test missing data handling\n  complete_cases &lt;- df[complete.cases(df), ]\n  expect_lt(nrow(complete_cases), nrow(df))  # Some rows should be removed\n  expect_equal(sum(is.na(complete_cases)), 0)  # No NAs remaining\n  # Adapt: Test your specific data cleaning operations\n})\n\n# Test 9: Summary Statistics are Reasonable\n# Generic application: Verify computed statistics match domain knowledge \n# expectations\n# Catches: Calculation errors, unit mistakes, algorithm bugs, extreme \n# outliers\ntest_that(\"Summary statistics fall within expected ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test means fall within expected ranges\n  mean_flipper &lt;- mean(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(mean_flipper, 190)  # Adapt: Set realistic bounds for your \n                                # variables\n  expect_lt(mean_flipper, 210)\n  # Examples: Average customer age 20-80, mean salary $30k-200k, etc.\n  \n  # Test other central tendencies\n  mean_mass &lt;- mean(df$body_mass_g, na.rm = TRUE)\n  expect_gt(mean_mass, 4000)\n  expect_lt(mean_mass, 5000)\n  \n  # Test variability measures are reasonable\n  sd_flipper &lt;- sd(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(sd_flipper, 5)   # Not zero variance\n  expect_lt(sd_flipper, 30)  # Not excessive variance\n  # Adapt: CV should be &lt;50%, SD should be meaningful relative to mean\n})\n\n# Test 10: Complete Analysis Pipeline Integration Test\n# Generic application: Test your entire analysis workflow runs without \n# errors\n# Catches: Pipeline breaks, dependency issues, function interaction problems\ntest_that(\"Complete analysis pipeline executes successfully\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test that full workflow executes without errors\n  expect_no_error({\n    # Data preparation step\n    clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                       \"bill_length_mm\")]), ]\n    \n    # Statistical analysis step - Adapt: Your key analyses\n    correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                   clean_df$bill_length_mm)\n    \n    # Visualization step - Adapt: Your key plots\n    plot_result &lt;- ggplot(clean_df, \n                          aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      geom_smooth(method = \"lm\") +\n      theme_minimal() +\n      labs(title = \"Flipper Length vs. Bill Length\",\n           x = \"Flipper Length (mm)\",\n           y = \"Bill Length (mm)\")\n  })\n  # Adapt: Add model fitting, prediction, reporting steps as needed\n  \n  # Verify analysis produces meaningful results\n  clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                     \"bill_length_mm\")]), ]\n  correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                 clean_df$bill_length_mm)\n  expect_lt(correlation_result$p.value, 0.05)  # Significant result expected\n  # Adapt: Check model R², prediction accuracy, convergence, etc.\n})"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "href": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.6 Running the Tests",
    "text": "9.6 Running the Tests\nTo run all tests in your project:\n# Run all tests\ntestthat::test_dir(\"tests/testthat\")\n\n# Run specific test file\ntestthat::test_file(\"tests/testthat/test-comprehensive-analysis.R\")\n\n# Run tests with detailed output\ntestthat::test_dir(\"tests/testthat\", reporter = \"detailed\")"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.7 Test Categories Explained",
    "text": "9.7 Test Categories Explained\nData Validation Tests (1-5): Verify data structure, types, ranges, and missing patterns Statistical Tests (6): Confirm expected relationships in the data Functional Tests (7-8): Ensure analysis functions work correctly Sanity Tests (9): Check that summary statistics are reasonable Integration Tests (10): Verify the complete analysis pipeline works end-to-end\nThese tests provide coverage for a data analysis project and can catch issues ranging from data corruption to environment setup problems."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.8 Key Features Explained:",
    "text": "9.8 Key Features Explained:\nData Organization: - raw_data/: Original, unmodified datasets as received - derived_data/: Processed, cleaned, or transformed data - metadata/: Documentation about data sources, collection methods, variables - validation/: Scripts that verify data integrity and quality - external_data/: Third-party datasets or reference data\nMultiple Output Formats: - figures/: Generated plots, charts, and visualizations - tables/: Generated summary tables and statistical results - paper/: Main manuscript and analysis documents - templates/: Document templates and citation style files\nR Package Structure: - R/: Custom functions and utilities - man/: Generated documentation for R functions - tests/testthat/: Unit tests and validation scripts - vignettes/: Long-form documentation and tutorials - DESCRIPTION: Package metadata and dependency specifications\nDocker Orchestration: - Dockerfile: Main container specification - docker-compose.yml: Multi-service development environments - Makefile: Build automation supporting both native R and Docker workflows\nWorkflows: - .github/workflows/: GitHub Actions for testing, checking, and rendering - setup_renv.R: Package environment setup - RRTOOLS_USER_GUIDE.md: Usage documentation\nNavigation Shortcuts: - Symbolic links: Single-letter shortcuts for easy navigation - a → analysis/, n → analysis/, f → figures/ - t → tests/, s → scripts/, m → man/ - e → external_data/, o → output/, c → cache/\nThis structure supports research projects while maintaining clear organization and following established research compendium principles."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.9 Multi-Service Docker Architecture",
    "text": "9.9 Multi-Service Docker Architecture\nzzrrtools creates specialized Docker environments for different development tasks:\n# Build the containerized research environment\nmake docker-build\n\n# Interactive R console (primary development environment)\nmake docker-r\n\n# Development shell with personal dotfiles\nmake docker-zsh\n\n# Interactive bash session\nmake docker-bash\n\n# RStudio Server (web-based IDE)\nmake docker-rstudio    # Access at http://localhost:8787\n\n# Render research paper\nmake docker-render\n\n# Run tests\nmake docker-test\n\n# Package checking\nmake docker-check\n\n# renv dependency validation\nmake docker-check-renv-fix\n\n# See all available commands\nmake help\nCollaborative Benefits: - Zero-setup onboarding: Team members run identical commands - Consistent environments: Same container across all developer machines - ARM64/Apple Silicon support: Platform-specific flags ensure compatibility - Shell-optimized workflows: Command-line development with rich tooling - Personal customization: Dotfiles integration for familiar environments - Web-based development: Optional RStudio Server for GUI-based workflows"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.10 Option 2: Docker Compose Services",
    "text": "9.10 Option 2: Docker Compose Services\nDocker Compose orchestrates multiple container configurations:\n# Interactive R session\ndocker-compose run --rm r-session\n\n# Bash shell access\ndocker-compose run --rm bash\n\n# Automated paper rendering\ndocker-compose run --rm research\n\n# Package testing\ndocker-compose run --rm test\n\n# Package checking\ndocker-compose run --rm check\nDocker Compose Configuration Example:\nservices:\n  r-session:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./cache:/home/analyst/cache\n    working_dir: /home/analyst/project\n    \n  bash:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n    working_dir: /home/analyst/project\n    entrypoint: [\"/bin/bash\"]\n    \n  research:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./analysis/figures:/home/analyst/output\n    working_dir: /home/analyst/project\n    command: [\"R\", \"-e\", \"rmarkdown::render('analysis/paper/paper.Rmd')\"]\nBenefits: - Service setup: Multiple predefined container configurations - Volume management: Consistent volume mounting across services - Environment isolation: Different services for different purposes - Parallel execution: Can run multiple services simultaneously"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.11 Option 3: Direct Docker Commands",
    "text": "9.11 Option 3: Direct Docker Commands\nFor maximum control, use Docker commands directly:\n# Basic interactive session\ndocker run --rm -it -v \"$(pwd):/home/analyst/project\" \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Interactive session with mounted cache\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/cache:/home/analyst/cache\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Render research paper\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/analysis/figures:/home/analyst/output\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n\n# Run specific tests\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"testthat::test_file('tests/testthat/test-data-integrity.R')\"\n\n# Interactive bash session\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  /bin/bash\nCommon Docker Flags Explained: - --rm: Remove container when it exits - -it: Interactive terminal session - -v: Mount volume (host:container) - -w: Set working directory inside container - --entrypoint: Override default command\nBenefits: - Full flexibility: Complete control over container configuration - Educational: Shows exactly what’s happening under the hood - Troubleshooting: Easier to debug when you see all options - Portability: Commands work on any Docker installation"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "href": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.12 Volume Mounting Strategies",
    "text": "9.12 Volume Mounting Strategies\nProject Files:\n# Mount entire project directory\n-v \"$(pwd):/home/analyst/project\"\nOutput Separation:\n# Separate outputs from source\n-v \"$(pwd)/analysis/figures:/home/analyst/output\"\nCache Persistence:\n# Persistent package cache across sessions\n-v \"$(pwd)/cache:/home/analyst/cache\"\nRead-only Source:\n# Protect source files from modification\n-v \"$(pwd):/home/analyst/project:ro\""
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.13 Choosing the Right Approach",
    "text": "9.13 Choosing the Right Approach\nUse Make Commands When: - You want simplicity and consistency - You’re new to Docker - You’re focusing on analysis rather than infrastructure\nUse Docker Compose When: - You need multiple service configurations - You’re working with a team using standardized environments - You want to define complex volume and networking setups\nUse Direct Commands When: - You need maximum flexibility - You’re troubleshooting container issues - You’re creating custom workflows not covered by Make targets\nAll three approaches can be used together in the same project, depending on the specific task and user preferences."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "href": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.14 Understanding GitHub Actions for Research",
    "text": "9.14 Understanding GitHub Actions for Research\nWhat is CI/CD for Research?\nContinuous Integration/Continuous Deployment (CI/CD) tests your research code whenever changes are made. For research compendia, this means:\n\nTesting: Every push triggers your test suite\nEnvironment consistency: Tests run in identical Docker environments\nEarly error detection: Problems caught during development\nCollaboration confidence: Team members see if changes break functionality\nReproducibility validation: Ensures analysis works across different systems"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.15 Step-by-Step Setup",
    "text": "9.15 Step-by-Step Setup\n\n9.15.1 Step 1: Create Workflow Directory\n# Create the GitHub Actions directory\nmkdir -p .github/workflows\n\n\n9.15.2 Step 2: Docker-based CI Workflow with renv Validation\nCreate .github/workflows/docker-ci.yml:\nname: Docker CI with renv Validation\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  build-and-test:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      \n    - name: Set up R for renv validation\n      uses: r-lib/actions/setup-r@v2\n      with:\n        r-version: 'release'\n        \n    - name: Install renv for validation\n      run: |\n        install.packages(\"renv\")\n      shell: Rscript {0}\n        \n    - name: Validate renv consistency before Docker build\n      run: |\n        # Validate renv environment before building Docker image\n        Rscript check_renv_for_commit.R --fail-on-issues --quiet\n      \n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      \n    - name: Extract R version from renv.lock\n      id: r-version\n      run: |\n        R_VERSION=$(Rscript -e \"cat(renv::lockfile_read()\\$R\\$Version)\")\n        echo \"r-version=${R_VERSION}\" &gt;&gt; $GITHUB_OUTPUT\n      \n    - name: Build Docker image\n      uses: docker/build-push-action@v5\n      with:\n        context: .\n        push: false\n        tags: ${{ github.repository }}:latest\n        build-args: |\n          R_VERSION=${{ steps.r-version.outputs.r-version }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        \n    - name: Run tests in container\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          ${{ github.repository }}:latest \\\n          R -e \"testthat::test_dir('tests/testthat')\"\n          \n    - name: Render research paper\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          -v $PWD/analysis/figures:/home/analyst/output \\\n          ${{ github.repository }}:latest \\\n          R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n          \n    - name: Upload rendered paper\n      uses: actions/upload-artifact@v4\n      if: success()\n      with:\n        name: research-paper\n        path: analysis/paper/paper.pdf\n\n\n9.15.3 Step 3: R Package Check Workflow\nCreate .github/workflows/r-package.yml:\nname: R Package Check\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n    \n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n    \n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: macOS-latest,    r: 'release'}\n          - {os: windows-latest,  r: 'release'}\n    \n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: r-lib/actions/setup-pandoc@v2\n      \n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n          \n      - uses: r-lib/actions/setup-renv@v2\n      \n      - name: Install system dependencies\n        if: runner.os == 'Linux'\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y \\\n            libcurl4-openssl-dev \\\n            libssl-dev \\\n            libxml2-dev\n            \n      - name: Validate renv consistency\n        run: |\n          # Use the renv validation script included in the repository\n          Rscript check_renv_for_commit.R --fail-on-issues --quiet\n            \n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n9.15.4 Step 4: Automated Paper Rendering\nCreate .github/workflows/render-paper.yml:\nname: Render Research Paper\n\non:\n  workflow_dispatch:  # Manual trigger\n  push:\n    branches: [ main, master ]\n    paths:\n      - 'analysis/paper/**'\n      - 'analysis/data/**'\n      - 'R/**'\n      - 'data/**'\n\njobs:\n  render:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Build Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: false\n          tags: paper-render:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          \n      - name: Render paper in container\n        run: |\n          docker run --rm \\\n            -v $PWD:/home/analyst/project \\\n            -v $PWD/analysis/figures:/home/analyst/output \\\n            paper-render:latest \\\n            R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n            \n      - name: Upload rendered paper\n        uses: actions/upload-artifact@v4\n        with:\n          name: research-paper-${{ github.sha }}\n          path: |\n            analysis/paper/paper.pdf\n            analysis/figures/*.png\n            analysis/figures/*.jpg\n          retention-days: 30\n\n\n9.15.5 Step 5: Container Registry Integration\nCreate .github/workflows/container-publish.yml:\nname: Build and Push Container\n\non:\n  push:\n    branches: [ main ]\n    tags: [ 'v*' ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n      \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Log in to Container Registry\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n          \n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            \n      - name: Build and push Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          platforms: linux/amd64,linux/arm64\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "href": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.16 Workflow Explanations",
    "text": "9.16 Workflow Explanations\n\n9.16.1 Docker CI Workflow Features:\n\nPre-build renv Validation: Validates package dependency consistency before Docker build (prevents build failures)\nDynamic R Version: Extracts R version from renv.lock and passes it to Docker build\nBuild Testing: Ensures Docker image builds with latest changes using correct R version\nTesting: Runs R package tests and renders paper in container\nArtifact Generation: Saves rendered papers as downloadable artifacts\nCaching: Uses GitHub Actions cache for faster builds\nEarly Failure: Stops pipeline if dependency issues are detected\n\n\n\n9.16.2 R Package Check Features:\n\nMulti-platform Testing: Tests on Ubuntu, macOS, and Windows\nR CMD Check: Package validation\nrenv Integration: Restores package environment\nrenv Consistency Validation: Verifies dependency synchronization across platforms\nSystem Dependencies: Installs required system libraries\n\n\n\n9.16.3 Paper Rendering Features:\n\nSelective Triggering: Only runs when relevant files change\nManual Execution: Can be triggered manually via GitHub interface\nArtifact Storage: Saves PDFs and figures with retention policy\nPath-based Triggers: Responds to changes in analysis files\n\n\n\n9.16.4 Container Publishing Features:\n\nBuilding: Builds on pushes and tags\nMulti-platform: Supports AMD64 and ARM64 platforms\nSemantic Versioning: Tagging based on git tags\nSecurity: Uses built-in GitHub token for authentication"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "href": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.17 Authentication and Permissions",
    "text": "9.17 Authentication and Permissions\n\n9.17.1 Built-in GITHUB_TOKEN:\nThe built-in GITHUB_TOKEN automatically provides: - Read access to repository contents - Write access to GitHub Packages (when permissions are set) - No manual setup required\n\n\n9.17.2 Setting Repository Permissions:\n\nRepository Settings → Actions → General\nWorkflow permissions: Choose “Read and write permissions”\nAllow GitHub Actions to create and approve pull requests: Enable if needed\n\n\n\n9.17.3 Using Personal Access Tokens (Advanced):\nFor broader permissions, create repository secrets:\n\nRepository Settings → Secrets and variables → Actions\nNew repository secret: Add GHCR_TOKEN with Personal Access Token\nReference in workflow: password: ${{ secrets.GHCR_TOKEN }}"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.18 Integration with Collaborative Workflow",
    "text": "9.18 Integration with Collaborative Workflow\n\n9.18.1 Pull Request Integration:\nWhen a team member submits a pull request: 1. GitHub automatically triggers CI workflows 2. Tests run in clean environment identical to production 3. Results displayed directly in pull request interface 4. Merge can be blocked if tests fail\n\n\n9.18.2 Branch Protection Rules:\nEnable in Repository Settings → Branches: - Require status checks: Force CI to pass before merging - Require branches to be up to date: Ensure latest code is tested - Include administrators: Apply rules to all users"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "href": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.19 Monitoring and Troubleshooting",
    "text": "9.19 Monitoring and Troubleshooting\n\n9.19.1 Viewing Workflow Results:\n\nRepository → Actions tab\nClick specific workflow run to see details\nExpand steps to see detailed logs\nDownload artifacts (rendered papers, test results)\n\n\n\n9.19.2 Common Issues and Solutions:\nDocker Build Failures: - Check Dockerfile syntax - Verify all COPY paths exist - Ensure base image is accessible\nrenv Restore Failures: - Verify renv.lock is committed - Check for platform-specific packages - Consider using RSPM for faster installs\nPermission Errors: - Verify GITHUB_TOKEN permissions - Check repository secrets configuration - Ensure workflows have necessary permissions\n\n\n9.19.3 Performance Optimization:\nCaching Strategies: - Docker layer caching with cache-from/cache-to - renv package caching with r-lib/actions/setup-renv - Artifact caching for large datasets\nParallel Execution: - Run tests and documentation in parallel jobs - Use matrix strategies for multi-platform testing - Conditional execution based on changed files\nThis CI/CD setup ensures that research compendia remain reproducible, tested, and deployment-ready throughout the development lifecycle."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.20 Production Dockerfile",
    "text": "9.20 Production Dockerfile\nThe following Dockerfile provides a development environment with zsh, vim plugins, dotfiles integration, and development tools:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Install system dependencies including zsh and development tools\nRUN apt-get update && apt-get install -y \\\n    libxml2-dev \\\n    libcurl4-openssl-dev \\\n    libssl-dev \\\n    libgit2-dev \\\n    libfontconfig1-dev \\\n    libcairo2-dev \\\n    libxt-dev \\\n    pandoc \\\n    zsh \\\n    curl \\\n    git \\\n    fonts-dejavu \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user with zsh as default shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set working directory\nWORKDIR /home/${USERNAME}/project\n\n# Copy project files first (for better Docker layer caching)\nCOPY --chown=${USERNAME}:${USERNAME} DESCRIPTION .\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock* ./\nCOPY --chown=${USERNAME}:${USERNAME} .Rprofile* ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R* renv/activate.R\n\n# Configure renv library path\nENV RENV_PATHS_LIBRARY renv/library\n\n# Switch to non-root user for R package installation\nUSER ${USERNAME}\n\n# Install renv and essential R packages\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', 'knitr', \\\n    'rmarkdown'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Restore R packages from lockfile (if exists)\nRUN R -e \"if (file.exists('renv.lock')) renv::restore() else \\\n    cat('No renv.lock found, skipping restore\\\\n')\"\n\n# Copy dotfiles for development environment\n# Note: Ensure .vimrc and .zshrc_docker exist in build context or create \n# defaults\nCOPY --chown=${USERNAME}:${USERNAME} .vimrc /home/${USERNAME}/.vimrc\nCOPY --chown=${USERNAME}:${USERNAME} .zshrc_docker /home/${USERNAME}/.zshrc\n\n# Install zsh plugins for shell experience\nRUN mkdir -p /home/${USERNAME}/.zsh && \\\n    git clone https://github.com/zsh-users/zsh-autosuggestions \\\n        /home/${USERNAME}/.zsh/zsh-autosuggestions && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.zsh\n\n# Install vim-plug and configure vim environment\nRUN mkdir -p /home/${USERNAME}/.vim/autoload && \\\n    curl -fLo /home/${USERNAME}/.vim/autoload/plug.vim \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.vim\n\n# Install vim plugins (suppress interactive mode)\nRUN vim +PlugInstall +qall || true\n\n# Copy rest of project\nCOPY --chown=${USERNAME}:${USERNAME} . .\n\n# Install the research compendium as a package\nRUN R -e \"devtools::install('.', dependencies = TRUE)\"\n\n# Set default shell to zsh for development experience\nWORKDIR /home/${USERNAME}/project\nCMD [\"/bin/zsh\"]"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.21 Features of the Production Dockerfile",
    "text": "9.21 Features of the Production Dockerfile\nThis production-ready Dockerfile provides:\n\nR version consistency: Matches exact R version specified in renv.lock for perfect environment alignment\nMinimal base: rocker/r-ver provides clean R installation without unnecessary packages\nShell environment: zsh with autosuggestions and professional prompt for improved productivity\nEditor environment: vim with plugins configured automatically during build\nDotfiles integration: Personal development preferences (.vimrc, .zshrc) copied from host system\nDevelopment tools: git, curl, pandoc, and essential development libraries pre-installed\nSecurity: Non-root user execution with proper file permissions\nrenv integration: Automatic package restoration with proper library path configuration\nContainer-optimized workflow: Optimized layer caching and build process for efficient rebuilds"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "href": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.22 R Version Extraction",
    "text": "9.22 R Version Extraction\nThe Dockerfile uses a build argument to ensure the R version exactly matches what’s specified in renv.lock. The build command extracts the R version directly from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/username/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "href": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.23 renv Consistency Checker Features",
    "text": "9.23 renv Consistency Checker Features\nThe check_renv_for_commit.R script provides advanced team collaboration features through dependency validation:\n\nTeam conflict prevention: Pre-commit validation stops dependency inconsistencies before they reach the repository\nAutomated dependency discovery: Scans R/, scripts/, and analysis/ directories for library(), require(), and pkg:: calls\nMulti-source synchronization: Ensures packages are consistent across code files, DESCRIPTION, and renv.lock\nCRAN validation: Verifies packages exist and are properly named before team integration\nAutomatic fixing: Updates DESCRIPTION and regenerates renv.lock to maintain team synchronization\nCI/CD fail-fast: Provides proper exit codes for automated workflows\nInteractive collaboration mode: Guides developers through dependency resolution during development"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.24 Team Collaboration Commands",
    "text": "9.24 Team Collaboration Commands\n# Team development workflow (via Make)\nmake check-renv          # Interactive dependency checking\nmake check-renv-fix      # Auto-fix dependency issues\nmake check-renv-ci       # CI/CD validation with fail-fast\n\n# Docker-based validation (no local R required)\nmake docker-check-renv-fix  # Fix dependencies in container\n\n# Direct script usage\nRscript check_renv_for_commit.R --fix --fail-on-issues  # CI mode\nRscript check_renv_for_commit.R --quiet                 # Minimal output\nRscript check_renv_for_commit.R --help                  # Usage info"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.25 Multi-Developer Workflow",
    "text": "9.25 Multi-Developer Workflow\n\nInstall packages in container: Use install.packages() or renv::install() within Docker environment\nValidate team dependencies: Run make check-renv to check for conflicts before committing\nReview team impacts: Script identifies packages that would affect other team members\nSynchronize team environment: Use make check-renv-fix to update shared dependency files\nCommit with team confidence: Other developers can reproduce your exact environment"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, and Docker Strategy",
    "section": "9.26 Integration with Development Workflows",
    "text": "9.26 Integration with Development Workflows\n\n9.26.1 Pre-commit Hooks\n# Add to .git/hooks/pre-commit\nRscript check_renv_for_commit.R --fail-on-issues --quiet\n\n\n9.26.2 Makefile Integration\ncheck-renv:\n    Rscript check_renv_for_commit.R\n\ncheck-renv-fix:\n    Rscript check_renv_for_commit.R --fix\n\ncheck-renv-ci:\n    Rscript check_renv_for_commit.R --quiet --fail-on-issues\n\n\n9.26.3 CI/CD Integration\n- name: Validate renv consistency\n  run: Rscript check_renv_for_commit.R --fail-on-issues --quiet\nThis approach ensures that collaborators can reliably reproduce your package environment and that CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/setup_obs_p09/index.html#prerequisites",
    "href": "posts/setup_obs_p09/index.html#prerequisites",
    "title": "Setting up OBS for webcasting",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setup_obs_p09/index.html#step-by-step-implementation",
    "href": "posts/setup_obs_p09/index.html#step-by-step-implementation",
    "title": "Setting up OBS for webcasting",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setup_obs_p09/index.html#key-takeaways",
    "href": "posts/setup_obs_p09/index.html#key-takeaways",
    "title": "Setting up OBS for webcasting",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setup_obs_p09/index.html#further-reading",
    "href": "posts/setup_obs_p09/index.html#further-reading",
    "title": "Setting up OBS for webcasting",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/research_management/index.html",
    "href": "posts/research_management/index.html",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "posts/research_management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "href": "posts/research_management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by",
    "text": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by\nrunning this bash script to copy a prelude to the chatGPT prompt to your clipboard: Call it dp (dictation prompt).\n#!/bin/bash\n\n# Get current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Define the prompt with explicit instructions\nprompt=\"I'm an academic biostatistician. I'm working on a data analysis project.\nI'm about to dictate daily research progress notes.  \nWhen I'm done, provide a concise summary that includes:  \n\n1. The date  and time of dictation ($current_time).  The line with date and time\nshould be the second line of the summary. The first line should be blank. The\ndate and time line shound be enclosed in a box of ascii characters to set it apart.\n2. The name of the current research project directory ($current_dir).  \n3. Each line of the summary including the blank line and the date and time line\nand enclosing box lines should begin with \\\"$current_dir:\\\" so that it can be\nextracted using ripgrep.  \n\nThe notes start here: \"\n\n# Copy the prompt to clipboard (MacOS pbcopy)\necho -n \"$prompt\" | pbcopy\n\n# Notify the user\necho \"Prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "posts/research_management/index.html#step-3.2-dictating-notes",
    "href": "posts/research_management/index.html#step-3.2-dictating-notes",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nOpen ChatGPT (done automatically by “dp” script) and follow these steps:\ncopy text from clipboard into the prompt box.\nsubmit prompt to prep chatGPT for summarization.\nClick chatGPT microphone and Dictate your research notes.\nWhen finished dictating submit prompt to ChatGPT for summarization.\nCopy and generated summary onto the clipboard.\n\nUse the following script to append the summary to your daily log: and push the changes to daily_log.md to the remote repository on GitHub.\n#!/bin/bash\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Get the current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the clipboard content (MacOS pbpaste)\nclipboard_content=$(pbpaste)\n\n# Echo the output\n#\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"\" &gt;&gt; ~/prj/research_update/daily_log.md\n\n# Confirm success\necho \"Update for $current_dir appended to daily_log.md in ~/prj/research_update\"\ncd ~/prj/research_update\n  git add .\n    git commit -a -m \"Daily log update $(date +'%Y-%m-%d')\"\n    git push"
  },
  {
    "objectID": "posts/research_management/index.html#prerequisites",
    "href": "posts/research_management/index.html#prerequisites",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/research_management/index.html#step-by-step-implementation",
    "href": "posts/research_management/index.html#step-by-step-implementation",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/research_management/index.html#key-takeaways",
    "href": "posts/research_management/index.html#key-takeaways",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/research_management/index.html#further-reading",
    "href": "posts/research_management/index.html#further-reading",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#proprietary-edc-systems-with-built-in-validation",
    "href": "posts/rct_validation_lang/index.html#proprietary-edc-systems-with-built-in-validation",
    "title": "RCT validation language",
    "section": "2.1 1. Proprietary EDC Systems with Built-in Validation",
    "text": "2.1 1. Proprietary EDC Systems with Built-in Validation\n\nMedidata Rave (uses Medidata Rave Edit Check Scripts)\nOracle Clinical / InForm (PL/SQL-based validation)\nIBM Clinical Development\nVeeva Vault EDC\nCastor EDC\nProvide graphical interfaces or scripting languages for validation rules."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#open-source-edc-systems-with-custom-validation-capabilities",
    "href": "posts/rct_validation_lang/index.html#open-source-edc-systems-with-custom-validation-capabilities",
    "title": "RCT validation language",
    "section": "2.2 2. Open-Source EDC Systems with Custom Validation Capabilities",
    "text": "2.2 2. Open-Source EDC Systems with Custom Validation Capabilities\n\n2.2.1 a. OpenClinica\n\nValidation Features:\n\nReal-time edit checks (range, cross-field, logic-based).\nUses XPath expressions for validation.\n\nExample Implementation:\n&lt;rule&gt;\n    &lt;when&gt;\n        /StudyEventData/FormData/ItemGroupData/ItemData[@ItemOID='AGE'] &gt; 100\n    &lt;/when&gt;\n    &lt;then&gt;\n        &lt;message&gt;Age cannot be greater than 100 years.&lt;/message&gt;\n    &lt;/then&gt;\n&lt;/rule&gt;\nWebsite: openclinica.com\n\n\n\n\n2.2.2 b. REDCap\n\nValidation Features:\n\nReal-time range and logic checks.\nUses branching logic and calculated fields.\nCustom data quality rules via SQL queries.\n\nExample Implementation:\n[age] &gt; 18 AND [age] &lt; 65\nWebsite: projectredcap.org\n\n\n\n\n2.2.3 c. ClinCapture\n\nValidation Features:\n\nJavaScript-based validation for logic and range checks.\nCustom queries to detect missing or inconsistent data.\n\nWebsite: clincapture.com"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#custom-validation-using-general-purpose-tools",
    "href": "posts/rct_validation_lang/index.html#custom-validation-using-general-purpose-tools",
    "title": "RCT validation language",
    "section": "2.3 3. Custom Validation Using General-Purpose Tools",
    "text": "2.3 3. Custom Validation Using General-Purpose Tools\n\n2.3.1 a. R for Data Validation\n\nLibraries: validate, pointblank\nExample:\nlibrary(validate)\nrules &lt;- validator(\n  age &gt;= 18,\n  bmi &gt;= 15 & bmi &lt;= 50,\n  start_date &lt; end_date\n)\ncheck_results &lt;- confront(data, rules)\nsummary(check_results)\n\n\n\n\n2.3.2 b. Python for Data Validation\n\nLibraries: pandera, cerberus\nExample:\nfrom pandera import DataFrameSchema, Column, Check\n\nschema = DataFrameSchema({\n    \"age\": Column(int, Check(lambda x: 18 &lt;= x &lt;= 65, error=\"Age must be 18-65\")),\n    \"bmi\": Column(float, Check(lambda x: 15 &lt;= x &lt;= 50, error=\"BMI must be realistic\")),\n    \"start_date\": Column(str),\n    \"end_date\": Column(str, Check(lambda x, y: x &lt; y, error=\"Start date must be before end date\"))\n})\n\nvalidated_data = schema.validate(df)\n\n\n\n\n2.3.3 c. SQL for Data Integrity Checks\n\nExample:\nSELECT patient_id, age\nFROM clinical_data\nWHERE age &lt; 18 OR age &gt; 100;"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#integrating-validation-into-edc-workflows",
    "href": "posts/rct_validation_lang/index.html#integrating-validation-into-edc-workflows",
    "title": "RCT validation language",
    "section": "2.4 4. Integrating Validation into EDC Workflows",
    "text": "2.4 4. Integrating Validation into EDC Workflows\n\nAutomated Validation Pipelines: Apache NiFi, Talend, Pentaho for ETL-based validation.\nFHIR/CDISC Compliance: OpenCDISC Validator for CDISC standards (SDTM/ADaM)."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#conclusion",
    "href": "posts/rct_validation_lang/index.html#conclusion",
    "title": "RCT validation language",
    "section": "2.5 Conclusion",
    "text": "2.5 Conclusion\n\nFor real-time validation: OpenClinica, REDCap, and ClinCapture provide built-in rule engines.\nFor custom validation: R, Python, and SQL offer greater flexibility. Which approach fits your use case best?"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#can-shiny-create-forms-with-real-time-validation",
    "href": "posts/rct_validation_lang/index.html#can-shiny-create-forms-with-real-time-validation",
    "title": "RCT validation language",
    "section": "3.1 Can Shiny Create Forms with Real-Time Validation?",
    "text": "3.1 Can Shiny Create Forms with Real-Time Validation?\nYes, Shiny can create forms with real-time validation by using built-in reactive validation functions and JavaScript-based checks. Shiny provides several approaches for validating user input before submission."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#methods-for-real-time-validation-in-shiny",
    "href": "posts/rct_validation_lang/index.html#methods-for-real-time-validation-in-shiny",
    "title": "RCT validation language",
    "section": "3.2 Methods for Real-Time Validation in Shiny",
    "text": "3.2 Methods for Real-Time Validation in Shiny\n\n3.2.1 1. validate() and need() for Simple Input Validation\n\nThese functions allow dynamic validation of form inputs.\nError messages are displayed instantly when an invalid input is detected.\n\n\n3.2.1.1 Example: Age Validation (Must be Between 18-65)\nlibrary(shiny)\n\nui &lt;- fluidPage(\n    titlePanel(\"Real-Time Validation Example\"),\n    sidebarLayout(\n        sidebarPanel(\n            numericInput(\"age\", \"Enter Age:\", value = NULL, min = 0, max = 100),\n            verbatimTextOutput(\"validation_message\"),\n            actionButton(\"submit\", \"Submit\")\n        ),\n        mainPanel()\n    )\n)\n\nserver &lt;- function(input, output, session) {\n    output$validation_message &lt;- renderText({\n        validate(\n            need(input$age &gt;= 18, \"Age must be at least 18\"),\n            need(input$age &lt;= 65, \"Age must be 65 or below\")\n        )\n        \"Valid input!\"\n    })\n}\n\nshinyApp(ui, server)\n\n\n\n\n3.2.2 2. shinyvalidate Package for Advanced Form Validation\nThe shinyvalidate package allows multiple dependent form inputs to be validated before submission.\n\n3.2.2.1 Example: Multiple Field Validation (Email & Age)\nlibrary(shiny)\nlibrary(shinyvalidate)\n\nui &lt;- fluidPage(\n    titlePanel(\"Shinyvalidate Example\"),\n    textInput(\"email\", \"Enter Email:\"),\n    numericInput(\"age\", \"Enter Age:\", value = NULL, min = 0, max = 100),\n    actionButton(\"submit\", \"Submit\"),\n    verbatimTextOutput(\"validation_message\")\n)\n\nserver &lt;- function(input, output, session) {\n    iv &lt;- InputValidator$new()\n    \n    iv$add_rule(\"email\", sv_email()) # Validates email format\n    iv$add_rule(\"age\", sv_between(18, 65)) # Age must be between 18 and 65\n    \n    iv$enable()\n    \n    observeEvent(input$submit, {\n        if (iv$is_valid()) {\n            showModal(modalDialog(\"Form submitted successfully!\"))\n        } else {\n            showModal(modalDialog(\"Please fix errors before submitting.\"))\n        }\n    })\n}\n\nshinyApp(ui, server)\n\n\n\n\n3.2.3 3. JavaScript-Based Validation for Immediate Feedback\nShiny supports JavaScript validation for client-side real-time validation before sending data to the server.\n\n3.2.3.1 Example: Real-Time Numeric Input Restriction\nlibrary(shiny)\n\nui &lt;- fluidPage(\n    tags$script(HTML(\"\n        function validateNumericInput() {\n            var input = document.getElementById('numInput').value;\n            if (isNaN(input) || input &lt; 1 || input &gt; 100) {\n                document.getElementById('error').innerHTML = 'Enter a valid number (1-100)';\n            } else {\n                document.getElementById('error').innerHTML = '';\n            }\n        }\n    \")),\n    textInput(\"numInput\", \"Enter a number:\", \"\", oninput = \"validateNumericInput()\"),\n    span(id = \"error\", style = \"color: red;\")\n)\n\nserver &lt;- function(input, output, session) {}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#can-javascript-access-relational-data-and-machine-learning-tools",
    "href": "posts/rct_validation_lang/index.html#can-javascript-access-relational-data-and-machine-learning-tools",
    "title": "RCT validation language",
    "section": "3.3 Can JavaScript Access Relational Data and Machine Learning Tools?",
    "text": "3.3 Can JavaScript Access Relational Data and Machine Learning Tools?\nYes, JavaScript can access relational datasets and machine learning tools for real-time validation. This can be achieved through:\n\nClient-Side Validation via IndexedDB (local relational database in browser)\nAJAX Requests to Query a Remote Database (MySQL, PostgreSQL, etc.)\nCalling a Machine Learning Model via an API (TensorFlow.js, Python API)\nWebAssembly (WASM) for Local ML Computation"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#using-indexeddb-for-local-relational-data-validation",
    "href": "posts/rct_validation_lang/index.html#using-indexeddb-for-local-relational-data-validation",
    "title": "RCT validation language",
    "section": "3.4 1. Using IndexedDB for Local Relational Data Validation",
    "text": "3.4 1. Using IndexedDB for Local Relational Data Validation\n&lt;script&gt;\n  let db;\n  \n  // Open IndexedDB database\n  let request = indexedDB.open(\"ClinicalDB\", 1);\n  request.onsuccess = function(event) {\n      db = event.target.result;\n  };\n  \n  function validateUserID() {\n      let inputID = document.getElementById(\"userID\").value;\n      let transaction = db.transaction([\"patients\"]);\n      let objectStore = transaction.objectStore(\"patients\");\n      let request = objectStore.get(inputID);\n      \n      request.onsuccess = function() {\n          if (!request.result) {\n              document.getElementById(\"error\").innerHTML = \"Invalid Patient ID!\";\n          } else {\n              document.getElementById(\"error\").innerHTML = \"\";\n          }\n      };\n  }\n&lt;/script&gt;\n&lt;input id=\"userID\" type=\"text\" oninput=\"validateUserID()\"&gt;\n&lt;span id=\"error\" style=\"color: red;\"&gt;&lt;/span&gt;"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#using-ajax-to-query-a-remote-sql-database",
    "href": "posts/rct_validation_lang/index.html#using-ajax-to-query-a-remote-sql-database",
    "title": "RCT validation language",
    "section": "3.5 2. Using AJAX to Query a Remote SQL Database",
    "text": "3.5 2. Using AJAX to Query a Remote SQL Database\n&lt;script&gt;\n  function checkPatientID() {\n      let userID = document.getElementById(\"userID\").value;\n      fetch(`/validate_id?userID=${userID}`)\n          .then(response =&gt; response.json())\n          .then(data =&gt; {\n              if (data.valid) {\n                  document.getElementById(\"error\").innerHTML = \"\";\n              } else {\n                  document.getElementById(\"error\").innerHTML = \"Invalid Patient ID!\";\n              }\n          });\n  }\n&lt;/script&gt;\n&lt;input id=\"userID\" type=\"text\" oninput=\"checkPatientID()\"&gt;\n&lt;span id=\"error\" style=\"color: red;\"&gt;&lt;/span&gt;"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#calling-a-machine-learning-model-for-validation",
    "href": "posts/rct_validation_lang/index.html#calling-a-machine-learning-model-for-validation",
    "title": "RCT validation language",
    "section": "3.6 3. Calling a Machine Learning Model for Validation",
    "text": "3.6 3. Calling a Machine Learning Model for Validation\n&lt;script&gt;\n  function validateAdverseEvent() {\n      let eventText = document.getElementById(\"eventText\").value;\n      fetch(`/predict_adverse_event`, {\n          method: \"POST\",\n          headers: { \"Content-Type\": \"application/json\" },\n          body: JSON.stringify({ \"text\": eventText })\n      })\n      .then(response =&gt; response.json())\n      .then(data =&gt; {\n          document.getElementById(\"error\").innerHTML = \n              data.valid ? \"\" : \"Potentially invalid event!\";\n      });\n  }\n&lt;/script&gt;\n&lt;input id=\"eventText\" type=\"text\" oninput=\"validateAdverseEvent()\"&gt;\n&lt;span id=\"error\" style=\"color: red;\"&gt;&lt;/span&gt;"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#choosing-the-best-approach",
    "href": "posts/rct_validation_lang/index.html#choosing-the-best-approach",
    "title": "RCT validation language",
    "section": "3.7 Choosing the Best Approach",
    "text": "3.7 Choosing the Best Approach\n\n\n\nApproach\nBest For\nNeeds Server?\n\n\n\n\nIndexedDB\nLocal relational checks\n❌ No\n\n\nAJAX (SQL Backend)\nLarge relational datasets\n✅ Yes\n\n\nML API (Python/Flask)\nAdvanced validation via AI\n✅ Yes\n\n\nTensorFlow.js\nLocal ML without server\n❌ No"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#conclusion-1",
    "href": "posts/rct_validation_lang/index.html#conclusion-1",
    "title": "RCT validation language",
    "section": "3.8 Conclusion",
    "text": "3.8 Conclusion\n\nFor small datasets, use IndexedDB (local relational validation).\nFor real-time database validation, use AJAX + SQL backend.\nFor AI-powered checks, use Flask ML API or TensorFlow.js."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#your-idea-spreadsheet-driven-validation-system",
    "href": "posts/rct_validation_lang/index.html#your-idea-spreadsheet-driven-validation-system",
    "title": "RCT validation language",
    "section": "4.1 Your Idea: Spreadsheet-Driven Validation System",
    "text": "4.1 Your Idea: Spreadsheet-Driven Validation System\nYour idea of defining data validation rules in a spreadsheet, then processing them with Lua to generate JavaScript for Shiny validation is a great idea. This approach would: - Allow non-programmers (e.g., clinicians, data managers) to define custom validation rules in a familiar format (Excel, Google Sheets, CSV). - Automate the generation of JavaScript validation logic from a structured input (spreadsheet). - Integrate validation logic into Shiny dynamically, enabling real-time data validation."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#has-this-been-done-before",
    "href": "posts/rct_validation_lang/index.html#has-this-been-done-before",
    "title": "RCT validation language",
    "section": "4.2 Has This Been Done Before?",
    "text": "4.2 Has This Been Done Before?\nYes, similar approaches have been explored, but not exactly in the way you describe.\n\nSpreadsheet-Driven Validation Rules\n\nMedidata Rave (commercial EDC system) allows validation checks to be defined in a spreadsheet-like rule editor.\nOpenClinica supports rule definitions in a spreadsheet format (ODK XLSForm).\nRedCAP allows some rule-based constraints in CSV.\n\nCode Generation from Spreadsheets\n\nGoogle Sheets + Apps Script: People generate JavaScript validation from structured spreadsheet data.\nLua for Code Generation: Lua is used in game engines and config-driven workflows, but it has not been widely used to generate JavaScript validation rules from spreadsheets.\n\n\nThus, your approach is novel in the clinical data validation context—this could be a powerful open-source tool."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#why-this-is-a-good-idea",
    "href": "posts/rct_validation_lang/index.html#why-this-is-a-good-idea",
    "title": "RCT validation language",
    "section": "4.3 Why This is a Good Idea",
    "text": "4.3 Why This is a Good Idea\n\n\n\n\n\n\n\nFeature\nBenefit\n\n\n\n\nSpreadsheet as Validation Rule Storage\nEasy for non-programmers to modify rules\n\n\nLua as Code Generator\nFast, lightweight, and excellent for text processing\n\n\nJavaScript for Validation\nEnables real-time validation in Shiny without server overhead\n\n\nDynamic Validation Updates\nChanging the spreadsheet updates validation logic without modifying code"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#how-it-would-work",
    "href": "posts/rct_validation_lang/index.html#how-it-would-work",
    "title": "RCT validation language",
    "section": "4.4 How It Would Work",
    "text": "4.4 How It Would Work\n\n4.4.1 1. Define Rules in a Spreadsheet\nEach field in the Shiny app gets a validation rule in one cell per field.\n\n\n\n\n\n\n\nField\nValidation Rule\n\n\n\n\nage\nage &gt;= 18 && age &lt;= 65\n\n\nemail\n/^[a-z0-9._%+-]+@[a-z0-9.-]+\\.[a-z]{2,}$/i.test(email)\n\n\nheight\nheight &gt; 50 && height &lt; 250\n\n\nbmi\nweight / (height / 100) ** 2 &gt; 15 && weight / (height / 100) ** 2 &lt; 50\n\n\n\n\n\n\n4.4.2 2. Lua Script Processes the Spreadsheet\nA Lua script reads the spreadsheet (CSV, Excel) and generates JavaScript validation functions.\n\n4.4.2.1 Example Lua Script (process_validation.lua)\nlocal csv = require(\"csv\")  -- Use a CSV library like `luacsv`\nlocal file = io.open(\"validation_rules.csv\", \"r\")\nlocal parsed_data = csv.parse(file:read(\"*all\"))\n\nlocal js_code = \"const validationRules = {\\n\"\n\nfor i, row in ipairs(parsed_data) do\n    local field, rule = row[1], row[2]\n    js_code = js_code .. string.format('    \"%s\": function(value) { return %s; },\\n', field, rule)\nend\n\njs_code = js_code .. \"};\\n\"\nfile:close()\n\nlocal js_file = io.open(\"validation.js\", \"w\")\njs_file:write(js_code)\njs_file:close()\n\nprint(\"Validation JavaScript generated successfully!\")\n\n\n\n\n4.4.3 3. JavaScript File is Included in Shiny\nThe generated JavaScript file (validation.js) is included in the Shiny app.\n\n4.4.3.1 Example of Integrating validation.js in Shiny\nlibrary(shiny)\n\nui &lt;- fluidPage(\n    tags$head(tags$script(src=\"validation.js\")),  # Include generated JS\n    numericInput(\"age\", \"Enter Age:\", value = NULL),\n    textInput(\"email\", \"Enter Email:\"),\n    actionButton(\"submit\", \"Submit\"),\n    verbatimTextOutput(\"validation_message\")\n)\n\nserver &lt;- function(input, output, session) {\n    observeEvent(input$submit, {\n        # Call JavaScript function to validate fields\n        shinyjs::runjs(\"if (!validationRules.age(input$age)) alert('Invalid Age!');\")\n        shinyjs::runjs(\"if (!validationRules.email(input$email)) alert('Invalid Email!');\")\n    })\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#advantages-of-this-approach",
    "href": "posts/rct_validation_lang/index.html#advantages-of-this-approach",
    "title": "RCT validation language",
    "section": "4.5 Advantages of This Approach",
    "text": "4.5 Advantages of This Approach\n✅ Non-programmers can define validation rules in spreadsheets\n✅ Lua is fast & lightweight for generating JavaScript\n✅ JavaScript validation happens instantly in the browser\n✅ Shiny remains reactive while offloading validation to the client"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#potential-enhancements",
    "href": "posts/rct_validation_lang/index.html#potential-enhancements",
    "title": "RCT validation language",
    "section": "4.6 Potential Enhancements",
    "text": "4.6 Potential Enhancements\n🚀 Support relational data: Extend Lua to query databases and include dynamic constraints\n🚀 Integrate ML: Add TensorFlow.js or an API to use machine learning for validation\n🚀 Validation UI: Build a Shiny app to visualize and edit validation rules dynamically\n\n\n4.6.1 Next Steps\nWould you like a working prototype where we generate JavaScript from a spreadsheet and use it in a Shiny app? 🚀"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#dynamic-rule-reloading-spreadsheet-based",
    "href": "posts/rct_validation_lang/index.html#dynamic-rule-reloading-spreadsheet-based",
    "title": "RCT validation language",
    "section": "5.1 1. Dynamic Rule Reloading (Spreadsheet-Based)",
    "text": "5.1 1. Dynamic Rule Reloading (Spreadsheet-Based)\n\n5.1.1 A. Spreadsheet Format (validation_rules.csv)\nfield,rule\nage,age &gt;= 18 && age &lt;= 65\nemail,/^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$/.test(email)\nheight,height &gt; 50 && height &lt; 250\nbmi,weight / (height / 100) ** 2 &gt; 15 && weight / (height / 100) ** 2 &lt; 50\n\n\n\n5.1.2 B. Lua Script to Convert CSV to JavaScript (process_validation.lua)\nlocal csv = require(\"luacsv\")  -- Requires CSV parser library\nlocal file = io.open(\"validation_rules.csv\", \"r\")\nlocal parsed_data = csv.parse(file:read(\"*all\"))\n\nlocal js_code = \"const validationRules = {\n\"\n\nfor i, row in ipairs(parsed_data) do\n    local field, rule = row[1], row[2]\n    js_code = js_code .. string.format('    \"%s\": function(value) { return %s; },\n', field, rule)\nend\n\njs_code = js_code .. \"};\n\"\nfile:close()\n\nlocal js_file = io.open(\"validation.js\", \"w\")\njs_file:write(js_code)\njs_file:close()\n\nprint(\"Validation JavaScript generated successfully!\")\n\n\n\n5.1.3 C. Shiny App with Automatic Rule Reloading (app.R)\nlibrary(shiny)\nlibrary(shinyjs)\nlibrary(fs)\n\nui &lt;- fluidPage(\n    useShinyjs(),\n    tags$head(tags$script(src = \"validation.js\")),  # Include JS dynamically\n    titlePanel(\"Dynamic Validation Rules in Shiny\"),\n    \n    sidebarLayout(\n        sidebarPanel(\n            numericInput(\"age\", \"Enter Age:\", value = NULL),\n            textInput(\"email\", \"Enter Email:\"),\n            numericInput(\"height\", \"Enter Height (cm):\", value = NULL),\n            numericInput(\"weight\", \"Enter Weight (kg):\", value = NULL),\n            actionButton(\"submit\", \"Submit\"),\n            verbatimTextOutput(\"validation_message\")\n        ),\n        mainPanel()\n    )\n)\n\nserver &lt;- function(input, output, session) {\n    # Watch for changes in the validation rules file\n    observe({\n        invalidateLater(5000, session)  # Check every 5 seconds\n        runjs(\"delete window.validationRules; $.getScript('validation.js');\")\n    })\n    \n    observeEvent(input$submit, {\n        runjs(\"\n            let ageValid = validationRules['age'](parseFloat($('#age').val()));\n            let emailValid = validationRules['email']($('#email').val());\n            let heightValid = validationRules['height'](parseFloat($('#height').val()));\n            let bmi = parseFloat($('#weight').val()) / ((parseFloat($('#height').val()) / 100) ** 2);\n            let bmiValid = validationRules['bmi'](bmi);\n            \n            let messages = [];\n            if (!ageValid) messages.push('Invalid Age!');\n            if (!emailValid) messages.push('Invalid Email!');\n            if (!heightValid) messages.push('Invalid Height!');\n            if (!bmiValid) messages.push('Invalid BMI!');\n            \n            if (messages.length &gt; 0) {\n                alert(messages.join('\\n'));\n            } else {\n                alert('All inputs are valid!');\n            }\n        \");\n    })\n}\n\nshinyApp(ui, server)\n✔ Every 5 seconds, Shiny reloads validation.js if validation_rules.csv was modified.\n✔ The new validation rules apply immediately in the browser.\n✔ No need to restart the Shiny app."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#database-integration-for-validation-rules",
    "href": "posts/rct_validation_lang/index.html#database-integration-for-validation-rules",
    "title": "RCT validation language",
    "section": "5.2 2. Database Integration for Validation Rules",
    "text": "5.2 2. Database Integration for Validation Rules\nInstead of a CSV file, the validation rules can be stored in a database (e.g., MySQL, PostgreSQL, SQLite).\n\n5.2.1 A. Database Schema\nTable: validation_rules\nCREATE TABLE validation_rules (\n    field TEXT PRIMARY KEY,\n    rule TEXT\n);\nExample data:\nINSERT INTO validation_rules (field, rule) VALUES\n('age', 'age &gt;= 18 && age &lt;= 65'),\n('email', '/^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$/.test(email)'),\n('height', 'height &gt; 50 && height &lt; 250'),\n('bmi', 'weight / (height / 100) ** 2 &gt; 15 && weight / (height / 100) ** 2 &lt; 50');\n\n\n\n5.2.2 B. Lua Script to Fetch Rules from Database (process_validation_db.lua)\nlocal sqlite3 = require(\"lsqlite3\")\nlocal db = sqlite3.open(\"validation.db\")\n\nlocal js_code = \"const validationRules = {\n\"\n\nfor row in db:nrows(\"SELECT * FROM validation_rules\") do\n    js_code = js_code .. string.format('    \"%s\": function(value) { return %s; },\n', row.field, row.rule)\nend\n\njs_code = js_code .. \"};\n\"\nlocal js_file = io.open(\"validation.js\", \"w\")\njs_file:write(js_code)\njs_file:close()\n\ndb:close()\nprint(\"Validation JavaScript generated from database successfully!\")\nThis script queries the database and generates validation.js dynamically.\n\n\n\n5.2.3 C. Modify Shiny to Fetch Rules from Database\nModify the Shiny server function to reload validation rules every 5 seconds.\nserver &lt;- function(input, output, session) {\n    observe({\n        invalidateLater(5000, session)  # Reload every 5 seconds\n        system(\"lua process_validation_db.lua\")  # Run Lua script\n        runjs(\"delete window.validationRules; $.getScript('validation.js');\")\n    })\n}\n✔ Shiny queries the database every 5 seconds and updates validation rules dynamically.\n✔ Users can edit validation rules in the database, and they apply instantly.\n✔ No restart required."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#comparison-spreadsheet-vs.-database",
    "href": "posts/rct_validation_lang/index.html#comparison-spreadsheet-vs.-database",
    "title": "RCT validation language",
    "section": "5.3 Comparison: Spreadsheet vs. Database",
    "text": "5.3 Comparison: Spreadsheet vs. Database\n\n\n\nFeature\nCSV-Based Dynamic Rules\nDatabase-Based Dynamic Rules\n\n\n\n\nStorage\nLocal file\nCentralized database\n\n\nScalability\nBest for small teams\nIdeal for large-scale use\n\n\nUser Interface\nSpreadsheet\nWeb-based admin panel\n\n\nPerformance\nFast\nRequires DB query"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#next-steps-1",
    "href": "posts/rct_validation_lang/index.html#next-steps-1",
    "title": "RCT validation language",
    "section": "5.4 Next Steps",
    "text": "5.4 Next Steps\n🔥 Would you like an admin panel in Shiny to edit validation rules directly?\n🔥 Would you like to store validation rules in a NoSQL database (MongoDB)?\n🚀 Let me know what enhancements you’d like! 🚀"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#prerequisites",
    "href": "posts/rct_validation_lang/index.html#prerequisites",
    "title": "RCT validation language",
    "section": "5.5 Prerequisites",
    "text": "5.5 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#step-by-step-implementation",
    "href": "posts/rct_validation_lang/index.html#step-by-step-implementation",
    "title": "RCT validation language",
    "section": "5.6 Step-by-Step Implementation",
    "text": "5.6 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#key-takeaways",
    "href": "posts/rct_validation_lang/index.html#key-takeaways",
    "title": "RCT validation language",
    "section": "5.7 Key Takeaways",
    "text": "5.7 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/rct_validation_lang/index.html#further-reading",
    "href": "posts/rct_validation_lang/index.html#further-reading",
    "title": "RCT validation language",
    "section": "5.8 Further Reading",
    "text": "5.8 Further Reading\nIn development"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#user-interface",
    "href": "posts/power_analysis_shiny_app/index.html#user-interface",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.1 User interface",
    "text": "2.1 User interface"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#parameters",
    "href": "posts/power_analysis_shiny_app/index.html#parameters",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.2 Parameters",
    "text": "2.2 Parameters"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#visualization",
    "href": "posts/power_analysis_shiny_app/index.html#visualization",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.3 Visualization",
    "text": "2.3 Visualization"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#reporting-formats",
    "href": "posts/power_analysis_shiny_app/index.html#reporting-formats",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.4 Reporting formats",
    "text": "2.4 Reporting formats"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#specifying-effect-size",
    "href": "posts/power_analysis_shiny_app/index.html#specifying-effect-size",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.5 Specifying effect size",
    "text": "2.5 Specifying effect size"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#itt-and-completers",
    "href": "posts/power_analysis_shiny_app/index.html#itt-and-completers",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.6 Itt and completers",
    "text": "2.6 Itt and completers"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#prerequisites",
    "href": "posts/power_analysis_shiny_app/index.html#prerequisites",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "6.1 Prerequisites",
    "text": "6.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#step-by-step-implementation",
    "href": "posts/power_analysis_shiny_app/index.html#step-by-step-implementation",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "6.2 Step-by-Step Implementation",
    "text": "6.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#key-takeaways",
    "href": "posts/power_analysis_shiny_app/index.html#key-takeaways",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "6.3 Key Takeaways",
    "text": "6.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#further-reading",
    "href": "posts/power_analysis_shiny_app/index.html#further-reading",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "6.4 Further Reading",
    "text": "6.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/formula_parsing/index.html#references",
    "href": "posts/formula_parsing/index.html#references",
    "title": "Best practices for parsing a formula in R programming",
    "section": "2.1 References:",
    "text": "2.1 References:\n“the formula is used to specify the symbolic model as well as generating the intended design matrix” The R Formula Method: The Good Parts · R Views\n” You’re probably familiar with formulas from linear models (e.g. lm(mpg ~ displ, data = mtcars)) but formulas are more than just a tool for modelling: they are a general way of capturing an unevaluated expression”\n“because a formula captures two things:\nAn unevaluated expression.\nThe context (environment) in which the expression was created.\n~ is a single character that allows you to say: “I want to capture the meaning of this code, without evaluating it right away”. For that reason, the formula can be thought of as a “quoting” operator.”\nNon-standard evaluation\nAdvanced Programming and Non-Standard Evaluation with dplyr | by Ryan Boyer | Shipt Tech"
  },
  {
    "objectID": "posts/formula_parsing/index.html#prerequisites",
    "href": "posts/formula_parsing/index.html#prerequisites",
    "title": "Best practices for parsing a formula in R programming",
    "section": "2.2 Prerequisites",
    "text": "2.2 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/formula_parsing/index.html#step-by-step-implementation",
    "href": "posts/formula_parsing/index.html#step-by-step-implementation",
    "title": "Best practices for parsing a formula in R programming",
    "section": "2.3 Step-by-Step Implementation",
    "text": "2.3 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/formula_parsing/index.html#key-takeaways",
    "href": "posts/formula_parsing/index.html#key-takeaways",
    "title": "Best practices for parsing a formula in R programming",
    "section": "2.4 Key Takeaways",
    "text": "2.4 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/formula_parsing/index.html#further-reading",
    "href": "posts/formula_parsing/index.html#further-reading",
    "title": "Best practices for parsing a formula in R programming",
    "section": "2.5 Further Reading",
    "text": "2.5 Further Reading\nIn development"
  },
  {
    "objectID": "posts/drafts.html",
    "href": "posts/drafts.html",
    "title": "Draft Posts",
    "section": "",
    "text": "No Draft Posts Currently\n\n\n\nThere are currently no draft posts in development. Posts marked with draft: true in their YAML frontmatter will appear here instead of the main blog listing."
  },
  {
    "objectID": "posts/drafts.html#how-to-create-draft-posts",
    "href": "posts/drafts.html#how-to-create-draft-posts",
    "title": "Draft Posts",
    "section": "1 How to Create Draft Posts",
    "text": "1 How to Create Draft Posts\nPosts marked as drafts are excluded from: - Main blog listing - RSS feeds\n- Site search indexing - External link sharing\nTo create a draft post: 1. Add draft: true to the post’s YAML frontmatter 2. The post will appear on this page instead of the main blog\nTo publish a draft: 1. Remove the draft: true line from the post’s YAML frontmatter 2. The post will appear on the main blog listing\nUsing the draft management script:\n# Mark a post as draft\n./manage_drafts.sh draft posts/my-post/\n\n# Publish a draft\n./manage_drafts.sh publish posts/my-post/"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim is a powerful and efficient text editor that, with the right setup, can serve as a productive environment for data science work in Python, Julia, and R. This guide will walk you through the essential plugins and configurations to transform Vim into a fully functional IDE for data science.\n\n\n\nLightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage.\n\n\n\n\nA plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins.\n\n\n\nPlug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim\n\n\n\nPlug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']\n\n\n\nPlug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle\n\n\n\n\nPlug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1\n\n\n\nPlug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline.\n\n\n\nPlug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code.\n\n\n\nPlug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets.\n\n\n\nPlug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R.\n\n\n\nPlug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode\n\n\n\n\nScreenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science.\n\n\n\n\nWith this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!\n\n\n\n\n\n\nVim Editor"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Lightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "A plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Screenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "With this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim Editor"
  },
  {
    "objectID": "posts/coding_with_genAI/index.html",
    "href": "posts/coding_with_genAI/index.html",
    "title": "coding with genAI",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "posts/coding_with_genAI/index.html#prerequisites",
    "href": "posts/coding_with_genAI/index.html#prerequisites",
    "title": "coding with genAI",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/coding_with_genAI/index.html#step-by-step-implementation",
    "href": "posts/coding_with_genAI/index.html#step-by-step-implementation",
    "title": "coding with genAI",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/coding_with_genAI/index.html#key-takeaways",
    "href": "posts/coding_with_genAI/index.html#key-takeaways",
    "title": "coding with genAI",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/coding_with_genAI/index.html#further-reading",
    "href": "posts/coding_with_genAI/index.html#further-reading",
    "title": "coding with genAI",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "misc/index.html",
    "href": "misc/index.html",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#software-and-tools",
    "href": "misc/index.html#software-and-tools",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#resources-and-references",
    "href": "misc/index.html#resources-and-references",
    "title": "Misc",
    "section": "2 Resources and References",
    "text": "2 Resources and References\n\n2.1 Quick References\n\nCommand cheat sheets\nConfiguration snippets\nCommon patterns\nTroubleshooting guides\n\n\n\n2.2 External Links\n\nUseful websites and tools\nCommunity forums and discussions\nDocumentation and manuals\nProfessional resources"
  },
  {
    "objectID": "misc/index.html#personal-projects",
    "href": "misc/index.html#personal-projects",
    "title": "Misc",
    "section": "3 Personal Projects",
    "text": "3 Personal Projects\n\n3.1 Open Source Contributions\n\nSoftware packages and libraries\nDocumentation improvements\nBug fixes and feature requests\nCommunity support\n\n\n\n3.2 Experimental Work\n\nProof-of-concept implementations\nTechnology explorations\nSide projects and demos\nLearning exercises\n\n\nThis section contains miscellaneous content that doesn’t fit neatly into other categories - tools, references, personal projects, and various resources that might be useful to others."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Lab",
    "section": "",
    "text": "I’m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub • Twitter • About"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Thomas Lab",
    "section": "",
    "text": "I’m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub • Twitter • About"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html",
    "href": "guides/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "href": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesn’t exist or package isn’t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#data-type-errors",
    "href": "guides/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#subsetting-errors",
    "href": "guides/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesn’t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#missing-values-issues",
    "href": "guides/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions can’t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#file-reading-errors",
    "href": "guides/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R can’t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#memory-issues",
    "href": "guides/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#package-installation-issues",
    "href": "guides/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package won’t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "href": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#prevention-strategies",
    "href": "guides/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here you’ll find my latest thoughts on R programming, data science, statistical computing, and research workflows. These posts capture timely insights, new discoveries, and evolving perspectives on technical topics.\nBrowse by category or scroll through the chronological feed below.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nCoding with Generative AI\n\n\n\nAI-Automation\n\n\nProgramming-Development\n\n\n\nHow to effectively use AI tools like ChatGPT and GitHub Copilot for coding while maintaining good practices\n\n\n\nJun 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMac Workflow for Tracking Daily Research Progress\n\n\n\n\n\n\nJun 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaking optimal use of ChatGPT and other chatbots for data science\n\n\nAI-powered data science workflows\n\n\n\nAI\n\n\nautomation\n\n\nR\n\n\ndata-science\n\n\n\nHow ChatGPT and other LLM tools can enhance statistical analysis and research workflows.\n\n\n\nJan 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLooking Ahead: 2025 Plans for R and Data Science\n\n\nNew directions and goals for the year\n\n\n\nreflection\n\n\nplanning\n\n\nR\n\n\ndata-science\n\n\n\nMy plans and goals for R programming, data science, and research computing in 2025.\n\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html",
    "href": "blog/2025-01-01-year-ahead.html",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "",
    "text": "As we start 2025, I’m excited to share some thoughts on where I’m heading with R programming, data science tools, and research computing workflows."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "href": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "1 This Year’s Focus Areas",
    "text": "1 This Year’s Focus Areas\nPackage Development: Planning to release two new R packages focusing on statistical visualization and research workflow automation.\nDocker Integration: Expanding my containerization work to include more complex multi-service setups for data science teams.\nAI-Assisted Coding: Exploring how LLMs can enhance R development workflows without replacing fundamental programming skills."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "href": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "2 What’s Coming to the Blog",
    "text": "2 What’s Coming to the Blog\nYou’ll see more content in our new structure: - Tutorials on advanced R topics - References for quick command lookups\n- Guides for solving specific problems - Blog posts like this for timely thoughts and updates\nLooking forward to sharing the journey!"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Thomas Lab",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n\n  \n  \nThe Thomas Lab in the Herbert Wertheim School of Public Health and Human Longevity Science at UC San Diego focuses on developing data science methodology and educational materials. Our work spans statistical computing, reproducible research practices, and modern tools for data analysis."
  },
  {
    "objectID": "about/index.html#research-focus",
    "href": "about/index.html#research-focus",
    "title": "About Thomas Lab",
    "section": "1 Research Focus",
    "text": "1 Research Focus\nOur lab specializes in:\n\nStatistical methodologies for health research\nR package development for specialized analysis needs\nReproducible research workflows and best practices\nEducational materials for data science skills in public health\nApplications of machine learning in longitudinal studies"
  },
  {
    "objectID": "about/index.html#tools-expertise",
    "href": "about/index.html#tools-expertise",
    "title": "About Thomas Lab",
    "section": "2 Tools & Expertise",
    "text": "2 Tools & Expertise\n\n\n2.1 R Programming\n\nPackage development\nStatistical modeling\nData visualization\nReproducible reporting\n\n\n\n2.2 Research Computing\n\nDocker containerization\nCloud-based computing\nHigh-performance computing\nCollaborative workflows\n\n\n\n2.3 Education\n\nWorkshop development\nTutorial creation\nOpen educational resources\nMentoring and guidance"
  },
  {
    "objectID": "about/index.html#team",
    "href": "about/index.html#team",
    "title": "About Thomas Lab",
    "section": "3 Team",
    "text": "3 Team\nOur interdisciplinary team brings together expertise in statistics, computer science, and public health research to address complex challenges in health data analysis."
  },
  {
    "objectID": "about/index.html#collaborations",
    "href": "about/index.html#collaborations",
    "title": "About Thomas Lab",
    "section": "4 Collaborations",
    "text": "4 Collaborations\nWe actively collaborate with researchers across disciplines to apply novel methodological approaches to real-world health and longevity challenges. If you’re interested in working together, please get in touch!"
  },
  {
    "objectID": "about/index.html#publications",
    "href": "about/index.html#publications",
    "title": "About Thomas Lab",
    "section": "5 Publications",
    "text": "5 Publications\nSelected recent publications:\n\nAuthor A, Author B, Thomas RG (2024). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor C, Author D, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor E, Author F, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages."
  },
  {
    "objectID": "about/index.html#contact",
    "href": "about/index.html#contact",
    "title": "About Thomas Lab",
    "section": "6 Contact",
    "text": "6 Contact\nFor inquiries about collaboration, research opportunities, or educational resources, please reach out through the social media links above or email us directly."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html",
    "href": "blog/chatbots-in-stats/index.html",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "",
    "text": "chatGPT"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#whats-in-a-name",
    "href": "blog/chatbots-in-stats/index.html#whats-in-a-name",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "1.1 Whats in a name?",
    "text": "1.1 Whats in a name?\nGPT in ChatGPT stands for Generative Pre-trained Transformer. • Generative: It generates text rather than just analyzing or classifying it. • Pre-trained: It is trained on a large dataset before being fine-tuned for specific tasks. • Transformer: It uses the Transformer architecture, a neural network model designed for natural language processing (NLP).\nEssentially, ChatGPT is a chatbot built on a GPT model, which is designed to understand and generate human-like text based on prompts\nFrom a recent article in Nature:\n“ChatGPT stunned the world on its launch in November 2022. Powered by a large language model (LLM) and trained on much of the text published on the Internet, the artificial intelligence (AI) chatbot, created by OpenAI in San Francisco, California, makes the latest advances in natural-language processing broadly accessible by providing a dialogue-based interface capable of answering complex questions, composing sophisticated essays and generating source code. One obvious question was: how could this tool improve science?”\nNature: Chatbots in science: What can ChatGPT do for you?\nLets start with a couple examples to get an idea of how to use ChatGPT for data science tasks."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#example-work-up-of-a-regression-analysis-for-the-iris-data-set.",
    "href": "blog/chatbots-in-stats/index.html#example-work-up-of-a-regression-analysis-for-the-iris-data-set.",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "1.2 Example work up of a regression analysis for the iris data set.",
    "text": "1.2 Example work up of a regression analysis for the iris data set.\n\nPrompt: “I want to do a trial data analysis in R of the Fisher iris data set that is distributed with R. I want to start with logistic regression analysis and want to use K-fold cross-validation. I want to use an ROC curve to visualize the results.”\n\ncomment: this is a good example of a prompt that is clear and specific. It provides many of the necessary context and requirements for the task. However, it is not completely unambiguous. It does not specify the number of folds for cross-validatikn. It also does not specify the R package to use for the aanalysis. There ae several to choose from.\ninstall.packages(\"caret\")  # Install if not already installed\ninstall.packages(\"pROC\")   # Install if not already installed\ninstall.packages(\"glmnet\") # Install if not already installed\nlibrary(caret)\nlibrary(pROC)\nlibrary(glmnet)\n\n# Prepare binary dataset\ndata(iris)\niris_binary &lt;- iris[iris$Species != \"setosa\", ]\niris_binary$Species &lt;- factor(iris_binary$Species)\n\n# Split the data into training and test sets\nset.seed(42)\ntrainIndex &lt;- createDataPartition(iris_binary$Species, p = 0.8, list = FALSE)\ntrain_data &lt;- iris_binary[trainIndex, ]\ntest_data &lt;- iris_binary[-trainIndex, ]\n\n# Convert the data into matrix format as required by glmnet\nx_train &lt;- model.matrix(Species ~ ., train_data)[,-1]\ny_train &lt;- train_data$Species\n\nx_test &lt;- model.matrix(Species ~ ., test_data)[,-1]\ny_test &lt;- test_data$Species\n\n# Set up cross-validation for Lasso regression on the training data\ntrain_control &lt;- trainControl(method = \"cv\", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)\n\n# Define the lasso model using glmnet (alpha=1 for Lasso)\nlasso_model &lt;- train(x = x_train, y = y_train, method = \"glmnet\", trControl = train_control, tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.1, by = 0.001)), family = \"binomial\", metric = \"ROC\")\n\n# Make predictions on the test set\ntest_predictions &lt;- predict(lasso_model, newdata = x_test, type = \"prob\")[,2]\n\n# Plot ROC curve for the test set\nroc_curve_test &lt;- roc(y_test, test_predictions, levels = rev(levels(y_test)))\nplot(roc_curve_test, col = \"blue\", lwd = 2, main = \"ROC Curve for Lasso Regression on Test Data\")\nv\n# Calculate AUC and its 95% confidence interval\nauc_value &lt;- auc(roc_curve_test)\nci &lt;- ci.auc(roc_curve_test, conf.level = 0.95)\n\n# Add AUC with 95% confidence interval to the plot\nlegend_text &lt;- paste(\"AUC =\", round(auc_value, 2), \"\\n95% CI:\", round(ci[1], 2), \"-\", round(ci[3], 2))\nlegend(\"bottomright\", legend = legend_text, col = \"blue\", lwd = 2)\nOn completion of the analysis, the user may have additional questions or requests. For example, they may ask why use 10 folds specifically? Or why split the 80:20? Why use the lasso regression model?\nThey can just ask the chatbot directly.\nPronpt: why split the data set if we’re doing 10-fold cross validation?\nChatGPT answer: ### Why Not Split? - 10-fold CV inherently splits the data multiple times\n- Each fold acts as a validation set once, while the remaining 9 folds serve as the training set. - Every observation is used for both training and testing across different iterations.\n\nAn additional 80:20 split is redundant\n\nIt would unnecessarily reduce the amount of data available for training.\nK-fold CV already provides a better estimate of model performance.\n\n\n\n1.2.1 When Would We Still Use an 80:20 Split?\n\nIf we want one final test set to evaluate model performance after tuning hyperparameters using K-fold CV.\n\nExample: Use 80% for training, perform 10-fold CV on this training set, and then evaluate on the held-out 20% test set.\nThis prevents data leakage and ensures the final model is evaluated on completely unseen data.\n\n\n\n\n\n1.2.2 Best Practice for Model Selection\n\nCross-validation alone (no 80:20 split)\n\nWhen optimizing model parameters and assessing performance.\n\nAvoids unnecessary data loss.\n\nEvery observation contributes to both training and validation.\n\n80:20 Split + Cross-validation on training set\n\nIf we want to train the final model on the full dataset,\n\nThen evaluate generalization on a completely independent holdout test set.\n\n\nFor your Fisher Iris dataset analysis, just using 10-fold CV is sufficient unless you plan to tune hyperparameters before a final evaluation. 🚀 for a 95% confidence interval calculationgM “should I split my data set into train and test parts if I’m using k-fold cross-validation?” “add a 95% confidence interval calculation to the AUC annotation in the ROC plot” “do the same analysis but use lasso regression instead of logistic regression”"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-1-setting-up-the-package-structure",
    "href": "blog/chatbots-in-stats/index.html#step-1-setting-up-the-package-structure",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.1 Step 1: Setting Up the Package Structure",
    "text": "6.1 Step 1: Setting Up the Package Structure\n\nCreate a New Package Directory:\n\nUse usethis to create a package directory:\nusethis::create_package(\"path/to/zzlongplot\")\nThis sets up the necessary directory structure with folders like R/ and files like DESCRIPTION.\n\nAdd the Core Script:\n\nPlace the zzlongplot.R file in the R/ directory.\n\nSet Up the DESCRIPTION File:\n\nEdit the DESCRIPTION file to include metadata about the package. Use usethis::use_description() to create and fill this file:\nusethis::use_description(fields = list(\n  Title = \"Flexible Longitudinal Plotting in R\",\n  Description = \"Provides tools for generating observed and change plots in longitudinal datasets.\",\n  Version = \"0.1.0\",\n  Author = \"Your Name [aut, cre]\",\n  Maintainer = \"Your Name &lt;your_email@example.com&gt;\",\n  License = \"MIT\",\n  Encoding = \"UTF-8\"\n))\n\nAdd Dependencies:\n\nList package dependencies in the DESCRIPTION file under Imports. For example:\nImports:\n  dplyr,\n  ggplot2,\n  patchwork"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-2-document-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-2-document-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.2 Step 2: Document the Package",
    "text": "6.2 Step 2: Document the Package\n\nAdd Roxygen2 Comments:\n\nEnsure all functions in zzlongplot.R have Roxygen2 comments for documentation.\n\nGenerate Documentation:\n\nRun:\ndevtools::document()\nThis creates help files in the man/ directory and updates the NAMESPACE file.\n\nCreate a Vignette:\n\nAdd the vignette to introduce the package:\nusethis::use_vignette(\"Introduction_to_zzlongplot\")\nPlace the provided zzlongplot-vignette.Rmd file in the vignettes/ directory and build it:\ndevtools::build_vignettes()"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-3-test-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-3-test-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.3 Step 3: Test the Package",
    "text": "6.3 Step 3: Test the Package\n\nAdd Unit Tests:\n\nUse usethis to set up a testing framework:\nusethis::use_testthat()\nPlace the test-zzlongplot.R file in tests/testthat/.\n\nRun Tests:\n\nRun all tests:\ndevtools::test()"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-4-check-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-4-check-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.4 Step 4: Check the Package",
    "text": "6.4 Step 4: Check the Package\n\nBuild and Check:\n\nBuild the package:\ndevtools::build()\nCheck the package for CRAN compliance:\ndevtools::check()\n\nFix Issues:\n\nAddress any warnings or errors reported by devtools::check()."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-5-submit-to-cran",
    "href": "blog/chatbots-in-stats/index.html#step-5-submit-to-cran",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.5 Step 5: Submit to CRAN",
    "text": "6.5 Step 5: Submit to CRAN\n\nPrepare for Submission:\n\nEnsure the package passes R CMD check with no warnings, errors, or notes.\nCompress the package into a .tar.gz file using:\ndevtools::build()\n\nSubmit to CRAN:\n\nGo to the CRAN submission page.\nUpload the .tar.gz file and fill out the required metadata.\n\nRespond to Feedback:\n\nCRAN maintainers might request changes. Address them promptly and resubmit if needed."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-6-set-up-a-github-repository",
    "href": "blog/chatbots-in-stats/index.html#step-6-set-up-a-github-repository",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.6 Step 6: Set Up a GitHub Repository",
    "text": "6.6 Step 6: Set Up a GitHub Repository\n\nInitialize a Git Repository:\n\nIn the package directory, run:\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n\nCreate a Repository on GitHub:\n\nUse the GitHub website or the gh CLI tool:\ngh repo create yourusername/zzlongplot --public --source=.\n\nPush the Code:\n\nPush the code to GitHub:\ngit branch -M main\ngit push -u origin main"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-7-manage-the-development-repository",
    "href": "blog/chatbots-in-stats/index.html#step-7-manage-the-development-repository",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.7 Step 7: Manage the Development Repository",
    "text": "6.7 Step 7: Manage the Development Repository\n\nAdd Version Control:\n\nUse Git for version control. For example, create a branch for new features:\ngit checkout -b feature-new-plot\n\nTag Releases:\n\nTag versions for releases:\ngit tag -a v0.1.0 -m \"First release\"\ngit push origin v0.1.0\n\nAdd Continuous Integration:\n\nSet up GitHub Actions for testing:\nusethis::use_github_action_check_standard()\n\nPublish Development Versions:\n\nUse GitHub to manage development versions and issues."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-8-maintain-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-8-maintain-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.8 Step 8: Maintain the Package",
    "text": "6.8 Step 8: Maintain the Package\n\nAddress Issues:\n\nMonitor and address issues reported by users.\n\nUpdate the Package:\n\nFor updates, increment the version number in DESCRIPTION and tag the new version."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#prerequisites",
    "href": "blog/chatbots-in-stats/index.html#prerequisites",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.9 Prerequisites",
    "text": "6.9 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-by-step-implementation",
    "href": "blog/chatbots-in-stats/index.html#step-by-step-implementation",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.10 Step-by-Step Implementation",
    "text": "6.10 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#key-takeaways",
    "href": "blog/chatbots-in-stats/index.html#key-takeaways",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.11 Key Takeaways",
    "text": "6.11 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#further-reading",
    "href": "blog/chatbots-in-stats/index.html#further-reading",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.12 Further Reading",
    "text": "6.12 Further Reading\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html",
    "href": "blog/research-management/index.html",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "href": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by",
    "text": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by\nrunning this bash script to copy a prelude to the chatGPT prompt to your clipboard: Call it dp (dictation prompt).\n#!/bin/bash\n\n# Get current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Define the prompt with explicit instructions\nprompt=\"I'm an academic biostatistician. I'm working on a data analysis project.\nI'm about to dictate daily research progress notes.  \nWhen I'm done, provide a concise summary that includes:  \n\n1. The date  and time of dictation ($current_time).  The line with date and time\nshould be the second line of the summary. The first line should be blank. The\ndate and time line shound be enclosed in a box of ascii characters to set it apart.\n2. The name of the current research project directory ($current_dir).  \n3. Each line of the summary including the blank line and the date and time line\nand enclosing box lines should begin with \\\"$current_dir:\\\" so that it can be\nextracted using ripgrep.  \n\nThe notes start here: \"\n\n# Copy the prompt to clipboard (MacOS pbcopy)\necho -n \"$prompt\" | pbcopy\n\n# Notify the user\necho \"Prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.2-dictating-notes",
    "href": "blog/research-management/index.html#step-3.2-dictating-notes",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nOpen ChatGPT (done automatically by “dp” script) and follow these steps:\ncopy text from clipboard into the prompt box.\nsubmit prompt to prep chatGPT for summarization.\nClick chatGPT microphone and Dictate your research notes.\nWhen finished dictating submit prompt to ChatGPT for summarization.\nCopy and generated summary onto the clipboard.\n\nUse the following script to append the summary to your daily log: and push the changes to daily_log.md to the remote repository on GitHub.\n#!/bin/bash\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Get the current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the clipboard content (MacOS pbpaste)\nclipboard_content=$(pbpaste)\n\n# Echo the output\n#\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"\" &gt;&gt; ~/prj/research_update/daily_log.md\n\n# Confirm success\necho \"Update for $current_dir appended to daily_log.md in ~/prj/research_update\"\ncd ~/prj/research_update\n  git add .\n    git commit -a -m \"Daily log update $(date +'%Y-%m-%d')\"\n    git push"
  },
  {
    "objectID": "blog/research-management/index.html#prerequisites",
    "href": "blog/research-management/index.html#prerequisites",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#step-by-step-implementation",
    "href": "blog/research-management/index.html#step-by-step-implementation",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#key-takeaways",
    "href": "blog/research-management/index.html#key-takeaways",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#further-reading",
    "href": "blog/research-management/index.html#further-reading",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "guides/index.html",
    "href": "guides/index.html",
    "title": "Guides",
    "section": "",
    "text": "Practical guides for solving specific problems and accomplishing particular tasks. These step-by-step instructions help you tackle real-world challenges.\nEach guide provides: - Clear problem definition - Prerequisites and assumptions - Detailed implementation steps - Alternative approaches - Common pitfalls and solutions\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nFixing Common R Errors: A Troubleshooting Guide\n\n\nStep-by-step solutions for frequent R programming problems\n\n\n\nR\n\n\ntroubleshooting\n\n\ndebugging\n\n\nguide\n\n\n\nPractical solutions for the most common R errors encountered by data scientists and analysts.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html",
    "href": "misc/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "href": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesn’t exist or package isn’t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#data-type-errors",
    "href": "misc/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#subsetting-errors",
    "href": "misc/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesn’t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#missing-values-issues",
    "href": "misc/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions can’t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#file-reading-errors",
    "href": "misc/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R can’t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#memory-issues",
    "href": "misc/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#package-installation-issues",
    "href": "misc/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package won’t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "href": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#prevention-strategies",
    "href": "misc/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html",
    "href": "posts/chatbots_in_stats/index.html",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "",
    "text": "chatGPT"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#whats-in-a-name",
    "href": "posts/chatbots_in_stats/index.html#whats-in-a-name",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "1.1 Whats in a name?",
    "text": "1.1 Whats in a name?\nGPT in ChatGPT stands for Generative Pre-trained Transformer. • Generative: It generates text rather than just analyzing or classifying it. • Pre-trained: It is trained on a large dataset before being fine-tuned for specific tasks. • Transformer: It uses the Transformer architecture, a neural network model designed for natural language processing (NLP).\nEssentially, ChatGPT is a chatbot built on a GPT model, which is designed to understand and generate human-like text based on prompts\nFrom a recent article in Nature:\n“ChatGPT stunned the world on its launch in November 2022. Powered by a large language model (LLM) and trained on much of the text published on the Internet, the artificial intelligence (AI) chatbot, created by OpenAI in San Francisco, California, makes the latest advances in natural-language processing broadly accessible by providing a dialogue-based interface capable of answering complex questions, composing sophisticated essays and generating source code. One obvious question was: how could this tool improve science?”\nNature: Chatbots in science: What can ChatGPT do for you?\nLets start with a couple examples to get an idea of how to use ChatGPT for data science tasks."
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#example-work-up-of-a-regression-analysis-for-the-iris-data-set.",
    "href": "posts/chatbots_in_stats/index.html#example-work-up-of-a-regression-analysis-for-the-iris-data-set.",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "1.2 Example work up of a regression analysis for the iris data set.",
    "text": "1.2 Example work up of a regression analysis for the iris data set.\n\nPrompt: “I want to do a trial data analysis in R of the Fisher iris data set that is distributed with R. I want to start with logistic regression analysis and want to use K-fold cross-validation. I want to use an ROC curve to visualize the results.”\n\ncomment: this is a good example of a prompt that is clear and specific. It provides many of the necessary context and requirements for the task. However, it is not completely unambiguous. It does not specify the number of folds for cross-validatikn. It also does not specify the R package to use for the aanalysis. There ae several to choose from.\ninstall.packages(\"caret\")  # Install if not already installed\ninstall.packages(\"pROC\")   # Install if not already installed\ninstall.packages(\"glmnet\") # Install if not already installed\nlibrary(caret)\nlibrary(pROC)\nlibrary(glmnet)\n\n# Prepare binary dataset\ndata(iris)\niris_binary &lt;- iris[iris$Species != \"setosa\", ]\niris_binary$Species &lt;- factor(iris_binary$Species)\n\n# Split the data into training and test sets\nset.seed(42)\ntrainIndex &lt;- createDataPartition(iris_binary$Species, p = 0.8, list = FALSE)\ntrain_data &lt;- iris_binary[trainIndex, ]\ntest_data &lt;- iris_binary[-trainIndex, ]\n\n# Convert the data into matrix format as required by glmnet\nx_train &lt;- model.matrix(Species ~ ., train_data)[,-1]\ny_train &lt;- train_data$Species\n\nx_test &lt;- model.matrix(Species ~ ., test_data)[,-1]\ny_test &lt;- test_data$Species\n\n# Set up cross-validation for Lasso regression on the training data\ntrain_control &lt;- trainControl(method = \"cv\", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)\n\n# Define the lasso model using glmnet (alpha=1 for Lasso)\nlasso_model &lt;- train(x = x_train, y = y_train, method = \"glmnet\", trControl = train_control, tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.1, by = 0.001)), family = \"binomial\", metric = \"ROC\")\n\n# Make predictions on the test set\ntest_predictions &lt;- predict(lasso_model, newdata = x_test, type = \"prob\")[,2]\n\n# Plot ROC curve for the test set\nroc_curve_test &lt;- roc(y_test, test_predictions, levels = rev(levels(y_test)))\nplot(roc_curve_test, col = \"blue\", lwd = 2, main = \"ROC Curve for Lasso Regression on Test Data\")\nv\n# Calculate AUC and its 95% confidence interval\nauc_value &lt;- auc(roc_curve_test)\nci &lt;- ci.auc(roc_curve_test, conf.level = 0.95)\n\n# Add AUC with 95% confidence interval to the plot\nlegend_text &lt;- paste(\"AUC =\", round(auc_value, 2), \"\\n95% CI:\", round(ci[1], 2), \"-\", round(ci[3], 2))\nlegend(\"bottomright\", legend = legend_text, col = \"blue\", lwd = 2)\nOn completion of the analysis, the user may have additional questions or requests. For example, they may ask why use 10 folds specifically? Or why split the 80:20? Why use the lasso regression model?\nThey can just ask the chatbot directly.\nPronpt: why split the data set if we’re doing 10-fold cross validation?\nChatGPT answer: ### Why Not Split? - 10-fold CV inherently splits the data multiple times\n- Each fold acts as a validation set once, while the remaining 9 folds serve as the training set. - Every observation is used for both training and testing across different iterations.\n\nAn additional 80:20 split is redundant\n\nIt would unnecessarily reduce the amount of data available for training.\nK-fold CV already provides a better estimate of model performance.\n\n\n\n1.2.1 When Would We Still Use an 80:20 Split?\n\nIf we want one final test set to evaluate model performance after tuning hyperparameters using K-fold CV.\n\nExample: Use 80% for training, perform 10-fold CV on this training set, and then evaluate on the held-out 20% test set.\nThis prevents data leakage and ensures the final model is evaluated on completely unseen data.\n\n\n\n\n\n1.2.2 Best Practice for Model Selection\n\nCross-validation alone (no 80:20 split)\n\nWhen optimizing model parameters and assessing performance.\n\nAvoids unnecessary data loss.\n\nEvery observation contributes to both training and validation.\n\n80:20 Split + Cross-validation on training set\n\nIf we want to train the final model on the full dataset,\n\nThen evaluate generalization on a completely independent holdout test set.\n\n\nFor your Fisher Iris dataset analysis, just using 10-fold CV is sufficient unless you plan to tune hyperparameters before a final evaluation. 🚀 for a 95% confidence interval calculationgM “should I split my data set into train and test parts if I’m using k-fold cross-validation?” “add a 95% confidence interval calculation to the AUC annotation in the ROC plot” “do the same analysis but use lasso regression instead of logistic regression”"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-1-setting-up-the-package-structure",
    "href": "posts/chatbots_in_stats/index.html#step-1-setting-up-the-package-structure",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.1 Step 1: Setting Up the Package Structure",
    "text": "6.1 Step 1: Setting Up the Package Structure\n\nCreate a New Package Directory:\n\nUse usethis to create a package directory:\nusethis::create_package(\"path/to/zzlongplot\")\nThis sets up the necessary directory structure with folders like R/ and files like DESCRIPTION.\n\nAdd the Core Script:\n\nPlace the zzlongplot.R file in the R/ directory.\n\nSet Up the DESCRIPTION File:\n\nEdit the DESCRIPTION file to include metadata about the package. Use usethis::use_description() to create and fill this file:\nusethis::use_description(fields = list(\n  Title = \"Flexible Longitudinal Plotting in R\",\n  Description = \"Provides tools for generating observed and change plots in longitudinal datasets.\",\n  Version = \"0.1.0\",\n  Author = \"Your Name [aut, cre]\",\n  Maintainer = \"Your Name &lt;your_email@example.com&gt;\",\n  License = \"MIT\",\n  Encoding = \"UTF-8\"\n))\n\nAdd Dependencies:\n\nList package dependencies in the DESCRIPTION file under Imports. For example:\nImports:\n  dplyr,\n  ggplot2,\n  patchwork"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-2-document-the-package",
    "href": "posts/chatbots_in_stats/index.html#step-2-document-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.2 Step 2: Document the Package",
    "text": "6.2 Step 2: Document the Package\n\nAdd Roxygen2 Comments:\n\nEnsure all functions in zzlongplot.R have Roxygen2 comments for documentation.\n\nGenerate Documentation:\n\nRun:\ndevtools::document()\nThis creates help files in the man/ directory and updates the NAMESPACE file.\n\nCreate a Vignette:\n\nAdd the vignette to introduce the package:\nusethis::use_vignette(\"Introduction_to_zzlongplot\")\nPlace the provided zzlongplot-vignette.Rmd file in the vignettes/ directory and build it:\ndevtools::build_vignettes()"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-3-test-the-package",
    "href": "posts/chatbots_in_stats/index.html#step-3-test-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.3 Step 3: Test the Package",
    "text": "6.3 Step 3: Test the Package\n\nAdd Unit Tests:\n\nUse usethis to set up a testing framework:\nusethis::use_testthat()\nPlace the test-zzlongplot.R file in tests/testthat/.\n\nRun Tests:\n\nRun all tests:\ndevtools::test()"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-4-check-the-package",
    "href": "posts/chatbots_in_stats/index.html#step-4-check-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.4 Step 4: Check the Package",
    "text": "6.4 Step 4: Check the Package\n\nBuild and Check:\n\nBuild the package:\ndevtools::build()\nCheck the package for CRAN compliance:\ndevtools::check()\n\nFix Issues:\n\nAddress any warnings or errors reported by devtools::check()."
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-5-submit-to-cran",
    "href": "posts/chatbots_in_stats/index.html#step-5-submit-to-cran",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.5 Step 5: Submit to CRAN",
    "text": "6.5 Step 5: Submit to CRAN\n\nPrepare for Submission:\n\nEnsure the package passes R CMD check with no warnings, errors, or notes.\nCompress the package into a .tar.gz file using:\ndevtools::build()\n\nSubmit to CRAN:\n\nGo to the CRAN submission page.\nUpload the .tar.gz file and fill out the required metadata.\n\nRespond to Feedback:\n\nCRAN maintainers might request changes. Address them promptly and resubmit if needed."
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-6-set-up-a-github-repository",
    "href": "posts/chatbots_in_stats/index.html#step-6-set-up-a-github-repository",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.6 Step 6: Set Up a GitHub Repository",
    "text": "6.6 Step 6: Set Up a GitHub Repository\n\nInitialize a Git Repository:\n\nIn the package directory, run:\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n\nCreate a Repository on GitHub:\n\nUse the GitHub website or the gh CLI tool:\ngh repo create yourusername/zzlongplot --public --source=.\n\nPush the Code:\n\nPush the code to GitHub:\ngit branch -M main\ngit push -u origin main"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-7-manage-the-development-repository",
    "href": "posts/chatbots_in_stats/index.html#step-7-manage-the-development-repository",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.7 Step 7: Manage the Development Repository",
    "text": "6.7 Step 7: Manage the Development Repository\n\nAdd Version Control:\n\nUse Git for version control. For example, create a branch for new features:\ngit checkout -b feature-new-plot\n\nTag Releases:\n\nTag versions for releases:\ngit tag -a v0.1.0 -m \"First release\"\ngit push origin v0.1.0\n\nAdd Continuous Integration:\n\nSet up GitHub Actions for testing:\nusethis::use_github_action_check_standard()\n\nPublish Development Versions:\n\nUse GitHub to manage development versions and issues."
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-8-maintain-the-package",
    "href": "posts/chatbots_in_stats/index.html#step-8-maintain-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.8 Step 8: Maintain the Package",
    "text": "6.8 Step 8: Maintain the Package\n\nAddress Issues:\n\nMonitor and address issues reported by users.\n\nUpdate the Package:\n\nFor updates, increment the version number in DESCRIPTION and tag the new version."
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#prerequisites",
    "href": "posts/chatbots_in_stats/index.html#prerequisites",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.9 Prerequisites",
    "text": "6.9 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#step-by-step-implementation",
    "href": "posts/chatbots_in_stats/index.html#step-by-step-implementation",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.10 Step-by-Step Implementation",
    "text": "6.10 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#key-takeaways",
    "href": "posts/chatbots_in_stats/index.html#key-takeaways",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.11 Key Takeaways",
    "text": "6.11 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/chatbots_in_stats/index.html#further-reading",
    "href": "posts/chatbots_in_stats/index.html#further-reading",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.12 Further Reading",
    "text": "6.12 Further Reading\nIn development"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html",
    "href": "posts/config_term_zsh_p11/index.html",
    "title": "Configure the command line for data science development",
    "section": "",
    "text": "iterm2"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#configzsh.zsh_aliases",
    "href": "posts/config_term_zsh_p11/index.html#configzsh.zsh_aliases",
    "title": "Configure the command line for data science development",
    "section": "3.1 ~/.config/zsh/.zsh_aliases",
    "text": "3.1 ~/.config/zsh/.zsh_aliases\n\nalias mm='mutt'\nalias sk='open -a Skim'\nalias vc='vim ~/.vimrc'\nalias vz='vim ~/.zshrc'\nalias sz='source ~/.zshrc'\nalias p2='enscript -C -2 -r -j --media=Letter'\nalias p1='enscript  -j --media=Letter'\nalias yr=\"yabai --restart-service\"\nalias lt='eza -lrFha -sold'\nalias mvim=\"/Applications/MacVim.app/Contents/bin/mvim\"\nalias tp='trash-put -v'\nalias rm='echo \"This is not the command you are looking for.\"; false'\nalias s='scd'\nalias ZZ='exit'\nalias r=\"radian\"\nalias nt=\"nvim\"\nalias -g ...='../..'\nalias -g ....='../../..'\nalias -g .....='../../../..'\nalias -g ......='../../../../..'\n\nalias -- -='cd -'\nalias 1='cd -1'\nalias 2='cd -2'\nalias 3='cd -3'\nalias 4='cd -4'\nalias 5='cd -5'\nalias 6='cd -6'\nalias 7='cd -7'\nalias 8='cd -8'\nalias 9='cd -9'\n\nalias md='mkdir -p'\nalias rd=rmdir\n\n# List directory contents\nalias lsa='ls -lah'\nalias l='ls -lah'\nalias ll='ls -lh'\nalias la='ls -lAh'\n\n# search for directory and cd to it\nalias sd=\"cd ~ && cd \\$(find * -type d -not -path '*/Library/*' | fzf)\""
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#configzsh.zsh_exports",
    "href": "posts/config_term_zsh_p11/index.html#configzsh.zsh_exports",
    "title": "Configure the command line for data science development",
    "section": "3.2 ~/.config/zsh/.zsh_exports",
    "text": "3.2 ~/.config/zsh/.zsh_exports\n\nexport EDITOR=\"vim\"\nexport TEXINPUTS='.:/Users/zenn/shr/images:/Users/zenn/shr:'\nexport PATH=\".:.local/bin:/opt/homebrew/sbin:/opt/homebrew/bin:$PATH:$HOME/bin\"\nexport vpc_id=\"vpc-14814b73\"\nexport subnet_id=\"subnet-f02c90ab\"\nexport ami_id=\"ami-014d05e6b24240371\"\nexport keypair_name=\"rebecca_app\"\nexport proj_name=\"rebecca_app\"\nexport instance_type=\"t2.micro\"\nexport storage_size=\"30\"\nexport ami_id=\"ami-014d05e6b24240371\"\nexport security_grp=\"sg-008cace70d32f6267\"\nexport static_ip='13.56.101.209'\n\nif type rg &&gt; /dev/null; then\n  export FZF_DEFAULT_COMMAND='rg --files --hidden --no-ignore-vcs'\n  export FZF_DEFAULT_OPTS='-m --height 50% --border'\nfi\n\nexport ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=\"fg=011,bg=black,bold,underline\"\nLS_COLORS+='pi=01;33:so=01;33:do=01;33:bd=01;33:cd=01;33:su=01;35:sg=01;35:ca=01;35:ex=01;32'\nexport LSCOLORS='ExGxDxDxCxDxDxFxFxexEx'"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#configzsh.zsh_functions",
    "href": "posts/config_term_zsh_p11/index.html#configzsh.zsh_functions",
    "title": "Configure the command line for data science development",
    "section": "3.3 ~/.config/zsh/.zsh_functions",
    "text": "3.3 ~/.config/zsh/.zsh_functions\n\nfunction d () {\n  if [[ -n $1 ]]; then\n    dirs \"$@\"\n  else\n    dirs -v | head -n 10\n  fi\n}\n\nmma () { /Applications/Mathematica.app/Contents/MacOS/WolframKernel -script $1 }\nfunction gz() {\n    git add .\n    git commit -a -m \"$1\"\n    git push\n}"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#prerequisites",
    "href": "posts/config_term_zsh_p11/index.html#prerequisites",
    "title": "Configure the command line for data science development",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#step-by-step-implementation",
    "href": "posts/config_term_zsh_p11/index.html#step-by-step-implementation",
    "title": "Configure the command line for data science development",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#key-takeaways",
    "href": "posts/config_term_zsh_p11/index.html#key-takeaways",
    "title": "Configure the command line for data science development",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/config_term_zsh_p11/index.html#further-reading",
    "href": "posts/config_term_zsh_p11/index.html#further-reading",
    "title": "Configure the command line for data science development",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html",
    "href": "posts/configure_vim_for_r/index.html",
    "title": "Setting up a vim environment for R data science code development",
    "section": "",
    "text": "vimlogo"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#install-a-plugin-manager-vim-plug",
    "href": "posts/configure_vim_for_r/index.html#install-a-plugin-manager-vim-plug",
    "title": "Setting up a vim environment for R data science code development",
    "section": "3.1 Install a plugin manager vim-plug",
    "text": "3.1 Install a plugin manager vim-plug\nInstall vim-plug. From the home directory, run:\ncurl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n  https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#set-up-a-plugin",
    "href": "posts/configure_vim_for_r/index.html#set-up-a-plugin",
    "title": "Setting up a vim environment for R data science code development",
    "section": "3.2 Set up a plugin",
    "text": "3.2 Set up a plugin\nAdd to ~/.vim/vimrc or init.vim or init.lua\nPlug 'neoclide/coc.nvim', {'branch': 'release'}\nThen run\n:PlugInstall"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#setup-language-server",
    "href": "posts/configure_vim_for_r/index.html#setup-language-server",
    "title": "Setting up a vim environment for R data science code development",
    "section": "3.3 Setup language server",
    "text": "3.3 Setup language server\n:CocInstall coc-r-lsp"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#suggested-vim.confignviminit.vim",
    "href": "posts/configure_vim_for_r/index.html#suggested-vim.confignviminit.vim",
    "title": "Setting up a vim environment for R data science code development",
    "section": "3.4 Suggested vim/.config/nvim/init.vim",
    "text": "3.4 Suggested vim/.config/nvim/init.vim\nSuggested configuration to get started. I’ll explain after.\ncall plug#begin(\"~/.vim/plugged\")\n\" Plugin Section\nset nocompatible\nPlug 'morhetz/gruvbox'\nPlug 'vim-airline/vim-airline'\nPlug 'vim-airline/vim-airline-themes'\nPlug 'jalvesaq/Nvim-R', {'branch': 'stable'}\nPlug 'ncm2/ncm2'\nPlug 'roxma/nvim-yarp'\nPlug 'gaalcaras/ncm-R'\nPlug 'preservim/nerdtree'\nPlug 'tpope/vim-commentary'\nPlug 'tpope/vim-fugitive'\nPlug 'junegunn/fzf'\nPlug 'junegunn/fzf.vim'\nPlug 'neoclide/coc.nvim', {'branch': 'release'} \" Language Server Protocol (LSP) support\nPlug 'SirVer/ultisnips'\nPlug 'quangnguyen30192/cmp-nvim-ultisnips'\nPlug 'honza/vim-snippets'\nPlug 'lervag/vimtex'\nPlug 'tmhedberg/SimpylFold'\nPlug 'tpope/vim-surround'\nPlug 'jalvesaq/vimcmdline'\n\" End Plugin Section\ncall plug#end()\n\n\" Basic settings\ncolorscheme gruvbox\nset background=dark\nsyntax enable\nfiletype plugin indent on\nset tabstop=4\nset shiftwidth=4\nset expandtab\nset number\nset relativenumber\nset textwidth=80\nset splitright\nset nobackup\nset nowritebackup\nset updatetime=300\nset signcolumn=yes\n\n\" R settings (specific to Nvim-R)\n\" These are some examples of settings for Nvim-R\nlet R_app = \"radian\"  \" Use radian if you have it installed (pip install radian)\nlet R_cmd = \"R\"\nlet R_hl_term = 0\nlet R_rconsole_width = 80\nlet R_min_editor_width = 80\nlet g:R_auto_start = 2\nlet R_assign = 2  \" Use _ for assignment\nlet R_silent_term = 1\nlet R_close_term = 1\n\n\" LSP settings (Coc.nvim)\n\" Autocomplete settings\ninoremap &lt;expr&gt; &lt;Tab&gt; pumvisible() ? \"\\&lt;C-n&gt;\" : \"\\&lt;Tab&gt;\"\ninoremap &lt;expr&gt; &lt;S-Tab&gt; pumvisible() ? \"\\&lt;C-p&gt;\" : \"\\&lt;S-Tab&gt;\"\ninoremap &lt;silent&gt;&lt;expr&gt; &lt;CR&gt; pumvisible() ? coc#_select_confirm() : \"\\&lt;C-g&gt;u\\&lt;CR&gt;\"\n\n\" UltiSnips settings\nlet g:UltiSnipsExpandTrigger=\"&lt;c-j&gt;\"\nlet g:UltiSnipsJumpForwardTrigger=\"&lt;c-j&gt;\"\nlet g:UltiSnipsJumpBackwardTrigger=\"&lt;c-k&gt;\"\n\n\" Custom keymappings\nnmap &lt;C-n&gt; :NERDTreeToggle&lt;CR&gt;\nnnoremap &lt;leader&gt;f :Files&lt;CR&gt;\nnnoremap &lt;leader&gt;g :Rg&lt;CR&gt;\n\n\" Key mappings for sending lines to R\nnmap &lt;localleader&gt;ss &lt;Plug&gt;RStart\nvmap &lt;localleader&gt;ss &lt;Plug&gt;RStart\nnmap &lt;localleader&gt;r &lt;Plug&gt;RSendLine\nvmap &lt;localleader&gt;r &lt;Plug&gt;RSendSelection\nnmap &lt;localleader&gt;l &lt;Plug&gt;RSendLine\nnmap &lt;localleader&gt;p &lt;Plug&gt;RSendParagraph\nVerify that the plugins were installed by starting nvim and typing :checkhealth. You should have most of these items working. If not, either disable the troublesome plugin by commenting it out with a ” character at beginning of the line or looking up the solution.\nMost problems here are solvable with a few web searches."
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#solution-to-nodejs-issue",
    "href": "posts/configure_vim_for_r/index.html#solution-to-nodejs-issue",
    "title": "Setting up a vim environment for R data science code development",
    "section": "4.1 Solution to nodejs issue",
    "text": "4.1 Solution to nodejs issue\n# On Mac \nbrew install node\n# On Ubuntu\ncurl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -\nsudo apt-get install -y nodejs"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#ultisnips---adding-custom-snippets",
    "href": "posts/configure_vim_for_r/index.html#ultisnips---adding-custom-snippets",
    "title": "Setting up a vim environment for R data science code development",
    "section": "5.1 UltiSnips - adding custom snippets",
    "text": "5.1 UltiSnips - adding custom snippets\nUltiSnips is a powerful snippet engine. You can create custom snippets for R in a file like ~/.config/nvim/UltiSnips/r.snippets.\nHere’s an example of some useful R snippets:\nsnippet df \"Create data frame\"\ndata.frame(\n  ${1:col1} = ${2:value1},\n  ${3:col2} = ${4:value2}\n)\nendsnippet\n\nsnippet fun \"Function definition\"\n${1:function_name} &lt;- function(${2:arguments}) {\n  ${3:body}\n}\nendsnippet\n\nsnippet for \"For loop\"\nfor (${1:i} in ${2:sequence}) {\n  ${3:body}\n}\nendsnippet"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#vim-fugitive-for-git-integration",
    "href": "posts/configure_vim_for_r/index.html#vim-fugitive-for-git-integration",
    "title": "Setting up a vim environment for R data science code development",
    "section": "5.2 Vim-Fugitive for Git integration",
    "text": "5.2 Vim-Fugitive for Git integration\nIf you’re using Git for version control, vim-fugitive is an excellent plugin that gives you Git capabilities right from Vim:\n\" Add to your plugin section\nPlug 'tpope/vim-fugitive'\n\n\" Common commands:\n\" :Git - equivalent to git status\n\" :Git commit - commit changes\n\" :Git push - push to remote\n\" :Git pull - pull from remote\n\" :Git blame - see who wrote what"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#learning-path",
    "href": "posts/configure_vim_for_r/index.html#learning-path",
    "title": "Setting up a vim environment for R data science code development",
    "section": "5.3 Learning Path",
    "text": "5.3 Learning Path\nLearning Vim + R can be overwhelming at first. Here’s a suggested pathway:\n\nStart with basic Vim movements (hjkl, w, b, etc.)\nLearn how to send code to R using Nvim-R (r)\nGradually add more plugins and learn their features\nCustomize your configuration as you identify pain points\n\nRemember that the goal is to make your workflow more efficient. Don’t try to learn everything at once - add features gradually as you get comfortable."
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#step-by-step-implementation",
    "href": "posts/configure_vim_for_r/index.html#step-by-step-implementation",
    "title": "Setting up a vim environment for R data science code development",
    "section": "7.1 Step-by-Step Implementation",
    "text": "7.1 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#key-takeaways",
    "href": "posts/configure_vim_for_r/index.html#key-takeaways",
    "title": "Setting up a vim environment for R data science code development",
    "section": "7.2 Key Takeaways",
    "text": "7.2 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/configure_vim_for_r/index.html#further-reading",
    "href": "posts/configure_vim_for_r/index.html#further-reading",
    "title": "Setting up a vim environment for R data science code development",
    "section": "7.3 Further Reading",
    "text": "7.3 Further Reading\nIn development"
  },
  {
    "objectID": "posts/dual_boot_thinkpad/index.html",
    "href": "posts/dual_boot_thinkpad/index.html",
    "title": "Adding Windows as a Second OS on Thinkpad",
    "section": "",
    "text": "Windows"
  },
  {
    "objectID": "posts/dual_boot_thinkpad/index.html#setting-and-motivation",
    "href": "posts/dual_boot_thinkpad/index.html#setting-and-motivation",
    "title": "Adding Windows as a Second OS on Thinkpad",
    "section": "1.1 Setting and motivation",
    "text": "1.1 Setting and motivation\ncheck thinkpad model I have a relatively new Lenova Thinkpad, Carbon X1 Gen 9. It came with Ubuntu installed and now I want to add Windows 11 as a second OS.\nI have a 1TB SSD and I have allocated 500GB to Ubuntu. I want to allocate 500GB to Windows."
  },
  {
    "objectID": "posts/dual_boot_thinkpad/index.html#prerequisites",
    "href": "posts/dual_boot_thinkpad/index.html#prerequisites",
    "title": "Adding Windows as a Second OS on Thinkpad",
    "section": "2.1 Prerequisites",
    "text": "2.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/dual_boot_thinkpad/index.html#step-by-step-implementation",
    "href": "posts/dual_boot_thinkpad/index.html#step-by-step-implementation",
    "title": "Adding Windows as a Second OS on Thinkpad",
    "section": "2.2 Step-by-Step Implementation",
    "text": "2.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/dual_boot_thinkpad/index.html#key-takeaways",
    "href": "posts/dual_boot_thinkpad/index.html#key-takeaways",
    "title": "Adding Windows as a Second OS on Thinkpad",
    "section": "2.3 Key Takeaways",
    "text": "2.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/dual_boot_thinkpad/index.html#further-reading",
    "href": "posts/dual_boot_thinkpad/index.html#further-reading",
    "title": "Adding Windows as a Second OS on Thinkpad",
    "section": "2.4 Further Reading",
    "text": "2.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/mimicsoftmood/index.html",
    "href": "posts/mimicsoftmood/index.html",
    "title": "Mimicing the softmood reddit post",
    "section": "",
    "text": "under construction\n\n\nVery impressed with the reddit post of ykonstant\n[Cinnamon] Soft mood and latex workflow\nThis project is an attempt to mimic the various elements of the post, particularly the ultisnips portion.\nThe key elements to get started:\nThe list from the post:\n\nDE: Cinnamon\n\nTerminal emulator: iterm2 brew install iterm2\n\nWallpaper: Abstract geometry lofi coffee\n\n\n\n\n\n\nunder construction\n\n\n\nMusic mix credits: Loosen up your mind by Homework Radio\n\nRoot system animation: The Beauty of E8 by David Madore\n\nEye candy: cli-visualiser, cmatrix, neofetch, pipes.sh\n\nReference Management System: Zotero\n\nBrowser: qutebrowser with zotero connector\n\nVim Colorscheme: habiLight modified\n\nStatus Bar: airline with custom theme, adapted from gruvbox code.\n\nVim plugins: vimtex, ultisnips, vim-surround.\n\nbrew install neofetch\n\n\n\n\n\nunder construction"
  },
  {
    "objectID": "posts/mimicsoftmood/index.html#prerequisites",
    "href": "posts/mimicsoftmood/index.html#prerequisites",
    "title": "Mimicing the softmood reddit post",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/mimicsoftmood/index.html#step-by-step-implementation",
    "href": "posts/mimicsoftmood/index.html#step-by-step-implementation",
    "title": "Mimicing the softmood reddit post",
    "section": "3.2 Step-by-Step Implementation",
    "text": "3.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/mimicsoftmood/index.html#key-takeaways",
    "href": "posts/mimicsoftmood/index.html#key-takeaways",
    "title": "Mimicing the softmood reddit post",
    "section": "3.3 Key Takeaways",
    "text": "3.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/mimicsoftmood/index.html#further-reading",
    "href": "posts/mimicsoftmood/index.html#further-reading",
    "title": "Mimicing the softmood reddit post",
    "section": "3.4 Further Reading",
    "text": "3.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html",
    "href": "posts/r_code_package_updating_p34/index.html",
    "title": "Update R package development process",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#initial-code-changes",
    "href": "posts/r_code_package_updating_p34/index.html#initial-code-changes",
    "title": "Update R package development process",
    "section": "2.1 Initial Code Changes",
    "text": "2.1 Initial Code Changes\nThe workflow begins with modifying your R code. Let’s say we want to improve error handling in the package:\n\nNavigate to the package’s R directory\nOpen the relevant R file (in this case, zzdataframe2graphic.R)\nMake your changes\nDocument any new parameters or changes in the roxygen comments"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#local-testing-and-building",
    "href": "posts/r_code_package_updating_p34/index.html#local-testing-and-building",
    "title": "Update R package development process",
    "section": "2.2 Local Testing and Building",
    "text": "2.2 Local Testing and Building\nAfter making changes, follow these steps:\n\nDocument the changes:\n\ndevtools::document()\nThis updates the NAMESPACE and man/ files based on your roxygen comments.\n\nRun the tests:\n\ndevtools::test()\nFix any test failures that appear.\n\nBuild and install the package:\n\ndevtools::build()\ndevtools::install()"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#github-integration",
    "href": "posts/r_code_package_updating_p34/index.html#github-integration",
    "title": "Update R package development process",
    "section": "2.3 GitHub Integration",
    "text": "2.3 GitHub Integration\nOnce your local changes are working, it’s time to integrate with GitHub:\n\nCreate a new branch:\n\ngit checkout -b feature-name\n\nStage and commit your changes:\n\ngit add R/zzdataframe2graphic.R\ngit add tests/testthat/test-zzdataframe2graphic.R\ngit commit -m \"Add improved error handling\"\n\nPush to GitHub:\n\ngit push origin feature-name"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#github-actions",
    "href": "posts/r_code_package_updating_p34/index.html#github-actions",
    "title": "Update R package development process",
    "section": "2.4 GitHub Actions",
    "text": "2.4 GitHub Actions\nGitHub Actions automate the testing process. The package uses three main workflows:\n\n2.4.1 R-CMD-check\nThis workflow runs R CMD check on multiple operating systems: - Windows latest - macOS latest - Ubuntu latest (with R-release, R-devel, and R-oldrel)\nThe workflow is triggered on: - Push to main/master - Pull requests to main/master\n\n\n2.4.2 Test Coverage\nThis workflow: - Runs all package tests - Generates coverage reports - Requires proper setup of LaTeX dependencies - Reports which parts of the code need more testing\n\n\n2.4.3 pkgdown\nThis workflow: - Builds package documentation - Deploys to GitHub Pages - Updates whenever changes are pushed to main/master"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#setting-up-github-actions",
    "href": "posts/r_code_package_updating_p34/index.html#setting-up-github-actions",
    "title": "Update R package development process",
    "section": "2.5 Setting Up GitHub Actions",
    "text": "2.5 Setting Up GitHub Actions\nTo set up these workflows:\n\nCreate the workflows directory:\n\nmkdir -p .github/workflows\n\nAdd the necessary YAML files:\n\n\nR-CMD-check.yaml\ntest-coverage.yaml\npkgdown.yaml\n\n\nConfigure repository settings:\n\n\nGo to Settings → Actions → General\nSet “Workflow permissions” to “Read and write”\nEnable GitHub Pages deployment"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#monitoring-the-process",
    "href": "posts/r_code_package_updating_p34/index.html#monitoring-the-process",
    "title": "Update R package development process",
    "section": "2.6 Monitoring the Process",
    "text": "2.6 Monitoring the Process\nAfter pushing changes:\n\nCheck the “Actions” tab on GitHub\nMonitor each workflow’s progress\nReview any failures\nCheck the generated documentation site\nReview test coverage reports"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#best-practices",
    "href": "posts/r_code_package_updating_p34/index.html#best-practices",
    "title": "Update R package development process",
    "section": "2.7 Best Practices",
    "text": "2.7 Best Practices\n\nAlways create a new branch for changes\nRun tests locally before pushing\nWrite tests for new functionality\nKeep commits focused and well-documented\nMonitor GitHub Actions results\nAddress failures promptly"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#conclusion",
    "href": "posts/r_code_package_updating_p34/index.html#conclusion",
    "title": "Update R package development process",
    "section": "2.8 Conclusion",
    "text": "2.8 Conclusion\nThis workflow ensures that changes to the package are properly tested, documented, and integrated. The GitHub Actions automation provides confidence that the package works across different environments and maintains high-quality documentation.\nWould you like me to expand on any particular aspect of this workflow?\nHere’s an additional section for the blog post with references:"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#further-reading-and-resources",
    "href": "posts/r_code_package_updating_p34/index.html#further-reading-and-resources",
    "title": "Update R package development process",
    "section": "2.9 Further Reading and Resources",
    "text": "2.9 Further Reading and Resources\n\n2.9.1 Git Fundamentals\n\nPro Git Book - The official and comprehensive guide to Git\nGit Handbook - GitHub’s introduction to Git basics\nOh Shit, Git!?! - Practical solutions for common Git mistakes\n\n\n\n2.9.2 R Package Development\n\nR Packages (2e) by Hadley Wickham and Jenny Bryan\nWriting R Extensions - The official R manual for package development\ndevtools documentation - Comprehensive guide to the devtools package\n\n\n\n2.9.3 GitHub Actions\n\nGitHub Actions for R - r-lib’s collection of GitHub Actions for R\nGitHub Actions Documentation - Official documentation\nGitHub Actions for R packages - Examples from the usethis package\n\n\n\n2.9.4 Testing in R\n\ntestthat documentation - The standard testing framework for R\nTesting R packages - Chapter from R Packages book\ncovr documentation - For understanding test coverage\n\n\n\n2.9.5 Package Documentation\n\nroxygen2 documentation - For writing package documentation\npkgdown documentation - For creating package websites\nDocumentation guide from the tidyverse style guide\n\n\n\n2.9.6 Interactive Learning\n\nGitHub Skills - Interactive courses for learning GitHub\nTry Git - Resources to learn Git\nGitHub Learning Lab - Interactive GitHub tutorials\n\nThese resources range from beginner-friendly introductions to detailed technical references, allowing readers to dive deeper into any aspect of the workflow that interests them.\nThe official and comprehensive guide to Git is available in the Pro Git Book Chacon and Straub (2014). GitHub provides an excellent introduction through their Git Handbook “Git Handbook” (2024). For practical solutions to common Git problems, the Oh Shit, Git!?! guide Sylor-Miller (2024) is invaluable.\nThe definitive guide is “R Packages (2e)” by Hadley Wickham and Jenny Bryan Wickham and Bryan (2023). The official manual for package development is “Writing R Extensions” Writing r Extensions (2024). For practical development tools, see the devtools documentation Wickham et al. (2024a).\nThe r-lib collection of GitHub Actions for R “GitHub Actions for r” (2024) provides essential tools. The official GitHub Actions documentation “GitHub Actions Documentation” (2024) offers comprehensive coverage. The usethis package provides practical examples “GitHub Actions for r Packages” (2024).\nThe standard testing framework is documented in testthat Wickham (2024a). For comprehensive coverage of testing, see the testing chapter in R Packages Wickham and Bryan (2023). Understanding test coverage is explained in the covr documentation Hester (2024).\nPackage documentation tools include roxygen2 Wickham et al. (2024c) and pkgdown Wickham et al. (2024b). The tidyverse style guide provides documentation standards Wickham (2024b).\nGitHub provides interactive learning through GitHub Skills “GitHub Skills” (2024) and GitHub Learning Lab “GitHub Learning Lab” (2024). The Try Git resources “Try Git” (2024) offer hands-on practice."
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#prerequisites",
    "href": "posts/r_code_package_updating_p34/index.html#prerequisites",
    "title": "Update R package development process",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#step-by-step-implementation",
    "href": "posts/r_code_package_updating_p34/index.html#step-by-step-implementation",
    "title": "Update R package development process",
    "section": "3.2 Step-by-Step Implementation",
    "text": "3.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#key-takeaways",
    "href": "posts/r_code_package_updating_p34/index.html#key-takeaways",
    "title": "Update R package development process",
    "section": "3.3 Key Takeaways",
    "text": "3.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/r_code_package_updating_p34/index.html#further-reading",
    "href": "posts/r_code_package_updating_p34/index.html#further-reading",
    "title": "Update R package development process",
    "section": "3.4 Further Reading",
    "text": "3.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/research_backup_system_p32/index.html",
    "href": "posts/research_backup_system_p32/index.html",
    "title": "Setting Up a Comprehensive Research Backup System on macOS",
    "section": "",
    "text": "Backup"
  },
  {
    "objectID": "posts/research_backup_system_p32/index.html#backup-strategy-overview",
    "href": "posts/research_backup_system_p32/index.html#backup-strategy-overview",
    "title": "Setting Up a Comprehensive Research Backup System on macOS",
    "section": "1.1 Backup Strategy Overview",
    "text": "1.1 Backup Strategy Overview\nOur approach uses three complementary layers:\n\nAutomated Git commits and pushes (every 15 minutes)\nCloud synchronization (real-time via Google Drive/Dropbox)\nTime Machine backups (hourly system-wide backups)\n\nThis ensures your research is protected against hardware failure, accidental deletion, Git corruption, and provides easy access across devices."
  },
  {
    "objectID": "posts/research_backup_system_p32/index.html#initial-time-machine-setup",
    "href": "posts/research_backup_system_p32/index.html#initial-time-machine-setup",
    "title": "Setting Up a Comprehensive Research Backup System on macOS",
    "section": "2.1 Initial Time Machine Setup",
    "text": "2.1 Initial Time Machine Setup\n\n2.1.1 Step 1: Connect Your USB Drive\n\nConnect your 1TB USB drive to your MacBook\nWhen prompted, do not use it for Time Machine yet - we’ll configure this properly first\n\n\n\n2.1.2 Step 2: Format the Drive (if needed)\n\nOpen Disk Utility (Applications &gt; Utilities &gt; Disk Utility)\nSelect your USB drive from the sidebar\nClick Erase\nChoose format: Mac OS Extended (Journaled) or APFS (recommended for newer Macs)\nName it something like “Research Backup”\nClick Erase\n\n\n\n2.1.3 Step 3: Configure Time Machine\n\nOpen System Preferences &gt; Time Machine\nClick Select Backup Disk\nChoose your USB drive\nClick Use Disk\nIf prompted about encryption, choose Encrypt Backup for security\n\n\n\n2.1.4 Step 4: Customize Time Machine Settings\n\nClick Options in Time Machine preferences\nAdd any folders you want to exclude (like Downloads, Trash, etc.)\nImportant: Do NOT exclude ~/prj - we want this backed up\nEnsure “Back up while on battery power” is enabled if desired\n\nTime Machine will now automatically backup your entire system (including ~/prj) every hour when the USB drive is connected."
  },
  {
    "objectID": "posts/research_backup_system_p32/index.html#minimal-version-of-backup-script",
    "href": "posts/research_backup_system_p32/index.html#minimal-version-of-backup-script",
    "title": "Setting Up a Comprehensive Research Backup System on macOS",
    "section": "3.1 Minimal version of backup script:",
    "text": "3.1 Minimal version of backup script:\n#!/opt/homebrew/bin/bash\n\nfind \"$HOME/prj\" -name \".git\" -type d | while read git_dir; do\n    cd \"$(dirname \"$git_dir\")\" || continue\n    [[ -n $(git status --porcelain) ]] || continue\n    git add -A\n    git commit -m \"Auto-backup: $(date '+%Y-%m-%d %H:%M:%S')\"\n    git push origin main 2&gt;/dev/null || git push origin master 2&gt;/dev/null\ndone"
  },
  {
    "objectID": "posts/research_backup_system_p32/index.html#create-the-full-script-file",
    "href": "posts/research_backup_system_p32/index.html#create-the-full-script-file",
    "title": "Setting Up a Comprehensive Research Backup System on macOS",
    "section": "3.2 Create the full Script File",
    "text": "3.2 Create the full Script File\nAdd these features:\n\n3.2.1 Command Line Interface Features\n\nVerbose mode flag (-v|--verbose)\nHelp flag (-h|--help)\nCommand line argument parsing (while loop with case statements)\nUsage instructions and help text\n\n\n\n3.2.2 Logging and Output Features\n\nLog file creation (~/Library/Logs/research_backup.log)\nLog rotation (when file exceeds 10MB)\nTimestamped log entries\nColor-coded console output (red/yellow/green/blue messages)\nLog message function with level-based formatting\nDetailed progress reporting (“Processing repository X”)\nFinal summary statistics\nVerbose console output option\n\n\n\n3.2.3 Error Handling and Validation\n\nDirectory existence checks (research directory validation)\nGit repository validation (checking if .git is actually a valid repo)\nRemote repository checks (verifying origin remote exists)\nBranch existence validation (checking if branch exists on remote)\nFile staging error handling (git add -A failure detection)\nCommit failure detection and reporting\nPush failure detection with specific error messages\nNetwork/authentication error distinction\n\n\n\n3.2.4 Repository Filtering\n\nUser association filtering (only “rgt47” repositories)\nArchive directory exclusion (skip directories with “archive”)\nBackup directory exclusion (skip directories with “backup”)\nCase-insensitive name matching\nPath-based exclusion checks\n\n\n\n3.2.5 Advanced Git Features\n\nCurrent branch detection (get_current_branch function)\nUpstream branch creation (–set-upstream for new branches)\nChange analysis (counting untracked/modified/added/deleted files)\nBranch existence verification on remote\nGraceful handling of detached HEAD states\nSmart branch pushing (handles both main and master)\n\n\n\n3.2.6 Counting and Statistics\n\nRepository counters (repo_count, backup_count, error_count, etc.)\nExcluded repository tracking\nSkipped repository tracking\nWarning count tracking\nDetailed final summary with all statistics\n\n\n\n3.2.7 Safety Features\n\nWorking directory validation (cd error handling)\nGit status checks before operations\nClean repository detection (skip repos with no changes)\nRace condition handling (checking for empty commits)\n\n\n\n3.2.8 Documentation and Maintenance\n\nExtensive inline comments\nFunction documentation\nUsage examples\nError message explanations\nTroubleshooting information\n\n\n\n3.2.9 Configuration Features\n\nConfigurable research directory path\nConfigurable log file location\nConfigurable log size limits\nEnvironment variable handling"
  },
  {
    "objectID": "posts/research_backup_system_p32/index.html#setting-up-the-cron-job",
    "href": "posts/research_backup_system_p32/index.html#setting-up-the-cron-job",
    "title": "Setting Up a Comprehensive Research Backup System on macOS",
    "section": "4.1 Setting Up the Cron Job",
    "text": "4.1 Setting Up the Cron Job\n\n4.1.1 Step 1: Open the Crontab Editor\ncrontab -e\n\n\n4.1.2 Step 2: Add the Cron Entry\nAdd this line to your crontab:\n# Research backup - runs every 15 minutes\n*/15 * * * * /Users/$(whoami)/scripts/backup-research.sh\n\n\n4.1.3 Step 3: Save and Exit\n\nIf using nano: Ctrl + X, then Y, then Enter\nIf using vim: Esc, then :wq, then Enter\n\n\n\n4.1.4 Step 4: Verify the Cron Job\ncrontab -l\n\n\n4.1.5 Step 5: Test the Setup\nWait 15 minutes, then check if it ran:\ntail -20 ~/Library/Logs/research_backup.log"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html",
    "href": "posts/setup_R_vimtex/index.html",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "",
    "text": "vim setup"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html#yaml-header",
    "href": "posts/setup_R_vimtex/index.html#yaml-header",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "8.1 YAML header",
    "text": "8.1 YAML header\nThe RMD file contains a YAML metadata header delineated with the lines “—” above and below. For this example we want to generate a pdf formatted output file.\nThe YAML can be as simple as one line specifying the output as pdf.\n---\noutput: pdf_document\n---\nWhich results in a simple output file as follows:\nNB. to invoke file completion in vim for the rmd (or quarto) change the vim filetype using the command:\n:set filetype=tex\nthen enter, e.g., \\includegraphics{ or \\input{ followed by C-x C-o. and a pop-up menu with possible completions with appear.\n\n---\ntitle: \"Penguins data analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r Sys.Date()`\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\nheader-includes:\n    - \\usepackage{lipsum, fancyhdr, titling, currfile}\n    - \\usepackage[export]{adjustbox}\n    - \\pagestyle{fancy}\n    - \\pretitle{\n    - \\begin{flushright} \\includegraphics[width=3cm,valign=c]{sudoku.pdf}\n    - \\end{flushright}\n    - \\noindent\\rule{\\linewidth}{2pt}\\begin{flushleft}\\LARGE}\n    - \\posttitle{\\end{flushleft}\\noindent\\rule{\\linewidth}{2pt}}\n---"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html#prerequisites",
    "href": "posts/setup_R_vimtex/index.html#prerequisites",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "11.1 Prerequisites",
    "text": "11.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html#step-by-step-implementation",
    "href": "posts/setup_R_vimtex/index.html#step-by-step-implementation",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "11.2 Step-by-Step Implementation",
    "text": "11.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html#key-takeaways",
    "href": "posts/setup_R_vimtex/index.html#key-takeaways",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "11.3 Key Takeaways",
    "text": "11.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html#further-reading",
    "href": "posts/setup_R_vimtex/index.html#further-reading",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "11.4 Further Reading",
    "text": "11.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/setup_yabai/index.html",
    "href": "posts/setup_yabai/index.html",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "posts/setup_yabai/index.html#prerequisites",
    "href": "posts/setup_yabai/index.html#prerequisites",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setup_yabai/index.html#step-by-step-implementation",
    "href": "posts/setup_yabai/index.html#step-by-step-implementation",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "3.2 Step-by-Step Implementation",
    "text": "3.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setup_yabai/index.html#key-takeaways",
    "href": "posts/setup_yabai/index.html#key-takeaways",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "3.3 Key Takeaways",
    "text": "3.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setup_yabai/index.html#further-reading",
    "href": "posts/setup_yabai/index.html#further-reading",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "3.4 Further Reading",
    "text": "3.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "",
    "text": "chatGPT"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#section",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#section",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.1 ",
    "text": "1.1 \nchatGPT Prompts:\n“I want to use the Palmer Penguin dataset to create a Shiny app for data exploration.”\n“Update shiny app. Add a dropdown menu to select categorical variables, sex, species or island. Also add a dropdown menu to select continuouse variables Use selected categorical variable as a grouping variable in side-by-side boxplots of selected continuouse variables.”\n“add a second interactive plot to app.R code to provide scatterplots of 2 selected continuous variables. The two cont. vars are selected from drop down menus.”"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#r-code-to-launch.",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#r-code-to-launch.",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.2 R code to launch.",
    "text": "1.2 R code to launch.\nFrom inside R.\n    shiny::runApp(\"app.R\", launch.browser = TRUE)\nFrom shell.\n    R -e \"shiny::runApp('app.R', launch.browser=T)\"\nlibrary(shiny)\nlibrary(bslib)\nlibrary(bsicons)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\nlibrary(corrgram)\nlibrary(dplyr)\n\n# Load the dataset\ndata &lt;- na.omit(penguins) # Remove rows with NA for simplicity\n\n# Helper function for tooltip\nadd_tooltip &lt;- function(input_ui, tooltip_text) {\n  input_ui$children[[1]] &lt;- div(\n    input_ui$children[[1]], # Original label\n    span(\n      bs_icon(\"info-circle-fill\"),\n      class = \"tooltip-icon ms-2\",\n      `data-bs-toggle` = \"tooltip\",\n      `data-bs-placement` = \"right\",\n      title = tooltip_text\n    ),\n    style = \"display: flex; align-items: center;\"\n  )\n  input_ui\n}\n\n# Module for inputs\ninputsUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  tagList(\n    h4(\"Boxplot Controls\"),\n    add_tooltip(\n      selectInput(\n        ns(\"xvar\"),\n        \"Continuous Variable for Boxplot:\",\n        choices = names(data)[3:6]\n      ),\n      \"Select a continuous variable to display on the Y-axis of the boxplot.\"\n    ),\n    add_tooltip(\n      selectInput(\n        ns(\"groupvar\"),\n        \"Group by (Categorical Variable):\",\n        choices = c(\"species\", \"sex\", \"island\"),\n        selected = \"species\"\n      ),\n      \"Select a categorical variable to group data in the boxplot.\"\n    ),\n    hr(),\n    h4(\"Scatterplot Controls\"),\n    add_tooltip(\n      selectInput(\n        ns(\"scatter_x\"),\n        \"X-axis for Scatterplot:\",\n        choices = names(data)[3:6]\n      ),\n      \"Select a variable for the X-axis of the scatterplot.\"\n    ),\n    add_tooltip(\n      selectInput(\n        ns(\"scatter_y\"),\n        \"Y-axis for Scatterplot:\",\n        choices = names(data)[3:6]\n      ),\n      \"Select a variable for the Y-axis of the scatterplot.\"\n    ),\n    add_tooltip(\n      selectInput(\n        ns(\"groupvar_scatter\"),\n        \"Group by (Scatterplot):\",\n        choices = c(\"species\", \"sex\", \"island\"),\n        selected = \"species\"\n      ),\n      \"Select a variable to group points in the scatterplot by color.\"\n    )\n  )\n}\n\ninputsServer &lt;- function(id) {\n  moduleServer(id, function(input, output, session) {\n    reactive(input)\n  })\n}\n\n# Module for boxplot\nboxplotUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  plotOutput(ns(\"boxPlot\"), height = \"400px\")\n}\n\nboxplotServer &lt;- function(id, data, inputs) {\n  moduleServer(id, function(input, output, session) {\n    output$boxPlot &lt;- renderPlot({\n      req(data(), inputs())\n      ggplot(\n        data(),\n        aes(\n          x = .data[[inputs()$groupvar]],\n          y = .data[[inputs()$xvar]],\n          fill = .data[[inputs()$groupvar]]\n        )\n      ) +\n        geom_boxplot(alpha = 0.7) +\n        theme_minimal() +\n        labs(\n          x = inputs()$groupvar,\n          y = inputs()$xvar,\n          fill = inputs()$groupvar\n        ) +\n        theme(legend.position = \"bottom\")\n    })\n  })\n}\n\n# Module for scatterplot\nscatterplotUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  plotOutput(ns(\"scatterPlot\"), height = \"400px\")\n}\n\nscatterplotServer &lt;- function(id, data, inputs) {\n  moduleServer(id, function(input, output, session) {\n    output$scatterPlot &lt;- renderPlot({\n      req(data(), inputs())\n      ggplot(\n        data(),\n        aes(\n          x = .data[[inputs()$scatter_x]],\n          y = .data[[inputs()$scatter_y]],\n          color = .data[[inputs()$groupvar_scatter]]\n        )\n      ) +\n        geom_point(alpha = 0.7, size = 2) +\n        geom_smooth(\n          method = \"lm\",\n          se = FALSE,\n          aes(group = 1),\n          color = \"black\",\n          linetype = \"dashed\"\n        ) +\n        geom_smooth(method = \"lm\", se = FALSE) +\n        theme_minimal() +\n        labs(\n          x = inputs()$scatter_x,\n          y = inputs()$scatter_y,\n          color = inputs()$groupvar_scatter\n        ) +\n        theme(legend.position = \"bottom\")\n    })\n  })\n}\n\n# Module for correlation matrix\ncorrelationUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  plotOutput(ns(\"correlationMatrix\"), height = \"400px\")\n}\n\ncorrelationServer &lt;- function(id, data) {\n  moduleServer(id, function(input, output, session) {\n    output$correlationMatrix &lt;- renderPlot({\n      req(data())\n      numericData &lt;- data()[, sapply(data(), is.numeric)]\n      corrgram(\n        numericData,\n        order = TRUE,\n        lower.panel = panel.shade,\n        upper.panel = panel.pie,\n        text.panel = panel.txt,\n        main = \"Correlation Matrix\"\n      )\n    })\n  })\n}\n\n# Main UI and server\nui &lt;- fluidPage(\n  theme = bs_theme(bootswatch = \"litera\"), # Use a bslib theme\n  titlePanel(\"Palmer Penguins Explorer\"),\n  fluidRow(\n    column(3, inputsUI(\"inputs\"), \n       style = \"overflow-y: auto; max-height: 600px;\"),\n    column(\n      6,\n      fluidRow(\n        column(12, h4(\"Boxplot\"), boxplotUI(\"boxplot\"), style = \"height: 50%;\"),\n        column(12, h4(\"Scatterplot\"), scatterplotUI(\"scatterplot\"), \n           style = \"height: 50%;\")\n      ),\n      style = \"overflow-y: auto;\"\n    ),\n    column(3, h4(\"Correlation Matrix\"), correlationUI(\"correlation\"))\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  # Reactive dataset\n  filteredData &lt;- reactive({\n    data\n  })\n  \n  # Call modules\n  inputs &lt;- inputsServer(\"inputs\")\n  boxplotServer(\"boxplot\", filteredData, inputs)\n  scatterplotServer(\"scatterplot\", filteredData, inputs)\n  correlationServer(\"correlation\", filteredData)\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#prerequisites",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#prerequisites",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.3 Prerequisites",
    "text": "1.3 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#step-by-step-implementation",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#step-by-step-implementation",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.4 Step-by-Step Implementation",
    "text": "1.4 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#key-takeaways",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#key-takeaways",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.5 Key Takeaways",
    "text": "1.5 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#further-reading",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#further-reading",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.6 Further Reading",
    "text": "1.6 Further Reading\nIn development"
  },
  {
    "objectID": "posts/ultisnips_python_post/index.html#introduction",
    "href": "posts/ultisnips_python_post/index.html#introduction",
    "title": "Add python code as an ultisnip snippet",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nIn development"
  },
  {
    "objectID": "posts/ultisnips_python_post/index.html#prerequisites",
    "href": "posts/ultisnips_python_post/index.html#prerequisites",
    "title": "Add python code as an ultisnip snippet",
    "section": "1.2 Prerequisites",
    "text": "1.2 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/ultisnips_python_post/index.html#step-by-step-implementation",
    "href": "posts/ultisnips_python_post/index.html#step-by-step-implementation",
    "title": "Add python code as an ultisnip snippet",
    "section": "1.3 Step-by-Step Implementation",
    "text": "1.3 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/ultisnips_python_post/index.html#key-takeaways",
    "href": "posts/ultisnips_python_post/index.html#key-takeaways",
    "title": "Add python code as an ultisnip snippet",
    "section": "1.4 Key Takeaways",
    "text": "1.4 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/ultisnips_python_post/index.html#further-reading",
    "href": "posts/ultisnips_python_post/index.html#further-reading",
    "title": "Add python code as an ultisnip snippet",
    "section": "1.5 Further Reading",
    "text": "1.5 Further Reading\nIn development"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html",
    "href": "references/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-importexport",
    "href": "references/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#statistical-functions",
    "href": "references/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#string-operations",
    "href": "references/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#package-management",
    "href": "references/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#workspace-management",
    "href": "references/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-types-structure",
    "href": "references/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#missing-values",
    "href": "references/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#quick-tips",
    "href": "references/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "research/r-package-development-basics.html",
    "href": "research/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#learning-objectives",
    "href": "research/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#prerequisites",
    "href": "research/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-2-create-package-structure",
    "href": "research/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-4-generate-documentation",
    "href": "research/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-5-testing",
    "href": "research/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-6-package-checks",
    "href": "research/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "research/r-package-development-basics.html#next-steps",
    "href": "research/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "research/r-package-development-basics.html#resources",
    "href": "research/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html",
    "href": "teaching/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-importexport",
    "href": "teaching/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "href": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#string-operations",
    "href": "teaching/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#package-management",
    "href": "teaching/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#workspace-management",
    "href": "teaching/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "href": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#missing-values",
    "href": "teaching/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#quick-tips",
    "href": "teaching/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Comprehensive tutorials designed to teach you new skills from the ground up. These evergreen resources are regularly updated and expanded with new content.\nEach tutorial includes: - Clear learning objectives - Step-by-step instructions - Working examples - Practice exercises - Troubleshooting tips\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nR Package Development: From Idea to CRAN\n\n\nComplete tutorial for creating your first R package\n\n\n\nR\n\n\npackages\n\n\ndevelopment\n\n\ntutorial\n\n\n\nStep-by-step guide to developing, documenting, and submitting an R package to CRAN.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurely Deploying Your Shiny App Online: A Step-by-Step Guide\n\n\n\nDeployment & Operations\n\n\n\nA practical guide for data scientists on how to deploy R Shiny applications securely using open-source technologies.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up git for (solo) data science workflow\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "white-papers/index.html",
    "href": "white-papers/index.html",
    "title": "White Papers",
    "section": "",
    "text": "A comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\n🔗 Full Report • 📄 PDF\n\n\n\n\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#research-methodology-workflows",
    "href": "white-papers/index.html#research-methodology-workflows",
    "title": "White Papers",
    "section": "",
    "text": "A comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\n🔗 Full Report • 📄 PDF\n\n\n\n\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#statistical-computing-development",
    "href": "white-papers/index.html#statistical-computing-development",
    "title": "White Papers",
    "section": "2 Statistical Computing & Development",
    "text": "2 Statistical Computing & Development\n\n2.1 RCT Validation Language\nSpecification for a domain-specific programming language designed to capture clinical trial database validation logic, with compilation targets for Lua and JavaScript.\nClinical trials Programming languages Data validation DSL design\n\n🔗 Full Report • 📄 PDF\n\n\n\n2.2 Setting up an R Development Environment on GitHub\nBest practices and step-by-step methodology for establishing reproducible R package development workflows using GitHub integration and continuous integration.\nR development GitHub Package development CI/CD\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#data-science-applications",
    "href": "white-papers/index.html#data-science-applications",
    "title": "White Papers",
    "section": "3 Data Science Applications",
    "text": "3 Data Science Applications\n\n3.1 Making Optimal Use of ChatGPT and Other Chatbots for Data Science\nEvaluation framework and practical guidelines for integrating large language models into data science workflows, including prompt engineering and quality assessment.\nAI tools Data science LLM integration Prompt engineering\n\n🔗 Full Report • 📄 PDF\n\n\n\n3.2 Minimalist EDC Application Framework\nTechnical architecture for building lightweight electronic data capture systems for clinical research, emphasizing simplicity and regulatory compliance.\nEDC systems Clinical research Software architecture Regulatory compliance\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#technical-infrastructure",
    "href": "white-papers/index.html#technical-infrastructure",
    "title": "White Papers",
    "section": "4 Technical Infrastructure",
    "text": "4 Technical Infrastructure\n\n4.1 Containerized R Analysis Workflows with Docker\nImplementation guide for reproducible R analysis environments using Docker containerization, including best practices for sharing and deployment.\nDocker Reproducibility R environment Containerization\n\n🔗 Full Report • 📄 PDF\n\n\n\n4.2 AWS Server Configuration for Research Computing\nComprehensive guide for setting up and configuring AWS instances for statistical computing and research data analysis.\nAWS Cloud computing Server configuration Research computing\n\n🔗 Full Report • 📄 PDF\n\n\nThese white papers represent in-depth technical analyses, methodological frameworks, and implementation guides developed for research and statistical computing applications. Each document provides detailed specifications, best practices, and reproducible workflows."
  },
  {
    "objectID": "posts/extend_shiny_app/index.html",
    "href": "posts/extend_shiny_app/index.html",
    "title": "Extend Shiny power app to five tabs",
    "section": "",
    "text": "Shiny"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#modules",
    "href": "posts/extend_shiny_app/index.html#modules",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.1 Modules",
    "text": "2.1 Modules"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#golem",
    "href": "posts/extend_shiny_app/index.html#golem",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.2 Golem",
    "text": "2.2 Golem"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#package",
    "href": "posts/extend_shiny_app/index.html#package",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.3 Package",
    "text": "2.3 Package"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#prerequisites",
    "href": "posts/extend_shiny_app/index.html#prerequisites",
    "title": "Extend Shiny power app to five tabs",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#step-by-step-implementation",
    "href": "posts/extend_shiny_app/index.html#step-by-step-implementation",
    "title": "Extend Shiny power app to five tabs",
    "section": "3.2 Step-by-Step Implementation",
    "text": "3.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#key-takeaways",
    "href": "posts/extend_shiny_app/index.html#key-takeaways",
    "title": "Extend Shiny power app to five tabs",
    "section": "3.3 Key Takeaways",
    "text": "3.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#further-reading",
    "href": "posts/extend_shiny_app/index.html#further-reading",
    "title": "Extend Shiny power app to five tabs",
    "section": "3.4 Further Reading",
    "text": "3.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html#install-mint-on-a-macbook-air",
    "href": "posts/install_mint_on_macbook/index.html#install-mint-on-a-macbook-air",
    "title": "Install Linux Mint on a Macbook Air",
    "section": "1.1 Install Mint on a macbook air",
    "text": "1.1 Install Mint on a macbook air\nThe target machine is a 2016 13-inch MacBook Air with four Thunderbolt 3 Ports.\nTo start the process download an iso file from the Mint website. The current “Virginia” version of Mint iso file is 3.07 GB in size. The “Cinnamon” edition is recommended.\nSpecifically, download the torrent file for Linux Mint 22 Wilma Cinnamon edition. linuxmint-22-cinnamon-64bit.iso.torrent Install the mac app Transmission and add the torrent file.\nAlso download the associated sha256sum.txt file.\nTo check the integrity of your local ISO file, generate its SHA256 checksum and compare it to the content of the sha256sum.txt file:\n&gt; sha256sum -b linuxmint-22-cinnamon-64bit.iso\nWe can transfer the iso file to a USB flash drive using one of several methods. On macos we suggest using the app balanaEtcher. You can download balanaEtcher\nInsert the bootable USB flash drive into the target macbook and reboot. Hold the ALT key while the machine reboots and you’ll be presented with a screen offering boot drive options. Select the icon for the USB drive. A grub menu will appear.1\n1  GNU GRand Unified Bootloader (GRUB). “When your Linux operating system starts up, GRUB is the first program that runs. It loads the kernel of the operating system, and then the kernel loads the rest of the operating system, including the shell, the desktop environment, and other operating system features.”  codecademy.com  From the Grub menu choose Start Linux Mint 22 Cinnamon 64-bit. and the Mint install program will start.\nA linux mint desktop will appear allowing you to “test drive” Mint or to continue the install by double clicking the icon labeled install Linux Mint.\nA setup dialog will start. Select, in sequence\n\nLanguage (English for us),\nNetwork (If ethernet is available startup program will autmatically connect. If wifi only, not needed at this point, suggest skip),\ncodexes (check box “install multimedia codecs”),\noptions for installation type (choose “erase disk and install linux mint”).\nLocation (Los Angeles for us),\nname a user who will have administrator privileges, assign a password, and a hostname.\n\nAfter these screens the install process will proceed without additional user input.\nWhen complete connect the target machine to the Internet. As mentioned above, if you have ethernet connectivity plug the cable directly into the target macbook and Mint should connect automatically to the internet. For wireless wifi access Mint may or may not recognize hardware modem. If not use a supported external modem e.g. Panda Wireless modem. Panda is supported since Mint 22 has Ralink RT5372 drivers installed.\nThe final hardware related step is to add a second monitor, if available, via HDMI or “USB-C”.\nThats it. The base system is ready to go. Reboot and login with the admin username and password you provided earlier."
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html#prerequisites",
    "href": "posts/install_mint_on_macbook/index.html#prerequisites",
    "title": "Install Linux Mint on a Macbook Air",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html#step-by-step-implementation",
    "href": "posts/install_mint_on_macbook/index.html#step-by-step-implementation",
    "title": "Install Linux Mint on a Macbook Air",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html#key-takeaways",
    "href": "posts/install_mint_on_macbook/index.html#key-takeaways",
    "title": "Install Linux Mint on a Macbook Air",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html#further-reading",
    "href": "posts/install_mint_on_macbook/index.html#further-reading",
    "title": "Install Linux Mint on a Macbook Air",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html#polish-the-interface",
    "href": "posts/minimalist_edc_app/index.html#polish-the-interface",
    "title": "Minimal EDC in Shiny",
    "section": "2.1 Polish the interface",
    "text": "2.1 Polish the interface\nStart with the online/CRC book “Outstanding User interfaces with Shiny” Granjon (2022)"
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html#prerequisites",
    "href": "posts/minimalist_edc_app/index.html#prerequisites",
    "title": "Minimal EDC in Shiny",
    "section": "5.1 Prerequisites",
    "text": "5.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html#step-by-step-implementation",
    "href": "posts/minimalist_edc_app/index.html#step-by-step-implementation",
    "title": "Minimal EDC in Shiny",
    "section": "5.2 Step-by-Step Implementation",
    "text": "5.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html#key-takeaways",
    "href": "posts/minimalist_edc_app/index.html#key-takeaways",
    "title": "Minimal EDC in Shiny",
    "section": "5.3 Key Takeaways",
    "text": "5.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html#further-reading",
    "href": "posts/minimalist_edc_app/index.html#further-reading",
    "title": "Minimal EDC in Shiny",
    "section": "5.4 Further Reading",
    "text": "5.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html",
    "href": "posts/server_setup_aws_console/index.html",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#select-a-hosting-service",
    "href": "posts/server_setup_aws_console/index.html#select-a-hosting-service",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "2.1 Select a hosting service",
    "text": "2.1 Select a hosting service\nThere are a number of cloud based server hosting options to choose from: for example Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean or Hetzner to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll provide a step-by-step description of a process using Amazon Web Services Elastic Compute Cloud (AWS EC2) infrastructure.\nAWS is, in our view, a reasonable choice for setting up a small custom server. Its not the cheapest option, but the system is well documented and, in our experience, reliable.\nThe first step is to get set up with AWS. To start, open the EC2 console by visiting the URL:\n   https://aws.amazon.com/console\n(see margin figure)\nIn the console window choose regional service. For us its “N. California”.\n\n\n\n\n\nAWS console\n\n\nNext create an account, or sign in. Once you’re logged in navigate to the EC2 dashboard. Its through this dashboard (aka console) that we’ll define the parameters for the type of server to launch and the mechanisms for communicating with it. We’ll refer to these as “Pre-Launch” tasks."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#overview",
    "href": "posts/server_setup_aws_console/index.html#overview",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nAlong with selecting a server we need to set up a working environment. We recommend setting up the working environment before launching the server, as it saves some back and forth with the console, but doing so is not required. The working environment consists of four main components:\n\nA security credential (RSA key-pair) to allow remote and secure login to the virtual server once its launched.\nA firewall, or security model, which restricts incoming server access. The purpose of the firewall is to close ofe all incoming packet traffic except through those ports specifically named.\nA static IP address, say 111.222.333.444. A static IP is required for maintaining the link between the domain name and the server when rebooting. (The default is for the instance/server to be assigned a new IP address each time its rebooted).\nA domain name, say rgtlab.org. A domain name is not required but will facilitate collaborator access by not requiring the use of the IP address directly.\n\nThese working environment components are not directly tied to any specific server. In fact, you can define multiple instances of each component. The only requirement is that you pick one of each to associate with each server."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#work-environment-details.",
    "href": "posts/server_setup_aws_console/index.html#work-environment-details.",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "3.2 Work Environment Details.",
    "text": "3.2 Work Environment Details.\n\n3.2.1 Ssh key pair\nIn order to securely communicate with the server we need to exchange an RSA key pair with AWS. The pair consists of a private key and a public key. We can define a key pair in one of two ways in EC2. Either, generate the pair locally, on our workstation and upload the public key to EC2, or have EC2 generate the key pair and download the private key. The EC2 based generation process will place the public key in the ~/.ssh/authorized_keys file on the server.\nFor the first option (local generation) we create a directory on our workstation to hold the keys and navigate to it, e.g. ~/.ssh. In the ~/.ssh directory generate the keys with the command\n&gt; ssh-keygen -m PEM\nPEM defines the key format. More information on public key authentication can be found (here). Also detailed instructions are available on AWS (here)\nIn the interactive dialog that follows name the key prefix something like power1_app.pem. The dialog will ask for a passphrase. You can enter a phrase for an additional level of security, but its not required. The ssh-keygen program will generate two files: power1_app.pem and power1_app.pem.pub\nTo complete the process return to the EC2 dashboard and select Network & Security/Keypair/Actions and then Import key pair in the left panel. Enter the name power1_app and select the Browse button. Navigate to the ~/.ssh/power1_app.pem.pub file and and select the Import key pair button at the bottom of the page.\nFor the second approach (EC2 generated) select Create key pair button in the upper right of the console page. A form will appears and ask for a name. Enter something like power1_app. Select RSA for key pair type and .pem for key file format. The keys will be created and the private key power1_app.pem will be offered for download to the local machine. We suggest placing it in the ~/.ssh directory. Lastly, change the permissions for the private key, so only you can access with the following command:\n&gt; sudo chmod 400 power1_app.pem\n\n\n3.2.2 Firewall\nTo create a firewall, click on Security groups under Network & Security settings in the left hand panel. Choose Create security group, and name the security group something like power1_app.\nUnder Inbound Rules select SSH and HTTPS from the Type dropdown menu. Select Anywhere IPv4 0.0.0.0/0 for both (??).\nThis will create a firewall that leaves open only ports 22 and 443, for ssh and https incoming traffic, respectively.\n\n\n3.2.3 Static IP address\nYou can use the EC2 elastic IP service to get a static IP. Navigate to Network and Security again and select Allocate Elastic IP. An IP will be assigned from the EC2 pool of available IPv4 IP addresses e.g. 13.57.139.31.\n\n\n3.2.4 Domain Name\nTo obtain a dedicated domain name, leave the EC2 dashboard and go to Amazon route 53 dashboard to select a domain name and associate it with our static IP (select Service at the top of the dashboard and search for Route 53).\nOnce a domain name is acquired, e.g. rgtlab.org, you can associate it with any IP address, static or dynamic. This can be done via the Route 53 service. For example, to associate domain name rgtlab.org with the elastic IP 111.2222.333.444 do the following in Route 53:\n\nclick on hosted zones in the side panel\nclick on rgtlab.org in center panel\nclick on checkbox for rgtlab.org type=A line\nthen click on edit record in right panel\nchange IP address to the assigned static 111.222.333.444 in “value”."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#access-server",
    "href": "posts/server_setup_aws_console/index.html#access-server",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "4.1 Access server",
    "text": "4.1 Access server\nOn your laptop log into server with\nssh -i \"~/.ssh/power1_app\" ubuntu@rgtlab.org"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#prerequisites",
    "href": "posts/server_setup_aws_console/index.html#prerequisites",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "6.1 Prerequisites",
    "text": "6.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#step-by-step-implementation",
    "href": "posts/server_setup_aws_console/index.html#step-by-step-implementation",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "6.2 Step-by-Step Implementation",
    "text": "6.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#key-takeaways",
    "href": "posts/server_setup_aws_console/index.html#key-takeaways",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "6.3 Key Takeaways",
    "text": "6.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#further-reading",
    "href": "posts/server_setup_aws_console/index.html#further-reading",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "6.4 Further Reading",
    "text": "6.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/setupneovim/index.html",
    "href": "posts/setupneovim/index.html",
    "title": "Setting up a neovim environment for data science code development",
    "section": "",
    "text": "under construction"
  },
  {
    "objectID": "posts/setupneovim/index.html#prerequisites",
    "href": "posts/setupneovim/index.html#prerequisites",
    "title": "Setting up a neovim environment for data science code development",
    "section": "8.1 Prerequisites",
    "text": "8.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setupneovim/index.html#step-by-step-implementation",
    "href": "posts/setupneovim/index.html#step-by-step-implementation",
    "title": "Setting up a neovim environment for data science code development",
    "section": "8.2 Step-by-Step Implementation",
    "text": "8.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setupneovim/index.html#key-takeaways",
    "href": "posts/setupneovim/index.html#key-takeaways",
    "title": "Setting up a neovim environment for data science code development",
    "section": "8.3 Key Takeaways",
    "text": "8.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setupneovim/index.html#further-reading",
    "href": "posts/setupneovim/index.html#further-reading",
    "title": "Setting up a neovim environment for data science code development",
    "section": "8.4 Further Reading",
    "text": "8.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/share_shiny_code_via_docker/index.html#prerequisites",
    "href": "posts/share_shiny_code_via_docker/index.html#prerequisites",
    "title": "Simple process for sharing R code via Docker",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/share_shiny_code_via_docker/index.html#step-by-step-implementation",
    "href": "posts/share_shiny_code_via_docker/index.html#step-by-step-implementation",
    "title": "Simple process for sharing R code via Docker",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/share_shiny_code_via_docker/index.html#key-takeaways",
    "href": "posts/share_shiny_code_via_docker/index.html#key-takeaways",
    "title": "Simple process for sharing R code via Docker",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/share_shiny_code_via_docker/index.html#further-reading",
    "href": "posts/share_shiny_code_via_docker/index.html#further-reading",
    "title": "Simple process for sharing R code via Docker",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "test_minimal.html",
    "href": "test_minimal.html",
    "title": "Test Document",
    "section": "",
    "text": "This is a test document.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "test_minimal.html#test",
    "href": "test_minimal.html#test",
    "title": "Test Document",
    "section": "",
    "text": "This is a test document.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "blog/coding-with-genai/index.html",
    "href": "blog/coding-with-genai/index.html",
    "title": "Coding with Generative AI",
    "section": "",
    "text": "View this post in multiple formats:\n\n\n\n  HTML    PDF    Word"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#prerequisites",
    "href": "blog/coding-with-genai/index.html#prerequisites",
    "title": "Coding with Generative AI",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "href": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "title": "Coding with Generative AI",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#key-takeaways",
    "href": "blog/coding-with-genai/index.html#key-takeaways",
    "title": "Coding with Generative AI",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#further-reading",
    "href": "blog/coding-with-genai/index.html#further-reading",
    "title": "Coding with Generative AI",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/simpleS3/index.html",
    "href": "posts/simpleS3/index.html",
    "title": "Writing a Simple R Package in S3",
    "section": "",
    "text": "S3 OOP in R"
  },
  {
    "objectID": "posts/simpleS3/index.html#prerequisites",
    "href": "posts/simpleS3/index.html#prerequisites",
    "title": "Writing a Simple R Package in S3",
    "section": "2.1 Prerequisites",
    "text": "2.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/simpleS3/index.html#step-by-step-implementation",
    "href": "posts/simpleS3/index.html#step-by-step-implementation",
    "title": "Writing a Simple R Package in S3",
    "section": "2.2 Step-by-Step Implementation",
    "text": "2.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/simpleS3/index.html#key-takeaways",
    "href": "posts/simpleS3/index.html#key-takeaways",
    "title": "Writing a Simple R Package in S3",
    "section": "2.3 Key Takeaways",
    "text": "2.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/simpleS3/index.html#further-reading",
    "href": "posts/simpleS3/index.html#further-reading",
    "title": "Writing a Simple R Package in S3",
    "section": "2.4 Further Reading",
    "text": "2.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/develop_r_package/index.html",
    "href": "posts/develop_r_package/index.html",
    "title": "Setting up an R development environment on github",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/develop_r_package/index.html#introduction",
    "href": "posts/develop_r_package/index.html#introduction",
    "title": "Setting up an R development environment on github",
    "section": "0.1 Introduction",
    "text": "0.1 Introduction\nIts often the case that a data scientist needs to share an R function with a co-worker or a student. This post describes a step by step methodology for wrapping the function in a package, that includes a number of support files, and sharing it either via github or CRAN. This may seem like overkill for the simple task of sharing some code, but over time, not having to address the many technical issues that can arise when sharing a code in a more ad hoc manner will undoubtedly be appreciated."
  },
  {
    "objectID": "posts/develop_r_package/index.html#the-problemdata",
    "href": "posts/develop_r_package/index.html#the-problemdata",
    "title": "Setting up an R development environment on github",
    "section": "0.2 The Problem/Data",
    "text": "0.2 The Problem/Data\nThe initial goal is to create a directory (or repository) that contains the package contents on your local computer. The top level elements of the package are the DESCRIPTION file, the NAMESPACE file, the R directory, the tests directory, and the man directory. Additional files such as a README.md, a LICENSE file are optional but recommended. The DESCRIPTION file contains metadata about the package such as the package name, the version number, the author, and the license. The NAMESPACE file contains the export and import declarations. The R directory contains the R functions. The tests directory contains the unit tests. The man directory contains the documentation for the functions.\n\n0.2.1 Step 1: Initial Repo Setup\nStart by using the various helpful tools in the devtools and usethis packages to facilitate the repository building process.\nOpen R from the shell prompt in your development directory. and run the command usethis::create_package(\"zz_package\") to create the package directory, an R subdirectory, and the DESCRIPTION and NAMESPACE files. Assuming the package will be named zz_package.\nThe code below creates the package directory structure.\ninstall.packages(\"devtools\")\nlibrary(devtools)\nusethis::create_package(\"zz_package\")\nThis creates the following directory structure and generates the DESCRIPTION and NAMESPACE files.\nzz_package ☕ tree --charset=ascii\n.\n|-- DESCRIPTION\n|-- NAMESPACE\n`-- R\n\nzz_package ☕ more DESCRIPTION\nPackage: my_package\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.0.0.9000\nAuthors@R:\n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"),\n           comment = c(ORCID = \"YOUR-ORCID-ID\"))\nDescription: What the package does (one paragraph).\nLicense: `use_mit_license()`, `use_gpl3_license()` or friends to pick a\n    license\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.3.2\nNext use the usethis package tools to generate repository support files.\nusethis::use_git()\nusethis::use_github()\nuse_gpl_license(version = 3, include_future = TRUE)\nusethis::use_readme_md()\nusethis::use_code_of_conduct(\"rgthomas@ucsd.edu\")\nusethis::use_tidy_contributing()\nNext copy the R file containing the function to the R directory and add a #' Roxygen2 comment block to the top of the file providing a description of the functions in the file.\nThen call devtools::document() to generate the man directory containing the help page.\ndevtools::document()\nAt this point the directory structure looks like this.\njulia prj/zz_package ☕ tree --charset=ascii\n.\n|-- DESCRIPTION   # package Metadata\n|-- NAMESPACE     # Exports and imports declarations\n|-- R             # R functions\n|   `-- zz_package.R\n|-- man           # Documentation for the functions\n    `-- zz_package.Rd\nThe next step is to set up testing.\nusethis::use_testthat()\ncall inside R\nusethis::use_test(\"zz_package\")\nThis open an editor. Enter the unit tests using the test_that function.\n# Test: Empty dataframe error\ntest_that(\"t2f throws an error for empty dataframe\", {\n  empty_df &lt;- data.frame()\n  expect_error(my_package(empty_df, filename = \"empty_table\"), \"`df` must not be empty\")\n})\nInitate a git repository, add the files, and do an initial commit. When any of files change repeat the commit process to commit the changes.\ngit init\ngit add .\ngit commit -m \"Initial commit\"\nOnce all the pieces are in place in the local repository push the content to the cloud. First step is to set up a new repository on github.\nAs the code is developed and additional packages are required add each dependency (e.g. kableExtra) (e.g. kableExtra) (e.g. kableExtra) whth the use_package function. For example if the kableExtra package is required to generate a formatted table add\nusethis::use_package(\"kableExtra\", type = \"Imports\")\nAt interim stages run the build, install, and test functions to ensure that the package is functioning correctly. Finally do a full check using devtools::check(). This reflects the checks that CRAN will perform when you submit the package.\ndevtools::build()\ndevtools::install()\ndevtools::test()\ndevtools::check()"
  },
  {
    "objectID": "posts/develop_r_package/index.html#reproducibility",
    "href": "posts/develop_r_package/index.html#reproducibility",
    "title": "Setting up an R development environment on github",
    "section": "2.1 Reproducibility",
    "text": "2.1 Reproducibility\n\n# Print session info for reproducibility\nsessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1      lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.0     tidyselect_1.2.1  \n [5] scales_1.4.0       yaml_2.3.10        fastmap_1.2.0      R6_2.6.1          \n [9] generics_0.1.4     knitr_1.50         htmlwidgets_1.6.4  rprojroot_2.0.4   \n[13] pillar_1.10.2      RColorBrewer_1.1-3 tzdb_0.5.0         rlang_1.1.6       \n[17] stringi_1.8.7      xfun_0.52          timechange_0.3.0   cli_3.6.5         \n[21] withr_3.0.2        magrittr_2.0.3     digest_0.6.37      grid_4.5.0        \n[25] hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5        evaluate_1.0.3    \n[29] glue_1.8.0         farver_2.1.2       rmarkdown_2.29     tools_4.5.0       \n[33] pkgconfig_2.0.3    htmltools_0.5.8.1"
  },
  {
    "objectID": "posts/develop_r_package/index.html#next-steps",
    "href": "posts/develop_r_package/index.html#next-steps",
    "title": "Setting up an R development environment on github",
    "section": "2.2 Next Steps",
    "text": "2.2 Next Steps\n\nSuggest areas for further exploration\nMention potential improvements\nInvite reader engagement"
  },
  {
    "objectID": "posts/develop_r_package/index.html#references",
    "href": "posts/develop_r_package/index.html#references",
    "title": "Setting up an R development environment on github",
    "section": "2.3 References",
    "text": "2.3 References\n\nCite your sources\nLink to relevant documentation\nCredit other contributors"
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-1-understand-the-devtoolstest-workflow",
    "href": "posts/develop_r_package/index.html#step-1-understand-the-devtoolstest-workflow",
    "title": "Setting up an R development environment on github",
    "section": "3.1 Step 1: Understand the devtools::test() Workflow",
    "text": "3.1 Step 1: Understand the devtools::test() Workflow\n\nWhat It Does:\n\nRuns all test scripts in the tests/testthat/ directory using the testthat package.\nReports errors, warnings, and failed assertions.\n\nOutput Format:\n\nLists the file and test name where the error occurred.\nProvides the expected and actual outputs (if applicable).\nShows the error message and traceback for debugging."
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-2-interpret-the-error-message",
    "href": "posts/develop_r_package/index.html#step-2-interpret-the-error-message",
    "title": "Setting up an R development environment on github",
    "section": "3.2 Step 2: Interpret the Error Message",
    "text": "3.2 Step 2: Interpret the Error Message\nRun devtools::test() in your R console or IDE terminal and note the output. Focus on:\n\nTest File and Test Name:\n\nExample:\n── Failure (test-zzlongplot.R:31:3): parse_formula handles grouping and faceting variables ──\nresult$y (`actual`) not equal to \"y\" (`expected`).\nThis indicates:\n\nThe error is in test-zzlongplot.R.\nIt occurred in the test named parse_formula handles grouping and faceting variables.\n\n\nError Details:\n\nExample:\n`actual`:   \"y ~ x | group\"\n`expected`: \"y\"\nThe test expected result$y to be \"y\", but the actual output was \"y ~ x | group\".\n\nTraceback:\n\nThe traceback provides a stack of function calls leading to the error. Use traceback() immediately after the test failure to get additional context."
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-3-isolate-the-problem",
    "href": "posts/develop_r_package/index.html#step-3-isolate-the-problem",
    "title": "Setting up an R development environment on github",
    "section": "3.3 Step 3: Isolate the Problem",
    "text": "3.3 Step 3: Isolate the Problem\n\nRun the Test Manually:\n\nExtract the failing test from the test file and run it manually:\nlibrary(testthat)\nsource(\"path/to/zzlongplot/R/parse_formula.R\")\nresult &lt;- parse_formula(y ~ x | group ~ facet_y + facet_x)\nexpect_equal(result$y, \"y\")\nThis helps verify if the error occurs outside the testing framework.\n\nVerify Input Data:\n\nEnsure that the inputs to the function are as expected. For example, check if the formula passed to parse_formula matches the expected format.\n\nUse Debugging Tools:\n\nInsert browser() into the failing function to step through its execution:\nparse_formula &lt;- function(formula) {\n  browser()\n  # Function logic...\n}\nWhen the code pauses at browser(), inspect the environment using:\nls()\nprint(formula)"
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-4-debugging-common-errors",
    "href": "posts/develop_r_package/index.html#step-4-debugging-common-errors",
    "title": "Setting up an R development environment on github",
    "section": "3.4 Step 4: Debugging Common Errors",
    "text": "3.4 Step 4: Debugging Common Errors\n\n3.4.1 Error 1: Assertion Failures\nExample:\nresult$y (`actual`) not equal to \"y\" (`expected`).\nSteps: 1. Check the test code: - Verify if the expect_equal() or similar assertion accurately reflects the intended behavior. - Example: r      expect_equal(result$y, \"y\") - If the test expectation is wrong, update it to match the correct behavior.\n\nCheck the function output:\n\nRun the function manually with the same inputs and inspect its output:\nparse_formula(y ~ x | group ~ facet_y + facet_x)\n\nFix the function logic:\n\nIf the function output is incorrect, debug the function implementation.\n\n\n\n\n\n3.4.2 Error 2: Unexpected Errors or Warnings\nExample:\nError: Input must be a formula object\nSteps: 1. Reproduce the Error: - Identify the exact input that triggers the error.\n\nAdd Input Validation:\n\nValidate inputs at the start of the function to catch issues early.\nif (!inherits(formula, \"formula\")) {\n  stop(\"Input must be a formula object\")\n}\n\nCheck for Edge Cases:\n\nTest the function with edge cases, such as missing or malformed inputs.\n\n\n\n\n\n3.4.3 Error 3: Missing Dependencies\nExample:\nError: could not find function \"mutate\"\nSteps: 1. Check Imports: - Ensure the missing function’s package is listed under Imports in DESCRIPTION.\n\nExplicitly Load Dependencies:\n\nUse the :: operator to call functions explicitly:\ndplyr::mutate(...)\n\nAdd requireNamespace():\n\nDynamically load namespaces if not attached:\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) {\n  stop(\"dplyr is required for this function.\")\n}"
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-5-add-debugging-output",
    "href": "posts/develop_r_package/index.html#step-5-add-debugging-output",
    "title": "Setting up an R development environment on github",
    "section": "3.5 Step 5: Add Debugging Output",
    "text": "3.5 Step 5: Add Debugging Output\n\nPrint Debugging Information:\n\nAdd print() or cat() statements to inspect variables:\ncat(\"Parsed y:\", y_var, \"\\n\")\n\nUse Logging:\n\nUse a logging package like logger to add structured debug messages."
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-6-rerun-tests",
    "href": "posts/develop_r_package/index.html#step-6-rerun-tests",
    "title": "Setting up an R development environment on github",
    "section": "3.6 Step 6: Rerun Tests",
    "text": "3.6 Step 6: Rerun Tests\nAfter making changes: 1. Save the modified code and test files. 2. Re-run the tests: r    devtools::test()"
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-7-finalize-fixes",
    "href": "posts/develop_r_package/index.html#step-7-finalize-fixes",
    "title": "Setting up an R development environment on github",
    "section": "3.7 Step 7: Finalize Fixes",
    "text": "3.7 Step 7: Finalize Fixes\n\nRemove Debugging Code:\n\nRemove browser(), print(), and other debug artifacts.\n\nRe-run Full Checks:\n\nRun devtools::check() to ensure the package passes all CRAN checks."
  },
  {
    "objectID": "posts/develop_r_package/index.html#example-workflow-for-debugging",
    "href": "posts/develop_r_package/index.html#example-workflow-for-debugging",
    "title": "Setting up an R development environment on github",
    "section": "3.8 Example Workflow for Debugging",
    "text": "3.8 Example Workflow for Debugging\n\nIdentify the failing test:\ndevtools::test()\nManually isolate and debug the test:\nresult &lt;- parse_formula(y ~ x | group ~ facet_y + facet_x)\nprint(result)\nAdd debugging statements:\nparse_formula &lt;- function(formula) {\n  print(formula)\n  browser()\n  # Logic...\n}\nFix the issue and re-test:\ndevtools::test()\nRemove debugging artifacts and run final checks:\ndevtools::check()"
  },
  {
    "objectID": "posts/develop_r_package/index.html#conclusion",
    "href": "posts/develop_r_package/index.html#conclusion",
    "title": "Setting up an R development environment on github",
    "section": "3.9 Conclusion",
    "text": "3.9 Conclusion\nDebugging devtools::test() errors involves interpreting error messages, isolating failing tests, and systematically diagnosing issues in your code. With these steps, you can identify and fix problems effectively."
  },
  {
    "objectID": "posts/develop_r_package/index.html#prerequisites",
    "href": "posts/develop_r_package/index.html#prerequisites",
    "title": "Setting up an R development environment on github",
    "section": "3.10 Prerequisites",
    "text": "3.10 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/develop_r_package/index.html#step-by-step-implementation",
    "href": "posts/develop_r_package/index.html#step-by-step-implementation",
    "title": "Setting up an R development environment on github",
    "section": "3.11 Step-by-Step Implementation",
    "text": "3.11 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/develop_r_package/index.html#key-takeaways",
    "href": "posts/develop_r_package/index.html#key-takeaways",
    "title": "Setting up an R development environment on github",
    "section": "3.12 Key Takeaways",
    "text": "3.12 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/develop_r_package/index.html#further-reading",
    "href": "posts/develop_r_package/index.html#further-reading",
    "title": "Setting up an R development environment on github",
    "section": "3.13 Further Reading",
    "text": "3.13 Further Reading\nIn development"
  },
  {
    "objectID": "posts/setupquarto/index.html",
    "href": "posts/setupquarto/index.html",
    "title": "Setting up a minimal Quarto blog",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "posts/setupquarto/index.html#prerequisites",
    "href": "posts/setupquarto/index.html#prerequisites",
    "title": "Setting up a minimal Quarto blog",
    "section": "3.1 Prerequisites",
    "text": "3.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/setupquarto/index.html#step-by-step-implementation",
    "href": "posts/setupquarto/index.html#step-by-step-implementation",
    "title": "Setting up a minimal Quarto blog",
    "section": "3.2 Step-by-Step Implementation",
    "text": "3.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/setupquarto/index.html#key-takeaways",
    "href": "posts/setupquarto/index.html#key-takeaways",
    "title": "Setting up a minimal Quarto blog",
    "section": "3.3 Key Takeaways",
    "text": "3.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/setupquarto/index.html#further-reading",
    "href": "posts/setupquarto/index.html#further-reading",
    "title": "Setting up a minimal Quarto blog",
    "section": "3.4 Further Reading",
    "text": "3.4 Further Reading\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html",
    "href": "tutorials/docker-for-beginners/index.html",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#introduction",
    "href": "tutorials/docker-for-beginners/index.html#introduction",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis guide demonstrates how to deploy a Shiny application from your local workstation to a secure web environment. We’ll use a stack of open-source technologies including Linux, R, Shiny, Docker, and Caddy, deployed on AWS EC2. While we focus on AWS here, the principles apply to other cloud providers like Hetzner, which we’ll cover in future posts."
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#prerequisites",
    "href": "tutorials/docker-for-beginners/index.html#prerequisites",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore beginning this tutorial, you’ll need:\n\nA working Shiny application on your local machine\nAn AWS account with permissions to create EC2 instances\nBasic familiarity with the Linux command line\nGit (optional, for version control)"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#the-example-application",
    "href": "tutorials/docker-for-beginners/index.html#the-example-application",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "3 The Example Application",
    "text": "3 The Example Application\nLet’s start with a simple but practical example: hosting a shiny web application that provides a power calculator for two-sample t-tests. While straightforward, this application demonstrates all the key deployment concepts.\nHere is the code for the Shiny app (The app is intentionally minimal, using only base R functions, with a minimum of reactive widgets and layout commands.):\n\nPower Calculator Shiny App Code (power1_shiny/app.R)\nui &lt;- fluidPage(\n  titlePanel(\"Power Calculator for Two Group Parallel Designs\"),\n  sliderInput(\"N\", \"Total Sample Size:\", min = 0, max = 300, value = 100),\n  plotOutput(\"plot\"),\n  verbatimTextOutput(\"eff\"))\n\nserver &lt;- function(input, output, session) {\n  delta = seq(0, 1.5,.05)\n  pow = reactive(sapply(delta, function(x) power.t.test(input$N, d=x)$power ))\n  eff =  renderText(power.t.test(input$N, power=.8)$d)\n  output$plot &lt;- renderPlot({\n    plot(delta, pow(), cex=1.5, ylab=\"power\")\n    abline(h = .8,  col = \"red\", lwd =2.5, lty = 4)\n    abline(v = eff(), col = \"blue\",lwd =2.5, lty = 4)})\n  output$eff &lt;- renderText(\n    paste0(\"Std. effect detectable with power 80% = \", eff()) )\n}\nshinyApp(ui, server)\n\n\n\n\n\n\nShiny app interface"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "4 Step-by-Step Implementation",
    "text": "4 Step-by-Step Implementation\n\n4.1 Deployment Checklist\nAs an overview, to host our Shiny app securely online, we need to:\n\nObtain a static IP address\nRegister a domain name\nConfigure a firewall\nSet up the virtual server\nInstall and configure a web server\nImplement SSL encryption\nSet up user authentication\nConfigure reverse proxy routing\n\nWhile this might seem complex, we’ll break it down into manageable steps.\nDetailed instructions for setting up a virtual server (items 1 through 4 above) on EC2 both through the EC2 console and the command line interface can be found: here and here\n\n\n4.2 Step 1: Server Setup\nFirst, we’ll prepare our AWS EC2 environment: In the course of setting up your server, you’ll need to: 1. Create or access your AWS account 2. Generate SSH key-pair, named for example, power1_app.pem 3. Configure firewall settings, allowing SSH (port 22), HTTP (port 80) traffic and HTTPS (port 443) traffic. 4. Obtain static IP, e.g., 13.57.139.31 5. Register domain name, e.g. rgtlab.org 6. Launch Ubuntu instance (t2-micro is sufficient)\n\n\n4.3 Step 2: Installing Required Software\nconnect to your server via SSH:\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nOn your server, install Docker and Caddy (a modern web server with automatic HTTPS) using the following commands.\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\n\n\n4.4 Step 3: Containerizing the Application\nCreate a Dockerfile in your app directory:\n\nDockerfile Configuration\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\n\n\n4.5 Step 4: Configuring the Web Server\nCreate a Caddyfile:\n\nCaddy Server Configuration\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nCreate an index.html:\n\nLanding Page HTML\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n4.6 Step 5: Deployment\n\nCopy files to server:\n\nscp -r ~/prj/power1_app/ ubuntu@rgtlab.org:~\n\nBuild and run Docker container:\n\ndocker build -t power1_image .\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\n\nConfigure Caddy:\n\nsudo cp ./Caddyfile /etc/caddy/\ncp ./index.html /var/www/html/\nsudo systemctl reload caddy\nYour app should now be available at https://rgtlab.org!"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "href": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "5 Advanced Tips",
    "text": "5 Advanced Tips\nFor easier SSH access, create a ~/.ssh/config file:\nHost rgtlab.org\nHostName 13.57.139.31\nStrictHostKeyChecking no\nUser ubuntu\nPort 22\nIdentityFile ~/.ssh/power1_app.pem\nThis enables simple SSH access:\nssh rgtlab.org"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "6 Key Takeaways",
    "text": "6 Key Takeaways\n\nDocker containers provide isolation and reproducibility for your Shiny applications\nCaddy web server automatically handles SSL certificates and security\nBasic authentication provides a simple access control mechanism\nAWS EC2 offers a reliable platform for hosting web applications\nThe entire deployment can be automated for continuous delivery workflows"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading",
    "href": "tutorials/docker-for-beginners/index.html#further-reading",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "7 Further Reading",
    "text": "7 Further Reading\n\nShiny Server documentation\nDocker documentation\nCaddy Web Server documentation\nAWS EC2 documentation"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "8 Step-by-Step Implementation",
    "text": "8 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "9 Key Takeaways",
    "text": "9 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "href": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "10 Further Reading",
    "text": "10 Further Reading\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html",
    "href": "posts/dockerize_compose/index.html",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#hosting",
    "href": "posts/dockerize_compose/index.html#hosting",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 summarizes the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with the static IP address) from a domain registration provider. E.g rgtlab.org\nInstall and configure a webserver on the virtual server ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838, requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts (here) and (here).\nIn brief, the process is as follows: To get started with AWS create an account or sign in to the AWS EC2 dashboard. Once on the dashboard set up an environment in which to host the virtual server.\nThe components of this environment are: a ssh key-pair, a firewall, a static IP, and a domain name.\nWith the hosting environment in place, select an instance (AMI, type and disk size), then generate and launch the server.\nOnce the server is available, connect via ssh, and login.\nThe only software necessary to install at this point is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\n\n\nNote: snap is a package management system pre-installed in Ubuntu servers. Not to be confused with the apt package management system.\nOnce the host is set up and docker is installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, a unique domain name and firewall in place."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker",
    "href": "posts/dockerize_compose/index.html#docker",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access R and Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile located in the Shiny development directory:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#web-server",
    "href": "posts/dockerize_compose/index.html#web-server",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.2 Web-server",
    "text": "3.2 Web-server\nOne of the most challenging parts of setting up a standalone server is installling and configuring the web server this is because we need our web server to perform several functions” that is 1) Provide a method for receiving and processing packets from the internet 2) Restrict access to https protocol packets. 3) host web-certificates, 4) provide authentication, and 5) forward 443 packets to 3838.\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. (An SSL cert is required by most browsers to use the encrypted communication protocol https.)\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generate an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker-compose",
    "href": "posts/dockerize_compose/index.html#docker-compose",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#landing-page",
    "href": "posts/dockerize_compose/index.html#landing-page",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#prerequisites",
    "href": "posts/dockerize_compose/index.html#prerequisites",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "href": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#key-takeaways",
    "href": "posts/dockerize_compose/index.html#key-takeaways",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#further-reading",
    "href": "posts/dockerize_compose/index.html#further-reading",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  }
]