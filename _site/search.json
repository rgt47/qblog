[
  {
    "objectID": "BLOG_POST_TEMPLATE.html",
    "href": "BLOG_POST_TEMPLATE.html",
    "title": "Your Engaging Title Here",
    "section": "",
    "text": "Caption for your hero image - either conceptual or a preview of main results"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#subsection-1.1-more-specific-topic",
    "href": "BLOG_POST_TEMPLATE.html#subsection-1.1-more-specific-topic",
    "title": "Your Engaging Title Here",
    "section": "3.1 Subsection 1.1: [More Specific Topic]",
    "text": "3.1 Subsection 1.1: [More Specific Topic]\n\n[More detailed explanation or variation]\n\n\n\nOptional supporting visualization"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#subsection-2.1-handling-edge-cases",
    "href": "BLOG_POST_TEMPLATE.html#subsection-2.1-handling-edge-cases",
    "title": "Your Engaging Title Here",
    "section": "4.1 Subsection 2.1: [Handling Edge Cases]",
    "text": "4.1 Subsection 2.1: [Handling Edge Cases]\n\n[Discussion of potential issues and solutions]\n\n# Replace with your actual error handling code\n# tryCatch({\n#   risky_operation(data)\n# }, error = function(e) {\n#   message(\"Error handled: \", e$message)\n# })"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-a-complete-code",
    "href": "BLOG_POST_TEMPLATE.html#appendix-a-complete-code",
    "title": "Your Engaging Title Here",
    "section": "13.1 Appendix A: Complete Code",
    "text": "13.1 Appendix A: Complete Code\n\n\n# Complete code for easy reproduction - replace with your actual code\n# library(your_packages)\n# data &lt;- load_your_data()\n# results &lt;- your_analysis(data)\n# plot(results)"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-b-mathematical-details",
    "href": "BLOG_POST_TEMPLATE.html#appendix-b-mathematical-details",
    "title": "Your Engaging Title Here",
    "section": "13.2 Appendix B: Mathematical Details",
    "text": "13.2 Appendix B: Mathematical Details\n\n[Detailed mathematical explanations or derivations]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-c-additional-data",
    "href": "BLOG_POST_TEMPLATE.html#appendix-c-additional-data",
    "title": "Your Engaging Title Here",
    "section": "13.3 Appendix C: Additional Data",
    "text": "13.3 Appendix C: Additional Data\n\n[Additional tables, charts, or data summaries]\n\nHave questions or suggestions? Feel free to reach out on Twitter or LinkedIn. You can also find the complete code for this analysis on GitHub.\n\nAbout the Author: [Your name] is a [your role] specializing in [your expertise]. [Brief background and interests.]"
  },
  {
    "objectID": "posts/dockerize_compose/index.html",
    "href": "posts/dockerize_compose/index.html",
    "title": "1 Introduction",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#hosting",
    "href": "posts/dockerize_compose/index.html#hosting",
    "title": "1 Introduction",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 summarizes the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with the static IP address) from a domain registration provider. E.g rgtlab.org\nInstall and configure a webserver on the virtual server ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838, requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "title": "1 Introduction",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts (here) and (here).\nIn brief, the process is as follows: To get started with AWS create an account or sign in to the AWS EC2 dashboard. Once on the dashboard set up an environment in which to host the virtual server.\nThe components of this environment are: a ssh key-pair, a firewall, a static IP, and a domain name.\nWith the hosting environment in place, select an instance (AMI, type and disk size), then generate and launch the server.\nOnce the server is available, connect via ssh, and login.\nThe only software necessary to install at this point is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\n\n\nNote: snap is a package management system pre-installed in Ubuntu servers. Not to be confused with the apt package management system.\nOnce the host is set up and docker is installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, a unique domain name and firewall in place."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker",
    "href": "posts/dockerize_compose/index.html#docker",
    "title": "1 Introduction",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access R and Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile located in the Shiny development directory:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#web-server",
    "href": "posts/dockerize_compose/index.html#web-server",
    "title": "1 Introduction",
    "section": "3.2 Web-server",
    "text": "3.2 Web-server\nOne of the most challenging parts of setting up a standalone server is installling and configuring the web server this is because we need our web server to perform several functions” that is 1) Provide a method for receiving and processing packets from the internet 2) Restrict access to https protocol packets. 3) host web-certificates, 4) provide authentication, and 5) forward 443 packets to 3838.\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. (An SSL cert is required by most browsers to use the encrypted communication protocol https.)\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generate an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker-compose",
    "href": "posts/dockerize_compose/index.html#docker-compose",
    "title": "1 Introduction",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#landing-page",
    "href": "posts/dockerize_compose/index.html#landing-page",
    "title": "1 Introduction",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "title": "1 Introduction",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "title": "1 Introduction",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "title": "1 Introduction",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#prerequisites",
    "href": "posts/dockerize_compose/index.html#prerequisites",
    "title": "1 Introduction",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "href": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "title": "1 Introduction",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#key-takeaways",
    "href": "posts/dockerize_compose/index.html#key-takeaways",
    "title": "1 Introduction",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#further-reading",
    "href": "posts/dockerize_compose/index.html#further-reading",
    "title": "1 Introduction",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html",
    "href": "tutorials/docker-for-beginners/index.html",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#introduction",
    "href": "tutorials/docker-for-beginners/index.html#introduction",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis guide demonstrates how to deploy a Shiny application from your local workstation to a secure web environment. We’ll use a stack of open-source technologies including Linux, R, Shiny, Docker, and Caddy, deployed on AWS EC2. While we focus on AWS here, the principles apply to other cloud providers like Hetzner, which we’ll cover in future posts."
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#prerequisites",
    "href": "tutorials/docker-for-beginners/index.html#prerequisites",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore beginning this tutorial, you’ll need:\n\nA working Shiny application on your local machine\nAn AWS account with permissions to create EC2 instances\nBasic familiarity with the Linux command line\nGit (optional, for version control)"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#the-example-application",
    "href": "tutorials/docker-for-beginners/index.html#the-example-application",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "3 The Example Application",
    "text": "3 The Example Application\nLet’s start with a simple but practical example: hosting a shiny web application that provides a power calculator for two-sample t-tests. While straightforward, this application demonstrates all the key deployment concepts.\nHere is the code for the Shiny app (The app is intentionally minimal, using only base R functions, with a minimum of reactive widgets and layout commands.):\n\nPower Calculator Shiny App Code (power1_shiny/app.R)\nui &lt;- fluidPage(\n  titlePanel(\"Power Calculator for Two Group Parallel Designs\"),\n  sliderInput(\"N\", \"Total Sample Size:\", min = 0, max = 300, value = 100),\n  plotOutput(\"plot\"),\n  verbatimTextOutput(\"eff\"))\n\nserver &lt;- function(input, output, session) {\n  delta = seq(0, 1.5,.05)\n  pow = reactive(sapply(delta, function(x) power.t.test(input$N, d=x)$power ))\n  eff =  renderText(power.t.test(input$N, power=.8)$d)\n  output$plot &lt;- renderPlot({\n    plot(delta, pow(), cex=1.5, ylab=\"power\")\n    abline(h = .8,  col = \"red\", lwd =2.5, lty = 4)\n    abline(v = eff(), col = \"blue\",lwd =2.5, lty = 4)})\n  output$eff &lt;- renderText(\n    paste0(\"Std. effect detectable with power 80% = \", eff()) )\n}\nshinyApp(ui, server)\n\n\n\n\n\n\nShiny app interface"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "4 Step-by-Step Implementation",
    "text": "4 Step-by-Step Implementation\n\n4.1 Deployment Checklist\nAs an overview, to host our Shiny app securely online, we need to:\n\nObtain a static IP address\nRegister a domain name\nConfigure a firewall\nSet up the virtual server\nInstall and configure a web server\nImplement SSL encryption\nSet up user authentication\nConfigure reverse proxy routing\n\nWhile this might seem complex, we’ll break it down into manageable steps.\nDetailed instructions for setting up a virtual server (items 1 through 4 above) on EC2 both through the EC2 console and the command line interface can be found: here and here\n\n\n4.2 Step 1: Server Setup\nFirst, we’ll prepare our AWS EC2 environment: In the course of setting up your server, you’ll need to: 1. Create or access your AWS account 2. Generate SSH key-pair, named for example, power1_app.pem 3. Configure firewall settings, allowing SSH (port 22), HTTP (port 80) traffic and HTTPS (port 443) traffic. 4. Obtain static IP, e.g., 13.57.139.31 5. Register domain name, e.g. rgtlab.org 6. Launch Ubuntu instance (t2-micro is sufficient)\n\n\n4.3 Step 2: Installing Required Software\nconnect to your server via SSH:\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nOn your server, install Docker and Caddy (a modern web server with automatic HTTPS) using the following commands.\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\n\n\n4.4 Step 3: Containerizing the Application\nCreate a Dockerfile in your app directory:\n\nDockerfile Configuration\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\n\n\n4.5 Step 4: Configuring the Web Server\nCreate a Caddyfile:\n\nCaddy Server Configuration\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nCreate an index.html:\n\nLanding Page HTML\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n4.6 Step 5: Deployment\n\nCopy files to server:\n\nscp -r ~/prj/power1_app/ ubuntu@rgtlab.org:~\n\nBuild and run Docker container:\n\ndocker build -t power1_image .\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\n\nConfigure Caddy:\n\nsudo cp ./Caddyfile /etc/caddy/\ncp ./index.html /var/www/html/\nsudo systemctl reload caddy\nYour app should now be available at https://rgtlab.org!"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "href": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "5 Advanced Tips",
    "text": "5 Advanced Tips\nFor easier SSH access, create a ~/.ssh/config file:\nHost rgtlab.org\nHostName 13.57.139.31\nStrictHostKeyChecking no\nUser ubuntu\nPort 22\nIdentityFile ~/.ssh/power1_app.pem\nThis enables simple SSH access:\nssh rgtlab.org"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "6 Key Takeaways",
    "text": "6 Key Takeaways\n\nDocker containers provide isolation and reproducibility for your Shiny applications\nCaddy web server automatically handles SSL certificates and security\nBasic authentication provides a simple access control mechanism\nAWS EC2 offers a reliable platform for hosting web applications\nThe entire deployment can be automated for continuous delivery workflows"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading",
    "href": "tutorials/docker-for-beginners/index.html#further-reading",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "7 Further Reading",
    "text": "7 Further Reading\n\nShiny Server documentation\nDocker documentation\nCaddy Web Server documentation\nAWS EC2 documentation"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "8 Step-by-Step Implementation",
    "text": "8 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "9 Key Takeaways",
    "text": "9 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "href": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "10 Further Reading",
    "text": "10 Further Reading\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html",
    "href": "blog/coding-with-genai/index.html",
    "title": "Coding with Generative AI",
    "section": "",
    "text": "View this post in multiple formats:\n\n\n\n  HTML    PDF    Word"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#prerequisites",
    "href": "blog/coding-with-genai/index.html#prerequisites",
    "title": "Coding with Generative AI",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "href": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "title": "Coding with Generative AI",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#key-takeaways",
    "href": "blog/coding-with-genai/index.html#key-takeaways",
    "title": "Coding with Generative AI",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#further-reading",
    "href": "blog/coding-with-genai/index.html#further-reading",
    "title": "Coding with Generative AI",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "test_minimal.html",
    "href": "test_minimal.html",
    "title": "Test Document",
    "section": "",
    "text": "This is a test document.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "test_minimal.html#test",
    "href": "test_minimal.html#test",
    "title": "Test Document",
    "section": "",
    "text": "This is a test document.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "white-papers/index.html",
    "href": "white-papers/index.html",
    "title": "White Papers",
    "section": "",
    "text": "A comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\n🔗 Full Report • 📄 PDF\n\n\n\n\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#research-methodology-workflows",
    "href": "white-papers/index.html#research-methodology-workflows",
    "title": "White Papers",
    "section": "",
    "text": "A comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\n🔗 Full Report • 📄 PDF\n\n\n\n\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#statistical-computing-development",
    "href": "white-papers/index.html#statistical-computing-development",
    "title": "White Papers",
    "section": "2 Statistical Computing & Development",
    "text": "2 Statistical Computing & Development\n\n2.1 RCT Validation Language\nSpecification for a domain-specific programming language designed to capture clinical trial database validation logic, with compilation targets for Lua and JavaScript.\nClinical trials Programming languages Data validation DSL design\n\n🔗 Full Report • 📄 PDF\n\n\n\n2.2 Setting up an R Development Environment on GitHub\nBest practices and step-by-step methodology for establishing reproducible R package development workflows using GitHub integration and continuous integration.\nR development GitHub Package development CI/CD\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#data-science-applications",
    "href": "white-papers/index.html#data-science-applications",
    "title": "White Papers",
    "section": "3 Data Science Applications",
    "text": "3 Data Science Applications\n\n3.1 Making Optimal Use of ChatGPT and Other Chatbots for Data Science\nEvaluation framework and practical guidelines for integrating large language models into data science workflows, including prompt engineering and quality assessment.\nAI tools Data science LLM integration Prompt engineering\n\n🔗 Full Report • 📄 PDF\n\n\n\n3.2 Minimalist EDC Application Framework\nTechnical architecture for building lightweight electronic data capture systems for clinical research, emphasizing simplicity and regulatory compliance.\nEDC systems Clinical research Software architecture Regulatory compliance\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#technical-infrastructure",
    "href": "white-papers/index.html#technical-infrastructure",
    "title": "White Papers",
    "section": "4 Technical Infrastructure",
    "text": "4 Technical Infrastructure\n\n4.1 Containerized R Analysis Workflows with Docker\nImplementation guide for reproducible R analysis environments using Docker containerization, including best practices for sharing and deployment.\nDocker Reproducibility R environment Containerization\n\n🔗 Full Report • 📄 PDF\n\n\n\n4.2 AWS Server Configuration for Research Computing\nComprehensive guide for setting up and configuring AWS instances for statistical computing and research data analysis.\nAWS Cloud computing Server configuration Research computing\n\n🔗 Full Report • 📄 PDF\n\n\nThese white papers represent in-depth technical analyses, methodological frameworks, and implementation guides developed for research and statistical computing applications. Each document provides detailed specifications, best practices, and reproducible workflows."
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Comprehensive tutorials designed to teach you new skills from the ground up. These evergreen resources are regularly updated and expanded with new content.\nEach tutorial includes: - Clear learning objectives - Step-by-step instructions - Working examples - Practice exercises - Troubleshooting tips\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nR Package Development: From Idea to CRAN\n\n\nComplete tutorial for creating your first R package\n\n\n\nR\n\n\npackages\n\n\ndevelopment\n\n\ntutorial\n\n\n\nStep-by-step guide to developing, documenting, and submitting an R package to CRAN.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurely Deploying Your Shiny App Online: A Step-by-Step Guide\n\n\n\nDeployment & Operations\n\n\n\nA practical guide for data scientists on how to deploy R Shiny applications securely using open-source technologies.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up git for (solo) data science workflow\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html",
    "href": "teaching/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-importexport",
    "href": "teaching/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "href": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#string-operations",
    "href": "teaching/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#package-management",
    "href": "teaching/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#workspace-management",
    "href": "teaching/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "href": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#missing-values",
    "href": "teaching/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#quick-tips",
    "href": "teaching/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "research/r-package-development-basics.html",
    "href": "research/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#learning-objectives",
    "href": "research/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#prerequisites",
    "href": "research/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-2-create-package-structure",
    "href": "research/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-4-generate-documentation",
    "href": "research/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-5-testing",
    "href": "research/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-6-package-checks",
    "href": "research/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "research/r-package-development-basics.html#next-steps",
    "href": "research/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "research/r-package-development-basics.html#resources",
    "href": "research/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html",
    "href": "references/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-importexport",
    "href": "references/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#statistical-functions",
    "href": "references/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#string-operations",
    "href": "references/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#package-management",
    "href": "references/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#workspace-management",
    "href": "references/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-types-structure",
    "href": "references/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#missing-values",
    "href": "references/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#quick-tips",
    "href": "references/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html",
    "href": "misc/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "href": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesn’t exist or package isn’t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#data-type-errors",
    "href": "misc/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#subsetting-errors",
    "href": "misc/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesn’t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#missing-values-issues",
    "href": "misc/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions can’t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#file-reading-errors",
    "href": "misc/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R can’t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#memory-issues",
    "href": "misc/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#package-installation-issues",
    "href": "misc/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package won’t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "href": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#prevention-strategies",
    "href": "misc/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "guides/index.html",
    "href": "guides/index.html",
    "title": "Guides",
    "section": "",
    "text": "Practical guides for solving specific problems and accomplishing particular tasks. These step-by-step instructions help you tackle real-world challenges.\nEach guide provides: - Clear problem definition - Prerequisites and assumptions - Detailed implementation steps - Alternative approaches - Common pitfalls and solutions\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nFixing Common R Errors: A Troubleshooting Guide\n\n\nStep-by-step solutions for frequent R programming problems\n\n\n\nR\n\n\ntroubleshooting\n\n\ndebugging\n\n\nguide\n\n\n\nPractical solutions for the most common R errors encountered by data scientists and analysts.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/research-management/index.html",
    "href": "blog/research-management/index.html",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "href": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by",
    "text": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by\nrunning this bash script to copy a prelude to the chatGPT prompt to your clipboard: Call it dp (dictation prompt).\n#!/bin/bash\n\n# Get current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Define the prompt with explicit instructions\nprompt=\"I'm an academic biostatistician. I'm working on a data analysis project.\nI'm about to dictate daily research progress notes.  \nWhen I'm done, provide a concise summary that includes:  \n\n1. The date  and time of dictation ($current_time).  The line with date and time\nshould be the second line of the summary. The first line should be blank. The\ndate and time line shound be enclosed in a box of ascii characters to set it apart.\n2. The name of the current research project directory ($current_dir).  \n3. Each line of the summary including the blank line and the date and time line\nand enclosing box lines should begin with \\\"$current_dir:\\\" so that it can be\nextracted using ripgrep.  \n\nThe notes start here: \"\n\n# Copy the prompt to clipboard (MacOS pbcopy)\necho -n \"$prompt\" | pbcopy\n\n# Notify the user\necho \"Prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.2-dictating-notes",
    "href": "blog/research-management/index.html#step-3.2-dictating-notes",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nOpen ChatGPT (done automatically by “dp” script) and follow these steps:\ncopy text from clipboard into the prompt box.\nsubmit prompt to prep chatGPT for summarization.\nClick chatGPT microphone and Dictate your research notes.\nWhen finished dictating submit prompt to ChatGPT for summarization.\nCopy and generated summary onto the clipboard.\n\nUse the following script to append the summary to your daily log: and push the changes to daily_log.md to the remote repository on GitHub.\n#!/bin/bash\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Get the current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the clipboard content (MacOS pbpaste)\nclipboard_content=$(pbpaste)\n\n# Echo the output\n#\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"\" &gt;&gt; ~/prj/research_update/daily_log.md\n\n# Confirm success\necho \"Update for $current_dir appended to daily_log.md in ~/prj/research_update\"\ncd ~/prj/research_update\n  git add .\n    git commit -a -m \"Daily log update $(date +'%Y-%m-%d')\"\n    git push"
  },
  {
    "objectID": "blog/research-management/index.html#prerequisites",
    "href": "blog/research-management/index.html#prerequisites",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#step-by-step-implementation",
    "href": "blog/research-management/index.html#step-by-step-implementation",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#key-takeaways",
    "href": "blog/research-management/index.html#key-takeaways",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#further-reading",
    "href": "blog/research-management/index.html#further-reading",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html",
    "href": "blog/chatbots-in-stats/index.html",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "",
    "text": "chatGPT"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#whats-in-a-name",
    "href": "blog/chatbots-in-stats/index.html#whats-in-a-name",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "1.1 Whats in a name?",
    "text": "1.1 Whats in a name?\nGPT in ChatGPT stands for Generative Pre-trained Transformer. • Generative: It generates text rather than just analyzing or classifying it. • Pre-trained: It is trained on a large dataset before being fine-tuned for specific tasks. • Transformer: It uses the Transformer architecture, a neural network model designed for natural language processing (NLP).\nEssentially, ChatGPT is a chatbot built on a GPT model, which is designed to understand and generate human-like text based on prompts\nFrom a recent article in Nature:\n“ChatGPT stunned the world on its launch in November 2022. Powered by a large language model (LLM) and trained on much of the text published on the Internet, the artificial intelligence (AI) chatbot, created by OpenAI in San Francisco, California, makes the latest advances in natural-language processing broadly accessible by providing a dialogue-based interface capable of answering complex questions, composing sophisticated essays and generating source code. One obvious question was: how could this tool improve science?”\nNature: Chatbots in science: What can ChatGPT do for you?\nLets start with a couple examples to get an idea of how to use ChatGPT for data science tasks."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#example-work-up-of-a-regression-analysis-for-the-iris-data-set.",
    "href": "blog/chatbots-in-stats/index.html#example-work-up-of-a-regression-analysis-for-the-iris-data-set.",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "1.2 Example work up of a regression analysis for the iris data set.",
    "text": "1.2 Example work up of a regression analysis for the iris data set.\n\nPrompt: “I want to do a trial data analysis in R of the Fisher iris data set that is distributed with R. I want to start with logistic regression analysis and want to use K-fold cross-validation. I want to use an ROC curve to visualize the results.”\n\ncomment: this is a good example of a prompt that is clear and specific. It provides many of the necessary context and requirements for the task. However, it is not completely unambiguous. It does not specify the number of folds for cross-validatikn. It also does not specify the R package to use for the aanalysis. There ae several to choose from.\ninstall.packages(\"caret\")  # Install if not already installed\ninstall.packages(\"pROC\")   # Install if not already installed\ninstall.packages(\"glmnet\") # Install if not already installed\nlibrary(caret)\nlibrary(pROC)\nlibrary(glmnet)\n\n# Prepare binary dataset\ndata(iris)\niris_binary &lt;- iris[iris$Species != \"setosa\", ]\niris_binary$Species &lt;- factor(iris_binary$Species)\n\n# Split the data into training and test sets\nset.seed(42)\ntrainIndex &lt;- createDataPartition(iris_binary$Species, p = 0.8, list = FALSE)\ntrain_data &lt;- iris_binary[trainIndex, ]\ntest_data &lt;- iris_binary[-trainIndex, ]\n\n# Convert the data into matrix format as required by glmnet\nx_train &lt;- model.matrix(Species ~ ., train_data)[,-1]\ny_train &lt;- train_data$Species\n\nx_test &lt;- model.matrix(Species ~ ., test_data)[,-1]\ny_test &lt;- test_data$Species\n\n# Set up cross-validation for Lasso regression on the training data\ntrain_control &lt;- trainControl(method = \"cv\", number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)\n\n# Define the lasso model using glmnet (alpha=1 for Lasso)\nlasso_model &lt;- train(x = x_train, y = y_train, method = \"glmnet\", trControl = train_control, tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.1, by = 0.001)), family = \"binomial\", metric = \"ROC\")\n\n# Make predictions on the test set\ntest_predictions &lt;- predict(lasso_model, newdata = x_test, type = \"prob\")[,2]\n\n# Plot ROC curve for the test set\nroc_curve_test &lt;- roc(y_test, test_predictions, levels = rev(levels(y_test)))\nplot(roc_curve_test, col = \"blue\", lwd = 2, main = \"ROC Curve for Lasso Regression on Test Data\")\nv\n# Calculate AUC and its 95% confidence interval\nauc_value &lt;- auc(roc_curve_test)\nci &lt;- ci.auc(roc_curve_test, conf.level = 0.95)\n\n# Add AUC with 95% confidence interval to the plot\nlegend_text &lt;- paste(\"AUC =\", round(auc_value, 2), \"\\n95% CI:\", round(ci[1], 2), \"-\", round(ci[3], 2))\nlegend(\"bottomright\", legend = legend_text, col = \"blue\", lwd = 2)\nOn completion of the analysis, the user may have additional questions or requests. For example, they may ask why use 10 folds specifically? Or why split the 80:20? Why use the lasso regression model?\nThey can just ask the chatbot directly.\nPronpt: why split the data set if we’re doing 10-fold cross validation?\nChatGPT answer: ### Why Not Split? - 10-fold CV inherently splits the data multiple times\n- Each fold acts as a validation set once, while the remaining 9 folds serve as the training set. - Every observation is used for both training and testing across different iterations.\n\nAn additional 80:20 split is redundant\n\nIt would unnecessarily reduce the amount of data available for training.\nK-fold CV already provides a better estimate of model performance.\n\n\n\n1.2.1 When Would We Still Use an 80:20 Split?\n\nIf we want one final test set to evaluate model performance after tuning hyperparameters using K-fold CV.\n\nExample: Use 80% for training, perform 10-fold CV on this training set, and then evaluate on the held-out 20% test set.\nThis prevents data leakage and ensures the final model is evaluated on completely unseen data.\n\n\n\n\n\n1.2.2 Best Practice for Model Selection\n\nCross-validation alone (no 80:20 split)\n\nWhen optimizing model parameters and assessing performance.\n\nAvoids unnecessary data loss.\n\nEvery observation contributes to both training and validation.\n\n80:20 Split + Cross-validation on training set\n\nIf we want to train the final model on the full dataset,\n\nThen evaluate generalization on a completely independent holdout test set.\n\n\nFor your Fisher Iris dataset analysis, just using 10-fold CV is sufficient unless you plan to tune hyperparameters before a final evaluation. 🚀 for a 95% confidence interval calculationgM “should I split my data set into train and test parts if I’m using k-fold cross-validation?” “add a 95% confidence interval calculation to the AUC annotation in the ROC plot” “do the same analysis but use lasso regression instead of logistic regression”"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-1-setting-up-the-package-structure",
    "href": "blog/chatbots-in-stats/index.html#step-1-setting-up-the-package-structure",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.1 Step 1: Setting Up the Package Structure",
    "text": "6.1 Step 1: Setting Up the Package Structure\n\nCreate a New Package Directory:\n\nUse usethis to create a package directory:\nusethis::create_package(\"path/to/zzlongplot\")\nThis sets up the necessary directory structure with folders like R/ and files like DESCRIPTION.\n\nAdd the Core Script:\n\nPlace the zzlongplot.R file in the R/ directory.\n\nSet Up the DESCRIPTION File:\n\nEdit the DESCRIPTION file to include metadata about the package. Use usethis::use_description() to create and fill this file:\nusethis::use_description(fields = list(\n  Title = \"Flexible Longitudinal Plotting in R\",\n  Description = \"Provides tools for generating observed and change plots in longitudinal datasets.\",\n  Version = \"0.1.0\",\n  Author = \"Your Name [aut, cre]\",\n  Maintainer = \"Your Name &lt;your_email@example.com&gt;\",\n  License = \"MIT\",\n  Encoding = \"UTF-8\"\n))\n\nAdd Dependencies:\n\nList package dependencies in the DESCRIPTION file under Imports. For example:\nImports:\n  dplyr,\n  ggplot2,\n  patchwork"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-2-document-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-2-document-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.2 Step 2: Document the Package",
    "text": "6.2 Step 2: Document the Package\n\nAdd Roxygen2 Comments:\n\nEnsure all functions in zzlongplot.R have Roxygen2 comments for documentation.\n\nGenerate Documentation:\n\nRun:\ndevtools::document()\nThis creates help files in the man/ directory and updates the NAMESPACE file.\n\nCreate a Vignette:\n\nAdd the vignette to introduce the package:\nusethis::use_vignette(\"Introduction_to_zzlongplot\")\nPlace the provided zzlongplot-vignette.Rmd file in the vignettes/ directory and build it:\ndevtools::build_vignettes()"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-3-test-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-3-test-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.3 Step 3: Test the Package",
    "text": "6.3 Step 3: Test the Package\n\nAdd Unit Tests:\n\nUse usethis to set up a testing framework:\nusethis::use_testthat()\nPlace the test-zzlongplot.R file in tests/testthat/.\n\nRun Tests:\n\nRun all tests:\ndevtools::test()"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-4-check-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-4-check-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.4 Step 4: Check the Package",
    "text": "6.4 Step 4: Check the Package\n\nBuild and Check:\n\nBuild the package:\ndevtools::build()\nCheck the package for CRAN compliance:\ndevtools::check()\n\nFix Issues:\n\nAddress any warnings or errors reported by devtools::check()."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-5-submit-to-cran",
    "href": "blog/chatbots-in-stats/index.html#step-5-submit-to-cran",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.5 Step 5: Submit to CRAN",
    "text": "6.5 Step 5: Submit to CRAN\n\nPrepare for Submission:\n\nEnsure the package passes R CMD check with no warnings, errors, or notes.\nCompress the package into a .tar.gz file using:\ndevtools::build()\n\nSubmit to CRAN:\n\nGo to the CRAN submission page.\nUpload the .tar.gz file and fill out the required metadata.\n\nRespond to Feedback:\n\nCRAN maintainers might request changes. Address them promptly and resubmit if needed."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-6-set-up-a-github-repository",
    "href": "blog/chatbots-in-stats/index.html#step-6-set-up-a-github-repository",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.6 Step 6: Set Up a GitHub Repository",
    "text": "6.6 Step 6: Set Up a GitHub Repository\n\nInitialize a Git Repository:\n\nIn the package directory, run:\ngit init\ngit add .\ngit commit -m \"Initial commit\"\n\nCreate a Repository on GitHub:\n\nUse the GitHub website or the gh CLI tool:\ngh repo create yourusername/zzlongplot --public --source=.\n\nPush the Code:\n\nPush the code to GitHub:\ngit branch -M main\ngit push -u origin main"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-7-manage-the-development-repository",
    "href": "blog/chatbots-in-stats/index.html#step-7-manage-the-development-repository",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.7 Step 7: Manage the Development Repository",
    "text": "6.7 Step 7: Manage the Development Repository\n\nAdd Version Control:\n\nUse Git for version control. For example, create a branch for new features:\ngit checkout -b feature-new-plot\n\nTag Releases:\n\nTag versions for releases:\ngit tag -a v0.1.0 -m \"First release\"\ngit push origin v0.1.0\n\nAdd Continuous Integration:\n\nSet up GitHub Actions for testing:\nusethis::use_github_action_check_standard()\n\nPublish Development Versions:\n\nUse GitHub to manage development versions and issues."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-8-maintain-the-package",
    "href": "blog/chatbots-in-stats/index.html#step-8-maintain-the-package",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.8 Step 8: Maintain the Package",
    "text": "6.8 Step 8: Maintain the Package\n\nAddress Issues:\n\nMonitor and address issues reported by users.\n\nUpdate the Package:\n\nFor updates, increment the version number in DESCRIPTION and tag the new version."
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#prerequisites",
    "href": "blog/chatbots-in-stats/index.html#prerequisites",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.9 Prerequisites",
    "text": "6.9 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#step-by-step-implementation",
    "href": "blog/chatbots-in-stats/index.html#step-by-step-implementation",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.10 Step-by-Step Implementation",
    "text": "6.10 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#key-takeaways",
    "href": "blog/chatbots-in-stats/index.html#key-takeaways",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.11 Key Takeaways",
    "text": "6.11 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/chatbots-in-stats/index.html#further-reading",
    "href": "blog/chatbots-in-stats/index.html#further-reading",
    "title": "Making optimal use of ChatGPT and other chatbots for data science",
    "section": "6.12 Further Reading",
    "text": "6.12 Further Reading\nIn development"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Thomas Lab",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n\n  \n  \nThe Thomas Lab in the Herbert Wertheim School of Public Health and Human Longevity Science at UC San Diego focuses on developing data science methodology and educational materials. Our work spans statistical computing, reproducible research practices, and modern tools for data analysis."
  },
  {
    "objectID": "about/index.html#research-focus",
    "href": "about/index.html#research-focus",
    "title": "About Thomas Lab",
    "section": "1 Research Focus",
    "text": "1 Research Focus\nOur lab specializes in:\n\nStatistical methodologies for health research\nR package development for specialized analysis needs\nReproducible research workflows and best practices\nEducational materials for data science skills in public health\nApplications of machine learning in longitudinal studies"
  },
  {
    "objectID": "about/index.html#tools-expertise",
    "href": "about/index.html#tools-expertise",
    "title": "About Thomas Lab",
    "section": "2 Tools & Expertise",
    "text": "2 Tools & Expertise\n\n\n2.1 R Programming\n\nPackage development\nStatistical modeling\nData visualization\nReproducible reporting\n\n\n\n2.2 Research Computing\n\nDocker containerization\nCloud-based computing\nHigh-performance computing\nCollaborative workflows\n\n\n\n2.3 Education\n\nWorkshop development\nTutorial creation\nOpen educational resources\nMentoring and guidance"
  },
  {
    "objectID": "about/index.html#team",
    "href": "about/index.html#team",
    "title": "About Thomas Lab",
    "section": "3 Team",
    "text": "3 Team\nOur interdisciplinary team brings together expertise in statistics, computer science, and public health research to address complex challenges in health data analysis."
  },
  {
    "objectID": "about/index.html#collaborations",
    "href": "about/index.html#collaborations",
    "title": "About Thomas Lab",
    "section": "4 Collaborations",
    "text": "4 Collaborations\nWe actively collaborate with researchers across disciplines to apply novel methodological approaches to real-world health and longevity challenges. If you’re interested in working together, please get in touch!"
  },
  {
    "objectID": "about/index.html#publications",
    "href": "about/index.html#publications",
    "title": "About Thomas Lab",
    "section": "5 Publications",
    "text": "5 Publications\nSelected recent publications:\n\nAuthor A, Author B, Thomas RG (2024). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor C, Author D, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor E, Author F, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages."
  },
  {
    "objectID": "about/index.html#contact",
    "href": "about/index.html#contact",
    "title": "About Thomas Lab",
    "section": "6 Contact",
    "text": "6 Contact\nFor inquiries about collaboration, research opportunities, or educational resources, please reach out through the social media links above or email us directly."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html",
    "href": "blog/2025-01-01-year-ahead.html",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "",
    "text": "As we start 2025, I’m excited to share some thoughts on where I’m heading with R programming, data science tools, and research computing workflows."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "href": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "1 This Year’s Focus Areas",
    "text": "1 This Year’s Focus Areas\nPackage Development: Planning to release two new R packages focusing on statistical visualization and research workflow automation.\nDocker Integration: Expanding my containerization work to include more complex multi-service setups for data science teams.\nAI-Assisted Coding: Exploring how LLMs can enhance R development workflows without replacing fundamental programming skills."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "href": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "2 What’s Coming to the Blog",
    "text": "2 What’s Coming to the Blog\nYou’ll see more content in our new structure: - Tutorials on advanced R topics - References for quick command lookups\n- Guides for solving specific problems - Blog posts like this for timely thoughts and updates\nLooking forward to sharing the journey!"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here you’ll find my latest thoughts on R programming, data science, statistical computing, and research workflows. These posts capture timely insights, new discoveries, and evolving perspectives on technical topics.\nBrowse by category or scroll through the chronological feed below.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nCoding with Generative AI\n\n\n\nAI-Automation\n\n\nProgramming-Development\n\n\n\nHow to effectively use AI tools like ChatGPT and GitHub Copilot for coding while maintaining good practices\n\n\n\nJun 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMac Workflow for Tracking Daily Research Progress\n\n\n\n\n\n\nJun 30, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaking optimal use of ChatGPT and other chatbots for data science\n\n\nAI-powered data science workflows\n\n\n\nAI\n\n\nautomation\n\n\nR\n\n\ndata-science\n\n\n\nHow ChatGPT and other LLM tools can enhance statistical analysis and research workflows.\n\n\n\nJan 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLooking Ahead: 2025 Plans for R and Data Science\n\n\nNew directions and goals for the year\n\n\n\nreflection\n\n\nplanning\n\n\nR\n\n\ndata-science\n\n\n\nMy plans and goals for R programming, data science, and research computing in 2025.\n\n\n\nJan 1, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html",
    "href": "guides/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "href": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesn’t exist or package isn’t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#data-type-errors",
    "href": "guides/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#subsetting-errors",
    "href": "guides/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesn’t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#missing-values-issues",
    "href": "guides/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions can’t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#file-reading-errors",
    "href": "guides/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R can’t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#memory-issues",
    "href": "guides/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#package-installation-issues",
    "href": "guides/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package won’t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "href": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#prevention-strategies",
    "href": "guides/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Lab",
    "section": "",
    "text": "I’m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub • Twitter • About"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Thomas Lab",
    "section": "",
    "text": "I’m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub • Twitter • About"
  },
  {
    "objectID": "misc/index.html",
    "href": "misc/index.html",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#software-and-tools",
    "href": "misc/index.html#software-and-tools",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#resources-and-references",
    "href": "misc/index.html#resources-and-references",
    "title": "Misc",
    "section": "2 Resources and References",
    "text": "2 Resources and References\n\n2.1 Quick References\n\nCommand cheat sheets\nConfiguration snippets\nCommon patterns\nTroubleshooting guides\n\n\n\n2.2 External Links\n\nUseful websites and tools\nCommunity forums and discussions\nDocumentation and manuals\nProfessional resources"
  },
  {
    "objectID": "misc/index.html#personal-projects",
    "href": "misc/index.html#personal-projects",
    "title": "Misc",
    "section": "3 Personal Projects",
    "text": "3 Personal Projects\n\n3.1 Open Source Contributions\n\nSoftware packages and libraries\nDocumentation improvements\nBug fixes and feature requests\nCommunity support\n\n\n\n3.2 Experimental Work\n\nProof-of-concept implementations\nTechnology explorations\nSide projects and demos\nLearning exercises\n\n\nThis section contains miscellaneous content that doesn’t fit neatly into other categories - tools, references, personal projects, and various resources that might be useful to others."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim is a powerful and efficient text editor that, with the right setup, can serve as a productive environment for data science work in Python, Julia, and R. This guide will walk you through the essential plugins and configurations to transform Vim into a fully functional IDE for data science.\n\n\n\nLightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage.\n\n\n\n\nA plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins.\n\n\n\nPlug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim\n\n\n\nPlug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']\n\n\n\nPlug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle\n\n\n\n\nPlug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1\n\n\n\nPlug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline.\n\n\n\nPlug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code.\n\n\n\nPlug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets.\n\n\n\nPlug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R.\n\n\n\nPlug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode\n\n\n\n\nScreenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science.\n\n\n\n\nWith this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!\n\n\n\n\n\n\nVim Editor"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Lightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "A plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Screenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "With this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim Editor"
  },
  {
    "objectID": "posts/drafts.html",
    "href": "posts/drafts.html",
    "title": "Draft Posts",
    "section": "",
    "text": "No Draft Posts Currently\n\n\n\nThere are currently no draft posts in development. Posts marked with draft: true in their YAML frontmatter will appear here instead of the main blog listing."
  },
  {
    "objectID": "posts/drafts.html#how-to-create-draft-posts",
    "href": "posts/drafts.html#how-to-create-draft-posts",
    "title": "Draft Posts",
    "section": "1 How to Create Draft Posts",
    "text": "1 How to Create Draft Posts\nPosts marked as drafts are excluded from: - Main blog listing - RSS feeds\n- Site search indexing - External link sharing\nTo create a draft post: 1. Add draft: true to the post’s YAML frontmatter 2. The post will appear on this page instead of the main blog\nTo publish a draft: 1. Remove the draft: true line from the post’s YAML frontmatter 2. The post will appear on the main blog listing\nUsing the draft management script:\n# Mark a post as draft\n./manage_drafts.sh draft posts/my-post/\n\n# Publish a draft\n./manage_drafts.sh publish posts/my-post/"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html",
    "href": "posts/share_R_code_via_docker_p25/index.html",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "",
    "text": "Reproducibility is key to conducting data analysis, yet in practice, achieving it consistently with R workflows can be quite challenging. R projects frequently break when transferred between computers due to mismatched R versions, package dependencies, or inconsistent project organization. This white paper describes an approach to solving this problem by combining three tools: zzrrtools for creating structured research compendia, renv for R package management, and Docker for containerizing the computing environment. Together, these tools ensure that an R workflow runs identically across different computers by providing standardized project structure, identical R packages and versions, consistent R versions, and the same operating system libraries as the original setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "href": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "1.1 The Challenge of Reproducibility in R",
    "text": "1.1 The Challenge of Reproducibility in R\nR has become a standard tool for data science and statistical analysis across numerous scientific disciplines. However, as R projects grow in complexity, they often develop complex webs of dependencies that can make sharing and reproducing analyses difficult. Some common challenges include:\n\nDifferent R versions across machines\nIncompatible package versions\nMissing system-level dependencies\nOperating system differences (macOS vs. Windows vs. Linux)\nConflicts with other installed packages\nR startup files (.Rprofile, .Renviron, .RData) that can affect code behavior\n\nThese challenges often manifest as the frustrating “it works on my machine” problem, where analysis code runs perfectly for the original author but fails when others attempt to use it. This undermines the scientific and collaborative potential of R-based analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "href": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "1.2 A Three-Level Solution",
    "text": "1.2 A Three-Level Solution\nTo address these challenges, we need to tackle reproducibility at three distinct levels:\n\nProject-level reproducibility: Ensuring consistent project structure and organization using research compendium standards\nPackage-level reproducibility: Ensuring exact package versions and dependencies are maintained\nSystem-level reproducibility: Guaranteeing consistent R versions, operating system, and system libraries\n\nThe strategy presented in this white paper leverages zzrrtools for project-level structure, renv for package-level consistency, and Docker for system-level consistency. When combined, they provide a framework for end-to-end reproducible R workflows with proper research compendium organization.\nWith this three-level framework established, we can now examine how each tool addresses its specific layer of reproducibility. We begin with zzrrtools, which tackles the foundational challenge of project-level organization and provides the structural framework upon which package and system-level reproducibility can be built."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.1 What is zzrrtools?",
    "text": "2.1 What is zzrrtools?\nzzrrtools is a Docker-first framework that creates reproducible research compendia with containerized development workflows. The framework extends the research compendium concept introduced by Ben Marwick’s rrtools, adding container-based development and automated dependency validation. Team members install zzrrtools once on their system, then can create or join any zzrrtools-based project using the same framework. A research compendium organizes digital research materials to enable others to inspect, reproduce, and extend the research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.2 Key Features of zzrrtools",
    "text": "2.2 Key Features of zzrrtools\nzzrrtools creates containerized research compendia with these key features:\n\nDocker-first development: All workflows operate within containers, eliminating “works on my machine” issues\nCentralized framework: One-time zzrrtools installation enables consistent project creation and team collaboration\nMulti-service architecture: Provides specialized Docker environments for interactive R sessions, shell development, and paper rendering\nFlexible base images: Choice of minimal (rocker/r-ver) or pre-packaged (rgt47/r-pluspackages) Docker templates with common R packages\nAdvanced dependency validation: Automated renv consistency checking with CRAN verification and pre-commit validation\nShell-based workflows: Optimized for command-line development with rich automation via Make targets\nTeam collaboration focus: Designed for multi-developer teams working on shared research projects"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-self-replicating-collaboration",
    "href": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-self-replicating-collaboration",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.3 zzrrtools Workflow: Self-Replicating Collaboration",
    "text": "2.3 zzrrtools Workflow: Self-Replicating Collaboration\nThe zzrrtools workflow is designed for team collaboration:\n# Project creator initializes the research compendium\n~/prj/zzrrtools/zzrrtools.sh [OPTIONS]\n\n# Available options:\n#   --dotfiles DIR       Copy personal dotfiles (with leading dots)\n#   --dotfiles-nodot DIR Copy dotfiles (without leading dots) \n#   --base-image NAME    Use custom Docker base image (default: rocker/r-ver)\n#                        Popular options: rgt47/r-pluspackages (includes tidyverse)\n#   --no-docker          Skip Docker image build\n#   --next-steps         Show workflow guidance\nThis creates a Docker-first research compendium with:\n\nFramework-based setup using centrally installed zzrrtools for consistent project creation\nMulti-service Docker architecture for interactive R, shell, and rendering\nAdvanced renv validation with CRAN verification and pre-commit checking\nDual-track automation supporting both native R and Docker workflows\nNavigation shortcuts via symbolic links (a→data, p→paper, s→scripts)\nDeveloper environment integration with personal dotfiles support\nTeam synchronization via automated dependency validation\n\nTeam members can collaborate after one-time zzrrtools installation:\n# One-time zzrrtools installation\ngit clone zzrrtools-repo ~/prj/zzrrtools\ncd ~/prj/zzrrtools && ./install.sh  # Creates zzrrtools command in PATH\n\n# Per-project workflow\ngit clone project-repo && cd project-repo\nzzrrtools  # Set up project environment (command available anywhere)\nmake docker-r   # Start interactive R session\n\n2.3.1 Integrated renv Consistency Checking\nThe workflow includes advanced renv management through the check_renv_for_commit.R script, which provides automated dependency validation and team conflict prevention. This script:\n\nScans multiple directories (R/, scripts/, analysis/) for package dependencies\nValidates against CRAN to ensure packages exist and are properly named\n\nSynchronizes dependencies across code files, DESCRIPTION, and renv.lock\nProvides automated fixes to maintain team environment consistency\nIntegrates with CI/CD for fail-fast validation workflows\n\nUsage examples:\n# Interactive dependency checking (development)\nRscript check_renv_for_commit.R\n\n# Auto-fix dependency issues\nRscript check_renv_for_commit.R --fix\n\n# CI/CD validation with fail-fast\nRscript check_renv_for_commit.R --fix --fail-on-issues --quiet\n\n# Via Make targets (recommended)\nmake check-renv          # Check dependencies\nmake check-renv-fix      # Fix dependency issues\nmake docker-check-renv-fix  # Fix in container\nThis approach ensures collaborators can reliably reproduce package environments and CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "href": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.4 Research Compendium Structure",
    "text": "2.4 Research Compendium Structure\nThe zzrrtools setup creates a directory structure that follows research compendium best practices. The structure includes organized data folders, analysis directories, testing frameworks, and workflows.\nKey organizational principles:\n\nData management: Separate folders for raw, derived, and external data with proper documentation\nAnalysis workflow: Dedicated spaces for papers, figures, tables, and working scripts\n\nPackage structure: R package organization with documentation and testing\nIntegration support: Works with Docker, GitHub Actions, and build systems\n\nThis organizational framework provides the foundation for reproducible research while supporting team collaboration and automated workflows."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.5 Iterative Development Workflow",
    "text": "2.5 Iterative Development Workflow\nFor collaborative analysis development, the research compendium structure supports a phased approach that balances rapid iteration with publication-quality outputs:\n\n2.5.1 Phase 1: Exploration & Development (scripts/)\nDuring active analysis development, team members should work primarily in the scripts/ directory:\nscripts/\n├── 01_data_exploration.R\n├── 02_penguin_correlations.R  \n├── 03_species_analysis.R\n├── 04_body_mass_analysis.R    # Additional analysis\n└── 05_visualization_experiments.R\nBenefits of script-based development: - Fast iteration: No need to knit/render documents during development - Interactive debugging: Can run code line-by-line in R console - Version control friendly: Pure R files produce clean diffs in Git - Easy collaboration: Contributors can add numbered script files - Flexible experimentation: Quick to test ideas and approaches\n\n\n2.5.2 Phase 2: Function Extraction (R/)\nAs analysis patterns emerge, extract reusable functions to the R/ directory:\n# R/penguin_utils.R\ncalculate_species_correlation &lt;- function(data, x_var, y_var, \n                                          species_filter = NULL) {\n  # Reusable function extracted from scripts\n  if (!is.null(species_filter)) {\n    data &lt;- data[data$species == species_filter, ]\n  }\n  cor(data[[x_var]], data[[y_var]], use = \"complete.obs\")\n}\n\ncreate_species_plot &lt;- function(data, x_var, y_var) {\n  # Standardized plotting function\n  ggplot(data, aes_string(x = x_var, y = y_var, \n                          color = \"species\")) +\n    geom_point() +\n    theme_minimal()\n}\n\n\n2.5.3 Phase 3: Publication Integration (analysis/paper/)\nOnce analysis approaches stabilize, integrate polished results into the manuscript:\n# In analysis/paper/paper.Rmd\n# Option 1: Source complete scripts\nsource(\"../../scripts/02_penguin_correlations.R\")\nsource(\"../../scripts/04_body_mass_analysis.R\")\n\n# Option 2: Use extracted functions\nlibrary(here)\nsource(here(\"R\", \"penguin_utils.R\"))\n\ncorrelation_result &lt;- calculate_species_correlation(\n  penguins, \"flipper_length_mm\", \"bill_length_mm\"\n)\n\n\n2.5.4 Recommended Collaborative Workflow:\n\nProject initialization: Project maintainer runs zzrrtools.sh to create project structure\nImmediate containerization: Build Docker container and switch to container-based development from day one\nInitial development: Create exploratory scripts in scripts/ directory inside the container\nCollaborative iteration: Team members clone repo, build identical container, add additional script files through pull requests from within the container\nCode review in scripts: Both developers refine analysis logic in script files while working in identical Docker environments\nFunction extraction: Move stable, reusable code to R/ directory\nPaper integration: Source scripts or use functions in analysis/paper/paper.Rmd\nContinuous validation: All development and testing occurs within the containerized environment\n\nWhy this container-first approach works:\n\nReproducibility: Eliminates “works on my machine” problems from day one\nIdentical environments: All collaborators work in exactly the same computational environment\nNo environment drift: Cannot occur when everyone develops within containers\nSpeed: Script development is faster than R Markdown knitting\nModularity: Each script can focus on a specific analysis aspect\nTestability: Functions in R/ can be easily unit tested in the same environment they’ll run in production\nSimple collaboration: Environment setup becomes a one-time docker build command for all contributors\nDevelopment-production parity: The development environment IS the production environment\n\nThis container-first, phased approach gives collaborators the speed of script-based development during exploration while maintaining the reproducibility and narrative flow of literate programming for final outputs. Most importantly, it ensures that all development occurs within the exact computational environment that will be used for final analysis and publication.\nWhile zzrrtools establishes the organizational foundation for reproducible research, it relies on consistent R package environments to function effectively across different systems. The directory structure and R package framework created by zzrrtools becomes most useful when combined with precise dependency management. This is where renv becomes essential, providing the package-level consistency that complements zzrrtools’ structural approach."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.1 What is renv?",
    "text": "3.1 What is renv?\nrenv (Reproducible Environment) is an R package designed to create isolated, project-specific library environments. Instead of relying on a shared system-wide R library that might change over time, renv gives each project its own separate collection of packages with specific versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.2 Key Features of renv",
    "text": "3.2 Key Features of renv\n\nIsolated project library: renv creates a project-specific library (typically in renv/library) containing only the packages used by that project. This isolation ensures that updates or changes to packages in one project won’t affect others.\nLockfile for dependencies: When you finish installing or updating packages, renv::snapshot() produces a renv.lock file - a JSON document listing each package and its exact version and source. This lockfile is designed to be committed to version control and shared.\nEnvironment restoration: On a new machine (or when reproducing past results), renv::restore() installs the exact versions of packages specified in the lockfile. This creates an R package environment identical to the one that created the lockfile, provided the same R version is available. The R version is important since critical components of the R system, such as random number generation, and default factor handling policy vary between versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.3 Basic renv Workflow",
    "text": "3.3 Basic renv Workflow\nThe typical workflow with renv involves:\n# One-time installation of renv\ninstall.packages(\"renv\")\n\n# Initialize renv for the project\nrenv::init()  # Creates renv infrastructure\n\n# Install project-specific packages\n# ...\n\n# Save the package state to renv.lock\nrenv::snapshot()\n\n# Later or on another system...\nrenv::restore()  # Restore packages from renv.lock\nWhile renv successfully addresses package-level reproducibility by ensuring identical R package versions across environments, even perfect package consistency cannot prevent analyses from failing or producing different results due to variations in R versions, operating systems, or system-level dependencies. A complete reproducibility solution requires addressing these system-level differences, which is where Docker containerization becomes essential."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.1 What is Docker?",
    "text": "4.1 What is Docker?\nDocker is a platform that allows you to package software into standardized units called containers. A Docker container is like a lightweight virtual machine that includes everything needed to run an application: the code, runtime, system tools, libraries, and settings."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "href": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.2 Docker’s Role in Reproducibility",
    "text": "4.2 Docker’s Role in Reproducibility\nWhile renv handles R packages, Docker ensures consistency for:\n\nOperating system: The specific Linux distribution or OS version\nR interpreter: The exact R version\nSystem libraries: Required C/C++ libraries and other dependencies\nComputational environment: Memory limits, CPU configuration, etc.\nExternal tools: pandoc, LaTeX, and other utilities needed for R Markdown\n\nBy running an R Markdown project in Docker, you eliminate differences in OS or R installation as potential sources of irreproducibility. Any machine running Docker will execute the container in an identical environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#docker-components-for-r-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#docker-components-for-r-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.3 Docker Components for R Workflows",
    "text": "4.3 Docker Components for R Workflows\nFor R-based projects, a typical Docker approach involves:\n\nBase image: Starting from a pre-configured R image (e.g., from the Rocker project)\nDependencies: Adding system and R package dependencies\nConfiguration: Setting working directories and environment variables\nContent: Adding project files\nExecution: Defining how the project should run\n\nThe zzrrtools setup uses a streamlined Dockerfile based on rocker/r-ver with TinyTeX for LaTeX support. The R version is matched to the renv.lock file:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Prevent interactive prompts\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install minimal system dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    pandoc \\\n    vim \\\n    git \\\n    curl \\\n    fonts-dejavu \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/bash ${USERNAME}\n\n# Set user R library path\nENV R_LIBS_USER=/home/${USERNAME}/R/library\n\n# Create user R library directory and assign permissions\nRUN mkdir -p /home/${USERNAME}/R/library && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/R\n\n# Set working directory\nWORKDIR /home/${USERNAME}\n\n# Copy renv files with correct ownership\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R ./renv/\n\n# Switch to non-root user\nUSER ${USERNAME}\n\n# Install base R packages to user library\nRUN Rscript -e '.libPaths(Sys.getenv(\"R_LIBS_USER\")); \\\n    install.packages(c(\"tinytex\", \"rmarkdown\", \"renv\"), \\\n    repos = \"https://cloud.r-project.org\")'\n\n# Install TinyTeX in user directory\nRUN Rscript -e 'tinytex::install_tinytex()'\n\n# Add TinyTeX binaries to PATH\nENV PATH=/home/${USERNAME}/.TinyTeX/bin/x86_64-linux:$PATH\n\n# Restore R packages via renv\nRUN Rscript -e '.libPaths(Sys.getenv(\"R_LIBS_USER\")); \\\n    renv::restore()'\n\n# Default to interactive shell\nCMD [\"/bin/bash\"]\nThis configuration provides a minimal R installation with LaTeX support for PDF rendering and secure non-root user execution.\nDocker Compose Integration:\nThe setup also includes a docker-compose.yml that provides multiple development environments:\n# Multiple services for different workflows\nservices:\n  r-session:   # Interactive R session  \n  bash:        # Bash shell access\n  research:    # Automated paper rendering\n  test:        # Package testing\n  check:       # Package checking\nThis allows developers to choose their preferred development environment while maintaining identical package dependencies and system configuration."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "href": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "5.1 Why Use All Three?",
    "text": "5.1 Why Use All Three?\nUsing any single tool improves reproducibility, but combining all three provides the most complete solution:\n\nzzrrtools provides standardized project structure and research compendium organization\nrenv guarantees the R packages and their versions\nDocker guarantees the OS and R version\nTogether they achieve end-to-end reproducibility from project organization through package dependencies to operating system consistency\n\nThis approach creates a fully portable, well-organized research compendium that can be shared and will produce identical results across different computers while following established research best practices."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-governance-model",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-governance-model",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "5.2 Integration Strategy with Governance Model",
    "text": "5.2 Integration Strategy with Governance Model\nThe workflow integrates zzrrtools, renv, and Docker with a clear governance structure suitable for multi-developer research teams:\nProject Maintainer Role: - Creates and maintains the research compendium structure - Manages renv environment and package dependencies using consistency checking - Updates and maintains Docker images - Reviews and approves contributor changes - Runs renv validation before accepting pull requests\nContributor Role (Other Developers): - Access the private research compendium as invited collaborators - Add analysis content, papers, and documentation using feature branches - Propose new package dependencies through contributions - Submit changes via pull requests from feature branches\nWorkflow Steps:\n\nInitialize Research Compendium (Maintainer):\n\nCreate standardized project structure using zzrrtools framework\nSet up analysis directories with data organization\nInitialize renv environment with renv::init()\nCreate Dockerfile with container configuration\n\nEstablish Development Environment (Maintainer):\n\nInstall required packages and develop initial analysis\nCreate tests for analytical functions\nUse the renv consistency checker to validate and create initial lockfile:\n# Validate dependencies and create snapshot\nRscript check_renv_for_commit.R --fix\nBuild and test Docker image locally\n\nMaintain Infrastructure (Maintainer):\n\nReview contributor pull requests for package additions\nUse renv consistency checker to validate and update dependencies:\n# Validate contributor's package requirements\nRscript check_renv_for_commit.R --fail-on-issues\n\n# If validation passes, update environment\nRscript check_renv_for_commit.R --fix\nUpdate renv.lock by selectively incorporating new dependencies\nRebuild Docker images when system dependencies change\nPush updated images to container registry (Docker Hub, GitHub Container Registry)\n\nCollaborative Development (All Developers):\nResearch Compendium Files in GitHub Repository:\n\nProject Structure: DESCRIPTION, LICENSE, README.qmd (zzrrtools-generated)\nAnalysis Content: Files in analysis/paper/ directory (R Markdown manuscripts)\nDependencies: renv.lock (managed by maintainer), renv/activate.R\nInfrastructure: Dockerfile (maintained by project maintainer)\nCode: R/ directory (utility functions), tests/ directory\nDocumentation: Generated README files and project documentation\nConfiguration: .gitignore, .github/ (CI/CD workflows)\n\nSharing the Docker image using Docker Hub:\nDocker Hub provides public image hosting that enables reproducible research by sharing computational environments while protecting private research code in GitHub.\nDocker Hub (Recommended for Reproducible Research)\n# Build the image with GitHub Container Registry URL\ndocker build -t ghcr.io/username/penguins_analysis:v1.0 .\n\n# Login to GitHub Container Registry (using GitHub Personal Access Token)\necho $GITHUB_TOKEN | docker login ghcr.io -u username \\\n  --password-stdin\n\n# Push to GitHub Container Registry (automatically private)\ndocker push ghcr.io/username/penguins_analysis:v1.0\nSetting up GitHub Personal Access Token:\nCreate a Personal Access Token with the required permissions for container registry operations. The token must include write:packages and read:packages scopes, plus repo access for private repositories.\nFor detailed step-by-step instructions, see Appendix A: GitHub Personal Access Token Setup.\n# Export token as environment variable (replace with your actual token)\nexport GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n# Login and push\necho $GITHUB_TOKEN | docker login ghcr.io -u username \\\n  --password-stdin\ndocker build -t ghcr.io/username/penguins_analysis:v1.0 .\ndocker push ghcr.io/username/penguins_analysis:v1.0\nNote: If you get a “permission_denied” error when pushing, ensure your token includes the correct scopes (see Appendix A for details).\nGitHub Container Registry Benefits:\n\nFree tier: 0.5GB storage included, no billing currently active\nAutomatic access control: Inherits repository permissions\nIntegrated with GitHub Actions: Direct authentication in CI/CD\nSimple team sharing: Repository collaborators automatically have access\nPackage management: Integrated with GitHub Packages ecosystem\n\nDocker Workflow:\nThe zzrrtools setup provides multiple approaches for working with containers, from simple Make commands to direct Docker execution. Make commands offer simplicity:\n# Build and run with Make (recommended)\nmake docker-build    # Build the container\nmake docker-r        # Interactive R session\nmake docker-render   # Render research paper\nFor Docker workflow options including Docker Compose and direct commands, see Appendix D: Docker Workflow Options.\nExecute consistently:\n\nRun analyses in the Docker container for guaranteed reproducibility\nUse volume mounts to access local files while maintaining environment consistency\nRun tests within the container to verify functionality\n\n\nThis strategy ensures that your R Markdown documents and analyses will run identically for anyone who has access to your Docker container, regardless of their local setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "href": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.1 Project Scenario",
    "text": "6.1 Project Scenario\nA team of data scientists collaborates on Palmer Penguins analysis using zzrrtools’ Docker-first workflow that eliminates environment setup friction:\n\nJoe (joe): Project maintainer who initializes the repository\nSam (sam): Contributor who extends the analysis\n\nAdditional team members: Can join without any local R installation\n\nThe collaboration model emphasizes zero-setup team onboarding through self-replicating project distribution and containerized development environments.\n\nCollaboration Philosophy: - Self-contained projects: Each repository includes its own setup script - Container-first development: All work happens in identical Docker environments - Automated dependency validation: Pre-commit checks prevent conflicts - Shell-based workflows: Command-line tools for maximum flexibility\n\nKey Workflow Principles: - Joe initializes with zzrrtools and commits the setup script to the repository - Team members run the included script - no separate installation required - All development occurs in containers for perfect environment consistency - Dependency changes are validated before commits to prevent team conflicts - Each developer works in identical environments regardless of host system"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "href": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.2 Implementation Example",
    "text": "6.2 Implementation Example\n\n6.2.1 Project Maintainer Setup (Joe)\nJoe initializes a private GitHub repository and creates the containerized research environment:\n# Create repository and initialize zzrrtools\ngit clone https://github.com/joe/penguins_analysis.git\ncd penguins_analysis\n~/prj/zzrrtools/zzrrtools.sh --dotfiles ~/.config/shell \\\n                             --base-image rgt47/r-pluspackages\nThis creates: - Research compendium directory structure - Docker container configuration - renv dependency management - Automated validation scripts - GitHub Actions workflows\nFor a detailed view of the complete directory structure created by zzrrtools, see Appendix C: Directory Structure.\nJoe completes the setup and begins development:\n# Validate dependencies and build container\nmake check-renv\nmake docker-build\n\n# Start container-based development\nmake docker-r\nFor detailed information on renv dependency validation, troubleshooting, and team collaboration workflows, see Appendix G: renv Management and Validation.\nThe validation script ensures package environment consistency by verifying dependencies across code files, DESCRIPTION, and renv.lock, preventing common collaboration issues where team members have mismatched environments.\nStep 4: Create Initial Analysis Paper\nJoe creates an initial analysis examining flipper length vs. bill length relationships in the Palmer Penguins dataset, implementing basic visualization and statistical exploration within the research compendium structure.\nStep 5: Create Tests for Analysis Functions\nJoe implements testing to ensure reproducible research through data validation, error detection, and environment verification. Testing provides collaboration confidence and supports publication standards by validating data integrity, statistical relationships, and pipeline functionality.\nJoe sets up the testing framework and creates basic data validation tests to verify dataset availability, dimensions, and required columns. These tests ensure the analysis environment is correctly configured and catch data-related issues early in the development process.\nFor a complete test suite with data validation, statistical tests, and integration tests, see Appendix B: Test Suite.\nStep 6: Create a .gitignore file\nJoe configures version control to track source code and dependencies while excluding generated outputs and temporary files. The principle: track the “recipe” (code + dependencies), not the “meal” (outputs).\nJoe creates a .gitignore file excluding renv libraries, generated outputs, temporary files, and system artifacts. This keeps the repository lightweight while ensuring collaborators can recreate the complete environment from tracked dependencies.\nStep 7: Create a Dockerfile\nzzrrtools generates a Dockerfile with multiple template options. The standard template uses rocker/r-ver, while the pluspackages template includes common R packages like tidyverse. Both provide:\n\nR version consistency: Matches exact R version specified in renv.lock\nDevelopment environment: Includes zsh, vim, tmux, Node.js for plugin support\nSecurity: Non-root user execution with proper file permissions\nTinyTeX integration: LaTeX support for PDF rendering (pluspackages template)\nPre-installed packages: Common packages like tidyverse, DT, testthat (pluspackages template)\n\nThe generated Dockerfile includes development tools and optimizations:\nARG R_VERSION=latest\nFROM rocker/r-ver:${R_VERSION}\n\n# Install comprehensive development environment\nRUN apt-get update && apt-get install -y \\\n    git ssh curl wget vim tmux zsh build-essential \\\n    libcurl4-openssl-dev libssl-dev libxml2-dev \\\n    libfontconfig1-dev libharfbuzz-dev libfribidi-dev \\\n    libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev \\\n    man-db pandoc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Node.js for vim plugins\nRUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \\\n    apt-get install -y nodejs\n\n# Create non-root user with zsh shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set up R environment with renv\nWORKDIR /home/${USERNAME}/project\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nUSER ${USERNAME}\nRUN R -e \"install.packages('renv'); renv::restore()\"\n\n# Copy project files and install\nCOPY --chown=${USERNAME}:${USERNAME} . .\nRUN R -e \"devtools::install('.')\"\n\nCMD [\"/bin/zsh\"]\nAlternative: Pre-packaged Template\nFor projects using common packages, the pluspackages template includes TinyTeX and popular R packages:\n# Install TinyTeX for PDF rendering\nRUN R -e \"install.packages('tinytex')\" && \\\n    R -e \"tinytex::install_tinytex()\" && \\\n    /root/.TinyTeX/bin/*/tlmgr path add\n\n# Install common R packages (cached layer)\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', \\\n    'testthat', 'naniar', 'DT', 'conflicted', 'ggthemes', \\\n    'datapasta', 'janitor', 'kableExtra', 'tidytuesdayR', \\\n    'tidyverse'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Give user write permissions to R library\nRUN chown -R ${USERNAME}:${USERNAME} /usr/local/lib/R/site-library\nFor production Dockerfiles with development environment configuration (zsh, vim plugins, dotfiles integration), see Appendix F: Docker Configuration Examples.\nR Version Synchronization:\nThe Dockerfile uses a build argument to ensure the R version exactly matches what’s specified in renv.lock. This eliminates potential issues from R version mismatches between the package environment and the underlying R interpreter. The build command extracts the R version from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/joe/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment.\nStep 8: Container-Based Development\nJoe performs all development work inside the Docker container, ensuring consistent environments and immediate visibility of changes to the host system through volume mounting. The container provides a complete development environment with package management, editing tools, and validation utilities.\nStep 9: Update and Share Environment\nWhen package dependencies change, GitHub Actions automatically rebuilds the Docker image with updated renv.lock specifications and pushes the updated environment to Docker Hub for team access. This ensures collaborators have access to the identical development environment.\nStep 10: Prepare for Team Handoff\nBefore handing off to team members, Joe must complete several critical steps:\n# 1. Validate all dependencies are properly captured\nmake check-renv-fix\n\n# 2. Run complete test suite to ensure everything works\nmake docker-test\n\n# 3. Render paper to verify end-to-end workflow\nmake docker-render\n\n# 4. Build and tag the Docker image\nmake docker-build\ndocker tag penguins_analysis ghcr.io/joe/penguins_analysis:v1.0\n\n# 5. Push Docker image to Docker Hub for team access\necho $GITHUB_TOKEN | docker login ghcr.io -u joe --password-stdin\ndocker push ghcr.io/joe/penguins_analysis:v1.0\n\n# 6. Commit all setup files and push to repository\ngit add .\ngit commit -m \"Initial research compendium setup with Docker environment\"\ngit push origin main\nStep 11: Enable Team Access\nJoe configures repository permissions for team collaboration:\n\nRepository Settings → Collaborators → Add team members\nGrant “Write” access to enable forking and pull requests\nShare repository URL and Docker Hub image name with team\nDocument onboarding process in README or team communication\n\nAt this point, Joe has established a reproducible research framework ready for collaborative development. The containerized environment is available via the registry, and team members can join with zero local setup requirements.\n\n\n6.2.2 Team Member Onboarding (Sam)\nWhat Sam Receives from Joe: - Repository URL: https://github.com/joe/penguins_analysis - Container registry access (GitHub Personal Access Token) - Brief project overview and development guidelines\nSam’s Onboarding Process:\n# 1. Clone the zzrrtools framework\ngit clone https://github.com/username/zzrrtools.git ~/prj/zzrrtools\ncd ~/prj/zzrrtools\n./install.sh  # Creates zzrrtools command in PATH\n\n# 2. Fork and clone the project repository\ngit clone https://github.com/sam/penguins_analysis.git  # Sam's fork\ncd penguins_analysis\n\n# 3. Run zzrrtools setup with personal preferences\nzzrrtools --dotfiles ~/.config/shell  # Customize with personal dotfiles\n# Or use other options:\n# zzrrtools --base-image rgt47/r-pluspackages  # Use pre-packaged template\n# zzrrtools --no-docker                       # Skip Docker build\n# zzrrtools --next-steps                      # Show workflow guidance\n\n# 4. Pull the pre-built Docker environment\ndocker pull ghcr.io/joe/penguins_analysis:v1.0\n\n# 5. Start development in identical environment\nmake docker-r\nKey Advantage: After one-time zzrrtools installation, Sam has access to the framework for all future projects. The development environment setup becomes a simple script execution.\nSam develops new analysis components within the same containerized environment, ensuring identical results across team members.\nStep 5: Paper Integration and Testing\nSam integrates the new analysis into the research paper, combining Joe’s original visualizations with the new body mass analysis. Sam also creates tests to validate the new functionality and ensure package dependencies are properly documented.\nStep 6: Validation and Quality Assurance\nSam creates tests for the new body mass analysis, validates data integrity and statistical relationships, then runs the complete test suite and verifies paper rendering to ensure no regressions before submission.\nStep 7: Contribution Submission\nWhen Sam completes the analysis iteration, the submission process follows these steps:\n\nValidate dependencies: Run make docker-check-renv-fix to ensure package consistency\nRun complete test suite: Execute make docker-test to verify all tests pass\nVerify paper rendering: Run make docker-render to confirm analysis integrates properly\nCommit changes:\ngit add .\ngit commit -m \"Add body mass analysis and associated tests\"\ngit push origin feature/body-mass-analysis\nCreate pull request: Submit pull request from Sam’s fork to Joe’s original repository\nNotify Joe: Alert project maintainer about new packages or Docker changes needed\n\nNote: Only Joe (project maintainer) can accept pull requests. The official Docker image is automatically rebuilt and pushed to Docker Hub by GitHub Actions when package dependencies change.\nCI Feedback Loop: If the CI workflow fails (e.g., renv validation issues), Sam receives automatic GitHub notifications and can view detailed failure logs to fix the issues before Joe reviews the PR.\nSam commits the completed analysis, tests, and documentation to their feature branch and creates a cross-repository pull request to the original repository. This ensures proper code review and governance while maintaining clear attribution of contributions.\nAt this point, Sam has successfully contributed new analysis through the collaborative workflow. Joe reviews the pull request, tests the changes in the containerized environment, and merges the contribution while maintaining project governance and quality standards."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "href": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.3 Complete Handoff Workflow Summary",
    "text": "6.3 Complete Handoff Workflow Summary\nInitiating Developer (Joe) Responsibilities: 1. Run zzrrtools.sh to create research compendium 2. Develop initial analysis and create tests 3. Validate dependencies with make check-renv-fix\n4. Build initial Docker image and configure automated rebuilds via GitHub Actions 5. Push team Docker image to Docker Hub (public registry for reproducibility) 6. Commit all files and push to repository 7. Grant team member repository access\n8. Share repository URL and Docker Hub image name\nJoining Developer (Sam) Process: 1. Receive repository URL and Docker Hub image name from Joe 2. Clone zzrrtools framework: git clone zzrrtools ~/prj/zzrrtools 3. Install zzrrtools: cd ~/prj/zzrrtools && ./install.sh (creates zzrrtools command in PATH) 4. Fork and clone project repository 5. Pull pre-built team Docker image: docker pull [TEAM]/project:latest (from Docker Hub) 6. Start development immediately: make docker-r (no local setup needed) 7. Submit contributions via pull requests to private repository\nKey Success Factor: The containerized environment and centralized zzrrtools framework eliminate project-specific configuration requirements for team members after one-time framework installation."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "href": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.4 Collaboration Results",
    "text": "6.4 Collaboration Results\nThis workflow achieves: - Identical development environments across team members - Dependency validation preventing conflicts - Standardized project structure - Automated testing and CI/CD integration\nFor GitHub Actions setup instructions, workflow examples, and CI/CD configuration, see Appendix E: GitHub Actions CI/CD Setup.\nThe collaborative workflow demonstrated above illustrates the power of combining zzrrtools, renv, and Docker for reproducible research. However, successful implementation of this approach requires understanding both when it’s most beneficial and how to apply it effectively. The following best practices and considerations provide guidance for teams considering this strategy."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.1 When to Use This Approach",
    "text": "7.1 When to Use This Approach\nThe zzrrtools + renv + Docker approach with testing is particularly valuable for:\n\nLong-term research projects where reproducibility over time is crucial\nCollaborative analyses with multiple contributors on different systems\nProduction analytical pipelines that need to run consistently\nAcademic publications where methods must be reproducible\nTeaching and education to ensure consistent student experiences\nComplex analyses that require testing to validate results"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "href": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.2 Tips for Efficient Implementation",
    "text": "7.2 Tips for Efficient Implementation\n\nKeep Docker images minimal: Include only what’s necessary for reproducibility.\nUse specific version tags: For both R packages and Docker base images, specify exact versions.\nDocument system requirements: Include notes on RAM and storage requirements.\nLeverage bind mounts: Mount local directories to containers for easier development.\nWrite meaningful tests: Focus on validating both data integrity and analytical results.\nTest regularly: Use CI/CD pipelines to run tests on every change.\nConsider computational requirements: Particularly for resource-intensive analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "href": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.3 Testing Strategies for R Analyses",
    "text": "7.3 Testing Strategies for R Analyses\nTesting data analysis code differs from traditional software testing but provides crucial value for reproducible research:\n\nData Validation Tests: Ensure data has the expected structure, types, and values.\nFunction Tests: Verify that custom functions work as expected with known inputs and outputs.\nEdge Case Tests: Check how code handles missing values, outliers, or unexpected inputs.\nIntegration Tests: Confirm that different parts of the analysis work correctly together.\nRegression Tests: Make sure new changes don’t break existing functionality.\nOutput Validation: Verify that final results match expected patterns or benchmarks.\n\nWhile uncommon in traditional data analysis, these tests catch silent errors, validate assumptions, and provide confidence that analyses remain correct as code and data evolve."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "href": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.4 Potential Challenges",
    "text": "7.4 Potential Challenges\nSome challenges to be aware of:\n\nDocker image size: Images with many packages can become large\nLearning curve: Docker, renv, and testing frameworks require some initial learning\nSystem-specific features: Some analyses may rely on hardware features\nPerformance considerations: Containers may have different performance characteristics\nTest maintenance: Tests need to be updated as the analysis evolves"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.5 Troubleshooting Common Issues",
    "text": "7.5 Troubleshooting Common Issues\nDocker Build Failures: - Try: export DOCKER_BUILDKIT=0 (disable BuildKit) - Check Docker has sufficient memory/disk space - Ensure Docker is running and up to date\nPlatform Warnings on ARM64/Apple Silicon: - Use updated Makefile with --platform linux/amd64 flags - Or set: export DOCKER_DEFAULT_PLATFORM=linux/amd64\nPermission Errors in Container: - Rebuild image after copying dotfiles - Check file ownership in project directory\nPackage Name Errors: - Ensure directory name contains only letters/numbers/periods - Avoid underscores and special characters\nMissing Dotfiles in Container: - Use --dotfiles or --dotfiles-nodot flag during setup - Rebuild Docker image after adding dotfiles\nDespite these challenges, the benefits of reproducible research outweigh the implementation costs, particularly for collaborative and long-term projects. The approach described in this white paper provides a foundation for achieving reproducibility that meets the standards expected in data science and academic research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.1 Step-by-Step Token Creation",
    "text": "9.1 Step-by-Step Token Creation\n1. Navigate to GitHub Settings: - Go to GitHub.com and sign in - Click your profile picture (top right) → Settings - In the left sidebar: Developer settings → Personal access tokens\nNote: GitHub now offers two token types: - Fine-grained personal access tokens (recommended for new projects) - Personal access tokens (classic) (for broader compatibility)\n2. Create New Token: - Click “Generate new token” and select the appropriate type - Add a descriptive note (e.g., “Docker Container Registry Access”) - Set expiration (recommended: 90 days for security)\n3. Select Required Scopes (check these boxes): - ✅ repo (Full control of private repositories) - Required for private repos - ✅ write:packages (Upload Docker images to GitHub Container Registry) - Required for project maintainer - ✅ read:packages (Download Docker images from GitHub Container Registry) - Required for all team members - ✅ delete:packages (Delete packages from GitHub Package Registry) - Optional but recommended\nNote: Team members only need read:packages and repo, but the project maintainer needs all container permissions to push Docker images.\nToken Type Recommendation: Use fine-grained personal access tokens for new projects as they provide better security and more precise permissions.\n4. Generate and Copy Token: - Click “Generate token” at the bottom - Important: Copy the token immediately - you won’t see it again - Store it securely (see security practices below)"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "href": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.2 Token Security Best Practices",
    "text": "9.2 Token Security Best Practices\n\nNever commit tokens to repositories - Use .gitignore to exclude files containing tokens\nUse environment variables - Store tokens in shell environment variables\nSet reasonable expiration dates - Use 30-90 day expiration for security\nRevoke unused tokens - Clean up tokens when no longer needed\nConsider GitHub CLI - Use gh auth login for easier management\nMonitor token usage - Check GitHub Settings → Developer settings → Personal access tokens for activity"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "href": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.3 Alternative: Using GitHub CLI",
    "text": "9.3 Alternative: Using GitHub CLI\nFor simpler token management, consider using GitHub CLI instead of manual tokens:\n# Install and authenticate (handles tokens)\ngh auth login --scopes write:packages,read:packages,repo\n\n# Login to container registry (works with gh auth)\necho $(gh auth token) | docker login ghcr.io \\\n  -u $(gh api user --jq .login) --password-stdin"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.4 Troubleshooting Common Issues",
    "text": "9.4 Troubleshooting Common Issues\n“permission_denied: The token provided does not match expected scopes” - Verify your token includes write:packages and read:packages scopes - For private repositories, ensure repo scope is also selected - Create a new token with correct permissions if needed\nToken not recognized: - Ensure token is properly exported: export GITHUB_TOKEN=your_token_here - Verify token hasn’t expired - Check that you’re using the full token (starts with ghp_) 6. Horst, A.M., Hill, A.P., & Gorman, K.B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ 7. Marwick, B. (2016). Computational reproducibility in archaeological research: Basic principles and a case study of their implementation. Journal of Archaeological Method and Theory, 24(2), 424-473."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R",
    "text": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R\nlibrary(testthat)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\n# Test 1: Data Availability and Basic Structure\n# Generic application: Verify your primary dataset loads correctly and has \n# expected dimensions\n# Catches: Package loading issues, file path problems, corrupted data files\ntest_that(\"Palmer Penguins dataset is available and has correct structure\", \n          {\n  expect_true(exists(\"penguins\", where = \"package:palmerpenguins\"))\n  expect_s3_class(palmerpenguins::penguins, \"data.frame\")\n  expect_equal(ncol(palmerpenguins::penguins), 8)  # Adapt: Set expected \n                                                    # column count\n  expect_gt(nrow(palmerpenguins::penguins), 300)   # Adapt: Set minimum \n                                                    # row threshold\n  expect_equal(nrow(palmerpenguins::penguins), 344)  # Adapt: Set exact \n                                                      # expected count \n                                                      # if known\n})\n\n# Test 2: Required Columns Exist with Correct Types\n# Generic application: Ensure your analysis depends on columns that \n# actually \n# exist with correct types\n# Catches: Column name changes, type coercion issues, CSV import problems\ntest_that(\"Dataset contains required columns with expected data types\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Check column existence - Adapt: List columns your analysis requires\n  required_cols &lt;- c(\"species\", \"island\", \"bill_length_mm\", \n                     \"bill_depth_mm\", \"flipper_length_mm\", \n                     \"body_mass_g\", \"sex\", \"year\")\n  expect_true(all(required_cols %in% names(df)))\n  \n  # Check data types - Adapt: Verify types match your analysis \n  # expectations\n  expect_type(df$species, \"integer\")  # Factor stored as integer\n  expect_type(df$bill_length_mm, \"double\")  # Continuous measurements\n  expect_type(df$flipper_length_mm, \"integer\")  # Discrete measurements\n  expect_type(df$body_mass_g, \"integer\")  # Integer measurements\n})\n\n# Test 3: Categorical Variables Have Expected Levels\n# Generic application: Verify factor levels for categorical variables used\n# in \n# analysis\n# Catches: Missing categories, typos in factor levels, data encoding issues\ntest_that(\"Species factor has expected levels\", {\n  species_levels &lt;- levels(palmerpenguins::penguins$species)\n  expected_species &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")  # Adapt: Your \n                                                          # expected \n                                                          # categories\n  expect_equal(sort(species_levels), sort(expected_species))\n  expect_equal(length(species_levels), 3)  # Adapt: Expected number of \n                                           # categories\n  # For other datasets: Test treatment groups, regions, product types, etc.\n})\n\n# Test 4: Data Value Ranges are Domain-Reasonable\n# Generic application: Verify numeric values fall within realistic ranges\n# for \n# your domain\n# Catches: Data entry errors, unit conversion mistakes, outliers from \n# measurement errors\ntest_that(\"Measurement values fall within reasonable biological ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Bill length - Adapt: Set realistic bounds for your numeric variables\n  bill_lengths &lt;- df$bill_length_mm[!is.na(df$bill_length_mm)]\n  expect_true(all(bill_lengths &gt;= 30 & bill_lengths &lt;= 70))  # Penguin-\n                                                              # specific \n                                                              # range\n  \n  # Flipper length - Examples for other domains:\n  flipper_lengths &lt;- df$flipper_length_mm[!is.na(df$flipper_length_mm)]\n  expect_true(all(flipper_lengths &gt;= 150 & flipper_lengths &lt;= 250))\n  # Finance: stock prices &gt; 0, percentages 0-100\n  # Health: age 0-120, BMI 10-80, blood pressure 50-300\n  # Engineering: temperatures -273+°C, pressures &gt; 0\n  \n  # Body mass\n  body_masses &lt;- df$body_mass_g[!is.na(df$body_mass_g)]\n  expect_true(all(body_masses &gt;= 2000 & body_masses &lt;= 7000))\n})\n\n# Test 5: Missing Data Patterns are as Expected\n# Generic application: Verify missingness patterns match your data \n# collection \n# expectations\n# Catches: Unexpected data loss, systematic missingness, data pipeline \n# failures\ntest_that(\"Missing data follows expected patterns\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Total missing values should be manageable\n  total_na &lt;- sum(is.na(df))\n  expect_lt(total_na, nrow(df))  # Adapt: Set acceptable threshold for \n                                 # missing \n                                 # data\n  \n  # Some variables may have expected missingness\n  expect_gt(sum(is.na(df$sex)), 0)  # Sex determination sometimes difficult\n  # Adapt examples: Optional survey questions, historical data gaps, sensor \n  # failures\n  \n  # Critical variables should be complete\n  expect_equal(sum(is.na(df$species)), 0)  # Primary identifier must be \n                                           # complete\n  # Adapt: ID columns, primary keys, required fields should have no NAs\n})\n\n# Test 6: Expected Statistical Relationships Hold\n# Generic application: Test known relationships between variables in your \n# domain\n# Catches: Data corruption, encoding errors, units mix-ups that break known \n# patterns\ntest_that(\"Expected correlations between measurements exist\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test strong expected relationships\n  correlation &lt;- cor(df$flipper_length_mm, df$body_mass_g, \n                     use = \"complete.obs\")\n  expect_gt(correlation, 0.8)  # Strong positive correlation expected\n  # Adapt examples: height vs weight, price vs quality, experience vs salary\n  \n  # Test weaker but expected relationships\n  bill_cor &lt;- cor(df$bill_length_mm, df$bill_depth_mm, use = \"complete.obs\")\n  expect_gt(abs(bill_cor), 0.1)  # Some relationship should exist\n  # Adapt: Education vs income, advertising vs sales, temperature vs \n  # energy use\n})\n\n# Test 7: Visualization Functions Work Correctly\n# Generic application: Ensure your key plots and visualizations can be \n# generated\n# Catches: Missing aesthetic mappings, incompatible data types, package \n# conflicts\ntest_that(\"Basic plots can be generated without errors\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test basic plot creation without errors\n  expect_no_error({\n    p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      theme_minimal()\n  })\n  # Adapt: Test your key plot types - histograms, boxplots, time series,\n  # etc.\n  \n  # Test that plot object is properly created\n  p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n    geom_point()\n  expect_s3_class(p1, \"ggplot\")  # Adapt: Check for your plotting \n                                   # framework objects\n})\n\n# Test 8: Data Filtering and Subsetting Work Correctly\n# Generic application: Verify data manipulation operations produce expected\n# results\n# Catches: Logic errors in filtering, unexpected factor behaviors, \n# indexing mistakes\ntest_that(\"Data can be properly filtered and subsetted\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test categorical filtering\n  adelie_penguins &lt;- df[df$species == \"Adelie\" & !is.na(df$species), ]\n  expect_gt(nrow(adelie_penguins), 100)  # Adapt: Expected subset size\n  expect_true(all(adelie_penguins$species == \"Adelie\", na.rm = TRUE))\n  # Adapt: Filter by treatment groups, regions, time periods, etc.\n  \n  # Test missing data handling\n  complete_cases &lt;- df[complete.cases(df), ]\n  expect_lt(nrow(complete_cases), nrow(df))  # Some rows should be removed\n  expect_equal(sum(is.na(complete_cases)), 0)  # No NAs remaining\n  # Adapt: Test your specific data cleaning operations\n})\n\n# Test 9: Summary Statistics are Reasonable\n# Generic application: Verify computed statistics match domain knowledge \n# expectations\n# Catches: Calculation errors, unit mistakes, algorithm bugs, extreme \n# outliers\ntest_that(\"Summary statistics fall within expected ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test means fall within expected ranges\n  mean_flipper &lt;- mean(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(mean_flipper, 190)  # Adapt: Set realistic bounds for your \n                                # variables\n  expect_lt(mean_flipper, 210)\n  # Examples: Average customer age 20-80, mean salary $30k-200k, etc.\n  \n  # Test other central tendencies\n  mean_mass &lt;- mean(df$body_mass_g, na.rm = TRUE)\n  expect_gt(mean_mass, 4000)\n  expect_lt(mean_mass, 5000)\n  \n  # Test variability measures are reasonable\n  sd_flipper &lt;- sd(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(sd_flipper, 5)   # Not zero variance\n  expect_lt(sd_flipper, 30)  # Not excessive variance\n  # Adapt: CV should be &lt;50%, SD should be meaningful relative to mean\n})\n\n# Test 10: Complete Analysis Pipeline Integration Test\n# Generic application: Test your entire analysis workflow runs without \n# errors\n# Catches: Pipeline breaks, dependency issues, function interaction problems\ntest_that(\"Complete analysis pipeline executes successfully\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test that full workflow executes without errors\n  expect_no_error({\n    # Data preparation step\n    clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                       \"bill_length_mm\")]), ]\n    \n    # Statistical analysis step - Adapt: Your key analyses\n    correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                   clean_df$bill_length_mm)\n    \n    # Visualization step - Adapt: Your key plots\n    plot_result &lt;- ggplot(clean_df, \n                          aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      geom_smooth(method = \"lm\") +\n      theme_minimal() +\n      labs(title = \"Flipper Length vs. Bill Length\",\n           x = \"Flipper Length (mm)\",\n           y = \"Bill Length (mm)\")\n  })\n  # Adapt: Add model fitting, prediction, reporting steps as needed\n  \n  # Verify analysis produces meaningful results\n  clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                     \"bill_length_mm\")]), ]\n  correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                 clean_df$bill_length_mm)\n  expect_lt(correlation_result$p.value, 0.05)  # Significant result expected\n  # Adapt: Check model R², prediction accuracy, convergence, etc.\n})"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "href": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.6 Running the Tests",
    "text": "9.6 Running the Tests\nTo run all tests in your project:\n# Run all tests\ntestthat::test_dir(\"tests/testthat\")\n\n# Run specific test file\ntestthat::test_file(\"tests/testthat/test-comprehensive-analysis.R\")\n\n# Run tests with detailed output\ntestthat::test_dir(\"tests/testthat\", reporter = \"detailed\")"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.7 Test Categories Explained",
    "text": "9.7 Test Categories Explained\nData Validation Tests (1-5): Verify data structure, types, ranges, and missing patterns Statistical Tests (6): Confirm expected relationships in the data Functional Tests (7-8): Ensure analysis functions work correctly Sanity Tests (9): Check that summary statistics are reasonable Integration Tests (10): Verify the complete analysis pipeline works end-to-end\nThese tests provide coverage for a data analysis project and can catch issues ranging from data corruption to environment setup problems."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.8 Key Features Explained:",
    "text": "9.8 Key Features Explained:\nData Organization: - raw_data/: Original, unmodified datasets as received - derived_data/: Processed, cleaned, or transformed data - metadata/: Documentation about data sources, collection methods, variables - validation/: Scripts that verify data integrity and quality - external_data/: Third-party datasets or reference data\nMultiple Output Formats: - figures/: Generated plots, charts, and visualizations - tables/: Generated summary tables and statistical results - paper/: Main manuscript and analysis documents - templates/: Document templates and citation style files\nR Package Structure: - R/: Custom functions and utilities - man/: Generated documentation for R functions - tests/testthat/: Unit tests and validation scripts - vignettes/: Long-form documentation and tutorials - DESCRIPTION: Package metadata and dependency specifications\nDocker Orchestration: - Dockerfile: Main container specification - docker-compose.yml: Multi-service development environments - Makefile: Build automation supporting both native R and Docker workflows\nWorkflows: - .github/workflows/: GitHub Actions for testing, checking, and rendering - setup_renv.R: Package environment setup - RRTOOLS_USER_GUIDE.md: Usage documentation\nNavigation Shortcuts: - Symbolic links: Single-letter shortcuts for easy navigation - a → analysis/, n → analysis/, f → figures/ - t → tests/, s → scripts/, m → man/ - e → external_data/, o → output/, c → cache/\nThis structure supports research projects while maintaining clear organization and following established research compendium principles."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.9 Multi-Service Docker Architecture",
    "text": "9.9 Multi-Service Docker Architecture\nzzrrtools creates specialized Docker environments for different development tasks:\n# Build the containerized research environment\nmake docker-build\n\n# Interactive R console (primary development environment)\nmake docker-r\n\n# Development shell with personal dotfiles\nmake docker-zsh\n\n# Interactive bash session\nmake docker-bash\n\n# RStudio Server (web-based IDE)\nmake docker-rstudio    # Access at http://localhost:8787\n\n# Render research paper\nmake docker-render\n\n# Run tests\nmake docker-test\n\n# Package checking\nmake docker-check\n\n# renv dependency validation\nmake docker-check-renv-fix\n\n# See all available commands\nmake help\nCollaborative Benefits: - Zero-setup onboarding: Team members run identical commands - Consistent environments: Same container across all developer machines - ARM64/Apple Silicon support: Platform-specific flags ensure compatibility - Shell-optimized workflows: Command-line development with rich tooling - Personal customization: Dotfiles integration for familiar environments - Web-based development: Optional RStudio Server for GUI-based workflows"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.10 Option 2: Docker Compose Services",
    "text": "9.10 Option 2: Docker Compose Services\nDocker Compose orchestrates multiple container configurations:\n# Interactive R session\ndocker-compose run --rm r-session\n\n# Bash shell access\ndocker-compose run --rm bash\n\n# Automated paper rendering\ndocker-compose run --rm research\n\n# Package testing\ndocker-compose run --rm test\n\n# Package checking\ndocker-compose run --rm check\nDocker Compose Configuration Example:\nservices:\n  r-session:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./cache:/home/analyst/cache\n    working_dir: /home/analyst/project\n    \n  bash:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n    working_dir: /home/analyst/project\n    entrypoint: [\"/bin/bash\"]\n    \n  research:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./analysis/figures:/home/analyst/output\n    working_dir: /home/analyst/project\n    command: [\"R\", \"-e\", \"rmarkdown::render('analysis/paper/paper.Rmd')\"]\nBenefits: - Service setup: Multiple predefined container configurations - Volume management: Consistent volume mounting across services - Environment isolation: Different services for different purposes - Parallel execution: Can run multiple services simultaneously"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.11 Option 3: Direct Docker Commands",
    "text": "9.11 Option 3: Direct Docker Commands\nFor maximum control, use Docker commands directly:\n# Basic interactive session\ndocker run --rm -it -v \"$(pwd):/home/analyst/project\" \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Interactive session with mounted cache\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/cache:/home/analyst/cache\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Render research paper\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/analysis/figures:/home/analyst/output\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n\n# Run specific tests\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"testthat::test_file('tests/testthat/test-data-integrity.R')\"\n\n# Interactive bash session\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  /bin/bash\nCommon Docker Flags Explained: - --rm: Remove container when it exits - -it: Interactive terminal session - -v: Mount volume (host:container) - -w: Set working directory inside container - --entrypoint: Override default command\nBenefits: - Full flexibility: Complete control over container configuration - Educational: Shows exactly what’s happening under the hood - Troubleshooting: Easier to debug when you see all options - Portability: Commands work on any Docker installation"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "href": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.12 Volume Mounting Strategies",
    "text": "9.12 Volume Mounting Strategies\nProject Files:\n# Mount entire project directory\n-v \"$(pwd):/home/analyst/project\"\nOutput Separation:\n# Separate outputs from source\n-v \"$(pwd)/analysis/figures:/home/analyst/output\"\nCache Persistence:\n# Persistent package cache across sessions\n-v \"$(pwd)/cache:/home/analyst/cache\"\nRead-only Source:\n# Protect source files from modification\n-v \"$(pwd):/home/analyst/project:ro\""
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.13 Choosing the Right Approach",
    "text": "9.13 Choosing the Right Approach\nUse Make Commands When: - You want simplicity and consistency - You’re new to Docker - You’re focusing on analysis rather than infrastructure\nUse Docker Compose When: - You need multiple service configurations - You’re working with a team using standardized environments - You want to define complex volume and networking setups\nUse Direct Commands When: - You need maximum flexibility - You’re troubleshooting container issues - You’re creating custom workflows not covered by Make targets\nAll three approaches can be used together in the same project, depending on the specific task and user preferences."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "href": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.14 Understanding GitHub Actions for Research",
    "text": "9.14 Understanding GitHub Actions for Research\nWhat is CI/CD for Research?\nContinuous Integration/Continuous Deployment (CI/CD) tests your research code whenever changes are made. For research compendia, this means:\n\nTesting: Every push triggers your test suite\nEnvironment consistency: Tests run in identical Docker environments\nEarly error detection: Problems caught during development\nCollaboration confidence: Team members see if changes break functionality\nReproducibility validation: Ensures analysis works across different systems"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.15 Step-by-Step Setup",
    "text": "9.15 Step-by-Step Setup\n\n9.15.1 Step 1: Create Workflow Directory\n# Create the GitHub Actions directory\nmkdir -p .github/workflows\n\n\n9.15.2 Step 2: Docker-based CI Workflow with renv Validation\nCreate .github/workflows/docker-ci.yml:\nname: Docker CI with renv Validation\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  build-and-test:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      \n    - name: Set up R for renv validation\n      uses: r-lib/actions/setup-r@v2\n      with:\n        r-version: 'release'\n        \n    - name: Install renv for validation\n      run: |\n        install.packages(\"renv\")\n      shell: Rscript {0}\n        \n    - name: Validate renv consistency before Docker build\n      run: |\n        # Validate renv environment before building Docker image\n        Rscript check_renv_for_commit.R --fail-on-issues --quiet\n      \n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      \n    - name: Extract R version from renv.lock\n      id: r-version\n      run: |\n        R_VERSION=$(Rscript -e \"cat(renv::lockfile_read()\\$R\\$Version)\")\n        echo \"r-version=${R_VERSION}\" &gt;&gt; $GITHUB_OUTPUT\n      \n    - name: Build Docker image\n      uses: docker/build-push-action@v5\n      with:\n        context: .\n        push: false\n        tags: ${{ github.repository }}:latest\n        build-args: |\n          R_VERSION=${{ steps.r-version.outputs.r-version }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        \n    - name: Run tests in container\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          ${{ github.repository }}:latest \\\n          R -e \"testthat::test_dir('tests/testthat')\"\n          \n    - name: Render research paper\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          -v $PWD/analysis/figures:/home/analyst/output \\\n          ${{ github.repository }}:latest \\\n          R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n          \n    - name: Upload rendered paper\n      uses: actions/upload-artifact@v4\n      if: success()\n      with:\n        name: research-paper\n        path: analysis/paper/paper.pdf\n\n\n9.15.3 Step 3: R Package Check Workflow\nCreate .github/workflows/r-package.yml:\nname: R Package Check\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n    \n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n    \n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: macOS-latest,    r: 'release'}\n          - {os: windows-latest,  r: 'release'}\n    \n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: r-lib/actions/setup-pandoc@v2\n      \n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n          \n      - uses: r-lib/actions/setup-renv@v2\n      \n      - name: Install system dependencies\n        if: runner.os == 'Linux'\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y \\\n            libcurl4-openssl-dev \\\n            libssl-dev \\\n            libxml2-dev\n            \n      - name: Validate renv consistency\n        run: |\n          # Use the renv validation script included in the repository\n          Rscript check_renv_for_commit.R --fail-on-issues --quiet\n            \n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n9.15.4 Step 4: Automated Paper Rendering\nCreate .github/workflows/render-paper.yml:\nname: Render Research Paper\n\non:\n  workflow_dispatch:  # Manual trigger\n  push:\n    branches: [ main, master ]\n    paths:\n      - 'analysis/paper/**'\n      - 'analysis/data/**'\n      - 'R/**'\n      - 'data/**'\n\njobs:\n  render:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Build Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: false\n          tags: paper-render:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          \n      - name: Render paper in container\n        run: |\n          docker run --rm \\\n            -v $PWD:/home/analyst/project \\\n            -v $PWD/analysis/figures:/home/analyst/output \\\n            paper-render:latest \\\n            R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n            \n      - name: Upload rendered paper\n        uses: actions/upload-artifact@v4\n        with:\n          name: research-paper-${{ github.sha }}\n          path: |\n            analysis/paper/paper.pdf\n            analysis/figures/*.png\n            analysis/figures/*.jpg\n          retention-days: 30\n\n\n9.15.5 Step 5: Container Registry Integration\nCreate .github/workflows/container-publish.yml:\nname: Build and Push Container\n\non:\n  push:\n    branches: [ main ]\n    tags: [ 'v*' ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n      \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Log in to Container Registry\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n          \n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            \n      - name: Build and push Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          platforms: linux/amd64,linux/arm64\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "href": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.16 Workflow Explanations",
    "text": "9.16 Workflow Explanations\n\n9.16.1 Docker CI Workflow Features:\n\nPre-build renv Validation: Validates package dependency consistency before Docker build (prevents build failures)\nDynamic R Version: Extracts R version from renv.lock and passes it to Docker build\nBuild Testing: Ensures Docker image builds with latest changes using correct R version\nTesting: Runs R package tests and renders paper in container\nArtifact Generation: Saves rendered papers as downloadable artifacts\nCaching: Uses GitHub Actions cache for faster builds\nEarly Failure: Stops pipeline if dependency issues are detected\n\n\n\n9.16.2 R Package Check Features:\n\nMulti-platform Testing: Tests on Ubuntu, macOS, and Windows\nR CMD Check: Package validation\nrenv Integration: Restores package environment\nrenv Consistency Validation: Verifies dependency synchronization across platforms\nSystem Dependencies: Installs required system libraries\n\n\n\n9.16.3 Paper Rendering Features:\n\nSelective Triggering: Only runs when relevant files change\nManual Execution: Can be triggered manually via GitHub interface\nArtifact Storage: Saves PDFs and figures with retention policy\nPath-based Triggers: Responds to changes in analysis files\n\n\n\n9.16.4 Container Publishing Features:\n\nBuilding: Builds on pushes and tags\nMulti-platform: Supports AMD64 and ARM64 platforms\nSemantic Versioning: Tagging based on git tags\nSecurity: Uses built-in GitHub token for authentication"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "href": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.17 Authentication and Permissions",
    "text": "9.17 Authentication and Permissions\n\n9.17.1 Built-in GITHUB_TOKEN:\nThe built-in GITHUB_TOKEN automatically provides: - Read access to repository contents - Write access to GitHub Packages (when permissions are set) - No manual setup required\n\n\n9.17.2 Setting Repository Permissions:\n\nRepository Settings → Actions → General\nWorkflow permissions: Choose “Read and write permissions”\nAllow GitHub Actions to create and approve pull requests: Enable if needed\n\n\n\n9.17.3 Using Personal Access Tokens (Advanced):\nFor broader permissions, create repository secrets:\n\nRepository Settings → Secrets and variables → Actions\nNew repository secret: Add GHCR_TOKEN with Personal Access Token\nReference in workflow: password: ${{ secrets.GHCR_TOKEN }}"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.18 Integration with Collaborative Workflow",
    "text": "9.18 Integration with Collaborative Workflow\n\n9.18.1 Pull Request Integration:\nWhen a team member submits a pull request: 1. GitHub automatically triggers CI workflows 2. Tests run in clean environment identical to production 3. Results displayed directly in pull request interface 4. Merge can be blocked if tests fail\n\n\n9.18.2 Branch Protection Rules:\nEnable in Repository Settings → Branches: - Require status checks: Force CI to pass before merging - Require branches to be up to date: Ensure latest code is tested - Include administrators: Apply rules to all users"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "href": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.19 Monitoring and Troubleshooting",
    "text": "9.19 Monitoring and Troubleshooting\n\n9.19.1 Viewing Workflow Results:\n\nRepository → Actions tab\nClick specific workflow run to see details\nExpand steps to see detailed logs\nDownload artifacts (rendered papers, test results)\n\n\n\n9.19.2 Common Issues and Solutions:\nDocker Build Failures: - Check Dockerfile syntax - Verify all COPY paths exist - Ensure base image is accessible\nrenv Restore Failures: - Verify renv.lock is committed - Check for platform-specific packages - Consider using RSPM for faster installs\nPermission Errors: - Verify GITHUB_TOKEN permissions - Check repository secrets configuration - Ensure workflows have necessary permissions\n\n\n9.19.3 Performance Optimization:\nCaching Strategies: - Docker layer caching with cache-from/cache-to - renv package caching with r-lib/actions/setup-renv - Artifact caching for large datasets\nParallel Execution: - Run tests and documentation in parallel jobs - Use matrix strategies for multi-platform testing - Conditional execution based on changed files\nThis CI/CD setup ensures that research compendia remain reproducible, tested, and deployment-ready throughout the development lifecycle."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.20 Production Dockerfile",
    "text": "9.20 Production Dockerfile\nThe following Dockerfile provides a development environment with zsh, vim plugins, dotfiles integration, and development tools:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Install system dependencies including zsh and development tools\nRUN apt-get update && apt-get install -y \\\n    libxml2-dev \\\n    libcurl4-openssl-dev \\\n    libssl-dev \\\n    libgit2-dev \\\n    libfontconfig1-dev \\\n    libcairo2-dev \\\n    libxt-dev \\\n    pandoc \\\n    zsh \\\n    curl \\\n    git \\\n    fonts-dejavu \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user with zsh as default shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set working directory\nWORKDIR /home/${USERNAME}/project\n\n# Copy project files first (for better Docker layer caching)\nCOPY --chown=${USERNAME}:${USERNAME} DESCRIPTION .\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock* ./\nCOPY --chown=${USERNAME}:${USERNAME} .Rprofile* ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R* renv/activate.R\n\n# Configure renv library path\nENV RENV_PATHS_LIBRARY renv/library\n\n# Switch to non-root user for R package installation\nUSER ${USERNAME}\n\n# Install renv and essential R packages\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', 'knitr', \\\n    'rmarkdown'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Restore R packages from lockfile (if exists)\nRUN R -e \"if (file.exists('renv.lock')) renv::restore() else \\\n    cat('No renv.lock found, skipping restore\\\\n')\"\n\n# Copy dotfiles for development environment\n# Note: Ensure .vimrc and .zshrc_docker exist in build context or create \n# defaults\nCOPY --chown=${USERNAME}:${USERNAME} .vimrc /home/${USERNAME}/.vimrc\nCOPY --chown=${USERNAME}:${USERNAME} .zshrc_docker /home/${USERNAME}/.zshrc\n\n# Install zsh plugins for shell experience\nRUN mkdir -p /home/${USERNAME}/.zsh && \\\n    git clone https://github.com/zsh-users/zsh-autosuggestions \\\n        /home/${USERNAME}/.zsh/zsh-autosuggestions && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.zsh\n\n# Install vim-plug and configure vim environment\nRUN mkdir -p /home/${USERNAME}/.vim/autoload && \\\n    curl -fLo /home/${USERNAME}/.vim/autoload/plug.vim \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.vim\n\n# Install vim plugins (suppress interactive mode)\nRUN vim +PlugInstall +qall || true\n\n# Copy rest of project\nCOPY --chown=${USERNAME}:${USERNAME} . .\n\n# Install the research compendium as a package\nRUN R -e \"devtools::install('.', dependencies = TRUE)\"\n\n# Set default shell to zsh for development experience\nWORKDIR /home/${USERNAME}/project\nCMD [\"/bin/zsh\"]"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.21 Features of the Production Dockerfile",
    "text": "9.21 Features of the Production Dockerfile\nThis production-ready Dockerfile provides:\n\nR version consistency: Matches exact R version specified in renv.lock for perfect environment alignment\nMinimal base: rocker/r-ver provides clean R installation without unnecessary packages\nShell environment: zsh with autosuggestions and professional prompt for improved productivity\nEditor environment: vim with plugins configured automatically during build\nDotfiles integration: Personal development preferences (.vimrc, .zshrc) copied from host system\nDevelopment tools: git, curl, pandoc, and essential development libraries pre-installed\nSecurity: Non-root user execution with proper file permissions\nrenv integration: Automatic package restoration with proper library path configuration\nContainer-optimized workflow: Optimized layer caching and build process for efficient rebuilds"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "href": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.22 R Version Extraction",
    "text": "9.22 R Version Extraction\nThe Dockerfile uses a build argument to ensure the R version exactly matches what’s specified in renv.lock. The build command extracts the R version directly from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/username/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "href": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.23 renv Consistency Checker Features",
    "text": "9.23 renv Consistency Checker Features\nThe check_renv_for_commit.R script provides advanced team collaboration features through dependency validation:\n\nTeam conflict prevention: Pre-commit validation stops dependency inconsistencies before they reach the repository\nAutomated dependency discovery: Scans R/, scripts/, and analysis/ directories for library(), require(), and pkg:: calls\nMulti-source synchronization: Ensures packages are consistent across code files, DESCRIPTION, and renv.lock\nCRAN validation: Verifies packages exist and are properly named before team integration\nAutomatic fixing: Updates DESCRIPTION and regenerates renv.lock to maintain team synchronization\nCI/CD fail-fast: Provides proper exit codes for automated workflows\nInteractive collaboration mode: Guides developers through dependency resolution during development"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.24 Team Collaboration Commands",
    "text": "9.24 Team Collaboration Commands\n# Team development workflow (via Make)\nmake check-renv          # Interactive dependency checking\nmake check-renv-fix      # Auto-fix dependency issues\nmake check-renv-ci       # CI/CD validation with fail-fast\n\n# Docker-based validation (no local R required)\nmake docker-check-renv-fix  # Fix dependencies in container\n\n# Direct script usage\nRscript check_renv_for_commit.R --fix --fail-on-issues  # CI mode\nRscript check_renv_for_commit.R --quiet                 # Minimal output\nRscript check_renv_for_commit.R --help                  # Usage info"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.25 Multi-Developer Workflow",
    "text": "9.25 Multi-Developer Workflow\n\nInstall packages in container: Use install.packages() or renv::install() within Docker environment\nValidate team dependencies: Run make check-renv to check for conflicts before committing\nReview team impacts: Script identifies packages that would affect other team members\nSynchronize team environment: Use make check-renv-fix to update shared dependency files\nCommit with team confidence: Other developers can reproduce your exact environment"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.26 Integration with Development Workflows",
    "text": "9.26 Integration with Development Workflows\n\n9.26.1 Pre-commit Hooks\n# Add to .git/hooks/pre-commit\nRscript check_renv_for_commit.R --fail-on-issues --quiet\n\n\n9.26.2 Makefile Integration\ncheck-renv:\n    Rscript check_renv_for_commit.R\n\ncheck-renv-fix:\n    Rscript check_renv_for_commit.R --fix\n\ncheck-renv-ci:\n    Rscript check_renv_for_commit.R --quiet --fail-on-issues\n\n\n9.26.3 CI/CD Integration\n- name: Validate renv consistency\n  run: Rscript check_renv_for_commit.R --fail-on-issues --quiet\nThis approach ensures that collaborators can reliably reproduce your package environment and that CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html",
    "href": "posts/table_placement_rmarkdown/index.html",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "href": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "href": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "href": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#further-reading",
    "href": "posts/table_placement_rmarkdown/index.html#further-reading",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "References",
    "section": "",
    "text": "Quick reference materials for when you need answers fast. These living documents are continuously updated and expanded based on real-world usage.\nFind: - Command cheat sheets - Configuration templates - Common patterns and snippets - Troubleshooting checklists - Best practices summaries\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nCategories\n\n\nDescription\n\n\n\n\n\n\nR Commands Quick Reference\n\n\nR, reference, cheatsheet\n\n\nQuick lookup table of commonly used R commands for data manipulation, visualization, and analysis.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "321 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\n\n\n\n\nNote\n\n\n\nFilter by Topic: Click any badge below to filter publications by research area.\nMedical/Clinical Military/Defense Neuroimaging/Technical COVID/Healthcare General Research\n\nClear All Filters\n:::\nNA"
  },
  {
    "objectID": "research/index.html#publications",
    "href": "research/index.html#publications",
    "title": "Research",
    "section": "",
    "text": "321 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\n\n\n\n\nNote\n\n\n\nFilter by Topic: Click any badge below to filter publications by research area.\nMedical/Clinical Military/Defense Neuroimaging/Technical COVID/Healthcare General Research\n\nClear All Filters"
  },
  {
    "objectID": "research/index.html#advanced-filters",
    "href": "research/index.html#advanced-filters",
    "title": "Research",
    "section": "2 🔍 Advanced Filters",
    "text": "2 🔍 Advanced Filters\n\n2.1 📅 Publication Year\n\n\nYear Range: 1983 - 2024  \n\n1983 2024\n\n\n\n\n\n2.2 🏷️ Research Topics\n\n\n Clear Search\n\n\n\n\n🔍 Key Research Areas\n\n\nBiostatistics R\n\n\n\n\nMedical & Clinical\n\n\nAlzheimer’s disease Biomarkers Clinical trials Drug development Medical/Clinical\n\n\n\n\nMilitary & Defense\n\n\nMilitary health Military/Defense Traumatic brain injury\n\n\n\n\nNeuroimaging & Technical\n\n\nNeuroimaging Neuroimaging/Technical\n\n\n\n\nCOVID & Healthcare\n\n\nCOVID-19 COVID/Healthcare Sleep disorders\n\n\n\n\nOther Research\n\n\nbiomarkers blood-brain barrier cerebrospinal fluid Cognitive decline Epidemiology General Research hdl ldl Longitudinal studies Prevention trials ptau Statistical methods tau\n\n\n\n\n\n\n2.3 📊 Filter Summary\n\n\n\nTotal: 333 publications\n\n\nShowing: All\n\n\nActive filters: 0\n\n\n\nReset All Filters"
  },
  {
    "objectID": "research/index.html#publications-1",
    "href": "research/index.html#publications-1",
    "title": "Research",
    "section": "3 📚 Publications",
    "text": "3 📚 Publications\n\n\n\n3.1 2024\n\nGalasko, Douglas, Farlow, Martin R, Lucey, Brendan P, et al., “A multicenter, randomized, double-blind, placebo-controlled ascending dose study to evaluate the safety, tolerability, pharmacokinetics (PK) and pharmacodynamic (PD) effects of Posiphen in subjects with Early Alzheimer’s Disease”, Alzheimer’s Research & Therapy, (2024)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nMcEvoy, Cory, Crabtree, Adam, Case, John, et al., “Cumulative blast impulse is predictive for changes in chronic neurobehavioral symptoms following low level blast exposure during military training”, Military medicine, (2024)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kathleen F, Muzi, Mark, et al., “Increased [18F] Fluorodeoxyglucose Uptake in the Left Pallidum in Military Veterans with Blast-Related Mild Traumatic Brain Injury: Potential as an Imaging Biomarker and Mediation with Executive Dysfunction and Cognitive Impairment”, Journal of Neurotrauma, (2024)\nMedical/Clinical Biostatistics R Traumatic brain injury Military health Neuroimaging Biomarkers Cognitive decline\n\n🔗 Article\n\n\n\n\n3.2 2023\n\nReiman, Eric M, Pruzin, Jeremy J, Rios-Romenets, Silvia, et al., “A public resource of baseline data from the Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nRaskind, Murray A, Williams, Tammy, Holmes, Hollie, et al., “A randomized controlled clinical trial of prazosin for alcohol use disorder in active duty soldiers: Predictive effects of elevated cardiovascular parameters”, Alcoholism: Clinical and Experimental Research, (2023)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kati, Muzi, Mark, et al., “FDG-PET as a Clinical Diagnostic Biomarker for Repetitive Blast Mild Traumatic Brain Injury”, NEUROPSYCHOPHARMACOLOGY, (2023)\nMilitary/Defense Biostatistics R Traumatic brain injury Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Su, Yi, et al., “Impact of reference region on longitudinal florbetapir PET SUVR changes from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2023)\nNeuroimaging/Technical Biostatistics R Neuroimaging Longitudinal studies\n\n🔗 Article\n\n\n\nKeil, Samantha A, Schindler, Abigail G, Wang, Marie X, et al., “Longitudinal Sleep Patterns and Cognitive Impairment in Older Adults”, JAMA Network Open, (2023)\nMedical/Clinical Biostatistics R Sleep disorders Cognitive decline Longitudinal studies\n\n🔗 Article\n\n\n\nMeabon, James S, Schindler, Abigail G, Murray, Daniel R, et al., “Pontine pathology mediates common symptoms of blast-induced chronic mild traumatic brain injury”, medRxiv, (2023)\nMilitary/Defense Biostatistics R Traumatic brain injury\n\n🔗 Article\n\n\n\nQiu, Yuqi, Messer, Karen, Jacobs, Diane M, et al., “Prognostic value of plasma biomarkers in a clinical trial of mild-to-moderate Alzheimer’s Disease”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, McCall, Catherine A, Rosser, Aaron F, et al., “The relative contribution of COVID-19 infection versus COVID-19 related occupational stressors to insomnia in healthcare workers”, Sleep medicine: X, (2023)\nCOVID/Healthcare Biostatistics R COVID-19 Sleep disorders\n\n🔗 Article\n\n\n\n\n3.3 2022\n\nJansson, Deidre, Wang, Marie, Thomas, Ronald G., et al., “Markers of Cerebrovascular Injury, Inflammation, and Plasma Lipids Are Associated with Alzheimer’s Disease Cerebrospinal Fluid Biomarkers in Cognitively Normal Persons”, Journal of Alzheimer’s Disease, (2022)\nMedical/Clinical biomarkers blood-brain barrier cerebrospinal fluid hdl ldl ptau tau Alzheimer’s disease Biomarkers Cognitive decline\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, et al., “Sex differences in cognitive resilience in preclinical autosomal-dominant Alzheimer’s disease carriers and non-carriers: baseline findings from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2022)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nShadyab, Aladdin H, LaCroix, Andrea Z, Matthews, Genevieve, et al., “T2 Protect AD: Achieving a rapid recruitment timeline in a multisite clinical trial for individuals with mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2022)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Slevin, Rois', “The impact of the COVID-19 pandemic on mental health, occupational functioning, and professional retention among health care workers and first responders”, Journal of general internal medicine, (2022)\nCOVID/Healthcare Biostatistics R COVID-19\n\n🔗 Article\n\n\n\n\n3.4 2021\n\nSalloway, Stephen, Farlow, Martin, McDade, Eric, et al., “A trial of gantenerumab or solanezumab in dominantly inherited Alzheimer’s disease”, Nature Medicine, (2021), doi: 10.1038/s41591-021-01369-8\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article • 📄 PDF\n\n\n\nBinette, Alexa Pichet, Vachon-Presseau, Etienne, Morris, John, et al., “Amyloid and tau pathology associations with personality traits, neuropsychiatric symptoms, and cognitive lifestyle in the preclinical phases of sporadic and autosomal dominant Alzheimer’s disease”, Biological psychiatry, (2021)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, et al., “Optimizing aggregated N-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Creating Evidence from Real World Patient Digital Data, (2021)\nNeuroimaging/Technical Biostatistics R Biomarkers Statistical methods\n\n🔗 Article\n\n\n\nHu, Nan, Mackey, Howard, Thomas, Ronald, “Power and sample size for random coefficient regression models in randomized experiments with monotone missing data”, Biometrical Journal, (2021)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nMatthews, Dawn C, Ritter, Aaron, Thomas, Ronald G, et al., “Rasagiline effects on glucose metabolism, cognition, and tau in Alzheimer’s dementia”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2021)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nShadyab, Aladdin, others, “Recruitment of a multi-site randomized controlled trial of aerobic exercise for older adults with amnestic mild cognitive impairment: the EXERT trial”, Alzheimer’s & Dementia, (2021)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Slevin, Rois', “The Impact of the COVID-19 Pandemic on Mental Health, Occupational Functioning, and Professional Retention Among Health Care Workers and First Responders”, Journal of general internal medicine, (2021)\nCOVID/Healthcare Biostatistics R COVID-19\n\n🔗 Article\n\n\n\n\n3.5 2020\n\nRios-Romenets, Silvia, Lopera, Francisco, Sink, Kaycee M, et al., “Baseline demographic, clinical, and cognitive characteristics of the Alzheimer’s Prevention Initiative (API) Autosomal-Dominant Alzheimer’s Disease Colombia Trial”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Prevention trials\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, et al., “Development of a novel cognitive composite outcome to assess therapeutic effects of exercise in the EXERT trial for adults with MCI: The ADAS-Cog-Exec”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2020)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, et al., “Optimizing aggregated n-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Frontiers in Digital Health, (2020)\nNeuroimaging/Technical Biostatistics R Biomarkers Statistical methods\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Goradia, Dhruman D, et al., “PET evidence of preclinical cerebellar amyloid plaque deposition in autosomal dominant Alzheimer’s disease”, 2020 Alzheimer’s Association International Conference, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, et al., “Sex differences in neurodegeneration and memory performance in preclinical autosomal dominant Alzheimer’s disease: Baseline findings from the API ADAD trial: Intersections of sex/gender and race/ethnicity in cognitive aging and Alzheimer’s disease trajectories”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nLangbaum, Jessica B, Ellison, Noel N, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative Composite Cognitive Test: a practical measure for tracking cognitive decline in preclinical Alzheimer’s disease”, Alzheimer’s Research & Therapy, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Prevention trials\n\n🔗 Article\n\n\n\nMatthews, Dawn, Ritter, Aaron, Thomas, Ronald G, et al., “The Effects of Rasagiline on Glucose Metabolism and Cognition and Their Relationship to Tau Burden in a Double-Blind, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia”, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia (2/21/2020), (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n3.6 2019\n\nSano, Mary, Zhu, Carolyn W, Kaye, Jeffrey, et al., “A randomized clinical trial to evaluate home-based assessment of people over 75 years old”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Sink, Kaycee, et al., “F4-04-01: TRIAL DESIGN, DATA SHARING RISK MITIGATION, AND BASELINE CLINICAL AND COGNITIVE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nAcosta-Baena, Natalia, Rios-Romenets, Silvia, Munoz, Claudia, et al., “F4-04-02: AGE-RELATED CHANGES IN BASELINE COGNITIVE MEASURES IN UNIMPAIRED PSEN1 E280A MUTATION CARRIERS AND NON-CARRIERS IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nSu, Yi, Rios-Romenets, Silvia, Tariot, Pierre N, et al., “F4-04-03: RELATIONSHIPS BETWEEN BASELINE BRAIN IMAGING BIOMARKER MEASUREMENTS AND AGE IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nQuiroz, Yakeel T, Tariot, Pierre N, Sink, Kaycee, et al., “F4-04-04: ASSOCIATION BETWEEN CEREBRAL AMYLOIDOSIS AND WORSE COGNITIVE PERFORMANCE IN PRECLINICAL AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE: BASELINE FINDINGS FROM THE API COLOMBIA AUTOSOMAL DOMINANT AD TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nSchneider, Lon S, Geffen, Yona, Rabinowitz, Jonathan, et al., “Low-dose ladostigil for mild cognitive impairment: A phase 2 placebo-controlled clinical trial”, Neurology, (2019)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nHuisa, Branko N, Thomas, Ronald G, Jin, Shelia, et al., “Memantine and acetylcholinesterase inhibitor use in Alzheimer’s disease clinical trials: Potential for confounding by indication”, Journal of Alzheimer’s Disease, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKilian, Hett, Vinh-Thong, Ta, Gwenaelle, Catheline, et al., “Multimodal Hippocampal Subfield Grading For Alzheimer’s Disease Classification”, Scientific Reports (Nature Publisher Group), (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLiu, Jiao, Zhang, Binlong, Wilson, Georgia, et al., “New Perspective for Non-invasive Brain Stimulation Site Selection in Mild Cognitive Impairment: Based on Meta-and Functional Connectivity Analyses”, Frontiers in aging neuroscience, (2019)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nGupta, Yubraj, Lama, Ramesh Kumar, Kwon, Goo-Rak, et al., “Prediction and classification of Alzheimer’s disease based on combined features from apolipoprotein-E genotype, cerebrospinal fluid, MR, and FDG-PET imaging biomarkers”, Frontiers in computational neuroscience, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nZhao, Qian, Liu, Min, Ha, Lingxia, et al., “Quantitative 18F-AV1451 brain tau PET imaging in cognitively normal older adults, mild cognitive impairment, and Alzheimer’s disease patients”, Frontiers in neurology, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, et al., “Safety and efficacy of edonerpic maleate for patients with mild to moderate Alzheimer disease: a phase 2 randomized clinical trial”, JAMA neurology, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBorowsky, Beth, Lopez, Cristina Lopez, Tariot, Pierre, et al., “The Alzheimer Prevention Initiative Generation Program: Evaluation of CNP520 in Preclinical Alzheimer’s Disease (P4. 1-005)”, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nLopez, Cristina Lopez, Tariot, Pierre N, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative Generation Program: study design of two randomized controlled trials for individuals at risk for clinical onset of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Prevention trials\n\n🔗 Article\n\n\n\n\n3.7 2018\n\nKlinger, Rebecca Y, James, Olga G, Borges-Neto, Salvador, et al., “18F-florbetapir Positron Emission Tomography–determined Cerebral beta-Amyloid Deposition and Neurocognitive Performance after Cardiac Surgery”, Anesthesiology, (2018)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nRafii, Michael S, Tuszynski, Mark H, Thomas, Ronald G, et al., “Adeno-associated viral vector (serotype 2)–nerve growth factor for patients with alzheimer disease: a randomized clinical trial”, JAMA neurology, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHuisa, Branko, Thomas, Ronald, Jin, Shelia, et al., “Memantine and Cholinesterase Inhibitor Use in Alzheimer Disease Trials: Potential for Confounding by Indication (P6. 178)”, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, et al., “P3-032: SCREENING-TO-BASELINE COGNITIVE VARIABILITY DOES NOT PREDICT RATE OF DECLINE IN A CLINICAL TRIAL OF MILD-TO-MODERATE AD”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nReiman, Eric M, Sink, Kaycee M, Hu, Nan, et al., “P4-209: A PUBLIC RESOURCE OF BASELINE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nVerfaillie, Sander CJ, Binette, Alexa Pichet, Vachon-Presseau, Etienne, et al., “Subjective cognitive decline is associated with altered default mode network connectivity in individuals with a family history of Alzheimer’s disease”, Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Langbaum, Jessica B, et al., “The Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial: A study of crenezumab versus placebo in preclinical PSEN1 E280A mutation carriers to evaluate efficacy and safety in the treatment of autosomal-dominant Alzheimer’s disease, including a placebo-treated noncarrier cohort”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development Prevention trials\n\n🔗 Article\n\n\n\n\n3.8 2017\n\nRelkin, Norman R, Thomas, Ronald G, Rissman, Robert A, et al., “A phase 3 trial of IV immunoglobulin for Alzheimer disease”, Neurology, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLim, Yen Ying, Mormino, Elizabeth C, Alzheimer’s Disease Neuroimaging Initiative, et al., “APOE genotype and early beta-amyloid accumulation in older adults without dementia”, Neurology, (2017)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nRusso, Mar', “Adding recognition discriminability index to the delayed recall is useful to predict conversion from mild cognitive impairment to Alzheimer’s disease in the Alzheimer’s disease neuroimaging initiative”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nRisacher, Shannon L, Anderson, Wesley H, Charil, Arnaud, et al., “Alzheimer disease brain atrophy subtypes are associated with cognition and rate of decline”, Neurology, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMunilla, Jorge, Ortiz, Andres, Gorriz, Juan M, et al., “Construction and analysis of weighted brain networks from sice for the study of Alzheimer’s disease”, Frontiers in neuroinformatics, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nGuo, Shengwen, Lai, Chunren, Wu, Congling, et al., “Conversion discriminative analysis on mild cognitive impairment using multiple cortical features from MR images”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical Biostatistics R Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Aisen, Paul S, et al., “Randomized controlled trials in mild cognitive impairment: sources of variability”, Neurology, (2017)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nPark, Jong-Yun, Na, Han Kyu, Kim, Sungsoo, et al., “Robust identification of Alzheimer’s disease subtypes based on cortical atrophy patterns”, Scientific reports, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre, Lopez-Lopez, Cristina, Caputo, Angelika, et al., “The Alzheimer’s Prevention Initiative (API) Generation Program: Evaluating the Efficacy of the BACE-1 Inhibitor CNP520 in Preclinical Alzheimer’s Disease”, NEUROPSYCHOPHARMACOLOGY, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nLopez, C Lopez, Caputo, A, Liu, F, et al., “The Alzheimer’s Prevention Initiative Generation Program: evaluating CNP520 efficacy in the prevention of Alzheimer’s disease”, J Prev Alzheimers Dis, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nCaputo, Angelika, Racine, Amy, Paule, Ines, et al., “[O5–01–02]: RATIONALE FOR SELECTION OF PRIMARY ENDPOINTS IN THE ALZHEIMER PREVENTION INITIATIVE GENERATION STUDY IN COGNITIVELY HEALTHY APOE4 HOMOZYGOTES”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Prevention trials\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, et al., “[P4–573]: A PHASE 2 MULTICENTER, RANDOMIZED, PLACEBO-CONTROLLED TRIAL TO EVALUATE THE EFFICACY AND SAFETY OF EDONERPIC (T-817) IN PATIENTS WITH MILD TO MODERATE ALZHEIMER’s DISEASE”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n3.9 2016\n\nLiu, Haochen, Zhou, Xiaoting, Jiang, Hao, et al., “A semi-mechanism approach based on MRI and proteomics for prediction of conversion from mild cognitive impairment to Alzheimer’s disease”, Scientific reports, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nGelmont, David, Thomas, Ronald G, Britt, Jonathan, et al., “Demonstration of safety of intravenous immunoglobulin in geriatric patients in a long-term, placebo-controlled study of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDeming, Yuetiva, Xia, Jian, Cai, Yefei, et al., “Genetic studies of plasma analytes identify novel potential biomarkers for several complex traits”, Scientific Reports, (2016)\nNeuroimaging/Technical Biostatistics R Biomarkers\n\n🔗 Article\n\n\n\nThomas, Ronald G, Albert, Marilyn, Petersen, Ronald C, et al., “Longitudinal decline in mild-to-moderate Alzheimer’s disease: analyses of placebo data from clinical trials”, Alzheimer’s & Dementia, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nTariot, Pierre, Langbaum, Jessica, Schneider, Lon, et al., “The Alzheimer’s Prevention Initiative Generation Study: A Preclinical Trial in APOE4 Homozygotes”, NEUROPSYCHOPHARMACOLOGY, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Prevention trials\n\n🔗 Article\n\n\n\n\n3.10 2015\n\nTurner, R Scott, Thomas, Ronald G, Craft, Suzanne, et al., “A randomized, double-blind, placebo-controlled trial of resveratrol for Alzheimer disease”, Neurology, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nChen, Chi-Hua, Peng, Qian, Schork, Andrew J, et al., “Large-scale genomics unveil polygenic architecture of human cortical surface area”, Nature communications, (2015)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDonohue, Michael C, Moghadam, Setareh H, Roe, Allyson D, et al., “Longitudinal plasma amyloid beta in Alzheimer’s disease clinical trials”, Alzheimer’s & Dementia, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Raman, Rema, Sperling, Reisa A, et al., “Peripheral and central effects of \\\\gamma-secretase inhibition by semagacestat in Alzheimer’s disease”, Alzheimer’s research & therapy, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTurner, R, Thomas, Ronald, Craft, Suzanne, et al., “Resveratrol is safe and well-tolerated in individuals with mild-moderate dementia due to Alzheimer’s disease.(S33. 009)”, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGelmont, D, Thomas, RG, Dyck-Jones, JA, et al., “Safety of Intravenous Immunoglobulin Therapy in Patients with Probable Alzheimer’s Disease: A Randomized, Placebo-Controlled Clinical Study”, ANNALS OF ALLERGY ASTHMA & IMMUNOLOGY, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\nOrban, Pierre, Madjar, C'e, “Test-retest resting-state fMRI in healthy elderly persons with a family history of Alzheimer’s disease”, Scientific data, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nNewman, Rhian C, Ellis, Tim, Davison, Phil I, et al., “Using novel methodologies to examine the impact of artificial light at night on the cortisol stress response in dispersing Atlantic salmon (Salmo salar L.) fry”, Conservation physiology, (2015)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\n\n3.11 2014\n\nDoody, RS, Thomas, RG, Farlow, M, et al., “Alzheimer’s Disease Cooperative Study Steering Committee; Solanezumab study group. Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, MC, Sperling, RA, Salmon, DP, et al., “Australian imaging, biomarkers, and lifestyle flagship study of ageing; Alzheimer’s disease neuroimaging initiative; Alzheimer’s disease cooperative study. The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA Neurol, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Biomarkers Cognitive decline\n\n🔗 Article\n\n\n\nChen, Yun-Fei, Mohs, Richard, Ding, Ying, et al., “Bayesian Longitudinal Modeling on Placebo Data from Alzheimer’s Disease Clinical Studies (P1. 010)”, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Longitudinal studies\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bell, Joanne, Mancuso, Jessica Y, et al., “Clinical trial of an inhibitor of RAGE-A beta interactions in Alzheimer disease”, Neurology, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Jacqmin-Gadda, Hene, Le Goff, Melanie, et al., “Estimating long-term multivariate progression from short-term data”, Alzheimer’s & Dementia, (2014)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, Anthony, Jack, Clifford, et al., “F3-02-02: MODELING LONG-TERM DISEASE PROGRESSION WITH COVARIATES”, Alzheimer’s & Dementia, (2014)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo Adolfo, Thomas, Ronald G, Qiu, Hongmei, et al., “P1-357: ADCS EDC: INVESTIGATIONAL PRODUCT MANAGEMENT SYSTEM”, Alzheimer’s & Dementia, (2014)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nLaske, Christoph, “Phase 3 trials of solanezumab and bapineuzumab for Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Thomas, Ronald G, Farlow, Martin, et al., “Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, New England Journal of Medicine, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, Michael C, Sperling, Reisa A, Salmon, David P, et al., “The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA neurology, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\n\n3.12 2013\n\nDoody, Rachelle S, Raman, Rema, Farlow, Martin, et al., “A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, New England Journal of Medicine, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nSalmon, David P, Ferris, Steven H, Thomas, Ronald G, et al., “Age and apolipoprotein E genotype influence rate of cognitive decline in nondemented elderly.”, Neuropsychology, (2013)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nDoody, RS, Raman, R, Farlow, M, et al., “Alzheimer’s Disease Cooperative Study Steering Committee, Siemers E, Sethuraman G, Mohs R, Semagacestat Study Group. A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, N Engl J Med, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nPosner, Holly B, Cano, Stefan, Carrillo, Maria C, et al., “Establishing the psychometric underpinning of cognition measures for clinical trials of Alzheimer’s disease and its precursors: a new approach”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBurstein, Aaron, Galasko, Douglas, Aisen, Paul, et al., “P1–332: Evaluation of the relationship between TTP488 plasma concentrations and changes in ADAS-cog relative to placebo”, Alzheimer’s & Dementia, (2013)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald, Petersen, Ronald, Siuciak, Judith, et al., “P3–295: The Placebo Data Analysis in Alzheimer’s Disease (AD) and Mild Cognitive Impairment (MCI) Clinical Trials Project: Overview of progress in trial data collection, and key findings from the pooled Alzheimer’s disease trial datasets”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Bruschi, Stefania, et al., “P4–157: Adcs electronic data capture: Collaborative development and management of clinical trial databases”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nMills, Sarah M, Mallmann, J, Santacruz, Anna M, et al., “Preclinical trials in autosomal dominant AD: implementation of the DIAN-TU trial”, Revue neurologique, (2013)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nHobart, Jeremy, Cano, Stefan, Posner, Holly, et al., “Putting the Alzheimer’s cognitive test to the test II: Rasch Measurement Theory”, Alzheimer’s & dementia, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\n\n3.13 2012\n\nAustin, David, Thomas, Rob, “A Garden before the Garden: Landscape, History and the National Botanic Garden of Wales”, Landscapes, (2012)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGalasko, DR, Peskind, E, Clark, CM, et al., “Alzheimer’s Disease Cooperative Study. Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Arch Neurol, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nVellas, B, Hampel, H, Roug'e, “Alzheimer’s disease therapeutic trials: EU/US Task Force report on recruitment, retention, and methodology”, The journal of nutrition, health & aging, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nGalasko, Douglas R, Peskind, Elaine, Clark, Christopher M, et al., “Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Archives of neurology, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Jin, Shelia, He, Feng, et al., “Incidence of new-onset seizures in mild to moderate Alzheimer disease”, Archives of neurology, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nRelkin, Norman, Gessert, Devon, Stokes, Karen, et al., “O3-13-05: The Gammaglobulin Alzheimer Partnership Study (GAP): Design, screening, enrollment and futility analysis results”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Hong, Phuoc, et al., “P3-364: ADCS EDC”, Alzheimer’s & Dementia, (2012)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald, Jimenez, Gustavo, Brewer, James, et al., “P3-383: ADCS data sharing”, Alzheimer’s & Dementia, (2012)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAisen, Paul, Thomas, Ronald, Carrillo, Maria, et al., “P3-384: The placebo data analysis in Alzheimer’s disease and mild cognitive impairment (MCI) clinical trials project: Overview of progress in trial data collection, and key findings from the pooled MCI trial datasets”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\n\n3.14 2011\n\nRafii, MS, Walsh, S, Little, JT, et al., “A phase II trial of huperzine A in mild to moderate Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Bell, KL, Galasko, D, et al., “A randomized, double-blind, placebo-controlled trial of simvastatin to treat Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Raman, Rema, Emond, Jennifer, et al., “Adding delayed recall to the Alzheimer Disease Assessment Scale is useful in studies of mild cognitive impairment but not Alzheimer disease”, Alzheimer disease and associated disorders, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nTariot, Pierre N, Schneider, Lon S, Cummings, Jeffrey, et al., “Chronic divalproex sodium to attenuate agitation and clinical progression of Alzheimer disease”, Archives of General Psychiatry, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nFleisher, AS, Truran, D, Mai, JT, et al., “Chronic divalproex sodium use and brain atrophy in Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMockus, Danyte S, Macera, Caroline A, Wingard, Deborah L, et al., “Dietary self-monitoring and its impact on weight loss in overweight children”, International Journal of Pediatric Obesity, (2011)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nQuinn, JF, Raman, R, Thomas, RG, et al., “Omega-3 Fatty Acids for Alzheimer’s Disease. What a Pill Can Tell Us about Eating Fish”, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMessick, Viviana, Donohue, Michael, Raman, Rema, et al., “P3-406: Role of caregiver in subject’s compliance with treatment”, Alzheimer’s & Dementia, (2011)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nSmart, N, George, A, Khan, D, et al., “Radiological follow up of perineal repair with cross-linked acellular porcine dermal collagen following extralevator abdominoperineal excision for low rectal cancer: P115”, Colorectal Disease, (2011)\nGeneral Research Biostatistics R Longitudinal studies\n\n🔗 Article\n\n\n\nAisen, PS, Andrieu, S, Sampaio, C, et al., “Report of the task force on designing clinical trials in early (predementia) AD”, Neurology, (2011)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, AC, Thomas, RG, et al., “The relative efficiency of time-to-threshold and rate of change in longitudinal data”, Contemporary clinical trials, (2011)\nGeneral Research Biostatistics R Longitudinal studies\n\n🔗 Article\n\n\n\n\n3.15 2010\n\nAisen, Paul S, Petersen, Ronald C, Donohue, Michael C, et al., “Clinical Core of the Alzheimer’s Disease Neuroimaging Initiative: progress and plans”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, et al., “Docosahexaenoic acid supplementation and cognitive decline in Alzheimer disease: a randomized trial”, Jama, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nDonohue, Michael, Gamst, Anthony, Thomas, Ron, et al., “O3-01-07: Rate of decline in ADNI normal controls with evidence of amyloid burden”, Alzheimer’s & Dementia, (2010)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nFleisher, Adam S, Jack Jr, Clifford R, Weiner, Michael W, et al., “P1-433: Brain volume changes with divalproex sodium in Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Thomas, Ronald, Raman, Rema, et al., “P1-447: Cerebrospinal fluid biomarker outcomes in a trial of docosahexaenoic acid (DHA) for Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease Biomarkers\n\n🔗 Article\n\n\n\n\n3.16 2009\n\nRaman, Rema, Thomas, Ronald G, Weiner, Michael W, et al., “MRI substudy participation in Alzheimer disease (AD) clinical trials: baseline comparability of a substudy sample to entire study population”, Alzheimer disease and associated disorders, (2009)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Neuroimaging Epidemiology\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, et al., “O1-04-02: A clinical trial of docosahexanoic acid (DHA) for the treatment of Alzheimer’s disease”, Alzheimer’s & Dementia, (2009)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\nTariot, Pierre N, Aisen, Paul, Cummings, Jeffrey, et al., “O1-04-03: The ADCS valproate neuroprotection trial: Primary efficacy and safety results”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nCano, Stefan, Posner, Holly, Aisen, Paul, et al., “O4-04-07: The ADAS-cog’s performance as a measure—lessons from the ADNI study: Part 2-evaluation using modern psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nPosner, Holly, Cano, Stefan, Aisen, Paul, et al., “P1-269: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 1-evaluation using traditional psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nHobart, Jeremy, Posner, Holly, Aisen, Paul, et al., “P1-270: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 3-do the scale modifications add value?”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Raman, Rema, Schwarzschild, Michael A, et al., “Plasma urate and progression of mild cognitive impairment”, Neurodegenerative Diseases, (2009)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nMachado, C, Leisman, G, Koch, P, et al., “REVIEWS IN THE NEUROSCIENCES”, NEUROSCIENCES, (2009)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nPasner, Holly, Cano, Stefan J, Aisen, Paul, et al., “The ADAS-cog’s Performance as a Measure Lessons from the ADNI Study: Part 1-Evaluation Using Traditional Psychometric Methods”, Neurology, (2009)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\n\n3.17 2008\n\nKhachaturian, Zaven S, Petersen, Ronald C, Gauthier, Serge, et al., “A roadmap for the prevention of dementia: the inaugural Leon Thal Symposium”, Alzheimer’s & dementia: the journal of the Alzheimer’s Association, (2008)\nMedical/Clinical Biostatistics R Prevention trials\n\n🔗 Article\n\n\n\nAisen, PS, Schneider, LS, Sano, M, et al., “Alzheimer Disease Cooperative Study. High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nRoch-Levecq, Anne-Catherine, Brody, Barbara L, Thomas, Ronald G, et al., “Ametropia, preschoolers’ cognitive abilities, and effects of spectacle correction”, Archives of ophthalmology, (2008)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nDoody, RS, Gavrilova, SI, Sano, M, et al., “Dimebon investigators: Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, Lancet, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, et al., “Dual Task Test Could Help Diagnose Dementia”, JAMA, (2008)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana I, Sano, Mary, et al., “Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, The Lancet, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMeyer, Brett C, Raman, Rema, Hemmen, Thomas, et al., “Efficacy of site-independent telemedicine in the STRokE DOC trial: a randomised, blinded, prospective study”, The Lancet Neurology, (2008)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, et al., “High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nGalasko, Douglas, Peskind, Elaine, Clark, Christopher M, et al., “O2-04–06: Randomized clinical trial of antioxidant treatment in Alzheimer’s disease with CSF biomarker measures”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers Drug development\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Thomas, Ronald, et al., “P4-337: Dimebon improves cognition, function, and behavior in mild and moderate Alzheimer’s disease: Results by severity of a one-year, double-blind, placebo-controlled study”, Alzheimer’’s and Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald, et al., “P4-343: Omega 3 fatty acids and Alzheimer’s disease: Trial design and baseline study population characteristics in a clinical trial of docosahexanoic acid for Alzheimer’s disease”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Epidemiology\n\n🔗 Article\n\n\n\nRaman, Rema, Emond, Jennifer, Thomas, Ronald G, et al., “P4-387: Adding delayed recall to the Alzheimer’s disease assessment scale-cognitive subscale (ADAS-cog): Sensitivity in a clinical trial for Alzheimer’s disease and mild cognitive impairment”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nDoody, Rachelle, Seely, Lynn, Thomas, Ronald, et al., “Statistical treatment of withdrawal in trials of anti-dementia drugs–Authors’ reply”, The Lancet, (2008)\nMedical/Clinical Biostatistics R Drug development Statistical methods\n\n🔗 Article\n\n\n\n\n3.18 2007\n\nDoody, Rochelle, Gavrilova, Svetlana, Sano, Mary, et al., “Dimebon improves cognition, function, and behavior in patients with mild-moderate Alzheimer’s disease: Results of a randomized, double-blind, placebo-controlled study”, Neurology, (2007)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Kaye, Jeffrey, Ferris, Steven, et al., “P-081: The ACDS home assessment instrument: A pilot study”, Alzheimer’s & Dementia, (2007)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTHOMAS, RONALD J, CLARK, CHRISTOPHER A, “Population Dynamics of Meloidogyne incognita and RotylenchulusTenchulus reniformis Alone and in Combination, and Their Effects on Sweet Potato1”, (2007)\nGeneral Research Biostatistics R Epidemiology\n\n🔗 Article\n\n\n\nMay, Susanne, Gilman, Sid, Sowell, B Brooke, et al., “Potential outcome measures and trial design issues for multiple system atrophy”, Movement disorders, (2007)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAisen, Paul S, Jin, Shelia, Thomas, Ronald G, et al., “S3–02–01: ADCS homocysteine trial”, Alzheimer’s & Dementia, (2007)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Sano, Mary, et al., “S3–02–03: Results of a one-year randomized, placebo-controlled trial of dimebon for the treatment of mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia, (2007)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\n\n3.19 2006\n\nSano, Mary, Zhu, Carolyn W, Whitehouse, Peter J, et al., “ADCS Prevention Instrument Project: pharmacoeconomics: assessing health-related resource use among healthy elderly”, Alzheimer disease and associated disorders, (2006)\nGeneral Research Biostatistics R Prevention trials\n\n🔗 Article\n\n\n\nPetersen, Ronald, Thomas, Ronald, Grundman, Michael, et al., “Cognitive Changes in the Treatment of Mild Cognitive Impairment with Donepezil and Vitamin E: P02. 187”, Neurology, (2006)\nMedical/Clinical Biostatistics R Cognitive decline Drug development\n\n🔗 Article\n\n\n\n\n3.20 2005\n\nKrajewska, Maryla, Kim, Hoguen, Kim, Chul, et al., “Analysis of apoptosis protein expression in early-stage colorectal cancer suggests opportunities for new prognostic biomarkers”, Clinical Cancer Research, (2005)\nNeuroimaging/Technical Biostatistics R Biomarkers Statistical methods\n\n🔗 Article\n\n\n\nPfeiffer, E, Petersen, RC, Thomas, RG, et al., “Cognition in the treatment of mild cognitive impairment with donepezil and vitamin E”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical Biostatistics R Cognitive decline Drug development\n\n🔗 Article\n\n\n\nRoch–Levecq, A–C, Brody, B, Thomas, RG, et al., “Cognitive Outcomes of Corrective Lenses on Low Income Preschoolers With Hyperopia/Astimgatism: A Longitudinal Pilot Study”, Investigative Ophthalmology & Visual Science, (2005)\nMedical/Clinical Biostatistics R Cognitive decline Longitudinal studies\n\n🔗 Article\n\n\n\nGalasko, D, Schmitt, F, Thomas, R, et al., “Detailed assessment of activities of daily living in moderate to severe Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Raman, Rema, Jakimovich, Laura, et al., “Divalproex sodium in nursing home residents with possible or probable Alzheimer disease complicated by agitation: a randomized, controlled trial”, The American journal of geriatric psychiatry, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nPeskind, Elaine R, Tsuang, Debby W, Bonner, Lauren T, et al., “Propranolol for disruptive behaviors in nursing home residents with probable or possible Alzheimer disease: a placebo-controlled study”, Alzheimer Disease & Associated Disorders, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nEdland, SD, May, S, Emond, JA, et al., “Sample size considerations in dementia prevention trials: Data from the Alzheimer’s disease Cooperative Study MCI Trial”, NEUROLOGY, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nBrody, Barbara L, Roch-Levecq, Anne-Catherine, Thomas, Ronald G, et al., “Self-management of age-related macular degeneration at the 6-month follow-up: a randomized controlled trial”, Archives of Ophthalmology, (2005)\nGeneral Research Biostatistics R Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Grundman, M, et al., “Treatment of MCI with cholinesterase inhibitors: current data”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, et al., “Vitamin E and donepezil for the treatment of mild cognitive impairment”, New England Journal of Medicine, (2005)\nMedical/Clinical Biostatistics R Cognitive decline Drug development\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, et al., “[O1-04-04]: Operational criteria for patient recruitment in trials of mild cognitive impairment”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Grundman, Michael, et al., “[O2-01-01]: Donepezil and vitamin E in the progression of mild cognitive impairment to Alzheimer’s disease: A hazard-ratio analysis”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\n\n3.21 2004\n\nHamilton, Joanne M, Salmon, David P, Galasko, Douglas, et al., “A comparison of episodic memory deficits in neuropathologically-confirmed Dementia with Lewy bodies and Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nThomas, Ronald G, Aisen, Paul S, Shoulson, Ira, et al., “Distinguished From Alzheimer Disease and Normal Aging for Clinical Trials Michael Grundman, MD, MPH; Ronald C. Petersen, PhD, MD; Steven H. Ferris, PhD”, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Neuroimaging\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Thal, L, “Donepezil and vitamin E for mild cognitive impairment”, 9th International Congress on Alzheimer’s Disease. Philadelphia, (2004)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nArgent, R, Thomas, R, Boughan, P, et al., “MAP kinase inhibitors reduce Helicobacter pylori-induced interleukin-8 secretion and the phosphorylation of I\\\\kappaB\\\\\\\\alpha”, Helicobacter, (2004)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Ferris, Steven H, et al., “Mild cognitive impairment can be distinguished from Alzheimer disease and normal aging for clinical trials”, Archives of neurology, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, et al., “P1-003 ADCS Prevention instrument project: assessment of activities of daily living (ADL)”, Neurobiology of Aging, (2004)\nGeneral Research Biostatistics R Prevention trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Thal, Leon, Jakimovich, Laura, et al., “P1-322 A multicenter, randomized, double-blind, placebo-controlled trial of valproate for agitation associated with dementia”, Neurobiology of Aging, (2004)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Tractenberg, Rochelle E, Sano, Mary, et al., “Reliability of monitoring the clinical dementia rating in multicenter clinical trials”, Alzheimer disease and associated disorders, (2004)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon, “S5-03-02 Prevention trials in Alzheimer’s disease: design issues”, Neurobiology of Aging, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\n\n3.22 2003\n\nSinger, Clifford, Tractenberg, Rochelle E, Kaye, Jeffrey, et al., “A multicenter, placebo-controlled trial of melatonin for sleep disturbance in Alzheimer’s disease”, Sleep, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Sleep disorders\n\n🔗 Article\n\n\n\nGrundman, M, Capparelli, E, Kim, HT, et al., “A multicenter, randomized, placebo controlled, multiple-dose, safety and pharmacokinetic study of AIT-082 (Neotrofin™) in mild Alzheimer’s disease patients”, Life sciences, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, PS, Schafer, KA, Grundman, M, et al., “Alzheimer’s Disease Cooperative Study. Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly A, Grundman, Michael, et al., “Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Mulnard, Ruth, et al., “Estrogen levels do not correlate with improvement in cognition”, Archives of Neurology, (2003)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, RG, Choudhury, RK, Mohanty, AK, et al., “Fission fragment angular distributions: A probe to study heavy-ion fusion dynamics”, Physical Review C, (2003)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGrundman, Michael, Jack, Clifford R, Petersen, Ronald C, et al., “Hippocampal volume is associated with memory but not nonmemory cognitive performance in patients with mild cognitive impairment”, Journal of Molecular Neuroscience, (2003)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nThal, LJ, Grundman, M, Berg, J, et al., “Idebenone treatment fails to slow cognitive decline in Alzheimer’s disease”, Neurology, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Drug development\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly, Grundman, Michael, et al., “NSAIDs and hypertension”, Archives of internal medicine, (2003)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRaskind, Murray A, Peskind, Elaine R, Kanter, Evan D, et al., “Reduction of nightmares and other PTSD symptoms in combat veterans by prazosin: a placebo-controlled study”, American Journal of Psychiatry, (2003)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nBrody, BL, Roch-Levecq, AC, Thomas, RG, et al., “Self-Management of Age-Related Macular Degeneration and Quality of Life at 6 Months Follow-Up: A Randomized Controlled Trial”, Investigative Ophthalmology & Visual Science, (2003)\nGeneral Research Biostatistics R Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nAisen, PS, Berg, JD, Craft, S, et al., “Steroid-induced elevation of glucose in Alzheimer’s disease: relationship to gender, apolipoprotein E genotype and cognition”, Psychoneuroendocrinology, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n3.23 2002\n\nGrundman, Michael, Farlow, Martin, Peavy, Guerry, et al., “A phase I study of AIT-082 in healthy elderly volunteers”, Journal of Molecular Neuroscience, (2002)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nPierce, John P, Faerber, Susan, Wright, Fred A, et al., “A randomized trial of the effect of a plant-based dietary pattern on additional breast cancer events and survival:: the Women’s Healthy Eating and Living (WHEL) Study”, Controlled clinical trials, (2002)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nSalmon, David P, Thomas, RG, Pay, MM, et al., “Alzheimer’s disease can be accurately diagnosed in very mildly impaired individuals”, Neurology, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Jin, Shelia, et al., “Assessing Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory: scoring and clinical implications”, Journal of psychiatric research, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, Clifford R, et al., “Brain MRI hippocampal volume and prediction of clinical status in a mild cognitive impairment trial”, Journal of Molecular Neuroscience, (2002)\nMedical/Clinical Biostatistics R Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nGrundman, M, Kim, HT, Schultz, AN, et al., “Clinical correlates of hippocampal atrophy in patients with mild cognitive impairment”, NEUROBIOLOGY OF AGING, (2002)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nHamilton, JM, Corey-Bloom, J, Thomas, RG, et al., “Correlates of weight change in Huntington’s disease”, NEUROLOGY, (2002)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nLange, Kelly L, Bondi, Mark W, Salmon, David P, et al., “Decline in verbal memory during preclinical Alzheimer’s disease: examination of the effect of APOE genotype”, Journal of the International Neuropsychological Society: JINS, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nJames, MW, Argent, RH, Thomas, R, et al., “Indomethacin reduces Helicobacter pylori-induced interleukin-8 (IL-8) production by the gastric epithelial cell line, AGS.”, GASTROENTEROLOGY, (2002)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Gamst, Anthony, Thomas, Ronald G, et al., “Investigating emergent symptomatology as an outcome measure in a behavioral study of Alzheimer’s disease”, The Journal of neuropsychiatry and clinical neurosciences, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Sano, Mary, et al., “No long-term effect of behavioral treatment on psychotropic drug use for agitation in Alzheimer’s disease patients”, Journal of geriatric psychiatry and neurology, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nGoldberg, DE, Roch-Levecq, AC, Maclean, KK, et al., “Psychosocial and Functional Parameters in Patients with Age Related Macular Degeneration and Choroidal Neovascularization with and without Photodynamic Therapy”, Investigative Ophthalmology & Visual Science, (2002)\nGeneral Research Biostatistics R Drug development\n\n🔗 Article\n\n\n\nAisen, P, Schafer, K, Grundman, M, et al., “Results of a multicenter trial of rofecoxib and naproxen in Alzheimer’s disease”, Neurobiology of Aging, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSinger, C, Colling, E, Tractenberg, R, et al., “The ADCS clinical trial of melatonin for the sleep disturbance of alzheimer’s disease: Case report of an unusual sleep/wake cycle and response to melatonin.”, AMERICAN JOURNAL OF GERIATRIC PSYCHIATRY, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease Sleep disorders Clinical trials\n\n🔗 Article\n\n\n\n\n3.24 2001\n\nTractenberg, Rochelle E, Gamst, Anthony, Weiner, Myron F, et al., “Frequency of behavioral symptoms characterizes agitation in Alzheimer’s disease”, International journal of geriatric psychiatry, (2001)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Thomas, RG, et al., “Incidence and persistence of psychosis in Alzheimer’s disease”, Neurology, (2001)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLindblad, Ulf, Langer, Robert D, Wingard, Deborah L, et al., “Metabolic syndrome and ischemic heart disease in elderly men and women”, American journal of epidemiology, (2001)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.25 2000\n\nAisen, Paul S, Davis, KL, Berg, JD, et al., “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKoch, HJ, Szecsey, A, “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThomas, Ronald G, Berg, Julie D, Sano, Mary, et al., “Analysis of longitudinal data in an Alzheimer’s disease clinical trial”, Statistics in medicine, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Statistical methods Longitudinal studies\n\n🔗 Article\n\n\n\nBayley, Peter J, Salmon, David P, Bondi, Mark W, et al., “Comparison of the serial position effect in very mild Alzheimer’s disease, mild Alzheimer’s disease, and amnesia associated with electroconvulsive therapy”, Journal of the International Neuropsychological Society, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nGamst, A, Thomas, RG, Patterson, M, et al., “Description of behaviors emerging in community-dwelling persons with Alzheimer’s disease over 12 months”, ANNALS OF NEUROLOGY, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTHOMAS, R, MICHAEL, J, “Disorder among Veterans with Substance Abuse”, THE JOURNaL OF NERvOUs AND MEntal Disease, (2000)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nMulnard, Ruth A, Cotman, Carl W, Kawas, Claudia, et al., “Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, Jama, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\nPaulsen, Jane S, Salmon, DP, Thal, Leon J, et al., “Incidence of and risk factors for hallucinations and delusions in patients with probable AD”, Neurology, (2000)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Knopman, D, et al., “Predicting nursing home placement with change on cognitive measures in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Patterson, Marian, Weiner, Myron F, et al., “Prevalence of symptoms on the CERAD behavior rating scale for dementia in normal elderly subjects and Alzheimer’s disease patients”, The Journal of neuropsychiatry and clinical neurosciences, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Jin, Shelia, Patterson, Marian, et al., “Qualifying change: a method for defining clinically meaningful outcomes of change score computation”, Journal of the American Geriatrics Society, (2000)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle, Teri, Linda, et al., “Quantifying behavioral disturbance in Alzheimer’s disease patients”, Journal of Psychiatric Research, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTeri, Linda, Logsdon, RG, Peskind, E, et al., “Treatment of agitation in AD: a randomized, placebo-controlled clinical trial”, Neurology, (2000)\nMedical/Clinical Biostatistics R Clinical trials Drug development\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, CR, et al., “Use of brain MRI volumetric analysis in a mild cognitive impairment trial to delay the diagnosis of Alzheimer’s disease”, Drug discovery and development for Alzheimer’s disease, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\nMulnard, RA, Cotman, CW, Kawas, C, et al., “for the Alzheimer’s Disease Cooperative Study: Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, JAMA, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\n\n3.26 1999\n\nLineweaver, Tara T, Bondi, Mark W, Thomas, Ronald G, et al., “A normative study of Nelson’s (1976) modified version of the Wisconsin Card Sorting Test in healthy older adults”, The Clinical Neuropsychologist, (1999)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nBrody, Barbara L, Williams, Rebecca A, Thomas, Ronald G, et al., “Age-related macular degeneration: a randomized clinical trial of a self-management intervention”, Annals of Behavioral Medicine, (1999)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, et al., “Assessment of agitation in Alzheimer’s disease: the agitated behavior in dementia scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, et al., “Brief Methodological Reports-Assessment of Agitation in Alzheimer’s Disease: The Agitated Behavior in Dementia Scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nOlin, JT, Papka, M, Jin, S, et al., “Clinical symptoms of dementia with Lewy bodies: Secondary analyses of the Alzheimer’s disease cooperative study selegiline and vitamin E clinical trial”, European Neuropsychopharmacology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBell, Karen, Sano, Mary, Jin, Shelia, et al., “Ethnic differences in clinical measures among participants in Alzheimer’s disease clinical trials”, Neurology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHohl, Ursula, Grundman, Michael, Salmon, David P, et al., “Mini-mental state examination and Mattis Dementia Rating Scale performance differs in Hispanic and non-Hispanic Alzheimer’s disease patients”, Journal of the International Neuropsychological Society, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSabbagh, Marwan N, Corey-Bloom, Jody, Tiraboschi, Pietro, et al., “Neurochemical markers do not correlate with cognitive decline in the Lewy body variant of Alzheimer disease”, Archives of neurology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nBondi, Mark W, Salmon, David P, Galasko, Douglas, et al., “Neuropsychological function and apolipoprotein E genotype in the preclinical detection of Alzheimer’s disease.”, Psychology and aging, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nKnopman, David S, Berg, JD, Thomas, R, et al., “Nursing home placement is related to dementia progression: experience from a clinical trial”, Neurology, (1999)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Sano, Mary, Berg, Julie, et al., “The Beneficial Effects of Vitamin E and Selegiline in a Controlled Trial in Alzheimer’s Disease Are Independent of the Apolipoprotein E e4 Allele”, Neurology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nChambers, Christina D, Anderson, Philip O, Thomas, Ronald G, et al., “Weight gain in infants breastfed by mothers who take fluoxetine”, Pediatrics, (1999)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.27 1998\n\nWeiner, Myron F, Koss, Elisabeth, Patterson, Marian, et al., “A comparison of the Cohen-Mansfield agitation inventory with the cerad behavioral rating scale for dementia in community-dwelling persons with Alzheimers disease”, Journal of psychiatric research, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle, Schafer, Kimberly, Thomas, Ron, et al., “Agreement on CDR ratings by committee”, Controlled Clinical Trials, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTanaka, S, Chen, X, Xia, Y, et al., “Association of CYP2D microsatellite polymorphism with Lewy body variant of Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nPeavy, GM, Salmon, DP, Thomas, RG, “Cognitive and functional abilities in severely demented Alzheimer’s patients”, CLINICAL NEUROPSYCHOLOGIST, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nFerry, David R, O’Rourke, Robert A, Blaustein, Alvin S, et al., “Design and baseline characteristics of the veterans affairs non-Q-wave infarction strategies in-hospital (VANQWISH) trial”, Journal of the American College of Cardiology, (1998)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nJin, Shelia, Thomas, Ronald G, Galasko, Douglas, et al., “Dynamic measurement scale development for clinical trials in targeted populations”, Controlled Clinical Trials, (1998)\nMedical/Clinical Biostatistics R Clinical trials Epidemiology\n\n🔗 Article\n\n\n\nGalasko, D, Chang, L, Motter, R, et al., “High cerebrospinal fluid tau and low amyloid beta42 levels in the clinical diagnosis of Alzheimer disease and relation to apolipoprotein E genotype”, Archives of neurology, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nKatzman, R, Kang, D, Thomas, R, “Interaction of apolipoprotein E 4 with other genetic and non-genetic risk factors in late onset Alzheimer disease: problems facing the investigator”, Neurochemical research, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nBerg, Julie D, Thomas, Ronald G, Thal, Leon J, et al., “Measuring cognitive progression in Alzheimer’s disease”, Controlled Clinical Trials, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nKean, Yin M, Thomas, Ronald G, Thal, Leon J, “Power calculation for randomized start design”, Controlled Clinical Trials, (1998)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nLineweaver, TT, Bondi, MW, Thomas, RG, “Practice effects on the modified Wisconsin card sorting test in normally aging adults”, Archives of Clinical Neuropsychology, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nFroelicher, Victor F, Lehmann, Kenneth G, Thomas, Ronald, et al., “The electrocardiographic exercise test in a population with reduced workup bias: diagnostic performance, computerized interpretation, and multivariable prediction”, Annals of internal medicine, (1998)\nGeneral Research Biostatistics R Epidemiology\n\n🔗 Article\n\n\n\nWilliams, Rebecca A, Brody, Barbara L, Thomas, Ronald G, et al., “The psychosocial impact of macular degeneration”, Archives of ophthalmology, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nKnopman, David, Sano, Mary, Berg, Julie, et al., “The relationship between Nursing home placement and measures of change in Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Welty, Greg, Thomas, Ronald G, “Use of the world wide web in data dissemination to central review committees”, Controlled Clinical Trials, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nKeane, Terence M, Kolb, Lawrence C, Kaloupek, Danny G, et al., “Utility of psychophysiological measurement in the diagnosis of posttraumatic stress disorder: results from a Department of Veterans Affairs Cooperative Study.”, Journal of consulting and clinical psychology, (1998)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\n\n3.28 1997\n\nJeong, Jong-Hyeon, Klauber, Melville R, Thomas, Ronald G, et al., “53 Power comparisons among different number of categories under ordered polytomous logistic regression model”, Controlled Clinical Trials, (1997)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nWhitehouse, Peter J, Schmitt, HFrederick A, Sano, Mary, et al., “A Multicenter Evaluation of New Treatment Efficacy”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Thomas, Ronald G, et al., “A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease”, New England Journal of Medicine, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nPatterson, Marian B, Mack, James L, Mackell, Joan A, et al., “A longitudinal study of behavioral pathology across five levels of dementia severity in Alzheimer’s disease: The CERAD Behavior Rating Scale for Dementia.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Longitudinal studies\n\n🔗 Article\n\n\n\nSano, Mary, Thomas, Ronald G, Thal, Leon J, “Alpha-tocopherol and Alzheimer’s disease”, The New England Journal of Medicine, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, et al., “An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSeubert, PA, Motter, RN, Schenk, DB, et al., “ApoE genotype influences the CSF level of A \\\\beta 42 in Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nKoss, Elisabeth, Weiner, Myron, Ernesto, Christopher, et al., “Assessing patterns of agitation in Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory. The Alzheimer’s Disease Cooperative Study.”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Seubert, P, Motter, R, et al., “CSF levels of A beta 432 and tau as aids to diagnosing Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nRoch, J-M, Sundsmo, M, Otero, D, et al., “Defective Neurite Extension Is Caused by a Mutation in Amyloid /A4 (A ) Protein Precursor Found in Familial Alzheimer’s Disease”, JOURNAL OF NEUROBIOLOGY, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLi, Hai Ling, Roch, Jean-Marc, Sundsmo, Mary, et al., “Defective neurite extension is caused by a mutation in amyloid beta protein precursor found in familial Alzheimer’s disease”, Journal of neurobiology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nHohl, U, CoreyBloom, J, Hansen, LA, et al., “Diagnostic accuracy of dementia with Lewy bodies: A prospective evaluation”, Neurology, (1997)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, et al., “Effects of Selegiline and alpha-Tocopherol on cognitive and functional outcome measures in moderately impaired patients with Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nKatzman, R, Zhang, M-Y, Chen, PJ, et al., “Effects of apolipoprotein E on dementia and aging in the Shanghai Survey of Dementia”, Neurology, (1997)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nBarrett-Connor, Elizabeth, Thomas, Ronald G, “Estrogen, apolipoprotein E, and dementia”, Journal of women’s health, (1997)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nKang, DE, Saitoh, T, Chen, X, et al., “Genetic association of the low-density lipoprotein receptor-related protein gene (LRP), and apolipoprotein E receptor, with late-onset Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald G, Welty, Greg, et al., “P23 use of the world wide web for clinical monitoring in multicenter clinical trials”, Controlled Clinical Trials, (1997)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nWilliams, RA, Brody, BL, Kaplan, RM, et al., “Quality of life among elderly adults with macular degeneration”, INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE, (1997)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Sano, Mary, “Tacrine and nursing home placement”, Neurology, (1997)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSano, M, Mackell, JA, Ponton, M, et al., “The Spanish Instrument Protocol: Design and implementation of a study to evaluate treatment efficacy instruments for Spanish-speaking patients with Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, et al., “Validity and reliability of the Alzheimer’s Disease Cooperative Study-Clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, et al., “for the members of the Alzheimer’s Disease Cooperative Study”, A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease. N Engl J Med, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, LS, Olin, JT, Doody, RS, et al., “the Alzheimer’s Disease Cooperative Study. Validity and reliability of the Alzheimer’s disease cooperative study-clinical global impression of change”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Sano, M, et al., “the Alzheimer’s Disease Cooperative Study. An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n3.29 1996\n\nThomas, Ronald G, Schafer, Kimberly, Woodbury, Peter, et al., “A32 computer-aided clinical monitoring: Results of a controlled experiment”, Controlled Clinical Trials, (1996)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Ernesto, Christopher, Sano, Mary, et al., “A34 Clinical monitoring of rating scales in multicenter clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nChen, X, Xia, Y, Gresham, LS, et al., “ApoE and CYP2D6 polymorphism with and without parkinsonism-dementia complex in the people of Chamorro, Guam”, Neurology, (1996)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nKatzman, R, Galasko, DR, Saitoh, T, et al., “Apolipoprotein-epsilon4 and head trauma: Synergistic or additive risks?”, Neurology, (1996)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Ernesto, C, et al., “Development of a pool of items to assess activities of daily living in clinical trials for Alzheimer’s disease”, Neurology, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, M, Growdon, J, Thomas, R, et al., “Evaluation of efficacy measures in clinical trials for Alzheimer’s disease: Does psychometric test performance predict clinically relevant outcomes?”, Neurology, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nWright, Fred A, Thomas, Ronald G, “Familial melanoma and pancreatic cancer”, The New England journal of medicine, (1996)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald, Galasko, Douglas, et al., “P63 Informed consent issues when including genetic testing in clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Morris, JC, et al., “Rate of dementia of the Alzheimer type (DAT) in subjects with mild cognitive impairment”, Neurology, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Klauber, Melville R, et al., “Rationale and design of a multicenter study of selegiline and alpha-tocopherol in the treatment of Alzheimer disease using novel clinical outcomes. Alzheimer’s Disease Cooperative Study.”, Alzheimer disease and associated disorders, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nSeidner, Andrea L, Burling, Thomas A, Gaither, David E, et al., “Substance-dependent inpatients who accept smoking treatment”, Journal of Substance Abuse, (1996)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, et al., “Validity and reliability of the Alzheimers disease cooperative study-clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease Springer, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n3.30 1995\n\nLi, Dominic, German, Donald, Lulla, Sulochina, et al., “Prospective study of hospitalization for asthma: a preliminary risk factor model”, American journal of respiratory and critical care medicine, (1995)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, RG, Jin, S, Schafer, K, et al., “The Spanish Instrument Protocol: a Study to Evaluate Treatment Efficacy Instruments for Spanish-Speaking Patients with Alzheimer’s Disease”, Alzheimer Disease and Associated Disorders, (1995)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\n\n3.31 1994\n\nAstion, Michael L, Wener, Mark H, Thomas, Ronald G, et al., “Application of neural networks to the classification of giant cell arteritis”, Arthritis & Rheumatism: Official Journal of the American College of Rheumatology, (1994)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nIrving, Lori M, Seidner, Andrea L, Burling, Thomas A, et al., “Drug and alcohol abuse inpatients’ attitudes about smoking cessation”, Journal of Substance Abuse, (1994)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nThomas, Ralf, “Zweibaryonensysteme mit Strangeness und die Antikaon-Deuteron Streuung”, (1994)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.32 1993\n\nWilson, Sandra R, Scamagas, Peter, German, Donald F, et al., “A controlled trial of two forms of self-management education for adults with asthma”, The American journal of medicine, (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nConlon, Michael, Thomas, Ronald G, “Algorithm AS 280: the power function for Fisher’s exact test”, Journal of the Royal Statistical Society. Series C (Applied Statistics), (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAstion, ML, Wener, MH, Thomas, RG, et al., “Overtraining in neural networks that interpret clinical data”, Clinical chemistry, (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nMorrow, Kiernan, Morris, Charles K, Froelicher, Victor F, et al., “Prediction of cardiovascular death in men undergoing noninvasive evaluation for coronary artery disease”, Annals of Internal Medicine, (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nWard, TT, Thomas, RG, Fye, CL, et al., “Trimethoprim-sulfamethoxazole prophylaxis in granulocytopenic patients with acute leukemia: evaluation of serum antibiotic levels in a randomized, double-blind, placebo-controlled Department of Veterans Affairs Cooperative Study”, Clinical infectious diseases, (1993)\nMilitary/Defense Biostatistics R Clinical trials Military health\n\n🔗 Article\n\n\n\n\n3.33 1992\n\nThomas, Ronald G, Conlon, Michael, “An algorithm for the rapid evaluation of the power function for Fisher’s Exact Test”, Journal of statistical computation and simulation, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nBeuschel, T, Feldkeller, B, Fuchs, M, et al., “Calculation of observables in the pion-deuteron system. Berechnung von Observablen im Pion Deuteron-System”, Verhandlungen der Deutschen Physikalischen Gesellschaft;(Germany), (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nKerns, David L, Ritter, Mary L, Thomas, Ronald G, “Concave hymenal variations in suspected child sexual abuse victims”, Pediatrics, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRAYNAULD, JP, THOMAS, RG, BLOCH, DA, “PROGRESSION OF FUNCTIONAL DISABILITY IN RHEUMATOID-ARTHRITIS”, ARTHRITIS AND RHEUMATISM, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald G, Conlon, Michael, “Sample size determination based on Fisher’s exact test for use in 2 x 2 comparative trials with low event rates”, Controlled clinical trials, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nFuchs, M, Huber, MG, Metsch, BC, et al., “Two-baryon systems with strangeness S=-1 and S=-2”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.34 1991\n\nSheridan, Lenore, Thomas, Ronald G, “An analysis of methods of communication in clinical trials”, Controlled Clinical Trials, (1991)\nMedical/Clinical Biostatistics R Clinical trials Statistical methods\n\n🔗 Article\n\n\n\nGordon, DE, Thomas, R, Shedrow, CB, et al., “Integration of statutory provisions of NEPA, RCRA, and CERCLA at the Savannah River site. Revision 1”, (1991)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.35 1990\n\nConlon, Michael, Thomas, Ronald G, “A new confidence interval for the difference of two binomial proportions”, Computational Statistics & Data Analysis, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Data monitoring through stochastic curtailing when the outcome proportions are small: An exact approach”, Controlled Clinical Trials, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, R, Empl, E, Kilian, K, et al., “Development of an active target for scattering of neutral baryons”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDecker, G, Kilian, K, Lippert, C, et al., “Test measurements of an asymmetric induction drift chamber with flash ADC’s”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTyrell, Doris, Cline, Dorothy R, Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nLee, Kelvin K, Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.36 1989\n\nHale, William E, May, Franklin E, Thomas, Ronald G, et al., “Effect of zinc supplementation on the development of cardiovascular disease in the elderly”, Journal of Nutrition for the Elderly, (1989)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Exact sample size calculations for 2x2 comparative trials when the outcome proportions are small”, Controlled Clinical Trials, (1989)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nEllis, Stephen G, Shaw, Richard E, Gershony, Gary, et al., “Risk factors, time course and treatment effect for restenosis after successful percutaneous transluminal coronary angioplasty of chronic total occlusion”, The American journal of cardiology, (1989)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\n\n3.37 1988\n\nEllis, SG, Roubin, GS, King 3rd, SB, et al., “Angiographic and clinical predictors of acute closure after native vessel coronary angioplasty.”, Circulation, (1988)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nMELLEN, BG, THOMAS, RG, CASTANO, D, “FORMS INVENTORY SYSTEM FOR A COMPLEX CLINICAL-TRIAL”, CONTROLLED CLINICAL TRIALS, (1988)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRoubin, Gary S, Douglas Jr, John S, King 3rd, SB, et al., “Influence of balloon size on initial success, acute complications, and restenosis after percutaneous transluminal coronary angioplasty. A prospective randomized study.”, Circulation, (1988)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\n\n3.38 1987\n\nMufson, LGAR, Roubin, GS, Black, A, et al., “A comparison of single lesion dilatation in single vessel and multivessel disease”, Circulation, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nMcGlynn, F Dudley, LeCompte, E Joseph, Thomas, Ronald G, et al., “Effects of behavioral self-management on oral hygiene adherence among orthodontic patients”, American Journal of Orthodontics and Dentofacial Orthopedics, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSherertz, Robert J, Belani, Anusha, Kramer, Barnett S, et al., “Impact of air filtration on nosocomial Aspergillus infections: unique risk of bone marrow transplant recipients”, The American journal of medicine, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nShcrertz, RJ, Belani, A, Kramer, BS, et al., “Impact of air filtration on nosocomial aspergillus infections”, Am J Med, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, RG, Black, A, Lin, S, et al., “Is there dependence between sites for continued success or restenosis after successful multisite coronary angioplasty”, Circulation, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRoubin, GS, Sutor, C, Lembo, NJ, et al., “PROGNOSIS AFTER MULTIPLE VESSEL ANGIOPLASTY (PTCA) IN PATIENTS WITH CORONARY-ARTERY DISEASE”, Circulation, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.39 1986\n\nThal, Leon J, Grundman, Michael, Golden, Robert, “Alzheimer’s disease: a correlational analysis of the Blessed Information-Memory-Concentration test and the Mini-Mental State Exam”, Neurology, (1986)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\n\n3.40 1985\n\nHUWS, DA, FAN, TP, THOMAS, RU, “ELUTION OF PROSTAGLANDIN-E2 FROM FILTER-PAPER STRIPS-EFFICIENCY AND REPRODUCIBILITY”, JOURNAL OF DENTAL RESEARCH, (1985)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.41 1984\n\nSchubert, Mark M, Guttu, Ronald L, Hunter, Letha H, et al., “Changes in shoulder and leg strength in athletes wearing mandibular orthopedic repositioning appliances”, The Journal of the American Dental Association, (1984)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n3.42 1983\n\nPepe, Paul E, Thomas, Ronald G, Stager, Marie Anne, et al., “Early prediction of the adult respiratory distress syndrome by a simple scoring method”, Annals of emergency medicine, (1983)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nThomas, Ronald J, Clark, Christopher A, “Effects of concomitant development on reproduction of Meloidogyne incognita and Rotylenchulus reniformis on sweet potato”, Journal of Nematology, (1983)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald J, Clark, Christopher A, “Population dynamics of Meloidogyne incognita and Rotylenchulus reniformis alone and in combination, and their effects on sweet potato”, Journal of Nematology, (1983)\nGeneral Research Biostatistics R Epidemiology\n\n🔗 Article\n\n\n\nSchubert, M, Guttu, R, Hunter, L, et al., “THE EFFECT OF MANDIBULAR ORTHOPEDIC REPOSITIONING APPLIANCES ON BODY STRENGTH”, JOURNAL OF DENTAL RESEARCH, (1983)\nGeneral Research Biostatistics R\n\n🔗 Article"
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#current-courses",
    "href": "teaching/index.html#current-courses",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#workshops-and-training",
    "href": "teaching/index.html#workshops-and-training",
    "title": "Teaching",
    "section": "2 Workshops and Training",
    "text": "2 Workshops and Training\n\n2.1 Professional Development\n\nR package development workshops\nReproducible research training\nStatistical consulting methodology\nAcademic writing for statisticians\n\n\n\n2.2 Conference Presentations\n\nInvited talks on statistical methods\nSoftware demonstrations\nMethodology tutorials\nBest practices sessions"
  },
  {
    "objectID": "teaching/index.html#educational-resources",
    "href": "teaching/index.html#educational-resources",
    "title": "Teaching",
    "section": "3 Educational Resources",
    "text": "3 Educational Resources\n\n3.1 Course Materials\n\nLecture slides and notes\nLab exercises and solutions\nAssignment templates\nAssessment rubrics\n\n\n\n3.2 Open Educational Content\n\nOnline tutorials and guides\nVideo lectures and demonstrations\nInteractive learning materials\nStudent project examples\n\n\nThis section will feature detailed course descriptions, syllabi, teaching materials, and educational resources developed for statistics and data science instruction."
  },
  {
    "objectID": "test_copy.html",
    "href": "test_copy.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "This is a test."
  },
  {
    "objectID": "test_copy.html#test",
    "href": "test_copy.html#test",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "This is a test."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html",
    "href": "tutorials/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#learning-objectives",
    "href": "tutorials/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#prerequisites",
    "href": "tutorials/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "href": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "href": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-5-testing",
    "href": "tutorials/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "href": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#next-steps",
    "href": "tutorials/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#resources",
    "href": "tutorials/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#connect-to-target-machine-with-ssh",
    "href": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#connect-to-target-machine-with-ssh",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "3.1 Connect to target machine with ssh",
    "text": "3.1 Connect to target machine with ssh\nconfigure WIFI\n\nbash&gt; iwctl\n\niwd&gt; device list (assume device is wlan0)\nidw&gt; station wlan0 scan\nidw&gt; station wlan0 connect rgtnet2\npassphrase for rgtnet2\nidw&gt; exit\nstart ssh and determine target machine IP address\n\n*  bash&gt; systemctl enable sshd\n*  bash&gt; systemctl start sshd\n*  bash&gt; ip route | grep default\n\n(assume the local IP address is 10.0.1.176)\nSet a password for root user. You’ll need it to log in.\nbash&gt; passwd\n  (enter `z` password)\nNew password: z\nRetype new password: z\n\nNow switch over to the mac\n* zsh&gt;   ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no root@10.0.1.176\n* ssh&gt; root@10.0.1.176's password: \n* z\n\nssh returns prompt on arch target machine\n\nroot@archiso ~ &gt;"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#begin-install-process",
    "href": "posts/install_arch_on_macbook/index (zzlenovo's conflicted copy 2025-02-20).html#begin-install-process",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "3.2 Begin install process",
    "text": "3.2 Begin install process\nFirst step:\n\npartition harddisk:\n\nbash&gt; cfdisk /dev/nvme0n1\nUse interface to create two partitions:\n\nEFI type of size 1gb\nroot of size entire rest of disk.\nwrite partition to disk\n\ncheck the partition:\n\nbash&gt; fdisk /dev/nvme0n1 -l\nFormat the partitions.\n\nEFI disk is fat32\nRoot is ext4\n\nbash&gt; mkfs.fat -F32 /dev/nvme0n1p1\nbash&gt; mkfs.ext4 /dev/nvme0n1p2\nset the keymap to mac us\n\nbash&gt; loadkeys mac-us\n\nSet system time and date\nbash&gt; timedatectl set-ntp true\n\n“The /mnt mount point in Linux is for mounting a storage device temporarily. As we only need to mount the partition for installing Arch Linux on it, the /mnt mount point is perfect.” The Arch Linux Handbook – Learn Arch Linux for Beginners\n\nbash&gt; mount /dev/nvme0n1p2 /mnt\nbash&gt; mount –mkdir /dev/efi_system_partition /mnt/boot\nFind best mirror:\n\nbash&gt; reflector –download-timeout 5 –country “United States” –age 12 –protocol https –sort rate –save /etc/pacman.d/mirrorlist\n\nbash&gt; pacstrap /mnt base base-devel linux linux-firmware sudo networkmanager\nbash&gt; genfstab -U /mnt &gt;&gt; /mnt/etc/fstab\nbash&gt; arch-chroot /mnt\nbash&gt; ln -sf /usr/share/zoneinfo/America/Los_Angeles /etc/localtime\nedit /etc/local.gen to set locale\nsearch for en_US and uncomment first row\nbash&gt; vim /etc/locale.gen\nbash&gt; locale.gen\nbash&gt; vim /etc/locale.conf\npacman -S networkmanager\nAvahi provides local hostname resolution using a “hostname.local” naming scheme. To enable it, install the nss-mdns package and start/enable avahi-daemon.service.\npacman -S nss-mdns\nsystemctl start avahi-daemon.service\nsystemctl enable NetworkManager (add root passwd)\npasswd\n\nuseradd -m -G wheel zenn\npasswd zenn\n\n4 for intel processors\npacman -S intel-ucode\n\npacman -S grub efibootmgr\n\nmkdir /boot/efi\nmount /dev/nvme0n1p1 /boot/efi\ngrub-install –target=x86_64-efi –bootloader-id=grub\ngrub-mkconfig -o /boot/grub/grub.cfg\n\npacman -S xorg-server\ncheck on what type of video card is in place on target\nlspci -v | grep -A1 -e VGA -e 3D\n\npacman -S xf86-video-intel\n\npacman -S gnome\n\npacman -S cinnamon\n\nsystemctl enable gdm\n\nexit\n\nroot@archiso ~ # umount -R /mnt\n\nPut the whole thing together for post disk partitioning …\nmkfs.fat -F32 /dev/nvme0n1p1\nmkfs.ext4 /dev/nvme0n1p2\nmount /dev/nvme0n1p2 /mnt\nreflector --download-timeout 5 --country \"United States\"  --age 12 --protocol https --sort rate --save /etc/pacman.d/mirrorlist\npacman -Sy\npacstrap /mnt base base-devel linux linux-firmware sudo networkmanager\ngenfstab -U /mnt &gt;&gt; /mnt/etc/fstab\narch-chroot /mnt\n\npasswd    \nuseradd -m -G wheel z\npasswd z\npacman -S vim\nvim /etc/sudoers\nuncomment # %wheel ALL=(ALL) ALL\nln -sf /usr/share/zoneinfo/America/Los\\_Angeles /etc/localtime\nvim /etc/locale.gen\n            uncomment en_US line\nlocale-gen\nvim /etc/locale.conf\n            LANG=en_US.UTF-8\nvim /etc/hostname\n            enter zz\npacman -S networkmanager\nsystemctl enable NetworkManager\npacman -S intel-ucode\npacman -S grub efibootmgr\nmkdir /boot/efi\nmount /dev/nvme0n1p1 /boot/efi\ngrub-install --target=x86_64-efi --bootloader-id=grub\ngrub-mkconfig -o /boot/grub/grub.cfg\npacman -S --noconfirm xorg-server\npacman -S --noconfirm xf86-video-intel\npacman -S --noconfirm gnome\npacman -S --noconfirm cinnamon\nsystemctl enable gdm\nexit\numount -R /mnt\n    \nThe final hardware related step is to add a second monitor, if available, via HDMI or “USB-C”.\nThats it. The base system is ready to go. Reboot and login with the admin username and password you provided earlier."
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html",
    "href": "tutorials/git-setup-guide/index.html",
    "title": "Setting up git for (solo) data science workflow",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#prerequisites",
    "href": "tutorials/git-setup-guide/index.html#prerequisites",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "href": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#key-takeaways",
    "href": "tutorials/git-setup-guide/index.html#key-takeaways",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#further-reading",
    "href": "tutorials/git-setup-guide/index.html#further-reading",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#hosting",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#hosting",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 illustrates the tools we’ll use and the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with static IP address) from a domain registration provider.\nInstall and configure a webserver ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838 requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#select-a-hosting-service",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nThere are a number of cloud based server options we can choose from: Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts ( here ) and ( here ).\nStep 0. Create an account or sign in to the AWS EC2 dashboard.\nStep 1. Set up an working environment with AWS server. This entails:\n\ndefine an ssh key-pair.\nconfigure a firewall.\nobtain a static IP.\nobtain a domain name.\nselect an instance (AMI, type and disk size), generate and launch server.\n\nOnce the server is available, connect via ssh, and login,\nThe only software necessary to install is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\nOnce the host is set up and docker installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, with a unique domain name and firewall are in place."
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838. We placed the power1_app/app.R code in the default location /srv/shiny-server we only need to start the server and it will find the shiny program.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#caddy",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#caddy",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.2 Caddy",
    "text": "3.2 Caddy\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. An SSL cert is required by most browsers to use the encrypted communication protocol https.\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generates an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker-compose",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#docker-compose",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#landing-page",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#landing-page",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-1.-docker-on-m1-macbook.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-2-add-user-to-docker-group-on-server.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index (zzlenovo's conflicted copy 2025-02-20).html#tip-3-ssh-config-file.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html",
    "href": "posts/setupquarto/quarto-blog-template.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#introduction",
    "href": "posts/setupquarto/quarto-blog-template.html#introduction",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#required-packages-and-setup",
    "href": "posts/setupquarto/quarto-blog-template.html#required-packages-and-setup",
    "title": "Your Technical Blog Post Title",
    "section": "2 Required Packages and Setup",
    "text": "2 Required Packages and Setup\n\n# List the packages readers will need\nlibrary(tidyverse)\n# Add other packages\n\nBrief explanation of why these packages were chosen and any setup requirements."
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#the-problemdata",
    "href": "posts/setupquarto/quarto-blog-template.html#the-problemdata",
    "title": "Your Technical Blog Post Title",
    "section": "3 The Problem/Data",
    "text": "3 The Problem/Data\n\n# Data loading and initial preparation\n# Load sample dataset\ndata &lt;- mtcars\nglimpse(data)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\nDescribe your data source\nExplain the problem you’re addressing\nShare any initial data preparation steps"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#analysistutorial-steps",
    "href": "posts/setupquarto/quarto-blog-template.html#analysistutorial-steps",
    "title": "Your Technical Blog Post Title",
    "section": "4 Analysis/Tutorial Steps",
    "text": "4 Analysis/Tutorial Steps\n\n4.1 Step 1: Initial Data Exploration\n\n# Your analysis code here\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\nggplot(mtcars, aes(x=cyl, y=mpg)) +\n  geom_point()\n\n\n\n\nDescription of your visualization\n\n\n\n  # Your visualization\n\nExplain what you found and why it’s interesting.\n\n\n4.2 Step 2: Main Analysis\n\n# Core analysis code\n\nWalk through your analysis, explaining: - Why you chose this approach - What the code does - What the results mean\n\n\n4.3 Step 3: Results and Visualization\n\n# Create compelling visualizations\n\nInterpret your results and explain their significance."
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#key-takeaways",
    "href": "posts/setupquarto/quarto-blog-template.html#key-takeaways",
    "title": "Your Technical Blog Post Title",
    "section": "5 Key Takeaways",
    "text": "5 Key Takeaways\n\nBullet point summary of main findings\nPractical applications\nImportant insights"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#reproducibility",
    "href": "posts/setupquarto/quarto-blog-template.html#reproducibility",
    "title": "Your Technical Blog Post Title",
    "section": "6 Reproducibility",
    "text": "6 Reproducibility\n\n# Print session info for reproducibility\nsessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1      lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.0     tidyselect_1.2.1  \n [5] scales_1.4.0       yaml_2.3.10        fastmap_1.2.0      R6_2.6.1          \n [9] labeling_0.4.3     generics_0.1.4     knitr_1.50         htmlwidgets_1.6.4 \n[13] rprojroot_2.0.4    pillar_1.10.2      RColorBrewer_1.1-3 tzdb_0.5.0        \n[17] rlang_1.1.6        stringi_1.8.7      xfun_0.52          timechange_0.3.0  \n[21] cli_3.6.5          withr_3.0.2        magrittr_2.0.3     digest_0.6.37     \n[25] grid_4.5.0         hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5       \n[29] evaluate_1.0.3     glue_1.8.0         farver_2.1.2       rmarkdown_2.29    \n[33] tools_4.5.0        pkgconfig_2.0.3    htmltools_0.5.8.1"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#next-steps",
    "href": "posts/setupquarto/quarto-blog-template.html#next-steps",
    "title": "Your Technical Blog Post Title",
    "section": "7 Next Steps",
    "text": "7 Next Steps\n\nSuggest areas for further exploration\nMention potential improvements\nInvite reader engagement"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#references",
    "href": "posts/setupquarto/quarto-blog-template.html#references",
    "title": "Your Technical Blog Post Title",
    "section": "8 References",
    "text": "8 References\n\nCite your sources\nLink to relevant documentation\nCredit other contributors"
  }
]