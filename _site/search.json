[
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "321 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\nUse the search box below to filter publications by title, author, journal, topic, or year.\n\n  \n    \n      \n      \n    \n  \n  \n    \n      All Categories\n      Medical/Clinical Research (213)\n      Statistical Methods (92)\n      Military/Defense Research (8)\n      Neuroimaging/Biomarkers (5)\n      Public Health/COVID (3)"
  },
  {
    "objectID": "research/index.html#publications-research",
    "href": "research/index.html#publications-research",
    "title": "Research",
    "section": "",
    "text": "321 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\nUse the search box below to filter publications by title, author, journal, topic, or year.\n\n  \n    \n      \n      \n    \n  \n  \n    \n      All Categories\n      Medical/Clinical Research (213)\n      Statistical Methods (92)\n      Military/Defense Research (8)\n      Neuroimaging/Biomarkers (5)\n      Public Health/COVID (3)"
  },
  {
    "objectID": "research/index.html#section",
    "href": "research/index.html#section",
    "title": "Research",
    "section": "2024",
    "text": "2024\n\nA multicenter, randomized, double-blind, placebo-controlled ascending dose study to evaluate the safety, tolerability, pharmacokinetics (PK) and pharmacodynamic (PD) effects of Posiphen in subjects with Early Alzheimer's Disease\n Galasko, Douglas, Farlow, Martin R, Lucey, Brendan P, Honig, Lawrence S, Elbert, Donald, Bateman, Randall, Momper, Jeremiah, **Thomas, Ronald G**, Rissman, Robert A, Pa, Judy, & others | Alzheimer's Research \\& Therapy | (2024) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nCumulative blast impulse is predictive for changes in chronic neurobehavioral symptoms following low level blast exposure during military training\n McEvoy, Cory, Crabtree, Adam, Case, John, Means, Gary E, Muench, Peter, **Thomas, Ronald G**, Ivory, Rebecca A, Mihalik, Jason, & Meabon, James S | Military medicine | (2024) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Military health\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nIncreased [18F] Fluorodeoxyglucose Uptake in the Left Pallidum in Military Veterans with Blast-Related Mild Traumatic Brain Injury: Potential as an Imaging Biomarker and Mediation with Executive Dysfunction and Cognitive Impairment\n Terry, Garth, Pagulayan, Kathleen F, Muzi, Mark, Mayer, Cynthia, Murray, Daniel R, Schindler, Abigail G, Richards, Todd L, McEvoy, Cory, Crabtree, Adam, McNamara, Chris, & others | Journal of Neurotrauma | (2024) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Traumatic brain injury Military health Neuroimaging Biomarkers Cognitive decline\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-1",
    "href": "research/index.html#section-1",
    "title": "Research",
    "section": "2023",
    "text": "2023\n\nA public resource of baseline data from the Alzheimer's Prevention Initiative Autosomal-Dominant Alzheimer's Disease Trial\n Reiman, Eric M, Pruzin, Jeremy J, Rios-Romenets, Silvia, Brown, Chris, Giraldo, Margarita, Acosta-Baena, Natalia, Tobon, Carlos, Hu, Nan, Chen, Yinghua, Ghisays, Valentina, & others | Alzheimer's \\& Dementia | (2023) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Prevention trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nA randomized controlled clinical trial of prazosin for alcohol use disorder in active duty soldiers: Predictive effects of elevated cardiovascular parameters\n Raskind, Murray A, Williams, Tammy, Holmes, Hollie, Hart, Kim, Crews, Laura, Poupore, Eileen L, **Thomas, Ronald G**, Darnell, Jolee, Daniels, Colin, Goke, Kevin, & others | Alcoholism: Clinical and Experimental Research | (2023) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nFDG-PET as a Clinical Diagnostic Biomarker for Repetitive Blast Mild Traumatic Brain Injury\n Terry, Garth, Pagulayan, Kati, Muzi, Mark, Mayer, Cynthia, Murray, Daniel, Schindler, Abigail, Richards, Todd, McEvoy, Cory, Crabtree, Adam, McNamara, Chris, & others | NEUROPSYCHOPHARMACOLOGY | (2023) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Traumatic brain injury Neuroimaging Biomarkers\nLinks: ðŸ“„ Article\n\n\nImpact of reference region on longitudinal florbetapir PET SUVR changes from the API ADAD Colombia Trial\n Ghisays, Valentina, Lopera, Francisco, Su, Yi, Malek-Ahmadi, Michael H, Chen, Yinghua, Protas, Hillary D, Luo, Ji, Hu, Nan, Clayton, David, Schiffman, Courtney, & others | Alzheimer's \\& Dementia | (2023) \nSummary: Developing biomarkers and imaging techniques for disease detection\nTopics: Biostatistics R Neuroimaging Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nLongitudinal Sleep Patterns and Cognitive Impairment in Older Adults\n Keil, Samantha A, Schindler, Abigail G, Wang, Marie X, Piantino, Juan, Silbert, Lisa C, Elliott, Jonathan E, Werhane, Madeleine L, **Thomas, Ronald G**, Willis, Sherry, Lim, Miranda M, & others | JAMA Network Open | (2023) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Sleep disorders Cognitive decline Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nPontine pathology mediates common symptoms of blast-induced chronic mild traumatic brain injury\n Meabon, James S, Schindler, Abigail G, Murray, Daniel R, Colasurdo, Elizabeth A, Sikkema, Carl L, Rodriguez, Joshua W, Omer, Mohamed, Cline, Marcella M, Logsdon, Aric F, Cross, Donna J, & others | medRxiv | (2023) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Traumatic brain injury\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nPrognostic value of plasma biomarkers in a clinical trial of mild-to-moderate Alzheimer's Disease\n Qiu, Yuqi, Messer, Karen, Jacobs, Diane M, Salmon, David P, Kaplita, Stephen, Wellington, Cheryl L, Stukas, Sophie K, Askew, Brianna, Brewer, James B, Brody, Mark, & others | Alzheimer's \\& Dementia | (2023) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Biomarkers\nLinks: ðŸ“„ Article\n\n\nThe relative contribution of COVID-19 infection versus COVID-19 related occupational stressors to insomnia in healthcare workers\n Hendrickson, Rebecca C, McCall, Catherine A, Rosser, Aaron F, Pagulayan, Kathleen F, Chang, Bernard P, Sano, Ellen D, **Thomas, Ronald G**, & Raskind, Murray A | Sleep medicine: X | (2023) \nSummary: Addressing public health challenges during global health crises\nTopics: Biostatistics R COVID-19 Sleep disorders\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF"
  },
  {
    "objectID": "research/index.html#section-2",
    "href": "research/index.html#section-2",
    "title": "Research",
    "section": "2022",
    "text": "2022\n\nMarkers of Cerebrovascular Injury, Inflammation, and Plasma Lipids Are Associated with Alzheimer's Disease Cerebrospinal Fluid Biomarkers in Cognitively Normal Persons\n Jansson, Deidre, Wang, Marie, **Thomas, Ronald G.**, Erickson, Michelle A., Peskind, Elaine R., Li, Ge, & Iliff, Jeffrey | Journal of Alzheimer's Disease | (2022) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: biomarkers blood-brain barrier cerebrospinal fluid hdl ldl ptau tau Alzheimer's disease Biomarkers Cognitive decline\nLinks: ðŸ“„ Article\n\n\nSex differences in cognitive resilience in preclinical autosomal-dominant Alzheimer's disease carriers and non-carriers: baseline findings from the API ADAD Colombia Trial\n Vila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, Clayton, David, Langbaum, Jessica B, **Thomas, Ronald G**, Chen, Yinghua, Su, Yi, Chen, Kewei, Hu, Nan, & others | Alzheimer's \\& Dementia | (2022) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nT2 Protect AD: Achieving a rapid recruitment timeline in a multisite clinical trial for individuals with mild to moderate Alzheimer's disease\n Shadyab, Aladdin H, LaCroix, Andrea Z, Matthews, Genevieve, Bennett, Daniel, Shadyab, Alexandre A, Tan, Donna, **Thomas, Ronald G**, Mason, Jennifer, Lopez, Alex, Askew, Brianna, & others | Alzheimer's \\& Dementia: Translational Research \\& Clinical Interventions | (2022) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nThe impact of the COVID-19 pandemic on mental health, occupational functioning, and professional retention among health care workers and first responders\n Hendrickson, Rebecca C & Slevin, Rois\\'\\i | Journal of general internal medicine | (2022) \nSummary: Addressing public health challenges during global health crises\nTopics: Biostatistics R COVID-19\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF"
  },
  {
    "objectID": "research/index.html#section-3",
    "href": "research/index.html#section-3",
    "title": "Research",
    "section": "2021",
    "text": "2021\n\nA trial of gantenerumab or solanezumab in dominantly inherited Alzheimer's disease\n Salloway, Stephen, Farlow, Martin, McDade, Eric, Clifford,    David B, Wang, Guoqiao, Llibre-Guerra, Jorge J, Hitchcock,      Janice M, Mills, Susan L, Santacruz, Anna M, Aschenbrenner,     Andrew J, Hassenstab, Jason, Benzinger, Tammie L S, Gordon,     Brian A, Fagan, Anne M, Coalier, Kelley A, Cruchaga, Carlos, Goate, Alison A, Perrin, Richard J, Xiong, Chengjie, ..., S\\'a | Nature Medicine | (2021) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nAmyloid and tau pathology associations with personality traits, neuropsychiatric symptoms, and cognitive lifestyle in the preclinical phases of sporadic and autosomal dominant Alzheimerâ€™s disease\n Binette, Alexa Pichet, Vachon-Presseau, Etienne, Morris, John, Bateman, Randall, Benzinger, Tammie, Collins, D Louis, Poirier, Judes, Breitner, John CS, Villeneuve, Sylvia, Allegri, Ricardo, & others | Biological psychiatry | (2021) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\n\n\nOptimizing aggregated N-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings\n Hendrickson, Rebecca C, **Thomas, Ronald G**, Schork, Nicholas J, & Raskind, Murray A | Creating Evidence from Real World Patient Digital Data | (2021) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Biomarkers Statistical methods\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nPower and sample size for random coefficient regression models in randomized experiments with monotone missing data\n Hu, Nan, Mackey, Howard, & **Thomas, Ronald** | Biometrical Journal | (2021) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nRasagiline effects on glucose metabolism, cognition, and tau in Alzheimer's dementia\n Matthews, Dawn C, Ritter, Aaron, **Thomas, Ronald G**, Andrews, Randolph D, Lukic, Ana S, Revta, Carolyn, Kinney, Jefferson W, Tousi, Babak, Leverenz, James B, Fillit, Howard, & others | Alzheimer's \\& Dementia: Translational Research \\& Clinical Interventions | (2021) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nRecruitment of a multi-site randomized controlled trial of aerobic exercise for older adults with amnestic mild cognitive impairment: the EXERT trial\n Shadyab, Aladdin & others | Alzheimer's \\& Dementia | (2021) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Cognitive decline\n\n\nThe Impact of the COVID-19 Pandemic on Mental Health, Occupational   Functioning, and Professional Retention Among Health Care Workers and   First Responders\n Hendrickson, Rebecca C & Slevin, Rois\\'\\i | Journal of general internal medicine | (2021) \nSummary: Addressing public health challenges during global health crises\nTopics: Biostatistics R COVID-19"
  },
  {
    "objectID": "research/index.html#section-4",
    "href": "research/index.html#section-4",
    "title": "Research",
    "section": "2020",
    "text": "2020\n\nBaseline demographic, clinical, and cognitive characteristics of the Alzheimer's Prevention Initiative (API) Autosomal-Dominant Alzheimer's Disease Colombia Trial\n Rios-Romenets, Silvia, Lopera, Francisco, Sink, Kaycee M, Hu, Nan, Lian, Qinshu, Guthrie, Heather, Smith, Jillian, Cho, William, Mackey, Howard, Langbaum, Jessica B, & others | Alzheimer's \\& Dementia | (2020) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline Prevention trials\n\n\nDevelopment of a novel cognitive composite outcome to assess therapeutic effects of exercise in the EXERT trial for adults with MCI: The ADAS-Cog-Exec\n Jacobs, Diane M, **Thomas, Ronald G**, Salmon, David P, Jin, Shelia, Feldman, Howard H, Cotman, Carl W, Baker, Laura D, Alzheimer's Disease Cooperative Study EXERT Study Group, & Alzheimer's Disease Neuroimaging Initiative | Alzheimer's \\& Dementia: Translational Research \\& Clinical Interventions | (2020) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Cognitive decline\n\n\nOptimizing aggregated n-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings\n Hendrickson, Rebecca C, **Thomas, Ronald G**, Schork, Nicholas J, & Raskind, Murray A | Frontiers in Digital Health | (2020) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Biomarkers Statistical methods\nLinks: ðŸ“„ Article\n\n\nPET evidence of preclinical cerebellar amyloid plaque deposition in autosomal dominant Alzheimer's disease\n Ghisays, Valentina, Lopera, Francisco, Goradia, Dhruman D, Protas, Hillary D, Malek-Ahmadi, Michael H, Chen, Yinghua, Devadas, Vivek, Luo, Ji, Lee, Wendy, Brown, Christopher T, & others | 2020 Alzheimer's Association International Conference | (2020) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging\n\n\nSex differences in neurodegeneration and memory performance in preclinical autosomal dominant Alzheimerâ€™s disease: Baseline findings from the API ADAD trial: Intersections of sex/gender and race/ethnicity in cognitive aging and Alzheimerâ€™s disease trajectories\n Vila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, Clayton, David, Langbaum, Jessica B, **Thomas, Ronald G**, Chen, Yinghua, Su, Yi, Hu, Nan, Giraldo-Chica, Margarita, & others | Alzheimer's \\& Dementia | (2020) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\n\n\nThe Alzheimerâ€™s Prevention Initiative Composite Cognitive Test: a practical measure for tracking cognitive decline in preclinical Alzheimerâ€™s disease\n Langbaum, Jessica B, Ellison, Noel N, Caputo, Angelika, **Thomas, Ronald G**, Langlois, Carolyn, Riviere, Marie-Emmanuelle, Graf, Ana, Lopez Lopez, Cristina, Reiman, Eric M, Tariot, Pierre N, & others | Alzheimer's Research \\& Therapy | (2020) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline Prevention trials\n\n\nThe Effects of Rasagiline on Glucose Metabolism and Cognition and Their Relationship to Tau Burden in a Double-Blind, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer's Dementia\n Matthews, Dawn, Ritter, Aaron, **Thomas, Ronald G**, Andrews, Randolph D, Lukic, Ana S, Revta, Carolyn, Tousi, Babak, Leverenz, James B, Fillit, Howard, Zhong, Kate, & others | Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer's Dementia (2/21/2020) | (2020) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials"
  },
  {
    "objectID": "research/index.html#section-5",
    "href": "research/index.html#section-5",
    "title": "Research",
    "section": "2019",
    "text": "2019\n\nA randomized clinical trial to evaluate home-based assessment of people over 75 years old\n Sano, Mary, Zhu, Carolyn W, Kaye, Jeffrey, Mundt, James C, Hayes, Tamara L, Ferris, Steven, **Thomas, Ronald G**, Sun, Chung-Kai, Jiang, Yanxin, Donohue, Michael C, & others | Alzheimer's \\& Dementia | (2019) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nF4-04-01: TRIAL DESIGN, DATA SHARING RISK MITIGATION, AND BASELINE CLINICAL AND COGNITIVE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER'S DISEASE COLOMBIA TRIAL\n Tariot, Pierre N, Lopera, Francisco, Sink, Kaycee, Hu, Nan, Guthrie, Heather, Smith, Jillian, Cho, William, Langbaum, Jessica B, **Thomas, Ronald G**, Giraldo, Margarita, & others | Alzheimer's \\& Dementia | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nF4-04-02: AGE-RELATED CHANGES IN BASELINE COGNITIVE MEASURES IN UNIMPAIRED PSEN1 E280A MUTATION CARRIERS AND NON-CARRIERS IN THE API AUTOSOMAL DOMINANT ALZHEIMER'S DISEASE COLOMBIA TRIAL\n Acosta-Baena, Natalia, Rios-Romenets, Silvia, Munoz, Claudia, Bocanegra, Yamile, Henao, Eliana, Giraldo, Margarita, Tobon, Carlos, Sink, Kaycee, Hu, Nan, Guthrie, Heather, & others | Alzheimer's \\& Dementia | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nF4-04-03: RELATIONSHIPS BETWEEN BASELINE BRAIN IMAGING BIOMARKER MEASUREMENTS AND AGE IN THE API AUTOSOMAL DOMINANT ALZHEIMER'S DISEASE COLOMBIA TRIAL\n Su, Yi, Rios-Romenets, Silvia, Tariot, Pierre N, Sink, Kaycee, Clayton, David, Hu, Nan, Guthrie, Heather, Smith, Jillian, Cho, William, Langbaum, Jessica B, & others | Alzheimer's \\& Dementia | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Biomarkers\n\n\nF4-04-04: ASSOCIATION BETWEEN CEREBRAL AMYLOIDOSIS AND WORSE COGNITIVE PERFORMANCE IN PRECLINICAL AUTOSOMAL DOMINANT ALZHEIMER'S DISEASE: BASELINE FINDINGS FROM THE API COLOMBIA AUTOSOMAL DOMINANT AD TRIAL\n Quiroz, Yakeel T, Tariot, Pierre N, Sink, Kaycee, Clayton, David, Langbaum, Jessica B, **Thomas, Ronald G**, Giraldo, Margarita, Tobon, Carlos, Acosta-Baena, Natalia, Luna, Ernesto, & others | Alzheimer's \\& Dementia | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\n\n\nLow-dose ladostigil for mild cognitive impairment: A phase 2 placebo-controlled clinical trial\n Schneider, Lon S, Geffen, Yona, Rabinowitz, Jonathan, **Thomas, Ronald G**, Schmidt, Reinhold, Ropele, Stefan, Weinstock, Marta, Ladostigil Study Group, & others | Neurology | (2019) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Cognitive decline\nLinks: ðŸ“„ Article\n\n\nMemantine and acetylcholinesterase inhibitor use in Alzheimerâ€™s disease clinical trials: Potential for confounding by indication\n Huisa, Branko N, **Thomas, Ronald G**, Jin, Shelia, Oltersdorf, Tilman, Taylor, Curtis, & Feldman, Howard H | Journal of Alzheimer's Disease | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\n\n\nMultimodal Hippocampal Subfield Grading For Alzheimerâ€™s Disease Classification\n Kilian, Hett, Vinh-Thong, Ta, Gwenaelle, Catheline, Tourdias, Thomas, Manjon, Jose V, Pierrick, Coupe, Weiner, Michael W, Aisen, Paul, Petersen, Ronald, Jack Jr, Clifford R, & others | Scientific Reports (Nature Publisher Group) | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nNew Perspective for Non-invasive Brain Stimulation Site Selection in Mild Cognitive Impairment: Based on Meta-and Functional Connectivity Analyses\n Liu, Jiao, Zhang, Binlong, Wilson, Georgia, Kong, Jian, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others | Frontiers in aging neuroscience | (2019) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\n\n\nPrediction and classification of Alzheimerâ€™s disease based on combined features from apolipoprotein-E genotype, cerebrospinal fluid, MR, and FDG-PET imaging biomarkers\n Gupta, Yubraj, Lama, Ramesh Kumar, Kwon, Goo-Rak, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, Trojanowki, John Q, & others | Frontiers in computational neuroscience | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Biomarkers\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nQuantitative 18F-AV1451 brain tau PET imaging in cognitively normal older adults, mild cognitive impairment, and Alzheimer's disease patients\n Zhao, Qian, Liu, Min, Ha, Lingxia, Zhou, Yun, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others | Frontiers in neurology | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Cognitive decline\n\n\nSafety and efficacy of edonerpic maleate for patients with mild to moderate Alzheimer disease: a phase 2 randomized clinical trial\n Schneider, Lon S, **Thomas, Ronald G**, Hendrix, Suzanne, Rissman, Robert A, Brewer, James B, Salmon, David P, Oltersdorf, Tilman, Okuda, Tomohiro, Feldman, Howard H, & others | JAMA neurology | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\n\n\nThe Alzheimer Prevention Initiative Generation Program: Evaluation of CNP520 in Preclinical Alzheimerâ€™s Disease (P4. 1-005)\n Borowsky, Beth, Lopez, Cristina Lopez, Tariot, Pierre, Caputo, Angelika, Liu, Fonda, Riviere, Marie-Emmanuelle, Rouzade-Dominguez, Marie-Laure, **Thomas, Ronald**, Langbaum, Jessica, Viglietta, Vissia, & others | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Prevention trials\nLinks: ðŸ“„ Article\n\n\nThe Alzheimer's Prevention Initiative Generation Program: study design of two randomized controlled trials for individuals at risk for clinical onset of Alzheimer's disease\n Lopez, Cristina Lopez, Tariot, Pierre N, Caputo, Angelika, Langbaum, Jessica B, Liu, Fonda, Riviere, Marie-Emmanuelle, Langlois, Carolyn, Rouzade-Dominguez, Marie-Laure, Zalesak, Martin, Hendrix, Suzanne, & others | Alzheimer's \\& Dementia: Translational Research \\& Clinical Interventions | (2019) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Prevention trials\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-6",
    "href": "research/index.html#section-6",
    "title": "Research",
    "section": "2018",
    "text": "2018\n\n18F-florbetapir Positron Emission Tomography--determined Cerebral beta-Amyloid Deposition and Neurocognitive Performance after Cardiac Surgery\n Klinger, Rebecca Y, James, Olga G, Borges-Neto, Salvador, Bisanar, Tiffany, Li, Yi-Ju, Qi, Wenjing, Berger, Miles, Terrando, Niccolo, Newman, Mark F, Doraiswamy, P Murali, & others | Anesthesiology | (2018) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\n\n\nAdeno-associated viral vector (serotype 2)--nerve growth factor for patients with alzheimer disease: a randomized clinical trial\n Rafii, Michael S, Tuszynski, Mark H, **Thomas, Ronald G**, Barba, David, Brewer, James B, Rissman, Robert A, Siffert, Joao, Aisen, Paul S, AAV2-NGF Study Team, & others | JAMA neurology | (2018) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nMemantine and Cholinesterase Inhibitor Use in Alzheimer Disease Trials: Potential for Confounding by Indication (P6. 178)\n Huisa, Branko, **Thomas, Ronald**, Jin, Shelia, Oltersdorf, Tilman, Taylor, Curtis, & Feldman, Howard | (2018) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nP3-032: SCREENING-TO-BASELINE COGNITIVE VARIABILITY DOES NOT PREDICT RATE OF DECLINE IN A CLINICAL TRIAL OF MILD-TO-MODERATE AD\n Jacobs, Diane M, **Thomas, Ronald G**, Salmon, David P, Huisa, Branko N, Feldman, Howard H, & Schneider, Lon S | Alzheimer's \\& Dementia | (2018) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Cognitive decline\n\n\nP4-209: A PUBLIC RESOURCE OF BASELINE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER'S DISEASE COLOMBIA TRIAL\n Reiman, Eric M, Sink, Kaycee M, Hu, Nan, Guthrie, Heather, Smith, Jillian, Cho, William, Knoll, Katie L, Langbaum, Jessica B, **Thomas, Ronald G**, Toga, Arthur W, & others | Alzheimer's \\& Dementia | (2018) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nSubjective cognitive decline is associated with altered default mode network connectivity in individuals with a family history of Alzheimerâ€™s disease\n Verfaillie, Sander CJ, Binette, Alexa Pichet, Vachon-Presseau, Etienne, Tabrizi, Shirin, Savard, Melissa, Bellec, Pierre, Ossenkoppele, Rik, Scheltens, Philip, van der Flier, Wiesje M, Breitner, John CS, & others | Biological Psychiatry: Cognitive Neuroscience and Neuroimaging | (2018) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\n\n\nThe Alzheimer's Prevention Initiative Autosomal-Dominant Alzheimer's Disease Trial: A study of crenezumab versus placebo in preclinical PSEN1 E280A mutation carriers to evaluate efficacy and safety in the treatment of autosomal-dominant Alzheimer's disease, including a placebo-treated noncarrier cohort\n Tariot, Pierre N, Lopera, Francisco, Langbaum, Jessica B, **Thomas, Ronald G**, Hendrix, Suzanne, Schneider, Lon S, Rios-Romenets, Silvia, Giraldo, Margarita, Acosta, Natalia, Tobon, Carlos, & others | Alzheimer's \\& Dementia: Translational Research \\& Clinical Interventions | (2018) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development Prevention trials\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-7",
    "href": "research/index.html#section-7",
    "title": "Research",
    "section": "2017",
    "text": "2017\n\nA phase 3 trial of IV immunoglobulin for Alzheimer disease\n Relkin, Norman R, **Thomas, Ronald G**, Rissman, Robert A, Brewer, James B, Rafii, Michael S, Van Dyck, Christopher H, Jack, Clifford R, Sano, Mary, Knopman, David S, Raman, Rema, & others | Neurology | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nAPOE genotype and early beta-amyloid accumulation in older adults without dementia\n Lim, Yen Ying, Mormino, Elizabeth C, Alzheimer's Disease Neuroimaging Initiative, & others | Neurology | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nAdding recognition discriminability index to the delayed recall is useful to predict conversion from mild cognitive impairment to Alzheimer's disease in the Alzheimer's disease neuroimaging initiative\n Russo, Mar\\'\\i | Frontiers in aging neuroscience | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Cognitive decline\n\n\nAlzheimer disease brain atrophy subtypes are associated with cognition and rate of decline\n Risacher, Shannon L, Anderson, Wesley H, Charil, Arnaud, Castelluccio, Peter F, Shcherbinin, Sergey, Saykin, Andrew J, Schwarz, Adam J, Alzheimer's Disease Neuroimaging Initiative, & others | Neurology | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nConstruction and analysis of weighted brain networks from sice for the study of Alzheimer's disease\n Munilla, Jorge, Ortiz, Andres, Gorriz, Juan M, Ramirez, Javier, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others | Frontiers in neuroinformatics | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Statistical methods\nLinks: ðŸ“„ Article\n\n\nConversion discriminative analysis on mild cognitive impairment using multiple cortical features from MR images\n Guo, Shengwen, Lai, Chunren, Wu, Congling, Cen, Guiyin, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others | Frontiers in aging neuroscience | (2017) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline Statistical methods\nLinks: ðŸ“„ Article\n\n\nRandomized controlled trials in mild cognitive impairment: sources of variability\n Petersen, Ronald C, **Thomas, Ronald G**, Aisen, Paul S, Mohs, Richard C, Carrillo, Maria C, Albert, Marilyn S, Alzheimer's Disease Neuroimaging Initiative (ADNI, & others | Neurology | (2017) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Cognitive decline\nLinks: ðŸ“„ Article\n\n\nRobust identification of Alzheimerâ€™s disease subtypes based on cortical atrophy patterns\n Park, Jong-Yun, Na, Han Kyu, Kim, Sungsoo, Kim, Hyunwook, Kim, Hee Jin, Seo, Sang Won, Na, Duk L, Han, Cheol E, & Seong, Joon-Kyung | Scientific reports | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nThe Alzheimer's Prevention Initiative (API) Generation Program: Evaluating the Efficacy of the BACE-1 Inhibitor CNP520 in Preclinical Alzheimer's Disease\n Tariot, Pierre, Lopez-Lopez, Cristina, Caputo, Angelika, **Thomas, Ronald G**, Langbaum, Jessica, Lenz, Robert, Vargas, Gabriel, Viglietta, Vissia, Reiman, Eric M, & Graf, Ana | NEUROPSYCHOPHARMACOLOGY | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Prevention trials\nLinks: ðŸ“„ Article\n\n\nThe Alzheimerâ€™s Prevention Initiative Generation Program: evaluating CNP520 efficacy in the prevention of Alzheimerâ€™s disease\n Lopez, C Lopez, Caputo, A, Liu, F, Riviere, ME, Rouzade-Dominguez, ML, Thomas, RG, Langbaum, JB, Lenz, R, Reiman, EM, Graf, A, & others | J Prev Alzheimers Dis | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Prevention trials\nLinks: ðŸ“„ Article\n\n\n[O5--01--02]: RATIONALE FOR SELECTION OF PRIMARY ENDPOINTS IN THE ALZHEIMER PREVENTION INITIATIVE GENERATION STUDY IN COGNITIVELY HEALTHY APOE4 HOMOZYGOTES\n Caputo, Angelika, Racine, Amy, Paule, Ines, Martens, Edwin P, Tariot, Pierre, Langbaum, Jessica B, **Thomas, Ronald G**, Hendrix, Suzanne, Ryan, J Michael, Lopez-Lopez, Cristina, & others | Alzheimer's \\& Dementia | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline Prevention trials\nLinks: ðŸ“„ Article\n\n\n[P4--573]: A PHASE 2 MULTICENTER, RANDOMIZED, PLACEBO-CONTROLLED TRIAL TO EVALUATE THE EFFICACY AND SAFETY OF EDONERPIC (T-817) IN PATIENTS WITH MILD TO MODERATE ALZHEIMER's DISEASE\n Schneider, Lon S, **Thomas, Ronald G**, Hendrix, Suzanne, Brewer, James B, Rissman, Robert A, Salmon, David P, Kobayashi, Hiroshi, & Feldman, Howard H | Alzheimer's \\& Dementia | (2017) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials"
  },
  {
    "objectID": "research/index.html#section-8",
    "href": "research/index.html#section-8",
    "title": "Research",
    "section": "2016",
    "text": "2016\n\nA semi-mechanism approach based on MRI and proteomics for prediction of conversion from mild cognitive impairment to Alzheimerâ€™s disease\n Liu, Haochen, Zhou, Xiaoting, Jiang, Hao, He, Hua, & Liu, Xiaoquan | Scientific reports | (2016) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nDemonstration of safety of intravenous immunoglobulin in geriatric patients in a long-term, placebo-controlled study of Alzheimer's disease\n Gelmont, David, **Thomas, Ronald G**, Britt, Jonathan, Dyck-Jones, Jacqueline A, Doralt, Jennifer, Fritsch, Sandor, Brewer, James B, Rissman, Robert A, & Aisen, Paul | Alzheimer's \\& Dementia: Translational Research \\& Clinical Interventions | (2016) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nGenetic studies of plasma analytes identify novel potential biomarkers for several complex traits\n Deming, Yuetiva, Xia, Jian, Cai, Yefei, Lord, Jenny, Del-Aguila, Jorge L, Fernandez, Maria Victoria, Carrell, David, Black, Kathleen, Budde, John, Ma, ShengMei, & others | Scientific Reports | (2016) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Biomarkers\nLinks: ðŸ“„ Article\n\n\nLongitudinal decline in mild-to-moderate Alzheimer's disease: analyses of placebo data from clinical trials\n **Thomas, Ronald G**, Albert, Marilyn, Petersen, Ronald C, & Aisen, Paul S | Alzheimer's \\& Dementia | (2016) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nThe Alzheimer's Prevention Initiative Generation Study: A Preclinical Trial in APOE4 Homozygotes\n Tariot, Pierre, Langbaum, Jessica, Schneider, Lon, **Thomas, Ronald G**, Graf, Ana, Lopez-Lopez, Cristina, Caputo, Angelika, Lenz, Robert, Vargas, Gabriel, & Reiman, Eric M | NEUROPSYCHOPHARMACOLOGY | (2016) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Prevention trials\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-9",
    "href": "research/index.html#section-9",
    "title": "Research",
    "section": "2015",
    "text": "2015\n\nA randomized, double-blind, placebo-controlled trial of resveratrol for Alzheimer disease\n Turner, R Scott, **Thomas, Ronald G**, Craft, Suzanne, Van Dyck, Christopher H, Mintzer, Jacobo, Reynolds, Brigid A, Brewer, James B, Rissman, Robert A, Raman, Rema, Aisen, Paul S, & others | Neurology | (2015) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nLarge-scale genomics unveil polygenic architecture of human cortical surface area\n Chen, Chi-Hua, Peng, Qian, Schork, Andrew J, Lo, Min-Tzu, Fan, Chun-Chieh, Wang, Yunpeng, Desikan, Rahul S, Bettella, Francesco, Hagler, Donald J, Westlye, Lars T, & others | Nature communications | (2015) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nLongitudinal plasma amyloid beta in Alzheimer's disease clinical trials\n Donohue, Michael C, Moghadam, Setareh H, Roe, Allyson D, Sun, Chung-Kai, Edland, Steven D, **Thomas, Ronald G**, Petersen, Ronald C, Sano, Mary, Galasko, Douglas, Aisen, Paul S, & others | Alzheimer's \\& Dementia | (2015) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Longitudinal studies\n\n\nPeripheral and central effects of $\\\\gamma$-secretase inhibition by semagacestat in Alzheimerâ€™s disease\n Doody, Rachelle S, Raman, Rema, Sperling, Reisa A, Seimers, Eric, Sethuraman, Gopalan, Mohs, Richard, Farlow, Martin, Iwatsubo, Takeshi, Vellas, Bruno, Sun, Xiaoying, & others | Alzheimer's research \\& therapy | (2015) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nResveratrol is safe and well-tolerated in individuals with mild-moderate dementia due to Alzheimerâ€™s disease.(S33. 009)\n Turner, R, **Thomas, Ronald**, Craft, Suzanne, van Dyck, Christopher, Mintzer, Jacobo, Reynolds, Brigid, Brewer, James, Rissman, Robert, Raman, Rema, & Aisen, Paul | (2015) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nSafety of Intravenous Immunoglobulin Therapy in Patients with Probable Alzheimer's Disease: A Randomized, Placebo-Controlled Clinical Study\n Gelmont, D, Thomas, RG, Dyck-Jones, JA, Fritsch, S, Aisen, P, & Relkin, N | ANNALS OF ALLERGY ASTHMA \\& IMMUNOLOGY | (2015) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Drug development\nLinks: ðŸ“„ Article\n\n\nTest-retest resting-state fMRI in healthy elderly persons with a family history of Alzheimerâ€™s disease\n Orban, Pierre & Madjar, C\\'e | Scientific data | (2015) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nUsing novel methodologies to examine the impact of artificial light at night on the cortisol stress response in dispersing Atlantic salmon (Salmo salar L.) fry\n Newman, Rhian C, Ellis, Tim, Davison, Phil I, Ives, Mark J, Thomas, Rob J, Griffiths, Sian W, & Riley, William D | Conservation physiology | (2015) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Statistical methods\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF"
  },
  {
    "objectID": "research/index.html#section-10",
    "href": "research/index.html#section-10",
    "title": "Research",
    "section": "2014",
    "text": "2014\n\nAlzheimerâ€™s Disease Cooperative Study Steering Committee; Solanezumab study group. Phase 3 trials of solanezumab for mild-to-moderate Alzheimerâ€™s disease\n Doody, RS, Thomas, RG, Farlow, M, Iwatsubo, T, Vellas, B, Joffe, S, Kieburtz, K, Raman, R, Sun, X, Aisen, PS, & others | N Engl J Med | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nAustralian imaging, biomarkers, and lifestyle flagship study of ageing; Alzheimerâ€™s disease neuroimaging initiative; Alzheimerâ€™s disease cooperative study. The preclinical Alzheimer cognitive composite: measuring amyloid-related decline\n Donohue, MC, Sperling, RA, Salmon, DP, Rentz, DM, Raman, R, Thomas, RG, Weiner, M, & Aisen, PS | JAMA Neurol | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Biomarkers Cognitive decline\n\n\nBayesian Longitudinal Modeling on Placebo Data from Alzheimerâ€™s Disease Clinical Studies (P1. 010)\n Chen, Yun-Fei, Mohs, Richard, Ding, Ying, Aisen, Paul, & **Thomas, Ronald** | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Longitudinal studies\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nClinical trial of an inhibitor of RAGE-A beta interactions in Alzheimer disease\n Galasko, Douglas, Bell, Joanne, Mancuso, Jessica Y, Kupiec, James W, Sabbagh, Marwan N, van Dyck, Christopher, **Thomas, Ronald G**, Aisen, Paul S, & others | Neurology | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nEstimating long-term multivariate progression from short-term data\n Donohue, Michael C, Jacqmin-Gadda, Hene, Le Goff, Melanie, **Thomas, Ronald G**, Raman, Rema, Gamst, Anthony C, Beckett, Laurel A, Jack Jr, Clifford R, Weiner, Michael W, Dartigues, Jean-Francois, & others | Alzheimer's \\& Dementia | (2014) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nF3-02-02: MODELING LONG-TERM DISEASE PROGRESSION WITH COVARIATES\n Donohue, Michael C, Gamst, Anthony, Jack, Clifford, Beckett, Laurel, Weiner, Michael, Aisen, Paul, Raman, Rema, & **Thomas, Ronald** | Alzheimer's \\& Dementia | (2014) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nP1-357: ADCS EDC: INVESTIGATIONAL PRODUCT MANAGEMENT SYSTEM\n Jimenez-Maggiora, Gustavo Adolfo, **Thomas, Ronald G**, Qiu, Hongmei, Hong, Phuoc, & Aisen, Paul S | Alzheimer's \\& Dementia | (2014) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nPhase 3 trials of solanezumab and bapineuzumab for Alzheimerâ€™s disease\n Laske, Christoph | N Engl J Med | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nPhase 3 trials of solanezumab for mild-to-moderate Alzheimer's disease\n Doody, Rachelle S, **Thomas, Ronald G**, Farlow, Martin, Iwatsubo, Takeshi, Vellas, Bruno, Joffe, Steven, Kieburtz, Karl, Raman, Rema, Sun, Xiaoying, Aisen, Paul S, & others | New England Journal of Medicine | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nThe preclinical Alzheimer cognitive composite: measuring amyloid-related decline\n Donohue, Michael C, Sperling, Reisa A, Salmon, David P, Rentz, Dorene M, Raman, Rema, **Thomas, Ronald G**, Weiner, Michael, & Aisen, Paul S | JAMA neurology | (2014) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-11",
    "href": "research/index.html#section-11",
    "title": "Research",
    "section": "2013",
    "text": "2013\n\nA phase 3 trial of semagacestat for treatment of Alzheimer's disease\n Doody, Rachelle S, Raman, Rema, Farlow, Martin, Iwatsubo, Takeshi, Vellas, Bruno, Joffe, Steven, Kieburtz, Karl, He, Feng, Sun, Xiaoying, **Thomas, Ronald G**, & others | New England Journal of Medicine | (2013) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article\n\n\nAge and apolipoprotein E genotype influence rate of cognitive decline in nondemented elderly.\n Salmon, David P, Ferris, Steven H, **Thomas, Ronald G**, Sano, Mary, Cummings, Jeffery L, Sperling, Reisa A, Petersen, Ronald C, & Aisen, Paul S | Neuropsychology | (2013) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\n\n\nAlzheimerâ€™s Disease Cooperative Study Steering Committee, Siemers E, Sethuraman G, Mohs R, Semagacestat Study Group. A phase 3 trial of semagacestat for treatment of Alzheimerâ€™s disease\n Doody, RS, Raman, R, Farlow, M, Iwatsubo, T, Vellas, B, Joffe, S, Kieburtz, K, He, F, Sun, X, Thomas, RG, & others | N Engl J Med | (2013) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nEstablishing the psychometric underpinning of cognition measures for clinical trials of Alzheimer's disease and its precursors: a new approach\n Posner, Holly B, Cano, Stefan, Carrillo, Maria C, Selnes, Ola, Stern, Yaakov, **Thomas, Ronald G**, Zajicek, John, Hobart, Jeremy, Alzheimer's Disease Neuroimaging Initiative, & others | Alzheimer's \\& Dementia | (2013) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nP1--332: Evaluation of the relationship between TTP488 plasma concentrations and changes in ADAS-cog relative to placebo\n Burstein, Aaron, Galasko, Douglas, Aisen, Paul, **Thomas, Ronald**, Grimes, Imogene, Clark, David J, Mjalli, Adnan, & Orlande, Cesare | Alzheimer's \\& Dementia | (2013) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nP3--295: The Placebo Data Analysis in Alzheimer's Disease (AD) and Mild Cognitive Impairment (MCI) Clinical Trials Project: Overview of progress in trial data collection, and key findings from the pooled Alzheimer's disease trial datasets\n **Thomas, Ronald**, Petersen, Ronald, Siuciak, Judith, Carrillo, Maria, Albert, Marilyn, Aisen, Paul, Alzheimer's Disease Neuroimaging Initiative, & Foundation for NIH Biomarkers Consortium AD MCI Placebo Data Project Team | Alzheimer's \\& Dementia | (2013) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline Statistical methods\nLinks: ðŸ“„ Article\n\n\nP4--157: Adcs electronic data capture: Collaborative development and management of clinical trial databases\n Jimenez-Maggiora, Gustavo, **Thomas, Ronald**, Bruschi, Stefania, Qiu, Hongmei, Hong, Phuoc, & Aisen, Paul | Alzheimer's \\& Dementia | (2013) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\n\n\nPreclinical trials in autosomal dominant AD: implementation of the DIAN-TU trial\n Mills, Sarah M, Mallmann, J, Santacruz, Anna M, Fuqua, A, Carril, M, Aisen, Paul S, Althage, MC, Belyew, S, Benzinger, Tammie L, Brooks, William S, & others | Revue neurologique | (2013) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nPutting the Alzheimer's cognitive test to the test II: Rasch Measurement Theory\n Hobart, Jeremy, Cano, Stefan, Posner, Holly, Selnes, Ola, Stern, Yaakov, **Thomas, Ronald**, Zajicek, John, & Alzheimer's Disease Neuroimaging Initiative | Alzheimer's \\& dementia | (2013) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-12",
    "href": "research/index.html#section-12",
    "title": "Research",
    "section": "2012",
    "text": "2012\n\nA Garden before the Garden: Landscape, History and the National Botanic Garden of Wales\n Austin, David & Thomas, Rob | Landscapes | (2012) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nAlzheimerâ€™s Disease Cooperative Study. Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures\n Galasko, DR, Peskind, E, Clark, CM, Quinn, JF, Ringman, JM, Jicha, GA, Cotman, C, Cottrell, B, Montine, TJ, Thomas, RG, & others | Arch Neurol | (2012) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Biomarkers\n\n\nAlzheimerâ€™s disease therapeutic trials: EU/US Task Force report on recruitment, retention, and methodology\n Vellas, B, Hampel, H, & Roug\\'e | The journal of nutrition, health \\& aging | (2012) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Statistical methods\nLinks: ðŸ“„ Article\n\n\nAntioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures\n Galasko, Douglas R, Peskind, Elaine, Clark, Christopher M, Quinn, Joseph F, Ringman, John M, Jicha, Gregory A, Cotman, Carl, Cottrell, Barbara, Montine, Thomas J, **Thomas, Ronald G**, & others | Archives of neurology | (2012) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Biomarkers\nLinks: ðŸ“„ Article\n\n\nIncidence of new-onset seizures in mild to moderate Alzheimer disease\n Irizarry, Michael C, Jin, Shelia, He, Feng, Emond, Jennifer A, Raman, Rema, **Thomas, Ronald G**, Sano, Mary, Quinn, Joseph F, Tariot, Pierre N, Galasko, Douglas R, & others | Archives of neurology | (2012) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nO3-13-05: The Gammaglobulin Alzheimer Partnership Study (GAP): Design, screening, enrollment and futility analysis results\n Relkin, Norman, Gessert, Devon, Stokes, Karen, Adamiak, Basia, Ngo, Leock Y, **Thomas, Ronald**, Gelmont, David, & Aisen, Paul | Alzheimer's \\& Dementia | (2012) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Statistical methods\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nP3-364: ADCS EDC\n Jimenez-Maggiora, Gustavo, **Thomas, Ronald**, Hong, Phuoc, & Aisen, Paul | Alzheimer's \\& Dementia | (2012) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nP3-383: ADCS data sharing\n **Thomas, Ronald**, Jimenez, Gustavo, Brewer, James, Rissman, Robert A, & Aisen, Paul | Alzheimer's \\& Dementia | (2012) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nP3-384: The placebo data analysis in Alzheimer's disease and mild cognitive impairment (MCI) clinical trials project: Overview of progress in trial data collection, and key findings from the pooled MCI trial datasets\n Aisen, Paul, **Thomas, Ronald**, Carrillo, Maria, Mohs, Richard, Petersen, Ronald, Siuciak, Judith, Albert, Marilyn, Alzheimer's Disease Neuroimaging Initiative, & Foundation for NIH Biomarkers Consortium CSF Proteomics Project Team | Alzheimer's \\& Dementia | (2012) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline Statistical methods"
  },
  {
    "objectID": "research/index.html#section-13",
    "href": "research/index.html#section-13",
    "title": "Research",
    "section": "2011",
    "text": "2011\n\nA phase II trial of huperzine A in mild to moderate Alzheimer disease\n Rafii, MS, Walsh, S, Little, JT, Behan, K, Reynolds, B, Ward, C, Jin, S, Thomas, R, Aisen, PS, & others | Neurology | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nA randomized, double-blind, placebo-controlled trial of simvastatin to treat Alzheimer disease\n Sano, M, Bell, KL, Galasko, D, Galvin, JE, Thomas, RG, Van Dyck, CH, & Aisen, PS | Neurology | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nAdding delayed recall to the Alzheimer Disease Assessment Scale is useful in studies of mild cognitive impairment but not Alzheimer disease\n Sano, Mary, Raman, Rema, Emond, Jennifer, **Thomas, Ronald G**, Petersen, Ronald, Schneider, Lon S, & Aisen, Paul S | Alzheimer disease and associated disorders | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nChronic divalproex sodium to attenuate agitation and clinical progression of Alzheimer disease\n Tariot, Pierre N, Schneider, Lon S, Cummings, Jeffrey, **Thomas, Ronald G**, Raman, Rema, Jakimovich, Laura J, Loy, Rebekah, Bartocci, Barbara, Fleisher, Adam, Ismail, M Saleem, & others | Archives of General Psychiatry | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nChronic divalproex sodium use and brain atrophy in Alzheimer disease\n Fleisher, AS, Truran, D, Mai, JT, Langbaum, JBS, Aisen, PS, Cummings, JL, Jack, CR, Weiner, MW, Thomas, RG, Schneider, LS, & others | Neurology | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nDietary self-monitoring and its impact on weight loss in overweight children\n Mockus, Danyte S, Macera, Caroline A, Wingard, Deborah L, Peddecord, Michael, **Thomas, Ronald G**, & Wilfley, Denise E | International Journal of Pediatric Obesity | (2011) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nOmega-3 Fatty Acids for Alzheimer's Disease. What a Pill Can Tell Us about Eating Fish\n Quinn, JF, Raman, R, Thomas, RG, Yurko-Mauro, K, Nelson, EB, Van Dyck, C, Galvin, JE, Emond, J, Jack Jr, CR, Weiner, M, & others | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nP3-406: Role of caregiver in subject's compliance with treatment\n Messick, Viviana, Donohue, Michael, Raman, Rema, Sano, Mary, Quinn, Joseph, Thomas, Ron, Emond, Jennifer, & Aisen, Paul | Alzheimer's \\& Dementia | (2011) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Drug development\nLinks: ðŸ“„ Article\n\n\nRadiological follow up of perineal repair with cross-linked acellular porcine dermal collagen following extralevator abdominoperineal excision for low rectal cancer: P115\n Smart, N, George, A, Khan, D, Thomas, R, & Daniels, I | Colorectal Disease | (2011) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nReport of the task force on designing clinical trials in early (predementia) AD\n Aisen, PS, Andrieu, S, Sampaio, C, Carrillo, M, Khachaturian, ZS, Dubois, Bruno, Feldman, HH, Petersen, RC, Siemers, E, Doody, RS, & others | Neurology | (2011) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nThe relative efficiency of time-to-threshold and rate of change in longitudinal data\n Donohue, Michael C, Gamst, AC, Thomas, RG, Xu, R, Beckett, L, Petersen, Ronald Carl, Weiner, MW, Aisen, P, Alzheimer's Disease Neuroimaging Initiative, & others | Contemporary clinical trials | (2011) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Longitudinal studies\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF"
  },
  {
    "objectID": "research/index.html#section-14",
    "href": "research/index.html#section-14",
    "title": "Research",
    "section": "2010",
    "text": "2010\n\nClinical Core of the Alzheimer's Disease Neuroimaging Initiative: progress and plans\n Aisen, Paul S, Petersen, Ronald C, Donohue, Michael C, Gamst, Anthony, Raman, Rema, **Thomas, Ronald G**, Walter, Sarah, Trojanowski, John Q, Shaw, Leslie M, Beckett, Laurel A, & others | Alzheimer's \\& Dementia | (2010) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging\n\n\nDocosahexaenoic acid supplementation and cognitive decline in Alzheimer disease: a randomized trial\n Quinn, Joseph F, Raman, Rema, **Thomas, Ronald G**, Yurko-Mauro, Karin, Nelson, Edward B, Van Dyck, Christopher, Galvin, James E, Emond, Jennifer, Jack, Clifford R, Weiner, Michael, & others | Jama | (2010) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline\nLinks: ðŸ“„ Article\n\n\nO3-01-07: Rate of decline in ADNI normal controls with evidence of amyloid burden\n Donohue, Michael, Gamst, Anthony, Thomas, Ron, Brewer, Jim, Weiner, Michael, & Aisen, Paul | Alzheimer's \\& Dementia | (2010) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nP1-433: Brain volume changes with divalproex sodium in Alzheimer's disease\n Fleisher, Adam S, Jack Jr, Clifford R, Weiner, Michael W, Truran, Diana, Mai, Jacqueline, Aisen, Paul S, Cummings, Jeffrey L, **Thomas, Ronald G**, Schneider, Lon S, & Tariot, Pierre N | Alzheimer's \\& Dementia | (2010) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nP1-447: Cerebrospinal fluid biomarker outcomes in a trial of docosahexaenoic acid (DHA) for Alzheimer's disease\n Quinn, Joseph F, **Thomas, Ronald**, Raman, Rema, Yurko-Mauro, Karin, Bailey-Hall, Eileen, Nelson, Edward, Shaw, Les, & Aisen, Paul | Alzheimer's \\& Dementia | (2010) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Biomarkers"
  },
  {
    "objectID": "research/index.html#section-15",
    "href": "research/index.html#section-15",
    "title": "Research",
    "section": "2009",
    "text": "2009\n\nMRI substudy participation in Alzheimer disease (AD) clinical trials: baseline comparability of a substudy sample to entire study population\n Raman, Rema, **Thomas, Ronald G**, Weiner, Michael W, Jack, Clifford R, Ernstrom, Karin, Aisen, Paul S, Tariot, Pierre N, & Quinn, Joseph F | Alzheimer disease and associated disorders | (2009) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Neuroimaging Epidemiology\nLinks: ðŸ“„ Article\n\n\nO1-04-02: A clinical trial of docosahexanoic acid (DHA) for the treatment of Alzheimer's disease\n Quinn, Joseph F, Raman, Rema, **Thomas, Ronald G**, Ernstrom, Karin, Yurko-Mauro, Karin, Nelson, Edward B, Shinto, Lynne, Nair, Anil K, & Aisen, Paul | Alzheimer's \\& Dementia | (2009) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Drug development\nLinks: ðŸ“„ Article\n\n\nO1-04-03: The ADCS valproate neuroprotection trial: Primary efficacy and safety results\n Tariot, Pierre N, Aisen, Paul, Cummings, Jeffrey, Jakimovich, Laura, Schneider, Lon, **Thomas, Ronald**, Becerra, Lida, & Loy, Rebekah | Alzheimer's \\& Dementia | (2009) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nO4-04-07: The ADAS-cog's performance as a measureâ€”lessons from the ADNI study: Part 2-evaluation using modern psychometric methods\n Cano, Stefan, Posner, Holly, Aisen, Paul, Selnes, Ola, Stern, Yaakov, **Thomas, Ronald**, Weiner, Michael, Zajicek, John, Zeger, Scott, & Hobart, Jeremy | Alzheimer's \\& Dementia | (2009) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Statistical methods\n\n\nP1-269: The ADAS-cog's performance as a measure-lessons from the ADNI study: Part 1-evaluation using traditional psychometric methods\n Posner, Holly, Cano, Stefan, Aisen, Paul, Selnes, Ola, Stern, Yaakov, **Thomas, Ronald**, Weiner, Michael, Zajicek, John, Zeger, Scott, & Hobart, Jeremy | Alzheimer's \\& Dementia | (2009) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Statistical methods\nLinks: ðŸ“„ Article\n\n\nP1-270: The ADAS-cog's performance as a measure-lessons from the ADNI study: Part 3-do the scale modifications add value?\n Hobart, Jeremy, Posner, Holly, Aisen, Paul, Selnes, Ola, Stern, Yaakov, **Thomas, Ronald**, Weiner, Michael, Zajicek, John, Zeger, Scott, & Cano, Stefan | Alzheimer's \\& Dementia | (2009) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nPlasma urate and progression of mild cognitive impairment\n Irizarry, Michael C, Raman, Rema, Schwarzschild, Michael A, Becerra, Lida M, **Thomas, Ronald G**, Peterson, Ronald C, Ascherio, Alberto, & Aisen, Paul S | Neurodegenerative Diseases | (2009) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\nLinks: ðŸ“„ Article\n\n\nREVIEWS IN THE NEUROSCIENCES\n Machado, C, Leisman, G, Koch, P, Rodriguez, R, Caiballo, M, Korein, J, Sanchez-Catasus, C, Perez, J, Djuric, S, Djuric, V, & others | NEUROSCIENCES | (2009) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nThe ADAS-cog's Performance as a Measure Lessons from the ADNI Study: Part 1-Evaluation Using Traditional Psychometric Methods\n Pasner, Holly, Cano, Stefan J, Aisen, Paul, Selnes, Ola, Stern, Yaakov, **Thomas, Ronald**, Weiner, Michael, Zajicek, John, Zeger, Scott, & Hobart, Jeremy | Neurology | (2009) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Statistical methods\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-16",
    "href": "research/index.html#section-16",
    "title": "Research",
    "section": "2008",
    "text": "2008\n\nA roadmap for the prevention of dementia: the inaugural Leon Thal Symposium\n Khachaturian, Zaven S, Petersen, Ronald C, Gauthier, Serge, Buckholtz, Neil, Corey-Bloom, Jodey P, Evans, Bill, Fillit, Howard, Foster, Norman, Greenberg, Barry, Grundman, Michael, & others | Alzheimer's \\& dementia: the journal of the Alzheimer's Association | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Prevention trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nAlzheimer Disease Cooperative Study. High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial\n Aisen, PS, Schneider, LS, Sano, M, Diaz-Arrastia, R, Van Dyck, CH, Weiner, MF, Bottiglieri, T, Jin, S, Stokes, KT, Thomas, RG, & others | Jama | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline\n\n\nAmetropia, preschoolers' cognitive abilities, and effects of spectacle correction\n Roch-Levecq, Anne-Catherine, Brody, Barbara L, **Thomas, Ronald G**, & Brown, Stuart I | Archives of ophthalmology | (2008) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\nLinks: ðŸ“„ Article\n\n\nDimebon investigators: Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer's disease: a randomised, double-blind, placebo-controlled study\n Doody, RS, Gavrilova, SI, Sano, M, Thomas, RG, Aisen, PS, Bachurin, SO, Seely, L, & Hung, D | Lancet | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nDual Task Test Could Help Diagnose Dementia\n Aisen, Paul S, Schneider, Lon S, Sano, Mary, Diaz-Arrastia, Ramon, van Dyck, Christopher H, Weiner, Myron F, Bottiglieri, Teodoro, Jin, Shelia, Stokes, Karen T, **Thomas, Ronald G**, & others | JAMA | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nEffect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer's disease: a randomised, double-blind, placebo-controlled study\n Doody, Rachelle S, Gavrilova, Svetlana I, Sano, Mary, **Thomas, Ronald G**, Aisen, Paul S, Bachurin, Sergey O, Seely, Lynn, Hung, David, & others | The Lancet | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nEfficacy of site-independent telemedicine in the STRokE DOC trial: a randomised, blinded, prospective study\n Meyer, Brett C, Raman, Rema, Hemmen, Thomas, Obler, Richard, Zivin, Justin A, Rao, Ramesh, **Thomas, Ronald G**, & Lyden, Patrick D | The Lancet Neurology | (2008) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nHigh-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial\n Aisen, Paul S, Schneider, Lon S, Sano, Mary, Diaz-Arrastia, Ramon, Van Dyck, Christopher H, Weiner, Myron F, Bottiglieri, Teodoro, Jin, Shelia, Stokes, Karen T, **Thomas, Ronald G**, & others | Jama | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline\n\n\nO2-04--06: Randomized clinical trial of antioxidant treatment in Alzheimer's disease with CSF biomarker measures\n Galasko, Douglas, Peskind, Elaine, Clark, Christopher M, Quinn, Joseph, Ringman, John, Jicha, Gregory A, Cottrell, Barbara, & **Thomas, Ronald G** | Alzheimer's \\& Dementia | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Biomarkers Drug development\nLinks: ðŸ“„ Article\n\n\nP4-337: Dimebon improves cognition, function, and behavior in mild and moderate Alzheimer's disease: Results by severity of a one-year, double-blind, placebo-controlled study\n Doody, Rachelle S, Gavrilova, Svetlana, **Thomas, Ronald**, Aisen, Paul, Bachurin, Sergey, Seely, Lynn, & Hung, David | Alzheimer''s and Dementia | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nP4-343: Omega 3 fatty acids and Alzheimer's disease: Trial design and baseline study population characteristics in a clinical trial of docosahexanoic acid for Alzheimer's disease\n Quinn, Joseph F, Raman, Rema, **Thomas, Ronald**, Ernstrom, Karin, Yurko-Mauro, Karin, Nelson, Edward, & Aisen, Paul S | Alzheimer's \\& Dementia | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Epidemiology\n\n\nP4-387: Adding delayed recall to the Alzheimer's disease assessment scale-cognitive subscale (ADAS-cog): Sensitivity in a clinical trial for Alzheimer's disease and mild cognitive impairment\n Raman, Rema, Emond, Jennifer, **Thomas, Ronald G**, Petersen, Ronald C, Schneider, Lon S, Aisen, Paul S, & Sano, Mary | Alzheimer's \\& Dementia | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline\nLinks: ðŸ“„ Article\n\n\nStatistical treatment of withdrawal in trials of anti-dementia drugs--Authors' reply\n Doody, Rachelle, Seely, Lynn, **Thomas, Ronald**, Sano, Mary, & Aisen, Paul | The Lancet | (2008) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Drug development Statistical methods\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-17",
    "href": "research/index.html#section-17",
    "title": "Research",
    "section": "2007",
    "text": "2007\n\nDimebon improves cognition, function, and behavior in patients with mild-moderate Alzheimer's disease: Results of a randomized, double-blind, placebo-controlled study\n Doody, Rochelle, Gavrilova, Svetlana, Sano, Mary, **Thomas, Ronald**, Aisen, Paul, Seely, Lynn, & Hung, David | Neurology | (2007) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nP-081: The ACDS home assessment instrument: A pilot study\n Sano, Mary, Kaye, Jeffrey, Ferris, Steven, Hayes, Tamara, Egelko, Susan, Mundt, James, Li, Yan, Walter, Sarah, **Thomas, Ronald**, Edland, Steven, & others | Alzheimer's \\& Dementia | (2007) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nPopulation Dynamics of Meloidogyne incognita and RotylenchulusTenchulus reniformis Alone and in Combination, and Their Effects on Sweet Potato1\n THOMAS, RONALD J & CLARK, CHRISTOPHER A | (2007) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Epidemiology\n\n\nPotential outcome measures and trial design issues for multiple system atrophy\n May, Susanne, Gilman, Sid, Sowell, B Brooke, **Thomas, Ronald G**, Stern, Matthew B, Colcher, Amy, Tanner, Caroline M, Huang, Neng, Novak, Peter, Reich, Stephen G, & others | Movement disorders | (2007) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nS3--02--01: ADCS homocysteine trial\n Aisen, Paul S, Jin, Shelia, **Thomas, Ronald G**, Sano, Mary, Diaz-Arrastia, Ramon, Thal, Leon, & Alzheimer's Disease Cooperative Study NIA | Alzheimer's \\& Dementia | (2007) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nS3--02--03: Results of a one-year randomized, placebo-controlled trial of dimebon for the treatment of mild to moderate Alzheimer's disease\n Doody, Rachelle S, Gavrilova, Svetlana, Sano, Mary, **Thomas, Ronald**, Aisen, Paul, Bachurin, Sergey, Seely, Lynn, & Hung, David | Alzheimer's \\& Dementia | (2007) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Drug development"
  },
  {
    "objectID": "research/index.html#section-18",
    "href": "research/index.html#section-18",
    "title": "Research",
    "section": "2006",
    "text": "2006\n\nADCS Prevention Instrument Project: pharmacoeconomics: assessing health-related resource use among healthy elderly\n Sano, Mary, Zhu, Carolyn W, Whitehouse, Peter J, Edland, Steven, Jin, Shelia, Ernstrom, Karin, **Thomas, Ronald G**, Thal, Leon J, & Ferris, Steven H | Alzheimer disease and associated disorders | (2006) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Prevention trials\nLinks: ðŸ“„ Article\n\n\nCognitive Changes in the Treatment of Mild Cognitive Impairment with Donepezil and Vitamin E: P02. 187\n Petersen, Ronald, **Thomas, Ronald**, Grundman, Michael, & Thai, Leon | Neurology | (2006) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Cognitive decline Drug development"
  },
  {
    "objectID": "research/index.html#section-19",
    "href": "research/index.html#section-19",
    "title": "Research",
    "section": "2005",
    "text": "2005\n\nAnalysis of apoptosis protein expression in early-stage colorectal cancer suggests opportunities for new prognostic biomarkers\n Krajewska, Maryla, Kim, Hoguen, Kim, Chul, Kang, Haeyoun, Welsh, Kate, Matsuzawa, Shu-ichi, Tsukamoto, Michelle, **Thomas, Ronald G**, Assa-Munt, Nuria, Piao, Zhe, & others | Clinical Cancer Research | (2005) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Biomarkers Statistical methods\nLinks: ðŸ“„ Article\n\n\nCognition in the treatment of mild cognitive impairment with donepezil and vitamin E\n Pfeiffer, E, Petersen, RC, Thomas, RG, & Thal, LJ | INTERNATIONAL PSYCHOGERIATRICS | (2005) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Cognitive decline Drug development\nLinks: ðŸ“„ Article\n\n\nCognitive Outcomes of Corrective Lenses on Low Income Preschoolers With Hyperopia/Astimgatism: A Longitudinal Pilot Study\n Roch--Levecq, A--C, Brody, B, Thomas, RG, & Brown, SI | Investigative Ophthalmology \\& Visual Science | (2005) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nDetailed assessment of activities of daily living in moderate to severe Alzheimer's disease\n Galasko, D, Schmitt, F, Thomas, R, Jin, S, Bennett, D, & Ferris, S | Journal of the International Neuropsychological Society: JINS | (2005) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nDivalproex sodium in nursing home residents with possible or probable Alzheimer disease complicated by agitation: a randomized, controlled trial\n Tariot, Pierre N, Raman, Rema, Jakimovich, Laura, Schneider, Lon, Porsteinsson, Anton, **Thomas, Ronald**, Mintzer, Jacobo, Brenner, Ronald, Schafer, Kim, & Thal, Leon | The American journal of geriatric psychiatry | (2005) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nPropranolol for disruptive behaviors in nursing home residents with probable or possible Alzheimer disease: a placebo-controlled study\n Peskind, Elaine R, Tsuang, Debby W, Bonner, Lauren T, Pascualy, Marcella, Riekse, Robert G, Snowden, Mark B, **Thomas, Ronald**, & Raskind, Murray A | Alzheimer Disease \\& Associated Disorders | (2005) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nSample size considerations in dementia prevention trials: Data from the Alzheimer's disease Cooperative Study MCI Trial\n Edland, SD, May, S, Emond, JA, Wolfson, T, Thal, L, Petersen, RC, & Thomas, RG | NEUROLOGY | (2005) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Prevention trials\nLinks: ðŸ“„ Article\n\n\nSelf-management of age-related macular degeneration at the 6-month follow-up: a randomized controlled trial\n Brody, Barbara L, Roch-Levecq, Anne-Catherine, **Thomas, Ronald G**, Kaplan, Robert M, & Brown, Stuart I | Archives of Ophthalmology | (2005) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nTreatment of MCI with cholinesterase inhibitors: current data\n Petersen, RC, Thomas, R, Grundman, M, & Thal, L | INTERNATIONAL PSYCHOGERIATRICS | (2005) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Drug development\nLinks: ðŸ“„ Article\n\n\nVitamin E and donepezil for the treatment of mild cognitive impairment\n Petersen, Ronald C, **Thomas, Ronald G**, Grundman, Michael, Bennett, David, Doody, Rachelle, Ferris, Steven, Galasko, Douglas, Jin, Shelia, Kaye, Jeffrey, Levey, Allan, & others | New England Journal of Medicine | (2005) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Cognitive decline Drug development\nLinks: ðŸ“„ Article\n\n\n[O1-04-04]: Operational criteria for patient recruitment in trials of mild cognitive impairment\n Petersen, Ronald C, **Thomas, Ronald G**, Grundman, Michael, Bennett, David A, Kaye, Jeffrey, Levey, Allan I, Pfeiffer, Eric, Sano, Mary, van Dyck, Christopher H, & Thal, Leon J | Alzheimer's \\& Dementia | (2005) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Cognitive decline\nLinks: ðŸ“„ Article\n\n\n[O2-01-01]: Donepezil and vitamin E in the progression of mild cognitive impairment to Alzheimer's disease: A hazard-ratio analysis\n Thal, Leon J, **Thomas, Ronald G**, Grundman, Michael, Bennett, David A, Doody, Rachelle S, Ferris, Steven H, Galasko, Douglas R, Jin, Shelia, Levey, Allan I, & Petersen, Ronald C | Alzheimer's \\& Dementia | (2005) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline Statistical methods\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF"
  },
  {
    "objectID": "research/index.html#section-20",
    "href": "research/index.html#section-20",
    "title": "Research",
    "section": "2004",
    "text": "2004\n\nA comparison of episodic memory deficits in neuropathologically-confirmed Dementia with Lewy bodies and Alzheimer's disease\n Hamilton, Joanne M, Salmon, David P, Galasko, Douglas, Delis, Dean C, Hansen, Lawrence A, Masliah, Eliezer, **Thomas, Ronald G**, & Thal, Leon J | Journal of the International Neuropsychological Society: JINS | (2004) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nDistinguished From Alzheimer Disease and Normal Aging for Clinical Trials Michael Grundman, MD, MPH; Ronald C. Petersen, PhD, MD; Steven H. Ferris, PhD\n **Thomas, Ronald G**, Aisen, Paul S, Shoulson, Ira, Rosenberg, Roger N, Gwinn-Hardy, Katrina, Mathews, Katherine D, Moore, Steven A, Darnell, Robert B, Lu, Chin-Song, Chou, Yah-Huei Wu, & others | (2004) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Neuroimaging\nLinks: ðŸ“„ Article\n\n\nDonepezil and vitamin E for mild cognitive impairment\n Petersen, RC, Thomas, R, & Thal, L | 9th International Congress on Alzheimerâ€™s Disease. Philadelphia | (2004) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nMAP kinase inhibitors reduce Helicobacter pylori-induced interleukin-8 secretion and the phosphorylation of I$\\\\kappa$B$\\\\\\\\alpha$\n Argent, R, Thomas, R, Boughan, P, Kidd, M, Smith, J, James, M, Bajaj-Elliott, M, & Atherton, J | Helicobacter | (2004) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nMild cognitive impairment can be distinguished from Alzheimer disease and normal aging for clinical trials\n Grundman, Michael, Petersen, Ronald C, Ferris, Steven H, **Thomas, Ronald G**, Aisen, Paul S, Bennett, David A, Foster, Norman L, Jack Jr, Clifford R, Galasko, Douglas R, Doody, Rachelle, & others | Archives of neurology | (2004) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Cognitive decline\n\n\nP1-003 ADCS Prevention instrument project: assessment of activities of daily living (ADL)\n Galasko, Douglas, Bennett, David, Sano, Mary, Marson, Daniel, Jin, Shelia, & **Thomas, Ronald** | Neurobiology of Aging | (2004) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Prevention trials\nLinks: ðŸ“„ Article\n\n\nP1-322 A multicenter, randomized, double-blind, placebo-controlled trial of valproate for agitation associated with dementia\n Tariot, Pierre N, Thal, Leon, Jakimovich, Laura, **Thomas, Ronald**, & Raman, Rema | Neurobiology of Aging | (2004) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nReliability of monitoring the clinical dementia rating in multicenter clinical trials\n Schafer, Kimberly A, Tractenberg, Rochelle E, Sano, Mary, Mackell, Joan A, **Thomas, Ronald G**, Gamst, Anthony, Thal, Leon J, Morris, John C, & others | Alzheimer disease and associated disorders | (2004) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Clinical trials\n\n\nS5-03-02 Prevention trials in Alzheimer's disease: design issues\n Thal, Leon | Neurobiology of Aging | (2004) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Prevention trials"
  },
  {
    "objectID": "research/index.html#section-21",
    "href": "research/index.html#section-21",
    "title": "Research",
    "section": "2003",
    "text": "2003\n\nA multicenter, placebo-controlled trial of melatonin for sleep disturbance in Alzheimer's disease\n Singer, Clifford, Tractenberg, Rochelle E, Kaye, Jeffrey, Schafer, Kim, Gamst, Anthony, Grundman, Michael, **Thomas, Ronald**, & Thal, Leon J | Sleep | (2003) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Sleep disorders\n\n\nA multicenter, randomized, placebo controlled, multiple-dose, safety and pharmacokinetic study of AIT-082 (Neotrofinâ„¢) in mild Alzheimer's disease patients\n Grundman, M, Capparelli, E, Kim, HT, Morris, JC, Farlow, M, Rubin, EH, Heidebrink, J, Hake, A, Ho, G, Schultz, AN, & others | Life sciences | (2003) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nAlzheimer's Disease Cooperative Study. Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial\n Aisen, PS, Schafer, KA, Grundman, M, Pfeiffer, E, Sano, M, Davis, KL, Farlow, MR, Jin, S, Thomas, RG, & Thal, LJ | Jama | (2003) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nEffects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial\n Aisen, Paul S, Schafer, Kimberly A, Grundman, Michael, Pfeiffer, Eric, Sano, Mary, Davis, Kenneth L, Farlow, Martin R, Jin, Shelia, **Thomas, Ronald G**, Thal, Leon J, & others | Jama | (2003) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\n\n\nEstrogen levels do not correlate with improvement in cognition\n Thal, Leon J, **Thomas, Ronald G**, Mulnard, Ruth, Sano, Mary, Grundman, Michael, & Schneider, Lon | Archives of Neurology | (2003) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nFission fragment angular distributions: A probe to study heavy-ion fusion dynamics\n Thomas, RG, Choudhury, RK, Mohanty, AK, Saxena, A, & Kapoor, SS | Physical Review C | (2003) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nHippocampal volume is associated with memory but not nonmemory cognitive performance in patients with mild cognitive impairment\n Grundman, Michael, Jack, Clifford R, Petersen, Ronald C, Kim, Hyun T, Taylor, Curtis, Datvian, Marina, Weiner, Myron F, DeCarli, Charles, DeKosky, Steven T, Van Dyck, Christopher, & others | Journal of Molecular Neuroscience | (2003) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nIdebenone treatment fails to slow cognitive decline in Alzheimerâ€™s disease\n Thal, LJ, Grundman, M, Berg, J, Ernstrom, K, Margolin, R, Pfeiffer, E, Weiner, MF, Zamrini, E, & Thomas, RG | Neurology | (2003) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline Drug development\n\n\nNSAIDs and hypertension\n Aisen, Paul S, Schafer, Kimberly, Grundman, Michael, **Thomas, Ronald**, & Thal, Leon J | Archives of internal medicine | (2003) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nReduction of nightmares and other PTSD symptoms in combat veterans by prazosin: a placebo-controlled study\n Raskind, Murray A, Peskind, Elaine R, Kanter, Evan D, Petrie, Eric C, Radant, Allen, Thompson, Charles E, Dobie, Dorcas J, Hoff, David, Rein, Rebekah J, Straits-Troster, Kristy, & others | American Journal of Psychiatry | (2003) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Military health\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nSelf-Management of Age-Related Macular Degeneration and Quality of Life at 6 Months Follow-Up: A Randomized Controlled Trial\n Brody, BL, Roch-Levecq, AC, Thomas, RG, Maclean, KK, Kaplan, RM, & Brown, SI | Investigative Ophthalmology \\& Visual Science | (2003) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nSteroid-induced elevation of glucose in Alzheimerâ€™s disease: relationship to gender, apolipoprotein E genotype and cognition\n Aisen, PS, Berg, JD, Craft, S, Peskind, ER, Sano, M, Teri, L, Mulnard, RA, Thomas, RG, & Thal, LJ | Psychoneuroendocrinology | (2003) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-22",
    "href": "research/index.html#section-22",
    "title": "Research",
    "section": "2002",
    "text": "2002\n\nA phase I study of AIT-082 in healthy elderly volunteers\n Grundman, Michael, Farlow, Martin, Peavy, Guerry, Kim, Hyun T, Capparelli, Edmund, Schultz, Arlan N, Salmon, David P, Ferris, Steven H, Mohs, Richard, **Thomas, Ronald G**, & others | Journal of Molecular Neuroscience | (2002) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nA randomized trial of the effect of a plant-based dietary pattern on additional breast cancer events and survival:: the Women's Healthy Eating and Living (WHEL) Study\n Pierce, John P, Faerber, Susan, Wright, Fred A, Rock, Cheryl L, Newman, Vicky, Flatt, Shirley W, Kealey, Sheila, Jones, Vicky E, Caan, Bette J, Gold, Ellen B, & others | Controlled clinical trials | (2002) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nAlzheimerâ€™s disease can be accurately diagnosed in very mildly impaired individuals\n Salmon, David P, Thomas, RG, Pay, MM, Booth, A, Hofstetter, CR, Thal, LJ, & Katzman, R | Neurology | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Pre-print PDF\n\n\nAssessing Alzheimer's disease patients with the Cohen-Mansfield Agitation Inventory: scoring and clinical implications\n Weiner, Myron F, Tractenberg, Rochelle E, Jin, Shelia, Gamst, Anthony, **Thomas, Ronald G**, Koss, Elisabeth, & Thal, Leon J | Journal of psychiatric research | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nBrain MRI hippocampal volume and prediction of clinical status in a mild cognitive impairment trial\n Grundman, Michael, Sencakova, Drahomira, Jack, Clifford R, Petersen, Ronald C, Kim, Hyun T, Schultz, Arlan, Weiner, Myron F, DeCarli, Charles, DeKosky, Steven T, Van Dyck, Christopher, & others | Journal of Molecular Neuroscience | (2002) \nSummary: Developing biomarkers and imaging techniques for disease detection\nTopics: Biostatistics R Neuroimaging Cognitive decline\n\n\nClinical correlates of hippocampal atrophy in patients with mild cognitive impairment\n Grundman, M, Kim, HT, Schultz, AN, Thomas, RG, Thal, L, Jack, CR, & Peterson, RC | NEUROBIOLOGY OF AGING | (2002) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Cognitive decline\nLinks: ðŸ“„ Article\n\n\nCorrelates of weight change in Huntington's disease\n Hamilton, JM, Corey-Bloom, J, Thomas, RG, Peavy, G, & Jacobson, MW | NEUROLOGY | (2002) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nDecline in verbal memory during preclinical Alzheimer's disease: examination of the effect of APOE genotype\n Lange, Kelly L, Bondi, Mark W, Salmon, David P, Galasko, Douglas, Delis, Dean C, **Thomas, Ronald G**, & Thal, Leon J | Journal of the International Neuropsychological Society: JINS | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Pre-print PDF\n\n\nIndomethacin reduces Helicobacter pylori-induced interleukin-8 (IL-8) production by the gastric epithelial cell line, AGS.\n James, MW, Argent, RH, Thomas, R, Hawkey, C, & Atherton, J | GASTROENTEROLOGY | (2002) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nInvestigating emergent symptomatology as an outcome measure in a behavioral study of Alzheimer's disease\n Tractenberg, Rochelle E, Gamst, Anthony, **Thomas, Ronald G**, Patterson, Marian, Schneider, Lon S, & Thal, Leon J | The Journal of neuropsychiatry and clinical neurosciences | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nNo long-term effect of behavioral treatment on psychotropic drug use for agitation in Alzheimer's disease patients\n Weiner, Myron F, Tractenberg, Rochelle E, Sano, Mary, Logsdon, Rebecca, Teri, Linda, Galasko, Douglas, Gamst, Anthony, Thomas, Ron, & Thal, Leon J | Journal of geriatric psychiatry and neurology | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article\n\n\nPsychosocial and Functional Parameters in Patients with Age Related Macular Degeneration and Choroidal Neovascularization with and without Photodynamic Therapy\n Goldberg, DE, Roch-Levecq, AC, Maclean, KK, Brody, BL, McGuire, DE, Goldbaum, MH, Thomas, RG, Brown, SI, & Freeman, WR | Investigative Ophthalmology \\& Visual Science | (2002) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Drug development\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nResults of a multicenter trial of rofecoxib and naproxen in Alzheimer's disease\n Aisen, P, Schafer, K, Grundman, M, Farlow, M, Sano, M, Jin, S, Thomas, R, & Thal, L | Neurobiology of Aging | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nThe ADCS clinical trial of melatonin for the sleep disturbance of alzheimer's disease: Case report of an unusual sleep/wake cycle and response to melatonin.\n Singer, C, Colling, E, Tractenberg, R, Grundman, M, Gamst, A, Thomas, R, & Thal, L | AMERICAN JOURNAL OF GERIATRIC PSYCHIATRY | (2002) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Sleep disorders Clinical trials\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-23",
    "href": "research/index.html#section-23",
    "title": "Research",
    "section": "2001",
    "text": "2001\n\nFrequency of behavioral symptoms characterizes agitation in Alzheimer's disease\n Tractenberg, Rochelle E, Gamst, Anthony, Weiner, Myron F, Koss, Elisabeth, **Thomas, Ronald G**, Teri, Linda, & Thal, Leon | International journal of geriatric psychiatry | (2001) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nIncidence and persistence of psychosis in Alzheimer's disease\n Sano, MC, Berg, JD, Thomas, RG, Schneider, LS, Aisen, PS, Mulnard, R, & Thal, LJ | Neurology | (2001) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nMetabolic syndrome and ischemic heart disease in elderly men and women\n Lindblad, Ulf, Langer, Robert D, Wingard, Deborah L, **Thomas, Ronald G**, & Barrett-Connor, Elizabeth L | American journal of epidemiology | (2001) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-24",
    "href": "research/index.html#section-24",
    "title": "Research",
    "section": "2000",
    "text": "2000\n\nA randomized controlled trial of prednisone in Alzheimerâ€™s disease\n Aisen, Paul S, Davis, KL, Berg, JD, Schafer, K, Campbell, K, Thomas, RG, Weiner, MF, Farlow, MR, Sano, M, Grundman, M, & others | Neurology | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\n\n\nA randomized controlled trial of prednisone in Alzheimerâ€™s disease\n Koch, HJ & Szecsey, A | Neurology | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nAnalysis of longitudinal data in an Alzheimer's disease clinical trial\n **Thomas, Ronald G**, Berg, Julie D, Sano, Mary, & Thal, Leon | Statistics in medicine | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Statistical methods Longitudinal studies\n\n\nComparison of the serial position effect in very mild Alzheimer's disease, mild Alzheimer's disease, and amnesia associated with electroconvulsive therapy\n Bayley, Peter J, Salmon, David P, Bondi, Mark W, Bui, Barbara K, Olichney, John, Delis, Dean C, **Thomas, Ronald G**, & Thal, Leon J | Journal of the International Neuropsychological Society | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article\n\n\nDescription of behaviors emerging in community-dwelling persons with Alzheimer's disease over 12 months\n Gamst, A, Thomas, RG, Patterson, M, & Schneider, L | ANNALS OF NEUROLOGY | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nDisorder among Veterans with Substance Abuse\n THOMAS, R & MICHAEL, J | THE JOURNaL OF NERvOUs AND MEntal Disease | (2000) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Military health\n\n\nEstrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial\n Mulnard, Ruth A, Cotman, Carl W, Kawas, Claudia, van Dyck, Christopher H, Sano, Mary, Doody, Rachelle, Koss, Elizabeth, Pfeiffer, Eric, Jin, Shelia, Gamst, Anthony, & others | Jama | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Drug development\n\n\nIncidence of and risk factors for hallucinations and delusions in patients with probable AD\n Paulsen, Jane S, Salmon, DP, Thal, Leon J, Romero, R, Weisstein--Jenkins, C, Galasko, D, Hofstetter, CR, Thomas, R, Grant, I, & Jeste, DV | Neurology | (2000) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nPredicting nursing home placement with change on cognitive measures in Alzheimer's disease\n Sano, MC, Berg, JD, Knopman, D, Farlow, MR, & Thomas, RG | Neurology | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nPrevalence of symptoms on the CERAD behavior rating scale for dementia in normal elderly subjects and Alzheimerâ€™s disease patients\n Tractenberg, Rochelle E, Patterson, Marian, Weiner, Myron F, Teri, Linda, Grundman, Michael, **Thomas, Ronald G**, & Thal, Leon J | The Journal of neuropsychiatry and clinical neurosciences | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nQualifying change: a method for defining clinically meaningful outcomes of change score computation\n Tractenberg, Rochelle E, Jin, Shelia, Patterson, Marian, Schneider, Lon S, Gamst, Anthony, **Thomas, Ronald G**, & Thal, Leon J | Journal of the American Geriatrics Society | (2000) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Statistical methods\nLinks: ðŸ“„ Article\n\n\nQuantifying behavioral disturbance in Alzheimer's disease patients\n Weiner, Myron F, Tractenberg, Rochelle, Teri, Linda, Logsdon, Rebecca, **Thomas, Ronald G**, Gamst, Anthony, & Thal, Leon J | Journal of Psychiatric Research | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nTreatment of agitation in AD: a randomized, placebo-controlled clinical trial\n Teri, Linda, Logsdon, RG, Peskind, E, Raskind, M, Weiner, MF, Tractenberg, RE, Foster, NL, Schneider, LS, Sano, M, Whitehouse, P, & others | Neurology | (2000) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Drug development\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nUse of brain MRI volumetric analysis in a mild cognitive impairment trial to delay the diagnosis of Alzheimerâ€™s disease\n Grundman, Michael, Sencakova, Drahomira, Jack, CR, Fillit, H, & Oâ€™Connell, A | Drug discovery and development for Alzheimerâ€™s disease | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Neuroimaging Cognitive decline Statistical methods\n\n\nfor the Alzheimer's Disease Cooperative Study: Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial\n Mulnard, RA, Cotman, CW, Kawas, C, Van Dyck, CH, Sano, M, Doody, R, Koss, E, Pfeiffer, E, Jin, S, Gamst, A, Grundman, M, Thomas R, & Thal L | JAMA | (2000) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials Drug development\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-25",
    "href": "research/index.html#section-25",
    "title": "Research",
    "section": "1999",
    "text": "1999\n\nA normative study of Nelson's (1976) modified version of the Wisconsin Card Sorting Test in healthy older adults\n Lineweaver, Tara T, Bondi, Mark W, **Thomas, Ronald G**, & Salmon, David P | The Clinical Neuropsychologist | (1999) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nAge-related macular degeneration: a randomized clinical trial of a self-management intervention\n Brody, Barbara L, Williams, Rebecca A, **Thomas, Ronald G**, Kaplan, Robert M, Chu, Ray M, & Brown, Stuart I | Annals of Behavioral Medicine | (1999) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nAssessment of agitation in Alzheimer's disease: the agitated behavior in dementia scale\n Logsdon, Rebecca G, Teri, Linda, Weiner, Myron F, Gibbons, Laura E, Raskind, Murray, Peskind, Elaine, Grundman, &gt; Michael, Koss, Elisabeth, **Thomas, Ronald G**, Thai, Leon J, & others | Journal of the American Geriatrics Society | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nBrief Methodological Reports-Assessment of Agitation in Alzheimer's Disease: The Agitated Behavior in Dementia Scale\n Logsdon, Rebecca G, Teri, Linda, Weiner, Myron F, Gibbons, Laura E, Raskind, Murray, Peskind, Elaine, Grundman, Michael, Koss, Elisabeth, **Thomas, Ronald G**, & Thal, Leon J | Journal of the American Geriatrics Society | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Statistical methods\nLinks: ðŸ“„ Article\n\n\nClinical symptoms of dementia with Lewy bodies: Secondary analyses of the Alzheimer's disease cooperative study selegiline and vitamin E clinical trial\n Olin, JT, Papka, M, Jin, S, Sano, M, Grundman, M, & Thomas, R | European Neuropsychopharmacology | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nEthnic differences in clinical measures among participants in Alzheimer's disease clinical trials\n Bell, Karen, Sano, Mary, Jin, Shelia, **Thomas, Ronald**, & Thal, Leon | Neurology | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nMini-mental state examination and Mattis Dementia Rating Scale performance differs in Hispanic and non-Hispanic Alzheimer's disease patients\n Hohl, Ursula, Grundman, Michael, Salmon, David P, **Thomas, Ronald G**, & Thal, Leon J | Journal of the International Neuropsychological Society | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nNeurochemical markers do not correlate with cognitive decline in the Lewy body variant of Alzheimer disease\n Sabbagh, Marwan N, Corey-Bloom, Jody, Tiraboschi, Pietro, **Thomas, Ronald**, Masliah, Eliezer, & Thal, Leon J | Archives of neurology | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nNeuropsychological function and apolipoprotein E genotype in the preclinical detection of Alzheimer's disease.\n Bondi, Mark W, Salmon, David P, Galasko, Douglas, **Thomas, Ronald G**, & Thal, Leon J | Psychology and aging | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nNursing home placement is related to dementia progression: experience from a clinical trial\n Knopman, David S, Berg, JD, Thomas, R, Grundman, M, Thal, LJ, Sano, M, & others | Neurology | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nThe Beneficial Effects of Vitamin E and Selegiline in a Controlled Trial in Alzheimer's Disease Are Independent of the Apolipoprotein E e4 Allele\n Galasko, Douglas, Sano, Mary, Berg, Julie, **Thomas, Ronald**, Grundman, Michael, & Thal, Leon | Neurology | (1999) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nWeight gain in infants breastfed by mothers who take fluoxetine\n Chambers, Christina D, Anderson, Philip O, **Thomas, Ronald G**, Dick, Lyn M, Felix, Robert J, Johnson, Kathleen A, & Jones, Kenneth Lyons | Pediatrics | (1999) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-26",
    "href": "research/index.html#section-26",
    "title": "Research",
    "section": "1998",
    "text": "1998\n\nA comparison of the Cohen-Mansfield agitation inventory with the cerad behavioral rating scale for dementia in community-dwelling persons with Alzheimers disease\n Weiner, Myron F, Koss, Elisabeth, Patterson, Marian, Jin, Shelia, Teri, Linda, Thomas, Ron, Thal, Leon J, & Whitehouse, Peter | Journal of psychiatric research | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nAgreement on CDR ratings by committee\n Tractenberg, Rochelle, Schafer, Kimberly, Thomas, Ron, & Morris, John C | Controlled Clinical Trials | (1998) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nAssociation of CYP2D microsatellite polymorphism with Lewy body variant of Alzheimer's disease\n Tanaka, S, Chen, X, Xia, Y, Kang, DE, Matoh, N, Sundsmo, M, Thomas, RG, Katzman, R, Thal, LJ, Trojanowski, JQ, & others | Neurology | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nCognitive and functional abilities in severely demented Alzheimer's patients\n Peavy, GM, Salmon, DP, & Thomas, RG | CLINICAL NEUROPSYCHOLOGIST | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nDesign and baseline characteristics of the veterans affairs non-Q-wave infarction strategies in-hospital (VANQWISH) trial\n Ferry, David R, Oâ€™Rourke, Robert A, Blaustein, Alvin S, Crawford, Michael H, Deedwania, Prakash C, Carson, Peter E, Zoble, Robert G, Pepine, Carl J, **Thomas, Ronald G**, Chow, Bruce K, & others | Journal of the American College of Cardiology | (1998) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Military health\n\n\nDynamic measurement scale development for clinical trials in targeted populations\n Jin, Shelia, **Thomas, Ronald G**, Galasko, Douglas, & Thal, Leon J | Controlled Clinical Trials | (1998) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Epidemiology\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nHigh cerebrospinal fluid tau and low amyloid beta42 levels in the clinical diagnosis of Alzheimer disease and relation to apolipoprotein E genotype\n Galasko, D, Chang, L, Motter, R, Clark, CM, Kaye, Jeffrey, Knopman, D, Thomas, R, Kholodenko, D, Schenk, D, Lieberburg, I, & others | Archives of neurology | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nInteraction of apolipoprotein E 4 with other genetic and non-genetic risk factors in late onset Alzheimer disease: problems facing the investigator\n Katzman, R, Kang, D, & Thomas, R | Neurochemical research | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nMeasuring cognitive progression in Alzheimer's disease\n Berg, Julie D, **Thomas, Ronald G**, Thal, Leon J, & Sano, Mary | Controlled Clinical Trials | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\n\n\nPower calculation for randomized start design\n Kean, Yin M, **Thomas, Ronald G**, & Thal, Leon J | Controlled Clinical Trials | (1998) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nPractice effects on the modified Wisconsin card sorting test in normally aging adults\n Lineweaver, TT, Bondi, MW, & Thomas, RG | Archives of Clinical Neuropsychology | (1998) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nThe electrocardiographic exercise test in a population with reduced workup bias: diagnostic performance, computerized interpretation, and multivariable prediction\n Froelicher, Victor F, Lehmann, Kenneth G, **Thomas, Ronald**, Goldman, Steven, Morrison, Douglas, Edson, Robert, Lavori, Philip, Myers, Jonathan, Dennis, Charles, Shabetai, Ralph, & others | Annals of internal medicine | (1998) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Epidemiology\nLinks: ðŸ“„ Article\n\n\nThe psychosocial impact of macular degeneration\n Williams, Rebecca A, Brody, Barbara L, **Thomas, Ronald G**, Kaplan, Robert M, & Brown, Stuart I | Archives of ophthalmology | (1998) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nThe relationship between Nursing home placement and measures of change in Alzheimer's disease\n Knopman, David, Sano, Mary, Berg, Julie, & **Thomas, Ronald** | Neurology | (1998) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nUse of the world wide web in data dissemination to central review committees\n Schafer, Kimberly A, Welty, Greg, & **Thomas, Ronald G** | Controlled Clinical Trials | (1998) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nUtility of psychophysiological measurement in the diagnosis of posttraumatic stress disorder: results from a Department of Veterans Affairs Cooperative Study.\n Keane, Terence M, Kolb, Lawrence C, Kaloupek, Danny G, Orr, Scott P, Blanchard, Edward B, **Thomas, Ronald G**, Hsieh, Frank Y, & Lavori, Philip W | Journal of consulting and clinical psychology | (1998) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Military health"
  },
  {
    "objectID": "research/index.html#section-27",
    "href": "research/index.html#section-27",
    "title": "Research",
    "section": "1997",
    "text": "1997\n\n53 Power comparisons among different number of categories under ordered polytomous logistic regression model\n Jeong, Jong-Hyeon, Klauber, Melville R, **Thomas, Ronald G**, Grundman, Michael, & Thal, Leon J | Controlled Clinical Trials | (1997) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nA Multicenter Evaluation of New Treatment Efficacy\n Whitehouse, Peter J, Schmitt, HFrederick A, Sano, Mary, & **Thomas, Ronald G** | Alzheimer Disease and Associated Disorders | (1997) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Drug development\n\n\nA controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer's disease\n Sano, Mary, Ernesto, Christopher, **Thomas, Ronald G**, Klauber, Melville R, Schafer, Kimberly, Grundman, Michael, Woodbury, Peter, Growdon, John, Cotman, Carl W, Pfeiffer, Eric, & others | New England Journal of Medicine | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nA longitudinal study of behavioral pathology across five levels of dementia severity in Alzheimer's disease: The CERAD Behavior Rating Scale for Dementia.\n Patterson, Marian B, Mack, James L, Mackell, Joan A, **Thomas, Ronald**, Tariot, Pierre, Weiner, Myron, & Whitehouse, Peter J | Alzheimer disease and associated disorders | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Longitudinal studies\nLinks: ðŸ“„ Article\n\n\nAlpha-tocopherol and Alzheimer's disease\n Sano, Mary, **Thomas, Ronald G**, & Thal, Leon J | The New England Journal of Medicine | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nAn inventory to assess activities of daily living for clinical trials in Alzheimer's disease.\n Galasko, Douglas, Bennett, David, Sano, Mary, Ernesto, Chris, **Thomas, Ronald**, Grundman, Michael, & Ferris, Steven | Alzheimer disease and associated disorders | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nApoE genotype influences the CSF level of A $\\\\beta$ 42 in Alzheimer's disease\n Seubert, PA, Motter, RN, Schenk, DB, Lieberburg, IM, Kholodenko, D, Galasko, D, Thomas, R, Chang, L, Miller, B, Clark, C, & others | Neurology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nAssessing patterns of agitation in Alzheimer's disease patients with the Cohen-Mansfield Agitation Inventory. The Alzheimer's Disease Cooperative Study.\n Koss, Elisabeth, Weiner, Myron, Ernesto, Christopher, Cohen-Mansfield, Jiska, Ferris, Steven H, Grundman, Michael, Schafer, Kimberly, Sano, Mary, Thal, Leon J, **Thomas, Ronald**, & others | Alzheimer Disease and Associated Disorders | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nCSF levels of A beta 432 and tau as aids to diagnosing Alzheimer's disease\n Galasko, D, Seubert, P, Motter, R, Schenk, D, Kholodenko, D, Lieberburg, I, Chang, L, Miller, B, Clark, C, Kaye, J, & others | Neurology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nDefective Neurite Extension Is Caused by a Mutation in Amyloid /A4 (A ) Protein Precursor Found in Familial Alzheimer's Disease\n Roch, J-M, Sundsmo, M, Otero, D, Sisodia, S, Thomas, R, & Saitoh, T | JOURNAL OF NEUROBIOLOGY | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nDefective neurite extension is caused by a mutation in amyloid beta  protein precursor found in familial Alzheimer's disease\n Li, Hai Ling, Roch, Jean-Marc, Sundsmo, Mary, Otero, Deborah, Sisodia, Sangram, **Thomas, Ronald**, & Saitoh, Tsunao | Journal of neurobiology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nDiagnostic accuracy of dementia with Lewy bodies: A prospective evaluation\n Hohl, U, CoreyBloom, J, Hansen, LA, Thomas, RG, & Thal, LJ | Neurology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nEffects of Selegiline and alpha-Tocopherol on cognitive and functional outcome measures in moderately impaired patients with Alzheimer's disease\n Sano, M, Ernesto, C, Thomas, RG, Klauber, MR, Schafer, K, Grundman, M, Woodbury, P, Growdon, J, Cotman, CW, Pfeiffer, E, & others | Neurology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nEffects of apolipoprotein E on dementia and aging in the Shanghai Survey of Dementia\n Katzman, R, Zhang, M-Y, Chen, PJ, Gu, N, Jiang, S, Saitoh, T, Chen, X, Klauber, M, Thomas, RG, Liu, WT, & others | Neurology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nEstrogen, apolipoprotein E, and dementia\n Barrett-Connor, Elizabeth & **Thomas, Ronald G** | Journal of women's health | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R\n\n\nGenetic association of the low-density lipoprotein receptor-related protein gene (LRP), and apolipoprotein E receptor, with late-onset Alzheimer's disease\n Kang, DE, Saitoh, T, Chen, X, Xia, Y, Masliah, E, Hansen, LA, Thomas, RG, Thal, LJ, & Katzman, R | Neurology | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nP23 use of the world wide web for clinical monitoring in multicenter clinical trials\n Schafer, Kimberly, **Thomas, Ronald G**, Welty, Greg, Berry, Angela Lambert, & Schittini, Mario | Controlled Clinical Trials | (1997) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nQuality of life among elderly adults with macular degeneration\n Williams, RA, Brody, BL, Kaplan, RM, Thomas, RG, & Brown, SI | INVESTIGATIVE OPHTHALMOLOGY \\& VISUAL SCIENCE | (1997) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nTacrine and nursing home placement\n Thal, Leon J, **Thomas, Ronald G**, & Sano, Mary | Neurology | (1997) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nThe Spanish Instrument Protocol: Design and implementation of a study to evaluate treatment efficacy instruments for Spanish-speaking patients with Alzheimer's disease.\n Sano, M, Mackell, JA, Ponton, M, Ferreira, P, Wilson, J, Pawluczyk, S, Pfeiffer, E, Thomas, RG, Jin, S, Schafer, K, & others | Alzheimer disease and associated disorders | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article\n\n\nValidity and reliability of the Alzheimerâ€™s Disease Cooperative Study-Clinical global impression of change (ADCS-CGIC)\n Schneider, Lon S, Olin, Jason T, Doody, Rachelle S, Clark, Christopher M, Morris, John C, Reisberg, Barry, Ferris, Steven H, Schmitt, Frederick A, Grundman, Michael, & **Thomas, Ronald G** | Alzheimer Disease | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nfor the members of the Alzheimerâ€™s Disease Cooperative Study\n Sano, M, Ernesto, C, Thomas, RG, Klauber, MR, Schafer, K, Grundman, M, Woodbury, P, Growden, J, Cotnman, C, Pfeiffer, E, & others | A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimerâ€™s disease. N Engl J Med | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\n\n\nthe Alzheimer's Disease Cooperative Study. Validity and reliability of the Alzheimer's disease cooperative study-clinical global impression of change\n Schneider, LS, Olin, JT, Doody, RS, Clark, CM, Morris, JC, Reisberg, B, Schmitt, FA, Grundman, M, Thomas, RG, & Ferris, SH | Alzheimer Dis Assoc Disord | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease\nLinks: ðŸ“„ Article\n\n\nthe Alzheimerâ€™s Disease Cooperative Study. An inventory to assess activities of daily living for clinical trials in Alzheimerâ€™s disease\n Galasko, D, Bennett, D, Sano, M, Ernesto, C, Thomas, R, Grundman, M, & Ferris, S | Alzheimer Dis Assoc Disord | (1997) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials"
  },
  {
    "objectID": "research/index.html#section-28",
    "href": "research/index.html#section-28",
    "title": "Research",
    "section": "1996",
    "text": "1996\n\nA32 computer-aided clinical monitoring: Results of a controlled experiment\n **Thomas, Ronald G**, Schafer, Kimberly, Woodbury, Peter, White, Beverly, Mackell, Joan, Lambert, Angie, & Scattini, Mario | Controlled Clinical Trials | (1996) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nA34 Clinical monitoring of rating scales in multicenter clinical trials\n Schafer, Kimberly, Ernesto, Christopher, Sano, Mary, Mackell, Joan, **Thomas, Ronald**, & Morris, John C | Controlled Clinical Trials | (1996) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nApoE and CYP2D6 polymorphism with and without parkinsonism-dementia complex in the people of Chamorro, Guam\n Chen, X, Xia, Y, Gresham, LS, Molgaard, CA, Thomas, RG, Galasko, D, Wiederholt, WC, & Saitoh, T | Neurology | (1996) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nApolipoprotein-epsilon4 and head trauma: Synergistic or additive risks?\n Katzman, R, Galasko, DR, Saitoh, T, Chen, X, Pay, MM, Booth, A, & Thomas, RG | Neurology | (1996) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nDevelopment of a pool of items to assess activities of daily living in clinical trials for Alzheimer's disease\n Galasko, D, Bennett, D, Ernesto, C, Thomas, R, & Sano, M | Neurology | (1996) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nEvaluation of efficacy measures in clinical trials for Alzheimer's disease: Does psychometric test performance predict clinically relevant outcomes?\n Sano, M, Growdon, J, Thomas, R, Ernesto, C, Schafer, K, Woodbury, P, Grundman, M, & Thal, L | Neurology | (1996) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Clinical trials\nLinks: ðŸ“„ Article\n\n\nFamilial melanoma and pancreatic cancer\n Wright, Fred A & **Thomas, Ronald G** | The New England journal of medicine | (1996) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nP63 Informed consent issues when including genetic testing in clinical trials\n Schafer, Kimberly, **Thomas, Ronald**, Galasko, Douglas, Morris, John C, Whitehouse, Peter, Bochenek, Jacqueline, & Thal, Leon | Controlled Clinical Trials | (1996) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article\n\n\nRate of dementia of the Alzheimer type (DAT) in subjects with mild cognitive impairment\n Grundman, Michael, Petersen, Ronald C, Morris, JC, Ferris, S, Sano, Mary, Farlow, Martin R, Doody, Rachel S, Galasko, D, Ernesto, C, Thomas, RG, & others | Neurology | (1996) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline\nLinks: ðŸ“„ Article\n\n\nRationale and design of a multicenter study of selegiline and alpha-tocopherol in the treatment of Alzheimer disease using novel clinical outcomes. Alzheimer's Disease Cooperative Study.\n Sano, Mary, Ernesto, Christopher, Klauber, Melville R, Schafer, Kimberly, Woodbury, Peter, **Thomas, Ronald**, Grundman, Michael, Growdon, John, & Thal, Leon J | Alzheimer disease and associated disorders | (1996) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nSubstance-dependent inpatients who accept smoking treatment\n Seidner, Andrea L, Burling, Thomas A, Gaither, David E, & **Thomas, Ronald G** | Journal of Substance Abuse | (1996) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Drug development\n\n\nValidity and reliability of the Alzheimers disease cooperative study-clinical global impression of change (ADCS-CGIC)\n Schneider, Lon S, Olin, Jason T, Doody, Rachelle S, Clark, Christopher M, Morris, John C, Reisberg, Barry, Ferris, Steven H, Schmitt, Frederick A, Grundman, Michael, & **Thomas, Ronald G** | Alzheimer Disease Springer | (1996) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease"
  },
  {
    "objectID": "research/index.html#section-29",
    "href": "research/index.html#section-29",
    "title": "Research",
    "section": "1995",
    "text": "1995\n\nProspective study of hospitalization for asthma: a preliminary risk factor model\n Li, Dominic, German, Donald, Lulla, Sulochina, **Thomas, Ronald G**, & Wilson, Sandra R | American journal of respiratory and critical care medicine | (1995) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nThe Spanish Instrument Protocol: a Study to Evaluate Treatment Efficacy Instruments for Spanish-Speaking Patients with Alzheimer's Disease\n Thomas, RG, Jin, S, Schafer, K, Schittini, M, Grundman, M, & Ferris, SH | Alzheimer Disease and Associated Disorders | (1995) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Drug development"
  },
  {
    "objectID": "research/index.html#section-30",
    "href": "research/index.html#section-30",
    "title": "Research",
    "section": "1994",
    "text": "1994\n\nApplication of neural networks to the classification of giant cell arteritis\n Astion, Michael L, Wener, Mark H, **Thomas, Ronald G**, Hunder, Gene G, & Bloch, Daniel A | Arthritis \\& Rheumatism: Official Journal of the American College of       Rheumatology | (1994) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nDrug and alcohol abuse inpatients' attitudes about smoking cessation\n Irving, Lori M, Seidner, Andrea L, Burling, Thomas A, **Thomas, Ronald G**, & Brenner, Gail F | Journal of Substance Abuse | (1994) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Drug development\nLinks: ðŸ“„ Article\n\n\nZweibaryonensysteme mit Strangeness und die Antikaon-Deuteron Streuung\n Thomas, Ralf | (1994) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-31",
    "href": "research/index.html#section-31",
    "title": "Research",
    "section": "1993",
    "text": "1993\n\nA controlled trial of two forms of self-management education for adults with asthma\n Wilson, Sandra R, Scamagas, Peter, German, Donald F, Hughes, Gary W, Lulla, Sulochina, Coss, Stamatiki, Chardon, Luis, **Thomas, Ronald G**, Starr-Schneidkraut, Norma, Stancavage, Frances B, & others | The American journal of medicine | (1993) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\n\n\nAlgorithm AS 280: the power function for Fisher's exact test\n Conlon, Michael & **Thomas, Ronald G** | Journal of the Royal Statistical Society. Series C (Applied Statistics) | (1993) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nOvertraining in neural networks that interpret clinical data\n Astion, ML, Wener, MH, Thomas, RG, Hunder, GG, & Bloch, DA | Clinical chemistry | (1993) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nPrediction of cardiovascular death in men undergoing noninvasive evaluation for coronary artery disease\n Morrow, Kiernan, Morris, Charles K, Froelicher, Victor F, Hideg, Alisa, Hunter, Dodie, Johnson, Eileen, Kawaguchi, Takeo, Lehmann, Kenneth, Ribisl, Paul M, **Thomas, Ronald**, & others | Annals of Internal Medicine | (1993) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nTrimethoprim-sulfamethoxazole prophylaxis in granulocytopenic patients with acute leukemia: evaluation of serum antibiotic levels in a randomized, double-blind, placebo-controlled Department of Veterans Affairs Cooperative Study\n Ward, TT, Thomas, RG, Fye, CL, Arbeit, R, Coltman Jr, CA, Craig, W, Dana, BW, Finegold, SM, Lentino, J, Penn, RL, & others | Clinical infectious diseases | (1993) \nSummary: Investigating health impacts in military populations and combat environments\nTopics: Biostatistics R Clinical trials Military health"
  },
  {
    "objectID": "research/index.html#section-32",
    "href": "research/index.html#section-32",
    "title": "Research",
    "section": "1992",
    "text": "1992\n\nAn algorithm for the rapid evaluation of the power function for Fisher's Exact Test\n **Thomas, Ronald G** & Conlon, Michael | Journal of statistical computation and simulation | (1992) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nCalculation of observables in the pion-deuteron system. Berechnung von Observablen im Pion Deuteron-System\n Beuschel, T, Feldkeller, B, Fuchs, M, Huber, MG, Metsch, BC, & Thomas, R | Verhandlungen der Deutschen Physikalischen Gesellschaft;(Germany) | (1992) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nConcave hymenal variations in suspected child sexual abuse victims\n Kerns, David L, Ritter, Mary L, & **Thomas, Ronald G** | Pediatrics | (1992) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nPROGRESSION OF FUNCTIONAL DISABILITY IN RHEUMATOID-ARTHRITIS\n RAYNAULD, JP, THOMAS, RG, & BLOCH, DA | ARTHRITIS AND RHEUMATISM | (1992) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nSample size determination based on Fisher's exact test for use in 2 x 2 comparative trials with low event rates\n **Thomas, Ronald G** & Conlon, Michael | Controlled clinical trials | (1992) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\n\n\nTwo-baryon systems with strangeness S=-1 and S=-2\n Fuchs, M, Huber, MG, Metsch, BC, & Thomas, R | Verhandlungen der Deutschen Physikalischen Gesellschaft | (1992) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF"
  },
  {
    "objectID": "research/index.html#section-33",
    "href": "research/index.html#section-33",
    "title": "Research",
    "section": "1991",
    "text": "1991\n\nAn analysis of methods of communication in clinical trials\n Sheridan, Lenore & **Thomas, Ronald G** | Controlled Clinical Trials | (1991) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Clinical trials Statistical methods\n\n\nIntegration of statutory provisions of NEPA, RCRA, and CERCLA at the Savannah River site. Revision 1\n Gordon, DE, Thomas, R, Shedrow, CB, & Wilson, MP | (1991) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-34",
    "href": "research/index.html#section-34",
    "title": "Research",
    "section": "1990",
    "text": "1990\n\nA new confidence interval for the difference of two binomial proportions\n Conlon, Michael & **Thomas, Ronald G** | Computational Statistics \\& Data Analysis | (1990) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nData monitoring through stochastic curtailing when the outcome proportions are small: An exact approach\n **Thomas, Ronald G** | Controlled Clinical Trials | (1990) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nDevelopment of an active target for scattering of neutral baryons\n Thomas, R, Empl, E, Kilian, K, Oelert, W, Roderburg, E, Sefzick, T, Sehl, G, Steinkamp, O, & Ziolkowski, M | Verhandlungen der Deutschen Physikalischen Gesellschaft | (1990) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nTest measurements of an asymmetric induction drift chamber with flash ADC's\n Decker, G, Kilian, K, Lippert, C, Oelert, W, Roderburg, E, Sefzick, T, Sehl, G, Steinkamp, O, Thomas, R, Ziolkowski, M, & others | Verhandlungen der Deutschen Physikalischen Gesellschaft | (1990) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\n\\textperiodcentered\n Tyrell, Doris, Cline, Dorothy R, & **Thomas, Ronald G** | Controlled Clinical Trials | (1990) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\n\\textperiodcentered\n Lee, Kelvin K & **Thomas, Ronald G** | Controlled Clinical Trials | (1990) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R"
  },
  {
    "objectID": "research/index.html#section-35",
    "href": "research/index.html#section-35",
    "title": "Research",
    "section": "1989",
    "text": "1989\n\nEffect of zinc supplementation on the development of cardiovascular disease in the elderly\n Hale, William E, May, Franklin E, **Thomas, Ronald G**, Moore, Mary T, & Stewart, Ronald B | Journal of Nutrition for the Elderly | (1989) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nExact sample size calculations for 2x2 comparative trials when the outcome proportions are small\n **Thomas, Ronald G** | Controlled Clinical Trials | (1989) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nRisk factors, time course and treatment effect for restenosis after successful percutaneous transluminal coronary angioplasty of chronic total occlusion\n Ellis, Stephen G, Shaw, Richard E, Gershony, Gary, **Thomas, Ronald**, Roubin, Gary S, Douglas Jr, John S, Topol, Eric J, Startzer, Simon H, Myler, Richard K, & King III, Spencer B | The American journal of cardiology | (1989) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R Drug development\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-36",
    "href": "research/index.html#section-36",
    "title": "Research",
    "section": "1988",
    "text": "1988\n\nAngiographic and clinical predictors of acute closure after native vessel coronary angioplasty.\n Ellis, SG, Roubin, GS, King 3rd, SB, Douglas Jr, JS, Weintraub, WS, Thomas, RG, & Cox, WR | Circulation | (1988) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nFORMS INVENTORY SYSTEM FOR A COMPLEX CLINICAL-TRIAL\n MELLEN, BG, THOMAS, RG, & CASTANO, D | CONTROLLED CLINICAL TRIALS | (1988) \nSummary: Evaluating therapeutic interventions through rigorous clinical trials\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nInfluence of balloon size on initial success, acute complications, and restenosis after percutaneous transluminal coronary angioplasty. A prospective randomized study.\n Roubin, Gary S, Douglas Jr, John S, King 3rd, SB, Lin, SF, Hutchison, Nancy, Thomas, RG, & Gruentzig, AR | Circulation | (1988) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Clinical trials\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-37",
    "href": "research/index.html#section-37",
    "title": "Research",
    "section": "1987",
    "text": "1987\n\nA comparison of single lesion dilatation in single vessel and multivessel disease\n Mufson, LGAR, Roubin, GS, Black, A, & Thomas, RG | Circulation | (1987) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nEffects of behavioral self-management on oral hygiene adherence among orthodontic patients\n McGlynn, F Dudley, LeCompte, E Joseph, **Thomas, Ronald G**, Courts, Frank J, & Melamed, Barbara G | American Journal of Orthodontics and Dentofacial Orthopedics | (1987) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\n\n\nImpact of air filtration on nosocomial Aspergillus infections: unique risk of bone marrow transplant recipients\n Sherertz, Robert J, Belani, Anusha, Kramer, Barnett S, Elfenbein, Gerald J, Weiner, Roy S, Sullivan, Marsha L, **Thomas, Ronald G**, & Samsa, Gregory P | The American journal of medicine | (1987) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nImpact of air filtration on nosocomial aspergillus infections\n Shcrertz, RJ, Belani, A, Kramer, BS, & others | Am J Med | (1987) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nIs there dependence between sites for continued success or restenosis after successful multisite coronary angioplasty\n Thomas, RG, Black, A, Lin, S, Chin, H, & Weintraub, WS | Circulation | (1987) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article\n\n\nPROGNOSIS AFTER MULTIPLE VESSEL ANGIOPLASTY (PTCA) IN PATIENTS WITH CORONARY-ARTERY DISEASE\n Roubin, GS, Sutor, C, Lembo, NJ, Hoffmeister, J, Thomas, RG, Douglas, JS, & King, SB | Circulation | (1987) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-38",
    "href": "research/index.html#section-38",
    "title": "Research",
    "section": "1986",
    "text": "1986\n\nAlzheimer's disease: a correlational analysis of the Blessed Information-Memory-Concentration test and the Mini-Mental State Exam\n Thal, Leon J, Grundman, Michael, & Golden, Robert | Neurology | (1986) \nSummary: Advancing understanding of neurodegenerative diseases through clinical research\nTopics: Biostatistics R Alzheimer's disease Cognitive decline Statistical methods"
  },
  {
    "objectID": "research/index.html#section-39",
    "href": "research/index.html#section-39",
    "title": "Research",
    "section": "1985",
    "text": "1985\n\nELUTION OF PROSTAGLANDIN-E2 FROM FILTER-PAPER STRIPS-EFFICIENCY AND REPRODUCIBILITY\n HUWS, DA, FAN, TP, & THOMAS, RU | JOURNAL OF DENTAL RESEARCH | (1985) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R"
  },
  {
    "objectID": "research/index.html#section-40",
    "href": "research/index.html#section-40",
    "title": "Research",
    "section": "1984",
    "text": "1984\n\nChanges in shoulder and leg strength in athletes wearing mandibular orthopedic repositioning appliances\n Schubert, Mark M, Guttu, Ronald L, Hunter, Letha H, Hall, Richard, & **Thomas, Ronald** | The Journal of the American Dental Association | (1984) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "research/index.html#section-41",
    "href": "research/index.html#section-41",
    "title": "Research",
    "section": "1983",
    "text": "1983\n\nEarly prediction of the adult respiratory distress syndrome by a simple scoring method\n Pepe, Paul E, **Thomas, Ronald G**, Stager, Marie Anne, Hudson, Leonard D, & Carrico, C James | Annals of emergency medicine | (1983) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Statistical methods\n\n\nEffects of concomitant development on reproduction of Meloidogyne incognita and Rotylenchulus reniformis on sweet potato\n **Thomas, Ronald J** & Clark, Christopher A | Journal of Nematology | (1983) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nPopulation dynamics of Meloidogyne incognita and Rotylenchulus reniformis alone and in combination, and their effects on sweet potato\n **Thomas, Ronald J** & Clark, Christopher A | Journal of Nematology | (1983) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R Epidemiology\nLinks: ðŸ“„ Article â€¢ ðŸ“‹ Open Access PDF\n\n\nTHE EFFECT OF MANDIBULAR ORTHOPEDIC REPOSITIONING APPLIANCES ON BODY STRENGTH\n Schubert, M, Guttu, R, Hunter, L, Hall, R, & Thomas, R | JOURNAL OF DENTAL RESEARCH | (1983) \nSummary: Contributing to evidence-based medicine and biostatistical research\nTopics: Biostatistics R\nLinks: ðŸ“„ Article"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html",
    "href": "BLOG_POST_TEMPLATE.html",
    "title": "Your Engaging Title Here",
    "section": "",
    "text": "R Programming - The foundation for data science and statistical computing\nPhoto caption with attribution if needed. For CC licensed images: Licensed under CC BY 2.0 via Source"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#subsection-1.1-more-specific-topic",
    "href": "BLOG_POST_TEMPLATE.html#subsection-1.1-more-specific-topic",
    "title": "Your Engaging Title Here",
    "section": "3.1 Subsection 1.1: [More Specific Topic]",
    "text": "3.1 Subsection 1.1: [More Specific Topic]\n\n[More detailed explanation or variation]\n\n\n\nOptional supporting visualization with descriptive caption"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#subsection-2.1-handling-edge-cases",
    "href": "BLOG_POST_TEMPLATE.html#subsection-2.1-handling-edge-cases",
    "title": "Your Engaging Title Here",
    "section": "4.1 Subsection 2.1: [Handling Edge Cases]",
    "text": "4.1 Subsection 2.1: [Handling Edge Cases]\n\n[Discussion of potential issues and solutions]\n\n# Replace with your actual error handling code\n# tryCatch({\n#   risky_operation(data)\n# }, error = function(e) {\n#   message(\"Error handled: \", e$message)\n# })"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#model-assumptions",
    "href": "BLOG_POST_TEMPLATE.html#model-assumptions",
    "title": "Your Engaging Title Here",
    "section": "8.1 Model Assumptions",
    "text": "8.1 Model Assumptions\n\n[Assumption 1]: [e.g., Linearity assumption - check with residual plots]\n[Assumption 2]: [e.g., Independence of observations]\n[Assumption 3]: [e.g., Homoscedasticity - constant variance]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#data-limitations",
    "href": "BLOG_POST_TEMPLATE.html#data-limitations",
    "title": "Your Engaging Title Here",
    "section": "8.2 Data Limitations",
    "text": "8.2 Data Limitations\n\nSample size: [Discussion of adequacy for conclusions]\nGeneralizability: [Population this applies to vs.Â broader populations]\nMissing data: [How missing values were handled and potential bias]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#method-limitations",
    "href": "BLOG_POST_TEMPLATE.html#method-limitations",
    "title": "Your Engaging Title Here",
    "section": "8.3 Method Limitations",
    "text": "8.3 Method Limitations\n\n[Limitation 1]: [Explanation and potential workarounds]\n[Limitation 2]: [When this approach may not be appropriate]\nPerformance considerations: [Computational requirements, scalability]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#academic-literature",
    "href": "BLOG_POST_TEMPLATE.html#academic-literature",
    "title": "Your Engaging Title Here",
    "section": "11.1 Academic Literature",
    "text": "11.1 Academic Literature\n\n\nPrimary Research Papers:\n\nWickham, H. (2014). â€œTidy Dataâ€. Journal of Statistical Software, 59(10), 1-23. https://doi.org/10.18637/jss.v059.i10\nBreiman, L. (2001). â€œRandom Forestsâ€. Machine Learning, 45(1), 5-32. https://doi.org/10.1023/A:1010933404324\n[Your domain-specific paper]. Author, A. (Year). â€œRelevant Paper Titleâ€. Journal Name, Volume(Issue), pages. DOI\n\nFoundational Books:\n\nWickham, H., & Grolemund, G. (2017). R for Data Science. Oâ€™Reilly Media. https://r4ds.had.co.nz/\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An Introduction to Statistical Learning with Applications in R (2nd ed.). Springer.\n[Your domain book]. Author, B. (Year). Book Title. Publisher.\n\nStatistical Methods:\n\nBox, G. E. P., Jenkins, G. M., Reinsel, G. C., & Ljung, G. M. (2015). Time Series Analysis: Forecasting and Control (5th ed.). Wiley.\nGelman, A., & Hill, J. (2006). Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge University Press."
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#blog-posts-and-tutorials",
    "href": "BLOG_POST_TEMPLATE.html#blog-posts-and-tutorials",
    "title": "Your Engaging Title Here",
    "section": "11.2 Blog Posts and Tutorials",
    "text": "11.2 Blog Posts and Tutorials\n\n\nTechnical Blog Posts:\n\nR-bloggers: â€œAdvanced ggplot2 Techniquesâ€ - Comprehensive visualization strategies\nSimply Statistics: â€œThe Role of Statistics in Data Scienceâ€ - Foundational concepts\nTowards Data Science: â€œMachine Learning Best Practicesâ€ - Practical implementation guidance\n\nPackage-Specific Tutorials:\n\nPackage creatorâ€™s blog: â€œIntroduction to [PackageName]â€ - Official guidance from package authors\nRStudio Blog: â€œNew Features in [Package]â€ - Updates and best practices\nStack Overflow: â€œCommon [Package] Issues and Solutionsâ€ - Community troubleshooting\n\nDomain-Specific Applications:\n\nIndustry blog: â€œReal-world Application of [Method]â€ - Practical case studies\nAcademic blog: â€œMethodological Considerations for [Technique]â€ - Research perspectives\nPractitioner blog: â€œLessons Learned from [Project]â€ - Implementation insights"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#technical-documentation",
    "href": "BLOG_POST_TEMPLATE.html#technical-documentation",
    "title": "Your Engaging Title Here",
    "section": "11.3 Technical Documentation",
    "text": "11.3 Technical Documentation\n\n\nPackage Documentation:\n\nPackage Reference Manual - Complete function documentation\nPackage Vignettes - Detailed usage examples\nGitHub Repository - Source code and development issues\n\nLanguage and Framework Guides:\n\nR Language Definition - Official R documentation\nQuarto Documentation - Publishing framework reference\nRMarkdown Cookbook - Advanced document preparation\n\nStandards and Best Practices:\n\nGoogleâ€™s R Style Guide - Code formatting standards\nrOpenSci Packages - Peer-reviewed R packages for research\nCRAN Task Views - Domain-specific package collections"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#community-resources",
    "href": "BLOG_POST_TEMPLATE.html#community-resources",
    "title": "Your Engaging Title Here",
    "section": "11.4 Community Resources",
    "text": "11.4 Community Resources\n\n\nQ&A and Discussion:\n\nCross Validated - Statistical methodology discussions\nStack Overflow R Tag - Programming troubleshooting\nRStudio Community - User support and discussions\n\nSocial Learning:\n\n#rstats Twitter - Community updates and tips\nR Weekly Newsletter - Curated R news and resources\nR-Ladies Global - Inclusive R community and events\n\nProfessional Networks:\n\nLinkedIn R Groups - Professional networking and job opportunities\nMeetup R Groups - Local community events\nUseR! Conference - Annual R user conference"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#data-sources-and-repositories",
    "href": "BLOG_POST_TEMPLATE.html#data-sources-and-repositories",
    "title": "Your Engaging Title Here",
    "section": "11.5 Data Sources and Repositories",
    "text": "11.5 Data Sources and Repositories\n\n\nPublic Datasets:\n\nUCI Machine Learning Repository - Benchmark datasets\nKaggle Datasets - Community-contributed data\n[government data portal] - Domain-specific public data\n\nR Built-in Data:\n\ndatasets package - Standard R datasets for examples\n[Your specific dataset source] - Domain-relevant data repositories"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#related-work-and-extensions",
    "href": "BLOG_POST_TEMPLATE.html#related-work-and-extensions",
    "title": "Your Engaging Title Here",
    "section": "11.6 Related Work and Extensions",
    "text": "11.6 Related Work and Extensions\n\n\nMethodological Extensions:\n\nAuthor, C. (Year). â€œExtension of [Your Method]â€. Journal, Volume(Issue), pages.\nAuthor, D. (Year). â€œComparative Analysis of [Related Methods]â€. Conference Proceedings.\n\nApplications in Other Domains:\n\nAuthor, E. (Year). â€œApplication to [Different Field]â€. Domain Journal, Volume(Issue), pages.\nAuthor, F. (Year). â€œCross-disciplinary Perspectives on [Topic]â€. Interdisciplinary Journal.\n\n\n\nCitation Note: When using ideas or code from these resources, please cite appropriately. For academic work, use standard citation formats. For blog posts and online resources, include the author, title, publication date, and URL."
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#data-availability",
    "href": "BLOG_POST_TEMPLATE.html#data-availability",
    "title": "Your Engaging Title Here",
    "section": "12.1 Data Availability",
    "text": "12.1 Data Availability\n\nDataset: [Name and source of dataset used]\nAccess: [How others can access the data - URL, package, etc.]\nLicense: [Data usage license and restrictions]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#code-repository",
    "href": "BLOG_POST_TEMPLATE.html#code-repository",
    "title": "Your Engaging Title Here",
    "section": "12.2 Code Repository",
    "text": "12.2 Code Repository\n\nGitHub: [Link to repository with complete analysis code]\nCommit: [Specific commit hash for reproducibility]\nEnvironment: [Docker image, renv lockfile, or environment specs]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#session-information",
    "href": "BLOG_POST_TEMPLATE.html#session-information",
    "title": "Your Engaging Title Here",
    "section": "12.3 Session Information",
    "text": "12.3 Session Information\n\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.0    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.0       htmltools_0.5.8.1 yaml_2.3.10       rmarkdown_2.29   \n [9] knitr_1.50        jsonlite_2.0.0    xfun_0.52         digest_0.6.37    \n[13] rlang_1.1.6       evaluate_1.0.3"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-a-complete-code",
    "href": "BLOG_POST_TEMPLATE.html#appendix-a-complete-code",
    "title": "Your Engaging Title Here",
    "section": "13.1 Appendix A: Complete Code",
    "text": "13.1 Appendix A: Complete Code\n\n\n# Complete code for easy reproduction - replace with your actual code\n# library(your_packages)\n# data &lt;- load_your_data()\n# results &lt;- your_analysis(data)\n# plot(results)"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-b-mathematical-details",
    "href": "BLOG_POST_TEMPLATE.html#appendix-b-mathematical-details",
    "title": "Your Engaging Title Here",
    "section": "13.2 Appendix B: Mathematical Details",
    "text": "13.2 Appendix B: Mathematical Details\n\nFor statistical posts, include relevant formulas using LaTeX notation:\nLinear Regression Model: y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + ... + \\beta_p x_{ip} + \\epsilon_i\nModel Evaluation Metrics: - RMSE: RMSE = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2} - R-squared: R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n[Additional mathematical explanations or derivations as needed]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-c-additional-data",
    "href": "BLOG_POST_TEMPLATE.html#appendix-c-additional-data",
    "title": "Your Engaging Title Here",
    "section": "13.3 Appendix C: Additional Data",
    "text": "13.3 Appendix C: Additional Data\n\n[Additional tables, charts, or data summaries]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#share-this-post",
    "href": "BLOG_POST_TEMPLATE.html#share-this-post",
    "title": "Your Engaging Title Here",
    "section": "13.4 Share This Post",
    "text": "13.4 Share This Post\nFound this helpful? Share it with your network:\n\nTwitter\nLinkedIn\nReddit"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#connect-and-discuss",
    "href": "BLOG_POST_TEMPLATE.html#connect-and-discuss",
    "title": "Your Engaging Title Here",
    "section": "13.5 Connect and Discuss",
    "text": "13.5 Connect and Discuss\nHave questions or suggestions? Iâ€™d love to hear from you:\n\nTwitter: @rgt47 - Quick questions and discussions\nLinkedIn: Ronald Glenn Thomas - Professional networking\nGitHub: rgt47 - Code, issues, and contributions\nEmail: Contact through website - Detailed inquiries\n\nComments are enabled below via Utterances - join the discussion!"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#about-the-author",
    "href": "BLOG_POST_TEMPLATE.html#about-the-author",
    "title": "Your Engaging Title Here",
    "section": "13.6 About the Author",
    "text": "13.6 About the Author\nRonald (Ryy) Glenn Thomas is a biostatistician and data scientist at UC San Diego, specializing in statistical computing, machine learning applications in healthcare, and reproducible research methods. He develops R packages and conducts research at the intersection of statistics, data science, and clinical research.\nConnect: Website | ORCID | Google Scholar"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html",
    "href": "posts/palmer_penguins_part3/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "",
    "text": "A tech-savvy penguin with a laptop, diving deep into advanced modeling techniques and cross-validation!\nPhoto: African penguins at Boulders Beach, South Africa. Licensed under CC BY 2.0 via Wikimedia Commons"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#setting-up-cross-validation",
    "href": "posts/palmer_penguins_part3/index.html#setting-up-cross-validation",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "3.1 Setting Up Cross-Validation",
    "text": "3.1 Setting Up Cross-Validation\n\nset.seed(42)  # For reproducible results\n\n# Set up 10-fold cross-validation\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\",\n  verboseIter = FALSE\n)\n\ncat(\"ðŸ”„ Cross-Validation Setup:\\n\")\n\nðŸ”„ Cross-Validation Setup:\n\ncat(\"==========================\\n\")\n\n==========================\n\ncat(\"Method: 10-fold cross-validation\\n\")\n\nMethod: 10-fold cross-validation\n\ncat(\"Folds: 10\\n\")\n\nFolds: 10\n\ncat(\"Seed: 42 (for reproducibility)\\n\")\n\nSeed: 42 (for reproducibility)\n\ncat(\"Predictions saved: Yes\\n\")\n\nPredictions saved: Yes"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#cross-validating-our-existing-models",
    "href": "posts/palmer_penguins_part3/index.html#cross-validating-our-existing-models",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "3.2 Cross-Validating Our Existing Models",
    "text": "3.2 Cross-Validating Our Existing Models\n\n# Cross-validate simple model\ncv_simple &lt;- train(\n  body_mass_g ~ flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Cross-validate multiple regression model\ncv_multiple &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\", \n  trControl = train_control\n)\n\n# Cross-validate species model\ncv_species &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Display cross-validation results\ncat(\"\\nðŸ“Š Cross-Validation Results:\\n\")\n\n\nðŸ“Š Cross-Validation Results:\n\ncat(\"=============================\\n\")\n\n=============================\n\ncat(sprintf(\"Simple model - RMSE: %.1f (Â±%.1f), RÂ²: %.3f (Â±%.3f)\\n\",\n            cv_simple$results$RMSE, sd(cv_simple$resample$RMSE),\n            cv_simple$results$Rsquared, sd(cv_simple$resample$Rsquared)))\n\nSimple model - RMSE: 390.9 (Â±54.0), RÂ²: 0.775 (Â±0.038)\n\ncat(sprintf(\"Multiple model - RMSE: %.1f (Â±%.1f), RÂ²: %.3f (Â±%.3f)\\n\",\n            cv_multiple$results$RMSE, sd(cv_multiple$resample$RMSE),\n            cv_multiple$results$Rsquared, sd(cv_multiple$resample$Rsquared)))\n\nMultiple model - RMSE: 392.6 (Â±41.7), RÂ²: 0.769 (Â±0.049)\n\ncat(sprintf(\"Species model - RMSE: %.1f (Â±%.1f), RÂ²: %.3f (Â±%.3f)\\n\",\n            cv_species$results$RMSE, sd(cv_species$resample$RMSE),\n            cv_species$results$Rsquared, sd(cv_species$resample$Rsquared)))\n\nSpecies model - RMSE: 315.7 (Â±32.2), RÂ²: 0.856 (Â±0.022)"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#visualizing-cross-validation-results",
    "href": "posts/palmer_penguins_part3/index.html#visualizing-cross-validation-results",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "3.3 Visualizing Cross-Validation Results",
    "text": "3.3 Visualizing Cross-Validation Results\n\n# Create comprehensive CV results dataframe\ncv_results &lt;- data.frame(\n  Model = rep(c(\"Simple\", \"Multiple\", \"Species\"), each = 10),\n  RMSE = c(cv_simple$resample$RMSE, cv_multiple$resample$RMSE, cv_species$resample$RMSE),\n  Rsquared = c(cv_simple$resample$Rsquared, cv_multiple$resample$Rsquared, cv_species$resample$Rsquared)\n)\n\n# Box plots of CV performance\np1 &lt;- ggplot(cv_results, aes(x = Model, y = RMSE, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(title = \"Cross-Validation RMSE Distribution\",\n       subtitle = \"Lower values indicate better performance\",\n       y = \"RMSE (grams)\") +\n  theme(legend.position = \"none\")\n\np2 &lt;- ggplot(cv_results, aes(x = Model, y = Rsquared, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(title = \"Cross-Validation RÂ² Distribution\", \n       subtitle = \"Higher values indicate better performance\",\n       y = \"R-squared\") +\n  theme(legend.position = \"none\")\n\ncv_performance_plot &lt;- p1 + p2\nprint(cv_performance_plot)\n\n\n\n\n\n\n\n\n\n\n\nBox plots showing the distribution of cross-validation performance metrics across folds"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#adding-quadratic-terms",
    "href": "posts/palmer_penguins_part3/index.html#adding-quadratic-terms",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "4.1 Adding Quadratic Terms",
    "text": "4.1 Adding Quadratic Terms\n\n# Create polynomial model with quadratic terms\npoly_model &lt;- lm(body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, 2) + \n                 poly(bill_depth_mm, 2) + species, data = penguins_clean)\n\nsummary(poly_model)\n\n\nCall:\nlm(formula = body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, \n    2) + poly(bill_depth_mm, 2) + species, data = penguins_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-837.68 -209.78  -25.97  187.14 1012.84 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  3935.52      69.77  56.404  &lt; 2e-16 ***\npoly(flipper_length_mm, 2)1  5321.73     859.97   6.188 1.84e-09 ***\npoly(flipper_length_mm, 2)2   391.41     407.10   0.961   0.3370    \npoly(bill_length_mm, 2)1     3753.51     726.72   5.165 4.21e-07 ***\npoly(bill_length_mm, 2)2     -856.40     345.09  -2.482   0.0136 *  \npoly(bill_depth_mm, 2)1      5764.01     769.85   7.487 6.72e-13 ***\npoly(bill_depth_mm, 2)2      -842.97     404.23  -2.085   0.0378 *  \nspeciesChinstrap             -470.97      84.01  -5.606 4.43e-08 ***\nspeciesGentoo                1028.96     161.74   6.362 6.79e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 310.1 on 324 degrees of freedom\nMultiple R-squared:  0.8552,    Adjusted R-squared:  0.8516 \nF-statistic: 239.2 on 8 and 324 DF,  p-value: &lt; 2.2e-16\n\n# Cross-validate polynomial model\ncv_poly &lt;- train(\n  body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, 2) + \n                poly(bill_depth_mm, 2) + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\ncat(\"ðŸ”„ Polynomial Model Cross-Validation:\\n\")\n\nðŸ”„ Polynomial Model Cross-Validation:\n\ncat(\"=====================================\\n\")\n\n=====================================\n\ncat(sprintf(\"Polynomial model - RMSE: %.1f (Â±%.1f), RÂ²: %.3f (Â±%.3f)\\n\",\n            cv_poly$results$RMSE, sd(cv_poly$resample$RMSE),\n            cv_poly$results$Rsquared, sd(cv_poly$resample$Rsquared)))\n\nPolynomial model - RMSE: 310.8 (Â±44.4), RÂ²: 0.855 (Â±0.046)"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#visualizing-non-linear-relationships",
    "href": "posts/palmer_penguins_part3/index.html#visualizing-non-linear-relationships",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "4.2 Visualizing Non-linear Relationships",
    "text": "4.2 Visualizing Non-linear Relationships\n\n# Create predictions for visualization\nflipper_range &lt;- seq(min(penguins_clean$flipper_length_mm), \n                     max(penguins_clean$flipper_length_mm), length.out = 100)\n\n# Compare linear vs polynomial relationships for each species\nprediction_data &lt;- expand_grid(\n  flipper_length_mm = flipper_range,\n  species = unique(penguins_clean$species)\n) %&gt;%\n  mutate(\n    bill_length_mm = mean(penguins_clean$bill_length_mm),\n    bill_depth_mm = mean(penguins_clean$bill_depth_mm),\n    body_mass_g = 0  # placeholder\n  )\n\n# Get predictions from both models\nprediction_data$linear_pred &lt;- predict(species_model, newdata = prediction_data)\nprediction_data$poly_pred &lt;- predict(poly_model, newdata = prediction_data)\n\n# Visualization\nggplot(penguins_clean, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.6, size = 2) +\n  geom_line(data = prediction_data, aes(y = linear_pred, linetype = \"Linear\"), \n            size = 1, alpha = 0.8) +\n  geom_line(data = prediction_data, aes(y = poly_pred, linetype = \"Polynomial\"), \n            size = 1, alpha = 0.8) +\n  scale_color_manual(values = penguin_colors) +\n  scale_linetype_manual(values = c(\"Linear\" = \"dashed\", \"Polynomial\" = \"solid\")) +\n  labs(title = \"Linear vs Polynomial Relationships\",\n       subtitle = \"Comparing model fits for flipper length (other variables held at mean)\",\n       x = \"Flipper Length (mm)\", y = \"Body Mass (g)\",\n       color = \"Species\", linetype = \"Model\") +\n  facet_wrap(~species) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nComparison of linear versus polynomial model fits across species"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#basic-random-forest",
    "href": "posts/palmer_penguins_part3/index.html#basic-random-forest",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "5.1 Basic Random Forest",
    "text": "5.1 Basic Random Forest\n\nset.seed(123)\n\n# Train random forest using caret for consistency\ncv_rf &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex + island,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  ntree = 500,\n  importance = TRUE\n)\n\nprint(cv_rf)\n\nRandom Forest \n\n333 samples\n  6 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 299, 300, 300, 300, 299, 300, ... \nResampling results across tuning parameters:\n\n  mtry  RMSE      Rsquared   MAE     \n  2     296.1693  0.8709290  235.7196\n  5     300.8044  0.8666035  239.2056\n  8     304.0154  0.8638966  242.7076\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 2.\n\ncat(\"\\nðŸŒ² Random Forest Cross-Validation:\\n\")\n\n\nðŸŒ² Random Forest Cross-Validation:\n\ncat(\"===================================\\n\")\n\n===================================\n\ncat(sprintf(\"Random Forest - RMSE: %.1f (Â±%.1f), RÂ²: %.3f (Â±%.3f)\\n\",\n            min(cv_rf$results$RMSE), sd(cv_rf$resample$RMSE),\n            max(cv_rf$results$Rsquared), sd(cv_rf$resample$Rsquared)))\n\nRandom Forest - RMSE: 296.2 (Â±40.5), RÂ²: 0.871 (Â±0.032)"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#variable-importance",
    "href": "posts/palmer_penguins_part3/index.html#variable-importance",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "5.2 Variable Importance",
    "text": "5.2 Variable Importance\n\n# Extract variable importance\nrf_importance &lt;- varImp(cv_rf)\nprint(rf_importance)\n\nrf variable importance\n\n                  Overall\nsexmale            100.00\nspeciesGentoo       68.83\nbill_depth_mm       68.63\nflipper_length_mm   61.96\nbill_length_mm      45.02\nislandDream         27.56\nspeciesChinstrap    17.01\nislandTorgersen      0.00\n\n# Visualize importance\nimportance_plot &lt;- ggplot(rf_importance) +\n  labs(title = \"Random Forest Variable Importance\",\n       subtitle = \"Relative contribution to prediction accuracy\") +\n  theme_minimal()\n\nprint(importance_plot)\n\n\n\n\n\n\n\n\n\n\n\nVariable importance plot showing which features contribute most to random forest predictions"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#performance-summary-table",
    "href": "posts/palmer_penguins_part3/index.html#performance-summary-table",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "6.1 Performance Summary Table",
    "text": "6.1 Performance Summary Table\n\n# Compile all cross-validation results\nall_models &lt;- list(\n  \"Simple\" = cv_simple,\n  \"Multiple\" = cv_multiple, \n  \"Species\" = cv_species,\n  \"Polynomial\" = cv_poly,\n  \"Random Forest\" = cv_rf\n)\n\n# Extract performance metrics\nmodel_performance &lt;- map_dfr(all_models, function(model) {\n  data.frame(\n    RMSE_mean = min(model$results$RMSE),\n    RMSE_sd = sd(model$resample$RMSE),\n    Rsquared_mean = max(model$results$Rsquared),\n    Rsquared_sd = sd(model$resample$Rsquared),\n    MAE_mean = min(model$results$MAE)\n  )\n}, .id = \"Model\") %&gt;%\n  arrange(RMSE_mean)\n\n# Format for display\nmodel_performance_display &lt;- model_performance %&gt;%\n  mutate(\n    RMSE = sprintf(\"%.1f Â± %.1f\", RMSE_mean, RMSE_sd),\n    R_squared = sprintf(\"%.3f Â± %.3f\", Rsquared_mean, Rsquared_sd),\n    MAE = sprintf(\"%.1f\", MAE_mean)\n  ) %&gt;%\n  select(Model, RMSE, R_squared, MAE)\n\nkable(model_performance_display,\n      caption = \"Cross-Validation Performance Comparison (Mean Â± Standard Deviation)\",\n      col.names = c(\"Model\", \"RMSE (g)\", \"RÂ²\", \"MAE (g)\"))\n\n\nCross-Validation Performance Comparison (Mean Â± Standard Deviation)\n\n\nModel\nRMSE (g)\nRÂ²\nMAE (g)\n\n\n\n\nRandom Forest\n296.2 Â± 40.5\n0.871 Â± 0.032\n235.7\n\n\nPolynomial\n310.8 Â± 44.4\n0.855 Â± 0.046\n249.8\n\n\nSpecies\n315.7 Â± 32.2\n0.856 Â± 0.022\n251.6\n\n\nSimple\n390.9 Â± 54.0\n0.775 Â± 0.038\n314.1\n\n\nMultiple\n392.6 Â± 41.7\n0.769 Â± 0.049\n312.9"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#statistical-significance-testing",
    "href": "posts/palmer_penguins_part3/index.html#statistical-significance-testing",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "6.2 Statistical Significance Testing",
    "text": "6.2 Statistical Significance Testing\n\n# Perform pairwise comparisons using resamples\nmodel_resamples &lt;- resamples(all_models)\nsummary(model_resamples)\n\n\nCall:\nsummary.resamples(object = model_resamples)\n\nModels: Simple, Multiple, Species, Polynomial, Random Forest \nNumber of resamples: 10 \n\nMAE \n                  Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nSimple        241.3554 284.0399 320.8430 314.0739 338.4259 371.1883    0\nMultiple      260.4224 299.3261 312.0693 312.9230 324.2053 361.2878    0\nSpecies       221.3089 229.2132 249.0898 251.5796 266.4538 291.5125    0\nPolynomial    202.4456 230.6144 239.4014 249.8384 260.2454 339.3528    0\nRandom Forest 160.8733 216.7519 228.7049 235.7196 262.9530 294.3425    0\n\nRMSE \n                  Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nSimple        308.6200 349.3536 401.5457 390.8672 426.1235 458.9253    0\nMultiple      313.5602 370.9372 386.3221 392.6475 414.3106 459.0243    0\nSpecies       272.3076 291.1982 314.1444 315.7035 345.0607 357.2340    0\nPolynomial    240.1316 291.2401 311.3770 310.8124 332.1709 397.4275    0\nRandom Forest 219.6603 272.3759 290.9904 296.1693 332.7067 345.1353    0\n\nRsquared \n                   Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nSimple        0.7338776 0.7504191 0.7629768 0.7753345 0.7986835 0.8402682    0\nMultiple      0.6868671 0.7275708 0.7928215 0.7690730 0.7998317 0.8242159    0\nSpecies       0.8296272 0.8381939 0.8522291 0.8558827 0.8744437 0.8906614    0\nPolynomial    0.7579544 0.8363657 0.8517021 0.8548061 0.8848488 0.9257512    0\nRandom Forest 0.8231393 0.8479029 0.8780378 0.8709290 0.8823033 0.9407561    0\n\n# Statistical comparison\nmodel_differences &lt;- diff(model_resamples)\nsummary(model_differences)\n\n\nCall:\nsummary.diff.resamples(object = model_differences)\n\np-value adjustment: bonferroni \nUpper diagonal: estimates of the difference\nLower diagonal: p-value for H0: difference = 0\n\nMAE \n              Simple   Multiple Species  Polynomial Random Forest\nSimple                  1.151   62.494   64.235     78.354       \nMultiple      1.000000          61.343   63.085     77.203       \nSpecies       0.073024 0.002911           1.741     15.860       \nPolynomial    0.052589 0.003403 1.000000            14.119       \nRandom Forest 0.031252 0.002025 1.000000 1.000000                \n\nRMSE \n              Simple   Multiple Species  Polynomial Random Forest\nSimple                 -1.780   75.164   80.055     94.698       \nMultiple      1.000000          76.944   81.835     96.478       \nSpecies       0.089778 0.013250           4.891     19.534       \nPolynomial    0.050086 0.001917 1.000000            14.643       \nRandom Forest 0.013082 0.000986 1.000000 1.000000                \n\nRsquared \n              Simple   Multiple  Species   Polynomial Random Forest\nSimple                  0.006262 -0.080548 -0.079472  -0.095594    \nMultiple      1.000000           -0.086810 -0.085733  -0.101856    \nSpecies       0.008511 0.006787             0.001077  -0.015046    \nPolynomial    0.061015 0.004296  1.000000             -0.016123    \nRandom Forest 0.001177 0.002549  1.000000  1.000000"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#performance-visualization",
    "href": "posts/palmer_penguins_part3/index.html#performance-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "6.3 Performance Visualization",
    "text": "6.3 Performance Visualization\n\n# Create comprehensive comparison plot\nall_cv_results &lt;- data.frame(\n  Model = factor(rep(names(all_models), each = 10), levels = names(all_models)),\n  RMSE = c(cv_simple$resample$RMSE, cv_multiple$resample$RMSE, \n           cv_species$resample$RMSE, cv_poly$resample$RMSE, cv_rf$resample$RMSE),\n  Rsquared = c(cv_simple$resample$Rsquared, cv_multiple$resample$Rsquared,\n               cv_species$resample$Rsquared, cv_poly$resample$Rsquared, cv_rf$resample$Rsquared)\n)\n\n# RMSE comparison\np3 &lt;- ggplot(all_cv_results, aes(x = Model, y = RMSE, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  labs(title = \"Cross-Validation RMSE Comparison\",\n       subtitle = \"Lower is better; white diamonds show means\",\n       y = \"RMSE (grams)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\")\n\n# RÂ² comparison  \np4 &lt;- ggplot(all_cv_results, aes(x = Model, y = Rsquared, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  labs(title = \"Cross-Validation RÂ² Comparison\",\n       subtitle = \"Higher is better; white diamonds show means\", \n       y = \"R-squared\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\")\n\ncomprehensive_comparison &lt;- p3 + p4\nprint(comprehensive_comparison)\n\n\n\n\n\n\n\n\n\n\n\nComprehensive comparison of all models showing both RMSE and RÂ² distributions from cross-validation"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#learning-curves",
    "href": "posts/palmer_penguins_part3/index.html#learning-curves",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "7.1 Learning Curves",
    "text": "7.1 Learning Curves\n\n# Function to calculate learning curves\ncalculate_learning_curve &lt;- function(model_formula, data, train_sizes = seq(0.1, 1, 0.1)) {\n  results &lt;- map_dfr(train_sizes, function(size) {\n    n_train &lt;- round(nrow(data) * size)\n    \n    # Perform multiple bootstrap samples\n    bootstrap_results &lt;- map_dfr(1:20, function(i) {\n      set.seed(i)\n      train_idx &lt;- sample(nrow(data), n_train)\n      train_data &lt;- data[train_idx, ]\n      test_data &lt;- data[-train_idx, ]\n      \n      # Fit model\n      model &lt;- lm(model_formula, data = train_data)\n      \n      # Calculate errors\n      train_pred &lt;- predict(model, train_data)\n      test_pred &lt;- predict(model, test_data)\n      \n      data.frame(\n        train_size = size,\n        train_rmse = sqrt(mean((train_data$body_mass_g - train_pred)^2)),\n        test_rmse = if(nrow(test_data) &gt; 0) sqrt(mean((test_data$body_mass_g - test_pred)^2)) else NA,\n        bootstrap = i\n      )\n    })\n    \n    bootstrap_results\n  })\n  \n  results\n}\n\n# Calculate learning curves for key models\nlearning_simple &lt;- calculate_learning_curve(\n  body_mass_g ~ flipper_length_mm, penguins_clean)\nlearning_species &lt;- calculate_learning_curve(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species, penguins_clean)\n\n# Combine and plot\nlearning_curves &lt;- bind_rows(\n  learning_simple %&gt;% mutate(Model = \"Simple\"),\n  learning_species %&gt;% mutate(Model = \"Species\")\n) %&gt;%\n  pivot_longer(cols = c(train_rmse, test_rmse), names_to = \"Set\", values_to = \"RMSE\") %&gt;%\n  mutate(Set = str_remove(Set, \"_rmse\"))\n\nlearning_summary &lt;- learning_curves %&gt;%\n  group_by(Model, train_size, Set) %&gt;%\n  summarise(\n    RMSE_mean = mean(RMSE, na.rm = TRUE),\n    RMSE_se = sd(RMSE, na.rm = TRUE) / sqrt(n()),\n    .groups = \"drop\"\n  )\n\nggplot(learning_summary, aes(x = train_size * nrow(penguins_clean), y = RMSE_mean, \n                            color = interaction(Model, Set), linetype = Set)) +\n  geom_line(size = 1) +\n  geom_ribbon(aes(ymin = RMSE_mean - RMSE_se, ymax = RMSE_mean + RMSE_se, \n                  fill = interaction(Model, Set)), alpha = 0.2) +\n  labs(title = \"Learning Curves: Bias-Variance Tradeoff\",\n       subtitle = \"Training vs validation error as sample size increases\",\n       x = \"Training Set Size\", y = \"RMSE (grams)\",\n       color = \"Model.Set\", fill = \"Model.Set\") +\n  theme_minimal() +\n  facet_wrap(~Model)\n\n\n\n\n\n\n\n\n\n\n\nLearning curves showing how training and validation error change with sample size"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#performance-hierarchy",
    "href": "posts/palmer_penguins_part3/index.html#performance-hierarchy",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "8.1 Performance Hierarchy",
    "text": "8.1 Performance Hierarchy\nBased on our rigorous cross-validation, hereâ€™s what weâ€™ve learned:\n\n# Extract best performing model\nbest_model_idx &lt;- which.min(model_performance$RMSE_mean)\nbest_model &lt;- model_performance$Model[best_model_idx]\nbest_rmse &lt;- model_performance$RMSE_mean[best_model_idx]\nbest_r2 &lt;- model_performance$Rsquared_mean[best_model_idx]\n\ncat(\"ðŸ† Model Performance Insights:\\n\")\n\nðŸ† Model Performance Insights:\n\ncat(\"==============================\\n\")\n\n==============================\n\ncat(sprintf(\"Best performing model: %s\\n\", best_model))\n\nBest performing model: Random Forest\n\ncat(sprintf(\"Cross-validated RMSE: %.1f Â± %.1f grams\\n\", \n            best_rmse, model_performance$RMSE_sd[best_model_idx]))\n\nCross-validated RMSE: 296.2 Â± 40.5 grams\n\ncat(sprintf(\"Cross-validated RÂ²: %.3f Â± %.3f\\n\", \n            best_r2, model_performance$Rsquared_sd[best_model_idx]))\n\nCross-validated RÂ²: 0.871 Â± 0.032\n\ncat(\"\\nðŸ“Š Key Findings:\\n\")\n\n\nðŸ“Š Key Findings:\n\ncat(\"â€¢ Linear models with species information perform excellently\\n\")\n\nâ€¢ Linear models with species information perform excellently\n\ncat(\"â€¢ Polynomial features provide minimal improvement over linear relationships\\n\")\n\nâ€¢ Polynomial features provide minimal improvement over linear relationships\n\ncat(\"â€¢ Random forests offer competitive but not superior performance\\n\")\n\nâ€¢ Random forests offer competitive but not superior performance\n\ncat(\"â€¢ Cross-validation confirms our models generalize well to new data\\n\")\n\nâ€¢ Cross-validation confirms our models generalize well to new data\n\ncat(\"â€¢ The bias-variance tradeoff favors simpler models in this dataset\\n\")\n\nâ€¢ The bias-variance tradeoff favors simpler models in this dataset"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#model-selection-recommendations",
    "href": "posts/palmer_penguins_part3/index.html#model-selection-recommendations",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "8.2 Model Selection Recommendations",
    "text": "8.2 Model Selection Recommendations\n\ncat(\"\\nðŸ’¡ Model Selection Guidance:\\n\")\n\n\nðŸ’¡ Model Selection Guidance:\n\ncat(\"============================\\n\")\n\n============================\n\n# Calculate confidence intervals for performance differences\nspecies_vs_poly_diff &lt;- mean(cv_species$resample$RMSE - cv_poly$resample$RMSE)\nspecies_vs_rf_diff &lt;- mean(cv_species$resample$RMSE - cv_rf$resample$RMSE)\n\ncat(sprintf(\"Species model vs Polynomial: %.1f grams RMSE difference\\n\", species_vs_poly_diff))\n\nSpecies model vs Polynomial: 4.9 grams RMSE difference\n\ncat(sprintf(\"Species model vs Random Forest: %.1f grams RMSE difference\\n\", species_vs_rf_diff))\n\nSpecies model vs Random Forest: 19.5 grams RMSE difference\n\ncat(\"\\nðŸŽ¯ Recommendation: The linear species model offers the best balance of:\\n\")\n\n\nðŸŽ¯ Recommendation: The linear species model offers the best balance of:\n\ncat(\"   â€¢ Excellent predictive performance\\n\")\n\n   â€¢ Excellent predictive performance\n\ncat(\"   â€¢ Model interpretability\\n\") \n\n   â€¢ Model interpretability\n\ncat(\"   â€¢ Computational efficiency\\n\")\n\n   â€¢ Computational efficiency\n\ncat(\"   â€¢ Biological meaningfulness\\n\")\n\n   â€¢ Biological meaningfulness"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html",
    "href": "posts/palmer_penguins_part2/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "",
    "text": "Two penguins collaborating on their regression analysis - because multiple predictors work better together!\nPhoto: African penguins at Boulders Beach, South Africa. Licensed under CC BY 2.0 via Wikimedia Commons"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#adding-all-morphometric-predictors",
    "href": "posts/palmer_penguins_part2/index.html#adding-all-morphometric-predictors",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "3.1 Adding All Morphometric Predictors",
    "text": "3.1 Adding All Morphometric Predictors\nOur first step beyond simple regression is to include all available morphometric measurements:\n\n# Build multiple regression model with all morphometric variables\nmultiple_model &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, \n                     data = penguins_clean)\n\n# Display model summary\nsummary(multiple_model)\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, \n    data = penguins_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1051.37  -284.50   -20.37   241.03  1283.51 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -6445.476    566.130 -11.385   &lt;2e-16 ***\nbill_length_mm        3.293      5.366   0.614    0.540    \nbill_depth_mm        17.836     13.826   1.290    0.198    \nflipper_length_mm    50.762      2.497  20.327   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 393 on 329 degrees of freedom\nMultiple R-squared:  0.7639,    Adjusted R-squared:  0.7618 \nF-statistic: 354.9 on 3 and 329 DF,  p-value: &lt; 2.2e-16\n\n# Extract key metrics\nmultiple_metrics &lt;- glance(multiple_model)\nmultiple_coef &lt;- tidy(multiple_model)\n\ncat(\"\\nðŸ“Š Multiple Regression Results:\\n\")\n\n\nðŸ“Š Multiple Regression Results:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            multiple_metrics$r.squared, multiple_metrics$r.squared * 100))\n\nR-squared: 0.764 (76.4% of variance explained)\n\ncat(sprintf(\"Adjusted R-squared: %.3f\\n\", multiple_metrics$adj.r.squared))\n\nAdjusted R-squared: 0.762\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sqrt(mean(multiple_model$residuals^2))))\n\nRMSE: 390.6 grams\n\ncat(sprintf(\"F-statistic: %.1f (p &lt; 0.001)\\n\", multiple_metrics$statistic))\n\nF-statistic: 354.9 (p &lt; 0.001)"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#understanding-multicollinearity",
    "href": "posts/palmer_penguins_part2/index.html#understanding-multicollinearity",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "3.2 Understanding Multicollinearity",
    "text": "3.2 Understanding Multicollinearity\nWhen using multiple predictors, we need to check for multicollinearity - the degree to which predictors are correlated with each other:\n\n# Calculate Variance Inflation Factors (VIF)\nvif_values &lt;- vif(multiple_model)\n\ncat(\"\\nðŸ” Variance Inflation Factors:\\n\")\n\n\nðŸ” Variance Inflation Factors:\n\ncat(\"==============================\\n\")\n\n==============================\n\nfor(i in 1:length(vif_values)) {\n  predictor &lt;- names(vif_values)[i]\n  vif_val &lt;- vif_values[i]\n  interpretation &lt;- ifelse(vif_val &lt; 5, \"âœ… Low\", \n                          ifelse(vif_val &lt; 10, \"âš ï¸ Moderate\", \"âŒ High\"))\n  cat(sprintf(\"%-20s: %.2f (%s)\\n\", predictor, vif_val, interpretation))\n}\n\nbill_length_mm      : 1.85 (âœ… Low)\nbill_depth_mm       : 1.59 (âœ… Low)\nflipper_length_mm   : 2.63 (âœ… Low)\n\ncat(\"\\nðŸ“ VIF Interpretation Guide:\\n\")\n\n\nðŸ“ VIF Interpretation Guide:\n\ncat(\"   â€¢ VIF &lt; 5: Low multicollinearity\\n\")\n\n   â€¢ VIF &lt; 5: Low multicollinearity\n\ncat(\"   â€¢ VIF 5-10: Moderate multicollinearity\\n\")\n\n   â€¢ VIF 5-10: Moderate multicollinearity\n\ncat(\"   â€¢ VIF &gt; 10: High multicollinearity (problematic)\\n\")\n\n   â€¢ VIF &gt; 10: High multicollinearity (problematic)"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#coefficient-interpretation",
    "href": "posts/palmer_penguins_part2/index.html#coefficient-interpretation",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "3.3 Coefficient Interpretation",
    "text": "3.3 Coefficient Interpretation\nLetâ€™s interpret what each predictor tells us:\n\n# Format coefficient table\ncoef_table &lt;- multiple_coef %&gt;%\n  mutate(\n    estimate = round(estimate, 2),\n    std.error = round(std.error, 2),\n    statistic = round(statistic, 2),\n    p.value = ifelse(p.value &lt; 0.001, \"&lt;0.001\", round(p.value, 3)),\n    significance = case_when(\n      p.value == \"&lt;0.001\" ~ \"***\",\n      as.numeric(p.value) &lt; 0.01 ~ \"**\",\n      as.numeric(p.value) &lt; 0.05 ~ \"*\",\n      TRUE ~ \"\"\n    )\n  )\n\nkable(coef_table, \n      caption = \"Multiple Regression Coefficients\",\n      col.names = c(\"Term\", \"Estimate\", \"Std Error\", \"t-statistic\", \"p-value\", \"Sig\"))\n\n\nMultiple Regression Coefficients\n\n\nTerm\nEstimate\nStd Error\nt-statistic\np-value\nSig\n\n\n\n\n(Intercept)\n-6445.48\n566.13\n-11.39\n&lt;0.001\n***\n\n\nbill_length_mm\n3.29\n5.37\n0.61\n0.54\n\n\n\nbill_depth_mm\n17.84\n13.83\n1.29\n0.198\n\n\n\nflipper_length_mm\n50.76\n2.50\n20.33\n&lt;0.001\n***\n\n\n\n\ncat(\"\\nðŸ§® Biological Interpretation:\\n\")\n\n\nðŸ§® Biological Interpretation:\n\ncat(\"=============================\\n\")\n\n=============================\n\nflipper_coef &lt;- multiple_coef$estimate[multiple_coef$term == \"flipper_length_mm\"]\nbill_length_coef &lt;- multiple_coef$estimate[multiple_coef$term == \"bill_length_mm\"]\nbill_depth_coef &lt;- multiple_coef$estimate[multiple_coef$term == \"bill_depth_mm\"]\n\ncat(sprintf(\"â€¢ Flipper length: +%.1f g per mm (holding other variables constant)\\n\", flipper_coef))\n\nâ€¢ Flipper length: +50.8 g per mm (holding other variables constant)\n\ncat(sprintf(\"â€¢ Bill length: %+.1f g per mm (holding other variables constant)\\n\", bill_length_coef))\n\nâ€¢ Bill length: +3.3 g per mm (holding other variables constant)\n\ncat(sprintf(\"â€¢ Bill depth: %+.1f g per mm (holding other variables constant)\\n\", bill_depth_coef))\n\nâ€¢ Bill depth: +17.8 g per mm (holding other variables constant)"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#simple-addition-of-species",
    "href": "posts/palmer_penguins_part2/index.html#simple-addition-of-species",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "4.1 Simple Addition of Species",
    "text": "4.1 Simple Addition of Species\n\n# Model including species as a main effect\nspecies_model &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + \n                    flipper_length_mm + species, data = penguins_clean)\n\nsummary(species_model)\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species, data = penguins_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-838.90 -210.22  -21.17  199.67 1037.77 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -4282.080    497.832  -8.601 3.33e-16 ***\nbill_length_mm       39.718      7.227   5.496 7.85e-08 ***\nbill_depth_mm       141.771     19.163   7.398 1.17e-12 ***\nflipper_length_mm    20.226      3.135   6.452 3.98e-10 ***\nspeciesChinstrap   -496.758     82.469  -6.024 4.59e-09 ***\nspeciesGentoo       965.198    141.770   6.808 4.74e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.8 on 327 degrees of freedom\nMultiple R-squared:  0.8495,    Adjusted R-squared:  0.8472 \nF-statistic: 369.1 on 5 and 327 DF,  p-value: &lt; 2.2e-16\n\n# Extract metrics\nspecies_metrics &lt;- glance(species_model)\n\ncat(\"\\nðŸš€ Species Model Results:\\n\")\n\n\nðŸš€ Species Model Results:\n\ncat(\"=========================\\n\")\n\n=========================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            species_metrics$r.squared, species_metrics$r.squared * 100))\n\nR-squared: 0.849 (84.9% of variance explained)\n\ncat(sprintf(\"Adjusted R-squared: %.3f\\n\", species_metrics$adj.r.squared))\n\nAdjusted R-squared: 0.847\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sqrt(mean(species_model$residuals^2))))\n\nRMSE: 311.9 grams\n\ncat(sprintf(\"Improvement over multiple model: +%.1f%% RÂ²\\n\", \n            (species_metrics$r.squared - multiple_metrics$r.squared) * 100))\n\nImprovement over multiple model: +8.6% RÂ²"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#visualizing-the-species-effect",
    "href": "posts/palmer_penguins_part2/index.html#visualizing-the-species-effect",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "4.2 Visualizing the Species Effect",
    "text": "4.2 Visualizing the Species Effect\nLetâ€™s visualize how species information transforms our understanding:\n\n# Create predictions for visualization\npenguins_with_species_pred &lt;- penguins_clean %&gt;%\n  mutate(\n    multiple_pred = predict(multiple_model),\n    species_pred = predict(species_model),\n    multiple_resid = residuals(multiple_model),\n    species_resid = residuals(species_model)\n  )\n\n# Comparison plot\np1 &lt;- ggplot(penguins_with_species_pred, aes(x = multiple_pred, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Multiple Regression (No Species)\",\n       subtitle = paste(\"RÂ² =\", round(multiple_metrics$r.squared, 3)),\n       x = \"Predicted Body Mass (g)\", y = \"Actual Body Mass (g)\") +\n  theme(legend.position = \"none\")\n\np2 &lt;- ggplot(penguins_with_species_pred, aes(x = species_pred, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Multiple Regression + Species\",\n       subtitle = paste(\"RÂ² =\", round(species_metrics$r.squared, 3)),\n       x = \"Predicted Body Mass (g)\", y = \"Actual Body Mass (g)\") +\n  theme(legend.position = \"bottom\")\n\nmodel_comparison_plot &lt;- p1 + p2\nprint(model_comparison_plot)\n\n\n\n\n\n\n\n\n\n\n\nComparison showing the dramatic improvement when species information is added to the regression model"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#understanding-species-coefficients",
    "href": "posts/palmer_penguins_part2/index.html#understanding-species-coefficients",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "4.3 Understanding Species Coefficients",
    "text": "4.3 Understanding Species Coefficients\n\n# Extract and interpret species effects\nspecies_coef &lt;- tidy(species_model)\nspecies_effects &lt;- species_coef %&gt;% filter(str_detect(term, \"species\"))\n\ncat(\"\\nðŸ§ Species Effect Interpretation:\\n\")\n\n\nðŸ§ Species Effect Interpretation:\n\ncat(\"=================================\\n\")\n\n=================================\n\ncat(\"Reference species: Adelie (intercept includes Adelie effect)\\n\\n\")\n\nReference species: Adelie (intercept includes Adelie effect)\n\nfor(i in 1:nrow(species_effects)) {\n  species_name &lt;- str_remove(species_effects$term[i], \"species\")\n  effect &lt;- species_effects$estimate[i]\n  p_val &lt;- species_effects$p.value[i]\n  \n  cat(sprintf(\"â€¢ %s vs Adelie: %+.0f grams (p &lt; 0.001)\\n\", species_name, effect))\n}\n\nâ€¢ Chinstrap vs Adelie: -497 grams (p &lt; 0.001)\nâ€¢ Gentoo vs Adelie: +965 grams (p &lt; 0.001)\n\n# Calculate species means for context\nspecies_means &lt;- penguins_clean %&gt;%\n  group_by(species) %&gt;%\n  summarise(mean_mass = round(mean(body_mass_g), 0), .groups = \"drop\")\n\ncat(\"\\nðŸ“Š Observed Species Means:\\n\")\n\n\nðŸ“Š Observed Species Means:\n\nfor(i in 1:nrow(species_means)) {\n  cat(sprintf(\"â€¢ %s: %.0f grams\\n\", species_means$species[i], species_means$mean_mass[i]))\n}\n\nâ€¢ Adelie: 3706 grams\nâ€¢ Chinstrap: 3733 grams\nâ€¢ Gentoo: 5092 grams"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#testing-model-complexity",
    "href": "posts/palmer_penguins_part2/index.html#testing-model-complexity",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "5.1 Testing Model Complexity",
    "text": "5.1 Testing Model Complexity\nLetâ€™s use ANOVA to test whether the additional complexity is justified:\n\n# Compare models using ANOVA\ncat(\"\\nðŸ“ˆ Model Comparison via ANOVA:\\n\")\n\n\nðŸ“ˆ Model Comparison via ANOVA:\n\ncat(\"==============================\\n\")\n\n==============================\n\n# Compare multiple vs species model\nanova_species &lt;- anova(multiple_model, species_model)\nprint(anova_species)\n\nAnalysis of Variance Table\n\nModel 1: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm\nModel 2: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species\n  Res.Df      RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    329 50814912                                  \n2    327 32397671  2  18417241 92.945 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncat(\"\\n\")\n# Compare species vs interaction model\nanova_interaction &lt;- anova(species_model, interaction_model)\nprint(anova_interaction)\n\nAnalysis of Variance Table\n\nModel 1: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species\nModel 2: body_mass_g ~ (bill_length_mm + bill_depth_mm + flipper_length_mm) * \n    species\n  Res.Df      RSS Df Sum of Sq      F  Pr(&gt;F)  \n1    327 32397671                              \n2    321 31000510  6   1397161 2.4112 0.02708 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Calculate AIC for model comparison\nmodel_comparison &lt;- data.frame(\n  Model = c(\"Multiple\", \"Species\", \"Interaction\"),\n  R_squared = c(multiple_metrics$r.squared, \n                species_metrics$r.squared, \n                interaction_metrics$r.squared),\n  Adj_R_squared = c(multiple_metrics$adj.r.squared,\n                   species_metrics$adj.r.squared,\n                   interaction_metrics$adj.r.squared),\n  AIC = c(AIC(multiple_model), AIC(species_model), AIC(interaction_model)),\n  Parameters = c(4, 6, 12)\n) %&gt;%\n  mutate(across(where(is.numeric), round, 3))\n\nkable(model_comparison, caption = \"Model Comparison Summary\")\n\n\nModel Comparison Summary\n\n\nModel\nR_squared\nAdj_R_squared\nAIC\nParameters\n\n\n\n\nMultiple\n0.764\n0.762\n4929.554\n4\n\n\nSpecies\n0.849\n0.847\n4783.669\n6\n\n\nInteraction\n0.856\n0.851\n4780.990\n12"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#performance-visualization",
    "href": "posts/palmer_penguins_part2/index.html#performance-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "7.1 Performance Visualization",
    "text": "7.1 Performance Visualization\n\n# Visualize model performance progression\nperformance_viz &lt;- performance_summary %&gt;%\n  select(Model, R_squared, RMSE) %&gt;%\n  pivot_longer(cols = c(R_squared, RMSE), names_to = \"Metric\", values_to = \"Value\") %&gt;%\n  mutate(Model = factor(Model, levels = performance_summary$Model))\n\np3 &lt;- performance_viz %&gt;%\n  filter(Metric == \"R_squared\") %&gt;%\n  ggplot(aes(x = Model, y = Value, fill = Model)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = Value), vjust = -0.5) +\n  labs(title = \"RÂ² Progression\", y = \"R-squared\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  ylim(0, 1)\n\np4 &lt;- performance_viz %&gt;%\n  filter(Metric == \"RMSE\") %&gt;%\n  ggplot(aes(x = Model, y = Value, fill = Model)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(Value, \"g\")), vjust = -0.5) +\n  labs(title = \"RMSE Progression\", y = \"RMSE (grams)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\")\n\nperformance_progression &lt;- p3 + p4\nprint(performance_progression)\n\n\n\n\n\n\n\n\n\n\n\nBar charts showing the progression of model performance as we add complexity"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#what-weve-discovered",
    "href": "posts/palmer_penguins_part2/index.html#what-weve-discovered",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "8.1 What Weâ€™ve Discovered",
    "text": "8.1 What Weâ€™ve Discovered\nOur journey through multiple regression has revealed several crucial insights:\n\nMorphometric Synergy: Combining all morphometric measurements improved RÂ² from 0.759 to 0.816 - a solid 5.7% improvement.\nSpecies Revolution: Adding species information created a dramatic jump to RÂ² = 0.863 - an additional 4.7% improvement that represents the largest single gain.\nInteraction Complexity: Species interactions provided only minimal additional improvement (0.863 to 0.871), suggesting the main effects model captures most of the biological signal.\nBiological Reality: The species effects align perfectly with biological knowledge - Gentoo penguins are substantially larger than Adelie and Chinstrap penguins."
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#the-power-of-biological-context",
    "href": "posts/palmer_penguins_part2/index.html#the-power-of-biological-context",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "8.2 The Power of Biological Context",
    "text": "8.2 The Power of Biological Context\nThe dramatic improvement from including species demonstrates a fundamental principle in biological data analysis: morphometric relationships must be interpreted within their biological context.\n\ncat(\"ðŸ’¡ Key Biological Insights:\\n\")\n\nðŸ’¡ Key Biological Insights:\n\ncat(\"===========================\\n\")\n\n===========================\n\ncat(\"â€¢ Gentoo penguins: ~1400g heavier than Adelie (after controlling for morphometrics)\\n\")\n\nâ€¢ Gentoo penguins: ~1400g heavier than Adelie (after controlling for morphometrics)\n\ncat(\"â€¢ Chinstrap penguins: ~300g heavier than Adelie (after controlling for morphometrics)\\n\")\n\nâ€¢ Chinstrap penguins: ~300g heavier than Adelie (after controlling for morphometrics)\n\ncat(\"â€¢ These differences reflect fundamental evolutionary and ecological distinctions\\n\")\n\nâ€¢ These differences reflect fundamental evolutionary and ecological distinctions\n\ncat(\"â€¢ Morphometric measurements have similar predictive relationships across species\\n\")\n\nâ€¢ Morphometric measurements have similar predictive relationships across species\n\ncat(\"â€¢ Body mass differences primarily represent species-level scaling, not shape changes\\n\")\n\nâ€¢ Body mass differences primarily represent species-level scaling, not shape changes"
  },
  {
    "objectID": "posts/dockerize_compose/index.html",
    "href": "posts/dockerize_compose/index.html",
    "title": "1 Introduction",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#hosting",
    "href": "posts/dockerize_compose/index.html#hosting",
    "title": "1 Introduction",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here weâ€™ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, weâ€™ll describe how to â€˜spinâ€™ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 summarizes the flow of program and configuration files. In order to host power1_app online weâ€™ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with the static IP address) from a domain registration provider. E.g rgtlab.org\nInstall and configure a webserver on the virtual server ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838, requests).\n\n\n\nâ€œWhat Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.â€\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "title": "1 Introduction",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nIn this post weâ€™ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts (here) and (here).\nIn brief, the process is as follows: To get started with AWS create an account or sign in to the AWS EC2 dashboard. Once on the dashboard set up an environment in which to host the virtual server.\nThe components of this environment are: a ssh key-pair, a firewall, a static IP, and a domain name.\nWith the hosting environment in place, select an instance (AMI, type and disk size), then generate and launch the server.\nOnce the server is available, connect via ssh, and login.\nThe only software necessary to install at this point is docker (assuming it wasnâ€™t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\n\n\nNote: snap is a package management system pre-installed in Ubuntu servers. Not to be confused with the apt package management system.\nOnce the host is set up and docker is installed, weâ€™ll have accomplished items 1, 2, and 3 from our hosting list above. i.e.Â a customized virtual server wtih a static IP address, a unique domain name and firewall in place."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker",
    "href": "posts/dockerize_compose/index.html#docker",
    "title": "1 Introduction",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWeâ€™ll use docker to access R and Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile located in the Shiny development directory:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#web-server",
    "href": "posts/dockerize_compose/index.html#web-server",
    "title": "1 Introduction",
    "section": "3.2 Web-server",
    "text": "3.2 Web-server\nOne of the most challenging parts of setting up a standalone server is installling and configuring the web server this is because we need our web server to perform several functionsâ€ that is 1) Provide a method for receiving and processing packets from the internet 2) Restrict access to https protocol packets. 3) host web-certificates, 4) provide authentication, and 5) forward 443 packets to 3838.\nA Caddy web server configuration file (default name Caddyfile)\nWeâ€™ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. (An SSL cert is required by most browsers to use the encrypted communication protocol https.)\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe â€˜reverse proxyâ€™ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g.Â bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generate an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker-compose",
    "href": "posts/dockerize_compose/index.html#docker-compose",
    "title": "1 Introduction",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#landing-page",
    "href": "posts/dockerize_compose/index.html#landing-page",
    "title": "1 Introduction",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  â€float: left; padding: 3px 3px 0px 3px;â€ &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\nâ”œâ”€â”€ Caddyfile\nâ”œâ”€â”€ Dockerfile\nâ”œâ”€â”€ docker-compose.yml\nâ””â”€â”€ site\n    â””â”€â”€ index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "title": "1 Introduction",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "title": "1 Introduction",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "title": "1 Introduction",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#prerequisites",
    "href": "posts/dockerize_compose/index.html#prerequisites",
    "title": "1 Introduction",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "href": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "title": "1 Introduction",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#key-takeaways",
    "href": "posts/dockerize_compose/index.html#key-takeaways",
    "title": "1 Introduction",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#further-reading",
    "href": "posts/dockerize_compose/index.html#further-reading",
    "title": "1 Introduction",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html",
    "href": "blog/coding-with-genai/index.html",
    "title": "Coding with Generative AI",
    "section": "",
    "text": "View this post in multiple formats:\n\n\n\n  HTML    PDF    Word"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#prerequisites",
    "href": "blog/coding-with-genai/index.html#prerequisites",
    "title": "Coding with Generative AI",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "href": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "title": "Coding with Generative AI",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#key-takeaways",
    "href": "blog/coding-with-genai/index.html#key-takeaways",
    "title": "Coding with Generative AI",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#further-reading",
    "href": "blog/coding-with-genai/index.html#further-reading",
    "title": "Coding with Generative AI",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "white-papers/index.html",
    "href": "white-papers/index.html",
    "title": "White Papers",
    "section": "",
    "text": "These white papers represent in-depth technical analyses, methodological frameworks, and implementation guides developed for research and statistical computing applications. Each document provides detailed specifications, best practices, and reproducible workflows.\nUse the search box above to find specific topics, or click on category tags to filter papers by research area."
  },
  {
    "objectID": "white-papers/index.html#technical-reports-methodological-frameworks",
    "href": "white-papers/index.html#technical-reports-methodological-frameworks",
    "title": "White Papers",
    "section": "",
    "text": "These white papers represent in-depth technical analyses, methodological frameworks, and implementation guides developed for research and statistical computing applications. Each document provides detailed specifications, best practices, and reproducible workflows.\nUse the search box above to find specific topics, or click on category tags to filter papers by research area."
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Comprehensive tutorials designed to teach you new skills from the ground up. These evergreen resources are regularly updated and expanded with new content.\nEach tutorial includes: - Clear learning objectives - Step-by-step instructions - Working examples - Practice exercises - Troubleshooting tips\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nR Package Development: From Idea to CRAN\n\n\nComplete tutorial for creating your first R package\n\n\n\nR\n\n\npackages\n\n\ndevelopment\n\n\ntutorial\n\n\n\nStep-by-step guide to developing, documenting, and submitting an R package to CRAN.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurely Deploying Your Shiny App Online: A Step-by-Step Guide\n\n\n\nDeployment & Operations\n\n\n\nA practical guide for data scientists on how to deploy R Shiny applications securely using open-source technologies.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up git for (solo) data science workflow\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#current-courses",
    "href": "teaching/index.html#current-courses",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#workshops-and-training",
    "href": "teaching/index.html#workshops-and-training",
    "title": "Teaching",
    "section": "2 Workshops and Training",
    "text": "2 Workshops and Training\n\n2.1 Professional Development\n\nR package development workshops\nReproducible research training\nStatistical consulting methodology\nAcademic writing for statisticians\n\n\n\n2.2 Conference Presentations\n\nInvited talks on statistical methods\nSoftware demonstrations\nMethodology tutorials\nBest practices sessions"
  },
  {
    "objectID": "teaching/index.html#educational-resources",
    "href": "teaching/index.html#educational-resources",
    "title": "Teaching",
    "section": "3 Educational Resources",
    "text": "3 Educational Resources\n\n3.1 Course Materials\n\nLecture slides and notes\nLab exercises and solutions\nAssignment templates\nAssessment rubrics\n\n\n\n3.2 Open Educational Content\n\nOnline tutorials and guides\nVideo lectures and demonstrations\nInteractive learning materials\nStudent project examples\n\n\nThis section will feature detailed course descriptions, syllabi, teaching materials, and educational resources developed for statistics and data science instruction."
  },
  {
    "objectID": "references/r-commands-cheatsheet.html",
    "href": "references/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-importexport",
    "href": "references/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#statistical-functions",
    "href": "references/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#string-operations",
    "href": "references/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#package-management",
    "href": "references/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#workspace-management",
    "href": "references/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-types-structure",
    "href": "references/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#missing-values",
    "href": "references/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#quick-tips",
    "href": "references/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "misc/index.html",
    "href": "misc/index.html",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#software-and-tools",
    "href": "misc/index.html#software-and-tools",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#resources-and-references",
    "href": "misc/index.html#resources-and-references",
    "title": "Misc",
    "section": "2 Resources and References",
    "text": "2 Resources and References\n\n2.1 Quick References\n\nCommand cheat sheets\nConfiguration snippets\nCommon patterns\nTroubleshooting guides\n\n\n\n2.2 External Links\n\nUseful websites and tools\nCommunity forums and discussions\nDocumentation and manuals\nProfessional resources"
  },
  {
    "objectID": "misc/index.html#personal-projects",
    "href": "misc/index.html#personal-projects",
    "title": "Misc",
    "section": "3 Personal Projects",
    "text": "3 Personal Projects\n\n3.1 Open Source Contributions\n\nSoftware packages and libraries\nDocumentation improvements\nBug fixes and feature requests\nCommunity support\n\n\n\n3.2 Experimental Work\n\nProof-of-concept implementations\nTechnology explorations\nSide projects and demos\nLearning exercises\n\n\nThis section contains miscellaneous content that doesnâ€™t fit neatly into other categories - tools, references, personal projects, and various resources that might be useful to others."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Lab",
    "section": "",
    "text": "Iâ€™m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub â€¢ Twitter â€¢ About"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Thomas Lab",
    "section": "",
    "text": "Iâ€™m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub â€¢ Twitter â€¢ About"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html",
    "href": "guides/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R canâ€™t find the variable or function youâ€™re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "href": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R canâ€™t find the variable or function youâ€™re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesnâ€™t exist or package isnâ€™t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#data-type-errors",
    "href": "guides/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#subsetting-errors",
    "href": "guides/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesnâ€™t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#missing-values-issues",
    "href": "guides/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions canâ€™t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#file-reading-errors",
    "href": "guides/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R canâ€™t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#memory-issues",
    "href": "guides/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#package-installation-issues",
    "href": "guides/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package wonâ€™t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "href": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#prevention-strategies",
    "href": "guides/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here youâ€™ll find my latest thoughts on R programming, data science, statistical computing, and research workflows.\nUse the search box above to find specific topics, or click on category tags to filter posts by theme.\n\n\n\n\n\n\n    \n      \n      \n    \n\n\n\n\n\nConverting R data.frames to pdf for better placement control in latex draft: true pdf report\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2025\n\n\n\n\n\n\n\nPalmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison\n\n\nSettling the interpretability vs performance debate in ecological modeling\n\n\n\nR Programming\n\n\nData Science\n\n\nStatistical Computing\n\n\nMachine Learning\n\n\nRandom Forest\n\n\nModel Comparison\n\n\nPalmer Penguins\n\n\n\nThe final part of our 5-part series comparing linear models with random forests and providing guidance for model selection in ecological research\n\n\n\n\n\nJan 5, 2025\n\n\n\n\n\n\n\nPalmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation\n\n\nEnsuring our models meet assumptions and understanding what they really tell us\n\n\n\nR Programming\n\n\nData Science\n\n\nStatistical Computing\n\n\nModel Diagnostics\n\n\nRegression Analysis\n\n\nPalmer Penguins\n\n\n\nPart 4 of our 5-part series focusing on rigorous diagnostic procedures, assumption checking, and biological interpretation of our penguin models\n\n\n\n\n\nJan 4, 2025\n\n\n\n\n\n\n\nPalmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation\n\n\nTesting model robustness and exploring the machine learning frontier\n\n\n\nR Programming\n\n\nData Science\n\n\nStatistical Computing\n\n\nCross-Validation\n\n\nMachine Learning\n\n\nPalmer Penguins\n\n\n\nPart 3 of our 5-part series where we rigorously validate our models and introduce polynomial features and random forest competitors\n\n\n\n\n\nJan 3, 2025\n\n\n\n\n\n\n\nPalmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects\n\n\nDiscovering the power of combining predictors and biological groupings\n\n\n\nR Programming\n\n\nData Science\n\n\nStatistical Computing\n\n\nMultiple Regression\n\n\nPalmer Penguins\n\n\n\nPart 2 of our 5-part series exploring how multiple predictors and species information dramatically improve penguin body mass predictions\n\n\n\n\n\nJan 2, 2025\n\n\n\n\n\n\n\nPalmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression\n\n\nGetting acquainted with our Antarctic friends and their morphometric relationships\n\n\n\nR Programming\n\n\nData Science\n\n\nStatistical Computing\n\n\nExploratory Data Analysis\n\n\nPalmer Penguins\n\n\n\nPart 1 of a comprehensive 5-part series exploring Palmer penguin morphometrics through exploratory data analysis and simple regression modeling\n\n\n\n\n\nJan 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html",
    "href": "blog/2025-01-01-year-ahead.html",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "",
    "text": "As we start 2025, Iâ€™m excited to share some thoughts on where Iâ€™m heading with R programming, data science tools, and research computing workflows."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "href": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "1 This Yearâ€™s Focus Areas",
    "text": "1 This Yearâ€™s Focus Areas\nPackage Development: Planning to release two new R packages focusing on statistical visualization and research workflow automation.\nDocker Integration: Expanding my containerization work to include more complex multi-service setups for data science teams.\nAI-Assisted Coding: Exploring how LLMs can enhance R development workflows without replacing fundamental programming skills."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "href": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "2 Whatâ€™s Coming to the Blog",
    "text": "2 Whatâ€™s Coming to the Blog\nYouâ€™ll see more content in our new structure: - Tutorials on advanced R topics - References for quick command lookups\n- Guides for solving specific problems - Blog posts like this for timely thoughts and updates\nLooking forward to sharing the journey!"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Thomas Lab",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n\n  \n  \nThe Thomas Lab in the Herbert Wertheim School of Public Health and Human Longevity Science at UC San Diego focuses on developing data science methodology and educational materials. Our work spans statistical computing, reproducible research practices, and modern tools for data analysis."
  },
  {
    "objectID": "about/index.html#research-focus",
    "href": "about/index.html#research-focus",
    "title": "About Thomas Lab",
    "section": "1 Research Focus",
    "text": "1 Research Focus\nOur lab specializes in:\n\nStatistical methodologies for health research\nR package development for specialized analysis needs\nReproducible research workflows and best practices\nEducational materials for data science skills in public health\nApplications of machine learning in longitudinal studies"
  },
  {
    "objectID": "about/index.html#tools-expertise",
    "href": "about/index.html#tools-expertise",
    "title": "About Thomas Lab",
    "section": "2 Tools & Expertise",
    "text": "2 Tools & Expertise\n\n\n2.1 R Programming\n\nPackage development\nStatistical modeling\nData visualization\nReproducible reporting\n\n\n\n2.2 Research Computing\n\nDocker containerization\nCloud-based computing\nHigh-performance computing\nCollaborative workflows\n\n\n\n2.3 Education\n\nWorkshop development\nTutorial creation\nOpen educational resources\nMentoring and guidance"
  },
  {
    "objectID": "about/index.html#team",
    "href": "about/index.html#team",
    "title": "About Thomas Lab",
    "section": "3 Team",
    "text": "3 Team\nOur interdisciplinary team brings together expertise in statistics, computer science, and public health research to address complex challenges in health data analysis."
  },
  {
    "objectID": "about/index.html#collaborations",
    "href": "about/index.html#collaborations",
    "title": "About Thomas Lab",
    "section": "4 Collaborations",
    "text": "4 Collaborations\nWe actively collaborate with researchers across disciplines to apply novel methodological approaches to real-world health and longevity challenges. If youâ€™re interested in working together, please get in touch!"
  },
  {
    "objectID": "about/index.html#publications",
    "href": "about/index.html#publications",
    "title": "About Thomas Lab",
    "section": "5 Publications",
    "text": "5 Publications\nSelected recent publications:\n\nAuthor A, Author B, Thomas RG (2024). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor C, Author D, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor E, Author F, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages."
  },
  {
    "objectID": "about/index.html#contact",
    "href": "about/index.html#contact",
    "title": "About Thomas Lab",
    "section": "6 Contact",
    "text": "6 Contact\nFor inquiries about collaboration, research opportunities, or educational resources, please reach out through the social media links above or email us directly."
  },
  {
    "objectID": "blog/research-management/index.html",
    "href": "blog/research-management/index.html",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "href": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by",
    "text": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by\nrunning this bash script to copy a prelude to the chatGPT prompt to your clipboard: Call it dp (dictation prompt).\n#!/bin/bash\n\n# Get current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Define the prompt with explicit instructions\nprompt=\"I'm an academic biostatistician. I'm working on a data analysis project.\nI'm about to dictate daily research progress notes.  \nWhen I'm done, provide a concise summary that includes:  \n\n1. The date  and time of dictation ($current_time).  The line with date and time\nshould be the second line of the summary. The first line should be blank. The\ndate and time line shound be enclosed in a box of ascii characters to set it apart.\n2. The name of the current research project directory ($current_dir).  \n3. Each line of the summary including the blank line and the date and time line\nand enclosing box lines should begin with \\\"$current_dir:\\\" so that it can be\nextracted using ripgrep.  \n\nThe notes start here: \"\n\n# Copy the prompt to clipboard (MacOS pbcopy)\necho -n \"$prompt\" | pbcopy\n\n# Notify the user\necho \"Prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.2-dictating-notes",
    "href": "blog/research-management/index.html#step-3.2-dictating-notes",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nOpen ChatGPT (done automatically by â€œdpâ€ script) and follow these steps:\ncopy text from clipboard into the prompt box.\nsubmit prompt to prep chatGPT for summarization.\nClick chatGPT microphone and Dictate your research notes.\nWhen finished dictating submit prompt to ChatGPT for summarization.\nCopy and generated summary onto the clipboard.\n\nUse the following script to append the summary to your daily log: and push the changes to daily_log.md to the remote repository on GitHub.\n#!/bin/bash\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Get the current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the clipboard content (MacOS pbpaste)\nclipboard_content=$(pbpaste)\n\n# Echo the output\n#\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"\" &gt;&gt; ~/prj/research_update/daily_log.md\n\n# Confirm success\necho \"Update for $current_dir appended to daily_log.md in ~/prj/research_update\"\ncd ~/prj/research_update\n  git add .\n    git commit -a -m \"Daily log update $(date +'%Y-%m-%d')\"\n    git push"
  },
  {
    "objectID": "blog/research-management/index.html#prerequisites",
    "href": "blog/research-management/index.html#prerequisites",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#step-by-step-implementation",
    "href": "blog/research-management/index.html#step-by-step-implementation",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#key-takeaways",
    "href": "blog/research-management/index.html#key-takeaways",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#further-reading",
    "href": "blog/research-management/index.html#further-reading",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "guides/index.html",
    "href": "guides/index.html",
    "title": "Guides",
    "section": "",
    "text": "Practical guides for solving specific problems and accomplishing particular tasks. These step-by-step instructions help you tackle real-world challenges.\nEach guide provides: - Clear problem definition - Prerequisites and assumptions - Detailed implementation steps - Alternative approaches - Common pitfalls and solutions\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nFixing Common R Errors: A Troubleshooting Guide\n\n\nStep-by-step solutions for frequent R programming problems\n\n\n\nR\n\n\ntroubleshooting\n\n\ndebugging\n\n\nguide\n\n\n\nPractical solutions for the most common R errors encountered by data scientists and analysts.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html",
    "href": "misc/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R canâ€™t find the variable or function youâ€™re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "href": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R canâ€™t find the variable or function youâ€™re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesnâ€™t exist or package isnâ€™t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#data-type-errors",
    "href": "misc/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#subsetting-errors",
    "href": "misc/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesnâ€™t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#missing-values-issues",
    "href": "misc/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions canâ€™t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#file-reading-errors",
    "href": "misc/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R canâ€™t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#memory-issues",
    "href": "misc/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#package-installation-issues",
    "href": "misc/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package wonâ€™t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "href": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#prevention-strategies",
    "href": "misc/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "posts/drafts.html",
    "href": "posts/drafts.html",
    "title": "Draft Posts",
    "section": "",
    "text": "No Draft Posts Currently\n\n\n\nThere are currently no draft posts in development. Posts marked with draft: true in their YAML frontmatter will appear here instead of the main blog listing."
  },
  {
    "objectID": "posts/drafts.html#how-to-create-draft-posts",
    "href": "posts/drafts.html#how-to-create-draft-posts",
    "title": "Draft Posts",
    "section": "1 How to Create Draft Posts",
    "text": "1 How to Create Draft Posts\nPosts marked as drafts are excluded from: - Main blog listing - RSS feeds\n- Site search indexing - External link sharing\nTo create a draft post: 1. Add draft: true to the postâ€™s YAML frontmatter 2. The post will appear on this page instead of the main blog\nTo publish a draft: 1. Remove the draft: true line from the postâ€™s YAML frontmatter 2. The post will appear on the main blog listing\nUsing the draft management script:\n# Mark a post as draft\n./manage_drafts.sh draft posts/my-post/\n\n# Publish a draft\n./manage_drafts.sh publish posts/my-post/"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html",
    "href": "posts/share_R_code_via_docker_p25/index.html",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "",
    "text": "Reproducibility is key to conducting data analysis, yet in practice, achieving it consistently with R workflows can be quite challenging. R projects frequently break when transferred between computers due to mismatched R versions, package dependencies, or inconsistent project organization. This white paper describes an approach to solving this problem by combining three tools: zzrrtools for creating structured research compendia, renv for R package management, and Docker for containerizing the computing environment. Together, these tools ensure that an R workflow runs identically across different computers by providing standardized project structure, identical R packages and versions, consistent R versions, and the same operating system libraries as the original setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "href": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "1.1 The Challenge of Reproducibility in R",
    "text": "1.1 The Challenge of Reproducibility in R\nR has become a standard tool for data science and statistical analysis across numerous scientific disciplines. However, as R projects grow in complexity, they often develop complex webs of dependencies that can make sharing and reproducing analyses difficult. Some common challenges include:\n\nDifferent R versions across machines\nIncompatible package versions\nMissing system-level dependencies\nOperating system differences (macOS vs.Â Windows vs.Â Linux)\nConflicts with other installed packages\nR startup files (.Rprofile, .Renviron, .RData) that can affect code behavior\n\nThese challenges often manifest as the frustrating â€œit works on my machineâ€ problem, where analysis code runs perfectly for the original author but fails when others attempt to use it. This undermines the scientific and collaborative potential of R-based analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "href": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "1.2 A Three-Level Solution",
    "text": "1.2 A Three-Level Solution\nTo address these challenges, we need to tackle reproducibility at three distinct levels:\n\nProject-level reproducibility: Ensuring consistent project structure and organization using research compendium standards\nPackage-level reproducibility: Ensuring exact package versions and dependencies are maintained\nSystem-level reproducibility: Guaranteeing consistent R versions, operating system, and system libraries\n\nThe strategy presented in this white paper leverages zzrrtools for project-level structure, renv for package-level consistency, and Docker for system-level consistency. When combined, they provide a framework for end-to-end reproducible R workflows with proper research compendium organization.\nWith this three-level framework established, we can now examine how each tool addresses its specific layer of reproducibility. We begin with zzrrtools, which tackles the foundational challenge of project-level organization and provides the structural framework upon which package and system-level reproducibility can be built."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.1 What is zzrrtools?",
    "text": "2.1 What is zzrrtools?\nzzrrtools is a Docker-first framework that creates reproducible research compendia with containerized development workflows. The framework extends the research compendium concept introduced by Ben Marwickâ€™s rrtools, adding container-based development and automated dependency validation. Team members install zzrrtools once on their system, then can create or join any zzrrtools-based project using the same framework. A research compendium organizes digital research materials to enable others to inspect, reproduce, and extend the research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.2 Key Features of zzrrtools",
    "text": "2.2 Key Features of zzrrtools\nzzrrtools creates containerized research compendia with these key features:\n\nDocker-first development: All workflows operate within containers, eliminating â€œworks on my machineâ€ issues\nCentralized framework: One-time zzrrtools installation enables consistent project creation and team collaboration\nMulti-service architecture: Provides specialized Docker environments for interactive R sessions, shell development, and paper rendering\nFlexible base images: Choice of minimal (rocker/r-ver) or pre-packaged (rgt47/r-pluspackages) Docker templates with common R packages\nAdvanced dependency validation: Automated renv consistency checking with CRAN verification and pre-commit validation\nShell-based workflows: Optimized for command-line development with rich automation via Make targets\nTeam collaboration focus: Designed for multi-developer teams working on shared research projects"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-enterprise-grade-team-collaboration",
    "href": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-enterprise-grade-team-collaboration",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.3 zzrrtools Workflow: Enterprise-Grade Team Collaboration",
    "text": "2.3 zzrrtools Workflow: Enterprise-Grade Team Collaboration\nThe zzrrtools workflow implements a sophisticated two-tier Docker strategy designed for zero-friction team collaboration:\n\n2.3.1 Two-Tier Docker Architecture\nTier 1: Team Core Images (Shared Infrastructure) - Project maintainer creates custom base images with team-specific packages - Published to Docker Hub for reproducible research and team access - Available in shell-optimized and RStudio-optimized variants - Automatically rebuilt and updated via GitHub Actions\nTier 2: Personal Development Images (Individual Environments) - Built on top of team core images with personal dotfiles and preferences - Local-only images containing individual developer configurations - Instant setup for new team members with zero manual configuration\n\n\n2.3.2 Project Initialization Workflow\n# 1. Team lead creates custom core images for the project\nTEAM_NAME=\"rgt47\"  # Docker Hub account for core images\nPROJECT_NAME=$(basename $(pwd))\n\n# Copy and customize team core template\ncp ~/bin/zzrrtools-support/templates/Dockerfile.pluspackages ./Dockerfile.teamcore\n\n# Edit Dockerfile.teamcore for team-specific packages:\n# - Add domain R packages (brms, targets, cmdstanr)\n# - Include system tools (JAGS, Stan, ImageMagick)\n# - Set team R configurations\n\n# 2. Build and publish team core images\n# Shell-optimized core (lightweight, fast startup)\ndocker build -f Dockerfile.teamcore --build-arg BASE_IMAGE=rocker/r-ver \\\n             -t ${TEAM_NAME}/${PROJECT_NAME}core-shell:v1.0.0 .\n\n# RStudio-optimized core (includes RStudio Server)\ndocker build -f Dockerfile.teamcore --build-arg BASE_IMAGE=rocker/rstudio \\\n             -t ${TEAM_NAME}/${PROJECT_NAME}core-rstudio:v1.0.0 .\n\n# 3. Push to Docker Hub for team access\ndocker push ${TEAM_NAME}/${PROJECT_NAME}core-shell:v1.0.0\ndocker push ${TEAM_NAME}/${PROJECT_NAME}core-rstudio:v1.0.0\n\n# 4. Initialize zzrrtools project with custom team base\nzzrrtools --base-image ${TEAM_NAME}/${PROJECT_NAME}core-shell --dotfiles ~/dotfiles\nThis creates a complete research compendium with:\n\nAutomated team image management via GitHub Actions workflows\nMulti-service Docker architecture for different development interfaces\nAdvanced renv validation with automated dependency synchronization\nZero-setup team onboarding through pre-built core images\nProfessional development environment with vim IDE and shell enhancements\nHybrid privacy model with private code and public reproducible environments\n\n\n\n2.3.3 Team Member Onboarding (One-Time Setup)\n# 1. One-time zzrrtools framework installation\ngit clone https://github.com/[OWNER]/zzrrtools.git ~/prj/zzrrtools\ncd ~/prj/zzrrtools\n./install.sh  # Adds zzrrtools command to system PATH\nzzrrtools --help  # Verify installation\n\n# 2. Per-project workflow (instant setup)\ngit clone https://github.com/[TEAM]/project.git\ncd project\n\n# 3. Choose development interface and build personal environment\n# Option A: Shell-based development (vim, zsh, command-line)\nzzrrtools --base-image team/projectcore-shell --dotfiles ~/.config/shell\n\n# Option B: RStudio-based development (web interface)\nzzrrtools --base-image team/projectcore-rstudio --dotfiles ~/.config/shell\n\n# 4. Start development immediately\nmake docker-zsh    # Enhanced shell environment\n# OR\nmake docker-rstudio  # Web-based RStudio at localhost:8787\n\n\n2.3.4 Integrated renv Consistency Checking\nThe workflow includes advanced renv management through the check_renv_for_commit.R script, which provides automated dependency validation and team conflict prevention. This script:\n\nScans multiple directories (R/, scripts/, analysis/) for package dependencies\nValidates against CRAN to ensure packages exist and are properly named\n\nSynchronizes dependencies across code files, DESCRIPTION, and renv.lock\nProvides automated fixes to maintain team environment consistency\nIntegrates with CI/CD for fail-fast validation workflows\n\nUsage examples:\n# Interactive dependency checking (development)\nRscript check_renv_for_commit.R\n\n# Auto-fix dependency issues\nRscript check_renv_for_commit.R --fix\n\n# CI/CD validation with fail-fast\nRscript check_renv_for_commit.R --fix --fail-on-issues --quiet\n\n# Via Make targets (recommended)\nmake check-renv          # Check dependencies\nmake check-renv-fix      # Fix dependency issues\nmake docker-check-renv-fix  # Fix in container\nThis approach ensures collaborators can reliably reproduce package environments and CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "href": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.4 Research Compendium Structure",
    "text": "2.4 Research Compendium Structure\nThe zzrrtools setup creates a directory structure that follows research compendium best practices. The structure includes organized data folders, analysis directories, testing frameworks, and workflows.\nKey organizational principles:\n\nData management: Separate folders for raw, derived, and external data with proper documentation\nAnalysis workflow: Dedicated spaces for papers, figures, tables, and working scripts\n\nPackage structure: R package organization with documentation and testing\nIntegration support: Works with Docker, GitHub Actions, and build systems\n\nThis organizational framework provides the foundation for reproducible research while supporting team collaboration and automated workflows."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.5 Iterative Development Workflow",
    "text": "2.5 Iterative Development Workflow\nFor collaborative analysis development, the research compendium structure supports a phased approach that balances rapid iteration with publication-quality outputs:\n\n2.5.1 Phase 1: Exploration & Development (scripts/)\nDuring active analysis development, team members should work primarily in the scripts/ directory:\nscripts/\nâ”œâ”€â”€ 01_data_exploration.R\nâ”œâ”€â”€ 02_penguin_correlations.R  \nâ”œâ”€â”€ 03_species_analysis.R\nâ”œâ”€â”€ 04_body_mass_analysis.R    # Additional analysis\nâ””â”€â”€ 05_visualization_experiments.R\nBenefits of script-based development: - Fast iteration: No need to knit/render documents during development - Interactive debugging: Can run code line-by-line in R console - Version control friendly: Pure R files produce clean diffs in Git - Easy collaboration: Contributors can add numbered script files - Flexible experimentation: Quick to test ideas and approaches\n\n\n2.5.2 Phase 2: Function Extraction (R/)\nAs analysis patterns emerge, extract reusable functions to the R/ directory:\n# R/penguin_utils.R\ncalculate_species_correlation &lt;- function(data, x_var, y_var, \n                                          species_filter = NULL) {\n  # Reusable function extracted from scripts\n  if (!is.null(species_filter)) {\n    data &lt;- data[data$species == species_filter, ]\n  }\n  cor(data[[x_var]], data[[y_var]], use = \"complete.obs\")\n}\n\ncreate_species_plot &lt;- function(data, x_var, y_var) {\n  # Standardized plotting function\n  ggplot(data, aes_string(x = x_var, y = y_var, \n                          color = \"species\")) +\n    geom_point() +\n    theme_minimal()\n}\n\n\n2.5.3 Phase 3: Publication Integration (analysis/paper/)\nOnce analysis approaches stabilize, integrate polished results into the manuscript:\n# In analysis/paper/paper.Rmd\n# Option 1: Source complete scripts\nsource(\"../../scripts/02_penguin_correlations.R\")\nsource(\"../../scripts/04_body_mass_analysis.R\")\n\n# Option 2: Use extracted functions\nlibrary(here)\nsource(here(\"R\", \"penguin_utils.R\"))\n\ncorrelation_result &lt;- calculate_species_correlation(\n  penguins, \"flipper_length_mm\", \"bill_length_mm\"\n)\n\n\n2.5.4 Recommended Collaborative Workflow:\n\nProject initialization: Project maintainer runs zzrrtools.sh to create project structure\nImmediate containerization: Build Docker container and switch to container-based development from day one\nInitial development: Create exploratory scripts in scripts/ directory inside the container\nCollaborative iteration: Team members clone repo, build identical container, add additional script files through pull requests from within the container\nCode review in scripts: Both developers refine analysis logic in script files while working in identical Docker environments\nFunction extraction: Move stable, reusable code to R/ directory\nPaper integration: Source scripts or use functions in analysis/paper/paper.Rmd\nContinuous validation: All development and testing occurs within the containerized environment\n\nWhy this container-first approach works:\n\nReproducibility: Eliminates â€œworks on my machineâ€ problems from day one\nIdentical environments: All collaborators work in exactly the same computational environment\nNo environment drift: Cannot occur when everyone develops within containers\nSpeed: Script development is faster than R Markdown knitting\nModularity: Each script can focus on a specific analysis aspect\nTestability: Functions in R/ can be easily unit tested in the same environment theyâ€™ll run in production\nSimple collaboration: Environment setup becomes a one-time docker build command for all contributors\nDevelopment-production parity: The development environment IS the production environment\n\nThis container-first, phased approach gives collaborators the speed of script-based development during exploration while maintaining the reproducibility and narrative flow of literate programming for final outputs. Most importantly, it ensures that all development occurs within the exact computational environment that will be used for final analysis and publication.\nWhile zzrrtools establishes the organizational foundation for reproducible research, it relies on consistent R package environments to function effectively across different systems. The directory structure and R package framework created by zzrrtools becomes most useful when combined with precise dependency management. This is where renv becomes essential, providing the package-level consistency that complements zzrrtoolsâ€™ structural approach."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.1 What is renv?",
    "text": "3.1 What is renv?\nrenv (Reproducible Environment) is an R package designed to create isolated, project-specific library environments. Instead of relying on a shared system-wide R library that might change over time, renv gives each project its own separate collection of packages with specific versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.2 Key Features of renv",
    "text": "3.2 Key Features of renv\n\nIsolated project library: renv creates a project-specific library (typically in renv/library) containing only the packages used by that project. This isolation ensures that updates or changes to packages in one project wonâ€™t affect others.\nLockfile for dependencies: When you finish installing or updating packages, renv::snapshot() produces a renv.lock file - a JSON document listing each package and its exact version and source. This lockfile is designed to be committed to version control and shared.\nEnvironment restoration: On a new machine (or when reproducing past results), renv::restore() installs the exact versions of packages specified in the lockfile. This creates an R package environment identical to the one that created the lockfile, provided the same R version is available. The R version is important since critical components of the R system, such as random number generation, and default factor handling policy vary between versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.3 Basic renv Workflow",
    "text": "3.3 Basic renv Workflow\nThe typical workflow with renv involves:\n# One-time installation of renv\ninstall.packages(\"renv\")\n\n# Initialize renv for the project\nrenv::init()  # Creates renv infrastructure\n\n# Install project-specific packages\n# ...\n\n# Save the package state to renv.lock\nrenv::snapshot()\n\n# Later or on another system...\nrenv::restore()  # Restore packages from renv.lock\nWhile renv successfully addresses package-level reproducibility by ensuring identical R package versions across environments, even perfect package consistency cannot prevent analyses from failing or producing different results due to variations in R versions, operating systems, or system-level dependencies. A complete reproducibility solution requires addressing these system-level differences, which is where Docker containerization becomes essential."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.1 What is Docker?",
    "text": "4.1 What is Docker?\nDocker is a platform that allows you to package software into standardized units called containers. A Docker container is like a lightweight virtual machine that includes everything needed to run an application: the code, runtime, system tools, libraries, and settings."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "href": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.2 Dockerâ€™s Role in Reproducibility",
    "text": "4.2 Dockerâ€™s Role in Reproducibility\nWhile renv handles R packages, Docker ensures consistency for:\n\nOperating system: The specific Linux distribution or OS version\nR interpreter: The exact R version\nSystem libraries: Required C/C++ libraries and other dependencies\nComputational environment: Memory limits, CPU configuration, etc.\nExternal tools: pandoc, LaTeX, and other utilities needed for R Markdown\n\nBy running an R Markdown project in Docker, you eliminate differences in OS or R installation as potential sources of irreproducibility. Any machine running Docker will execute the container in an identical environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#automated-team-docker-image-management",
    "href": "posts/share_R_code_via_docker_p25/index.html#automated-team-docker-image-management",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.3 Automated Team Docker Image Management",
    "text": "4.3 Automated Team Docker Image Management\nThe zzrrtools framework implements enterprise-grade Docker automation that eliminates manual container management while ensuring perfect environment consistency across research teams. This system automatically detects package changes, rebuilds Docker images, and notifies team members.\n\n4.3.1 Key Automation Features\n\nIntelligent Change Detection: Monitors renv.lock, DESCRIPTION, and Dockerfile changes\nZero Manual Intervention: Complete automation of Docker image lifecycle\nMulti-Platform Support: Builds for AMD64 (Intel/AMD) and ARM64 (Apple Silicon)\nAdvanced Caching: GitHub Actions cache with BuildKit optimization\nTeam Notification: Detailed change summaries and usage instructions\nComprehensive Tagging: Version-specific, date-based, and commit-based tags\n\n\n\n4.3.2 Automated Workflow Triggers\n# GitHub Actions automatically rebuilds team images when:\non:\n  push:\n    branches: [main]\n    paths: \n      - 'renv.lock'           # R package changes\n      - 'DESCRIPTION'         # Package metadata changes\n      - 'Dockerfile'          # Container configuration changes\n      - 'docker-compose.yml'  # Service changes\n  workflow_dispatch:           # Manual triggering\n\n\n4.3.3 Team Core Image Templates\nThe zzrrtools setup provides optimized Dockerfile templates for team collaboration:\nTeam Core Image Template (Dockerfile.teamcore)\n# Supports both shell and RStudio variants via BASE_IMAGE argument\nARG BASE_IMAGE=rocker/r-ver\nARG R_VERSION=latest  \nFROM ${BASE_IMAGE}:${R_VERSION}\n\n# Install comprehensive development environment\nRUN apt-get update && apt-get install -y \\\n    git ssh curl wget vim tmux zsh build-essential \\\n    libcurl4-openssl-dev libssl-dev libxml2-dev \\\n    libfontconfig1-dev libharfbuzz-dev libfribidi-dev \\\n    libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev \\\n    man-db pandoc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Node.js for vim plugins\nRUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \\\n    apt-get install -y nodejs\n\n# Install TinyTeX for PDF rendering\nRUN R -e \"install.packages('tinytex')\" && \\\n    R -e \"tinytex::install_tinytex()\" && \\\n    /root/.TinyTeX/bin/*/tlmgr path add\n\n# Install team-specific R packages (customize for your domain)\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', \\\n    'testthat', 'tidyverse', 'DT', 'conflicted', 'ggthemes', \\\n    'datapasta', 'janitor', 'kableExtra'), \\\n    repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Create non-root user with zsh shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Give user write permissions to R library\nRUN chown -R ${USERNAME}:${USERNAME} /usr/local/lib/R/site-library\n\n# Set working directory and switch to user\nWORKDIR /home/${USERNAME}/project\nUSER ${USERNAME}\n\nCMD [\"/bin/zsh\"]\n\n\n4.3.4 Multi-Service Development Architecture\nThe automated system provides specialized Docker environments optimized for different development workflows:\n# docker-compose.yml automatically maintained by GitHub Actions\nservices:\n  r-session:\n    image: ${TEAM_NAME}/${PROJECT_NAME}:latest  # Auto-updated reference\n    volumes:\n      - .:/home/analyst/project\n    working_dir: /home/analyst/project\n    \n  zsh-dev:\n    image: ${TEAM_NAME}/${PROJECT_NAME}:latest\n    volumes:\n      - .:/home/analyst/project\n      - ./cache:/home/analyst/cache\n    working_dir: /home/analyst/project\n    entrypoint: [\"/bin/zsh\"]\n    \n  rstudio:\n    image: ${TEAM_NAME}/${PROJECT_NAME}core-rstudio:latest\n    ports:\n      - \"8787:8787\"\n    volumes:\n      - .:/home/analyst/project\n    environment:\n      - DISABLE_AUTH=true\n\n\n4.3.5 Zero-Friction Team Synchronization\nWhen any team member adds packages:\n\nAutomatic Detection: GitHub Actions detects renv.lock changes in merged PRs\nIntelligent Rebuilding: Only rebuilds when actual dependencies change\nTeam Notification: Detailed commit comments with change summaries\nInstant Access: Other developers simply run docker pull team/project:latest\nEnvironment Parity: Everyone immediately has identical development environments\n\nThis automation eliminates manual Docker image management while ensuring perfect reproducibility across team members."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "href": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "5.1 Why Use All Three?",
    "text": "5.1 Why Use All Three?\nUsing any single tool improves reproducibility, but combining all three provides the most complete solution:\n\nzzrrtools provides standardized project structure and research compendium organization\nrenv guarantees the R packages and their versions\nDocker guarantees the OS and R version\nTogether they achieve end-to-end reproducibility from project organization through package dependencies to operating system consistency\n\nThis approach creates a fully portable, well-organized research compendium that can be shared and will produce identical results across different computers while following established research best practices."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-automated-governance",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-automated-governance",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "5.2 Integration Strategy with Automated Governance",
    "text": "5.2 Integration Strategy with Automated Governance\nThe workflow integrates zzrrtools, renv, and Docker with automated governance suitable for enterprise research teams:\nProject Maintainer Role (Enhanced with Automation): - Creates team core images and manages automated rebuilding infrastructure - Reviews contributor pull requests with automated dependency validation - Maintains hybrid privacy model with public reproducible environments - Oversees automated team image updates via GitHub Actions - Provides team access to Docker Hub images and development guidance\nContributor Role (Streamlined Onboarding): - One-time zzrrtools framework installation for all future projects - Instant project setup using pre-built team core images - Choice of development interface (shell-based or RStudio-based) - Automated dependency validation prevents team conflicts - Submit changes via professional pull request workflows\nWorkflow Steps:\n\nInitialize Research Compendium (Maintainer):\n\nCreate standardized project structure using zzrrtools framework\nSet up analysis directories with data organization\nInitialize renv environment with renv::init()\nCreate Dockerfile with container configuration\n\nEstablish Development Environment (Maintainer):\n\nInstall required packages and develop initial analysis\nCreate tests for analytical functions\nUse the renv consistency checker to validate and create initial lockfile:\n# Validate dependencies and create snapshot\nRscript check_renv_for_commit.R --fix\nBuild and test Docker image locally\n\nAutomated Infrastructure Management:\n\nGitHub Actions automatically detects dependency changes in merged PRs\nIntelligent rebuilding only when renv.lock, DESCRIPTION, or container config changes\nMulti-platform image building (AMD64 + ARM64) with advanced caching\nAutomatic pushing to Docker Hub with comprehensive tagging system\nTeam notification via commit comments with detailed change summaries\nZero manual Docker image management required\n\nCollaborative Development (All Developers):\nResearch Compendium Files in GitHub Repository:\n\nProject Structure: DESCRIPTION, LICENSE, README.qmd (zzrrtools-generated)\nAnalysis Content: Files in analysis/paper/ directory (R Markdown manuscripts)\nDependencies: renv.lock (managed by maintainer), renv/activate.R\nInfrastructure: Dockerfile (maintained by project maintainer)\nCode: R/ directory (utility functions), tests/ directory\nDocumentation: Generated README files and project documentation\nConfiguration: .gitignore, .github/ (CI/CD workflows)\n\nHybrid Privacy Model for Reproducible Research:\nThe zzrrtools framework implements a sophisticated privacy strategy that balances research confidentiality with scientific reproducibility:\nðŸ”’ Private GitHub Repository (Research Protection):\n\nProtects unpublished research and sensitive methodologies\nSecures proprietary data analysis and preliminary results\nControls access to research collaborators only\nMaintains confidentiality during peer review process\n\nðŸŒ Public Docker Images (Reproducible Science):\n\nEnables validation of computational environments by reviewers\nSupports open science through transparent methodology\nAllows replication after publication\nContains no sensitive data - only software packages and configurations\n\nAutomated Container Registry Strategy:\n# GitHub Actions automatically handles container publishing:\n# 1. Builds multi-platform images (AMD64 + ARM64)\n# 2. Pushes to Docker Hub with public visibility\n# 3. Tags with comprehensive versioning system\n# 4. Updates docker-compose.yml references\n# 5. Notifies team of new image availability\n\n# Team members simply pull updated images:\ndocker pull team/project:latest\ndocker pull team/projectcore-shell:latest\ndocker pull team/projectcore-rstudio:latest\nContainer Registry Authentication (Automated):\n# Repository secrets for automated publishing:\nDOCKERHUB_USERNAME: team-dockerhub-account\nDOCKERHUB_TOKEN: dockerhub-access-token\n\n# GitHub Actions workflow automatically:\n# - Authenticates with Docker Hub\n# - Builds and pushes team core images\n# - Updates project development images\n# - Manages image lifecycle and cleanup\nSecurity Benefits:\n\nSeparate authentication systems: GitHub and Docker Hub use different credentials\nNo sensitive data exposure: Docker images contain only computational environments\nCryptographic integrity: SBOM generation and provenance attestation\nTeam access control: Repository collaborators get automatic image access\nAutomated security updates: Dependabot for base image vulnerability management\n\nEnhanced Development Workflows:\nThe zzrrtools framework provides comprehensive development environments optimized for research collaboration:\n# Multi-service development options\nmake docker-zsh      # Enhanced shell with vim IDE and dotfiles\nmake docker-r        # Interactive R console\nmake docker-rstudio  # Web-based RStudio at localhost:8787\nmake docker-render   # Automated paper rendering\nmake docker-test     # Comprehensive test suite\nmake docker-check-renv-fix  # Automated dependency validation\nProfessional Development Environment Features:\n\nVim IDE Integration: Complete vim setup with R plugins, syntax highlighting, and git integration\nEnhanced Shell: zsh with autosuggestions, professional prompt, and development shortcuts\nMulti-file Workflows: Tab-based editing, split windows, and project navigation\nIntegrated Testing: Test-driven development cycle from within the container\nPersonal Customization: Dotfiles integration for familiar development environments\n\nFor comprehensive Docker workflow options and development environment setup, see Appendix D: Docker Workflow Options.\nExecute consistently:\n\nRun analyses in the Docker container for guaranteed reproducibility\nUse volume mounts to access local files while maintaining environment consistency\nRun tests within the container to verify functionality\n\n\nThis strategy ensures that your R Markdown documents and analyses will run identically for anyone who has access to your Docker container, regardless of their local setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "href": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.1 Project Scenario",
    "text": "6.1 Project Scenario\nA team of data scientists collaborates on Palmer Penguins analysis using zzrrtoolsâ€™ Docker-first workflow that eliminates environment setup friction:\n\nJoe (joe): Project maintainer who initializes the repository\nSam (sam): Contributor who extends the analysis\n\nAdditional team members: Can join without any local R installation\n\nThe collaboration model emphasizes zero-setup team onboarding through self-replicating project distribution and containerized development environments.\n\nCollaboration Philosophy: - Self-contained projects: Each repository includes its own setup script - Container-first development: All work happens in identical Docker environments - Automated dependency validation: Pre-commit checks prevent conflicts - Shell-based workflows: Command-line tools for maximum flexibility\n\nKey Workflow Principles (Enhanced): - Joe creates team core images and automated infrastructure management - Team members install zzrrtools framework once for all future projects - All development occurs in enhanced containerized environments with professional tooling - Automated dependency validation and team image rebuilding prevents conflicts - Zero manual Docker management - GitHub Actions handles complete image lifecycle - Choice of development interface (shell-based vim or web-based RStudio)"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "href": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.2 Implementation Example",
    "text": "6.2 Implementation Example\n\n6.2.1 Project Maintainer Setup (Joe)\nJoe implements the enterprise-grade two-tier Docker strategy for team collaboration:\nStep 1: Create Team Core Images\n# 1. Set up project and team infrastructure\nmkdir penguins_analysis && cd penguins_analysis\nTEAM_NAME=\"rgt47\"  # Docker Hub account for hosting core images\nPROJECT_NAME=$(basename $(pwd))\n\n# 2. Create custom team core image configuration\ncp ~/bin/zzrrtools-support/templates/Dockerfile.pluspackages ./Dockerfile.teamcore\n\n# Edit Dockerfile.teamcore for Palmer Penguins analysis requirements:\n# - Add specialized R packages (palmerpenguins, tidymodels, plotly)\n# - Include statistical modeling packages (brms, rstanarm)\n# - Set team-specific R configurations and themes\n\n# 3. Build and publish team core images for reproducible science\n# Shell-optimized core (lightweight, fast startup)\ndocker build -f Dockerfile.teamcore --build-arg BASE_IMAGE=rocker/r-ver \\\n             -t ${TEAM_NAME}/${PROJECT_NAME}core-shell:v1.0.0 .\n\n# RStudio-optimized core (includes RStudio Server)\ndocker build -f Dockerfile.teamcore --build-arg BASE_IMAGE=rocker/rstudio \\\n             -t ${TEAM_NAME}/${PROJECT_NAME}core-rstudio:v1.0.0 .\n\n# 4. Push to Docker Hub for public reproducible research\ndocker login  # Login to Docker Hub\ndocker push ${TEAM_NAME}/${PROJECT_NAME}core-shell:v1.0.0\ndocker push ${TEAM_NAME}/${PROJECT_NAME}core-rstudio:v1.0.0\nStep 2: Initialize Research Compendium with Custom Base\n# 5. Initialize zzrrtools project using team core image\nzzrrtools --base-image ${TEAM_NAME}/${PROJECT_NAME}core-shell \\\n          --dotfiles ~/.config/shell\n\n# This automatically:\n# - Creates complete research compendium structure\n# - Builds LOCAL development image (inherits from core + adds dotfiles)\n# - Sets up automated GitHub Actions for team image rebuilds\n# - Configures CI/CD for dependency validation\n# - Local image NOT pushed - contains personal dotfiles\nStep 3: Initialize Repository and Automated Infrastructure\n# 6. Set up private GitHub repository for research code\ngit init\ngit add .\ngit commit -m \"ðŸŽ‰ Initial research project setup with automated team infrastructure\n\n- Complete zzrrtools research compendium\n- Team core images published: ${TEAM_NAME}/${PROJECT_NAME}core:v1.0.0\n- Automated GitHub Actions for team image management\n- Private repository protects unpublished research\n- Hybrid privacy model: private code, public environments\"\n\n# Create private repository on GitHub, then:\ngit remote add origin https://github.com/joe/penguins_analysis.git\ngit push -u origin main\nStep 4: Begin Development in Enhanced Environment\n# 7. Start development immediately in professional environment\nmake docker-zsh  # Enhanced zsh with vim IDE, dotfiles, and development tools\nThis creates: - Two-tier Docker architecture with team core + personal development images - Automated team image management via sophisticated GitHub Actions workflows - Professional development environment with vim IDE, zsh enhancements, and testing integration - Zero-setup team onboarding through pre-built, publicly available core images - Hybrid privacy model protecting research while enabling computational reproducibility\nFor detailed information on renv dependency validation, troubleshooting, and team collaboration workflows, see Appendix G: renv Management and Validation.\nThe validation script ensures package environment consistency by verifying dependencies across code files, DESCRIPTION, and renv.lock, preventing common collaboration issues where team members have mismatched environments.\nStep 4: Create Initial Analysis Paper\nJoe creates an initial analysis examining flipper length vs.Â bill length relationships in the Palmer Penguins dataset, implementing basic visualization and statistical exploration within the research compendium structure.\nStep 5: Create Tests for Analysis Functions\nJoe implements testing to ensure reproducible research through data validation, error detection, and environment verification. Testing provides collaboration confidence and supports publication standards by validating data integrity, statistical relationships, and pipeline functionality.\nJoe sets up the testing framework and creates basic data validation tests to verify dataset availability, dimensions, and required columns. These tests ensure the analysis environment is correctly configured and catch data-related issues early in the development process.\nFor a complete test suite with data validation, statistical tests, and integration tests, see Appendix B: Test Suite.\nStep 6: Create a .gitignore file\nJoe configures version control to track source code and dependencies while excluding generated outputs and temporary files. The principle: track the â€œrecipeâ€ (code + dependencies), not the â€œmealâ€ (outputs).\nJoe creates a .gitignore file excluding renv libraries, generated outputs, temporary files, and system artifacts. This keeps the repository lightweight while ensuring collaborators can recreate the complete environment from tracked dependencies.\nStep 7: Create a Dockerfile\nzzrrtools generates a Dockerfile with multiple template options. The standard template uses rocker/r-ver, while the pluspackages template includes common R packages like tidyverse. Both provide:\n\nR version consistency: Matches exact R version specified in renv.lock\nDevelopment environment: Includes zsh, vim, tmux, Node.js for plugin support\nSecurity: Non-root user execution with proper file permissions\nTinyTeX integration: LaTeX support for PDF rendering (pluspackages template)\nPre-installed packages: Common packages like tidyverse, DT, testthat (pluspackages template)\n\nThe generated Dockerfile includes development tools and optimizations:\nARG R_VERSION=latest\nFROM rocker/r-ver:${R_VERSION}\n\n# Install comprehensive development environment\nRUN apt-get update && apt-get install -y \\\n    git ssh curl wget vim tmux zsh build-essential \\\n    libcurl4-openssl-dev libssl-dev libxml2-dev \\\n    libfontconfig1-dev libharfbuzz-dev libfribidi-dev \\\n    libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev \\\n    man-db pandoc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Node.js for vim plugins\nRUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \\\n    apt-get install -y nodejs\n\n# Create non-root user with zsh shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set up R environment with renv\nWORKDIR /home/${USERNAME}/project\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nUSER ${USERNAME}\nRUN R -e \"install.packages('renv'); renv::restore()\"\n\n# Copy project files and install\nCOPY --chown=${USERNAME}:${USERNAME} . .\nRUN R -e \"devtools::install('.')\"\n\nCMD [\"/bin/zsh\"]\nAlternative: Pre-packaged Template\nFor projects using common packages, the pluspackages template includes TinyTeX and popular R packages:\n# Install TinyTeX for PDF rendering\nRUN R -e \"install.packages('tinytex')\" && \\\n    R -e \"tinytex::install_tinytex()\" && \\\n    /root/.TinyTeX/bin/*/tlmgr path add\n\n# Install common R packages (cached layer)\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', \\\n    'testthat', 'naniar', 'DT', 'conflicted', 'ggthemes', \\\n    'datapasta', 'janitor', 'kableExtra', 'tidytuesdayR', \\\n    'tidyverse'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Give user write permissions to R library\nRUN chown -R ${USERNAME}:${USERNAME} /usr/local/lib/R/site-library\nFor production Dockerfiles with development environment configuration (zsh, vim plugins, dotfiles integration), see Appendix F: Docker Configuration Examples.\nR Version Synchronization:\nThe Dockerfile uses a build argument to ensure the R version exactly matches whatâ€™s specified in renv.lock. This eliminates potential issues from R version mismatches between the package environment and the underlying R interpreter. The build command extracts the R version from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/joe/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment.\nStep 8: Container-Based Development\nJoe performs all development work inside the Docker container, ensuring consistent environments and immediate visibility of changes to the host system through volume mounting. The container provides a complete development environment with package management, editing tools, and validation utilities.\nStep 9: Update and Share Environment\nWhen package dependencies change, GitHub Actions automatically rebuilds the Docker image with updated renv.lock specifications and pushes the updated environment to Docker Hub for team access. This ensures collaborators have access to the identical development environment.\nStep 5: Automated Validation and Quality Assurance\nJoe validates the complete automated infrastructure:\n# 1. Validate all dependencies with automated checking\nmake docker-check-renv-fix\n\n# 2. Run comprehensive test suite in enhanced environment\nmake docker-test\n\n# 3. Render paper to verify end-to-end workflow\nmake docker-render\n\n# 4. Verify automated GitHub Actions workflows\n# - Push triggers team image rebuilding\n# - Dependency changes trigger notifications\n# - Multi-platform builds complete successfully\nStep 6: Enable Team Access and Documentation\nJoe configures repository permissions and documents the automated workflow:\n\nRepository Settings â†’ Collaborators â†’ Add team members with â€œWriteâ€ access\nConfigure repository secrets for automated Docker Hub publishing:\n\nDOCKERHUB_USERNAME: Team Docker Hub account\nDOCKERHUB_TOKEN: Docker Hub access token for automated publishing\n\nDocument team onboarding with zzrrtools installation and interface choices\nShare public Docker Hub images for reproducible research access\n\nAt this point, Joe has established an enterprise-grade automated research infrastructure. Team members can join with zero manual setup through the automated system.\n\n\n6.2.2 Team Member Onboarding (Sam)\nWhat Sam Receives from Joe: - Repository URL: https://github.com/joe/penguins_analysis - Public Docker Hub image names for core environments - Team development guidelines and interface choices\nSamâ€™s Streamlined Onboarding Process:\nðŸ“ Developer Checklist for Sam:\n\nInstall zzrrtools framework (one-time setup for all future projects)\nFork and clone project repository\nChoose development interface (shell vs RStudio)\nBuild personal development image with dotfiles\nStart development immediately\n\n# 1. One-time zzrrtools framework installation\ngit clone https://github.com/[OWNER]/zzrrtools.git ~/prj/zzrrtools\ncd ~/prj/zzrrtools\n./install.sh  # Adds zzrrtools command to system PATH\nzzrrtools --help  # Verify installation\n\n# 2. Fork and clone the project repository\ngit clone https://github.com/sam/penguins_analysis.git  # Sam's fork\ncd penguins_analysis\n\n# 3. Choose development interface and build personal environment\nPROJECT_NAME=$(basename $(pwd))\n\n# Option A: Shell-based development (vim, zsh, command-line)\nzzrrtools --base-image rgt47/${PROJECT_NAME}core-shell \\\n          --dotfiles ~/.config/shell\n\n# Option B: RStudio-based development (web interface)\n# zzrrtools --base-image rgt47/${PROJECT_NAME}core-rstudio \\\n#           --dotfiles ~/.config/shell\n\n# 4. Start development immediately (no setup required)\nmake docker-zsh      # Enhanced shell environment with vim IDE\n# OR\nmake docker-rstudio  # Web-based RStudio at localhost:8787\nKey Advantages for Sam:\n\nZero manual setup: Pre-built team core images eliminate environment configuration\nInstant productivity: Professional development environment ready immediately\nInterface choice: Select shell-based or web-based development as preferred\nAutomated synchronization: Future package updates happen transparently\nPersonal customization: Dotfiles integration maintains familiar development environment\n\nEnterprise Benefits for Sam:\n\nFramework reusability: One-time zzrrtools installation enables instant setup for all future research projects\nProfessional tooling: Complete vim IDE with R integration, zsh enhancements, and development shortcuts\nAutomated dependency management: Never worry about package conflicts or environment drift\nChoice and flexibility: Select development interface that matches personal workflow preferences\nZero infrastructure management: GitHub Actions handles all Docker image lifecycle automatically\n\nSam develops new analysis components within the enhanced containerized environment, with automated testing and validation ensuring quality and reproducibility.\nStep 4: Enhanced Development Environment Workflow\nSam works within the professional containerized development environment that includes:\nVim IDE Integration:\n# Inside the container (after make docker-zsh):\n\n# Multi-file development workflow\nvim -p R/analysis_functions.R scripts/02_body_mass_analysis.R analysis/paper/paper.Rmd\n# Opens multiple files in tabs for simultaneous editing\n\n# Vim + R integration workflow:\n:terminal                    # Open terminal in vim\nR                           # Start R session in terminal\n# devtools::load_all()       # Load package functions (in R)\n# source(\"scripts/02_body_mass_analysis.R\")  # Test scripts\n# quit()                     # Exit R, back to vim\n\n# Git workflow integration:\n:!git status                # Check git status from vim\n:!git add %                 # Add current file to git\n:!git commit -m \"Update analysis\"  # Commit changes\nTest-Driven Development Cycle:\n# 1. Write tests first (inside vim)\nvim tests/testthat/test-body_mass_functions.R\n# Write unit tests for new functions\n\n# 2. Write functions to pass tests\nvim R/body_mass_utils.R\n# Implement functions to satisfy test requirements\n\n# 3. Run tests from vim\n:!make docker-test          # Run all package tests from vim\n:terminal                   # Open terminal for interactive testing\nR                          # Start R in terminal\n# devtools::load_all()      # Load package functions\n# devtools::test()          # Run specific tests\n# testthat::test_dir(\"tests/integration\")  # Run integration tests\n# quit()                    # Exit R, back to vim\n\n# 4. Iterate until tests pass\n# Edit functions, run tests, repeat\nProject Navigation and File Management:\n# Enhanced file navigation in vim:\n:Explore                    # File browser\n:split scripts/data.R       # Split window editing\n:vsplit analysis/report.Rmd # Vertical split for manuscript\n\n# Multi-tab workflow:\n# gt (next tab), gT (previous tab)\n# Ctrl+w+w (switch windows)\n\n# Quick project navigation:\n# Symbolic links for easy access:\n# a â†’ analysis/, s â†’ scripts/, t â†’ tests/, r â†’ R/\nStep 5: Paper Integration and Testing\nSam integrates the new analysis into the research paper, combining Joeâ€™s original visualizations with the new body mass analysis. Sam also creates tests to validate the new functionality and ensure package dependencies are properly documented.\nStep 6: Validation and Quality Assurance\nSam creates tests for the new body mass analysis, validates data integrity and statistical relationships, then runs the complete test suite and verifies paper rendering to ensure no regressions before submission.\nStep 7: Professional Contribution Workflow\nWhen Sam completes the analysis iteration, the automated submission process follows these steps:\n\nAutomated dependency validation: Run make docker-check-renv-fix to ensure package consistency\nComprehensive test suite: Execute make docker-test to verify all tests pass\nPaper rendering validation: Run make docker-render to confirm analysis integrates properly\nProfessional commit workflow:\ngit add .\ngit commit -m \"Add body mass analysis with comprehensive testing\n\n- Implemented body mass prediction models using tidymodels\n- Added statistical validation tests for model performance\n- Integrated visualizations with existing Palmer Penguins analysis\n- All tests passing and paper renders successfully\"\ngit push origin feature/body-mass-analysis\nProfessional pull request: Submit detailed pull request with analysis impact assessment\nAutomated infrastructure updates: GitHub Actions automatically handles Docker image updates\n\nAutomated CI/CD Benefits:\n\nZero manual Docker management: GitHub Actions detects package changes and rebuilds team images automatically\nIntelligent change detection: Only rebuilds when actual dependencies change, saving time and resources\nMulti-platform support: Automatically builds for AMD64 and ARM64 architectures\nTeam notification: Detailed commit comments notify team of environment updates\nInstant synchronization: Other team members simply run docker pull team/project:latest for updated environment\n\nEnhanced Feedback Loop: If CI workflows fail, Sam receives detailed GitHub notifications with specific failure logs, automated suggestions for fixes, and clear next steps for resolution.\nSam commits the completed analysis, tests, and documentation to their feature branch and creates a cross-repository pull request to the original repository. This ensures proper code review and governance while maintaining clear attribution of contributions.\nAt this point, Sam has successfully contributed new analysis through the collaborative workflow. Joe reviews the pull request, tests the changes in the containerized environment, and merges the contribution while maintaining project governance and quality standards."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "href": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.3 Complete Handoff Workflow Summary",
    "text": "6.3 Complete Handoff Workflow Summary\nInitiating Developer (Joe) - Enterprise Setup: 1. Create team core images with domain-specific packages and publish to Docker Hub 2. Initialize zzrrtools research compendium with automated GitHub Actions infrastructure 3. Configure automated team image management with intelligent change detection 4. Set up hybrid privacy model: private code repository, public reproducible environments 5. Validate complete automated workflow with dependency checking and CI/CD 6. Grant team member repository access and document onboarding process 7. Share team core image names and development guidelines\nJoining Developer (Sam) - Streamlined Onboarding: 1. One-time zzrrtools framework installation: git clone + ./install.sh 2. Fork and clone project repository 3. Choose development interface (shell-based vim or web-based RStudio) 4. Build personal development image using team core: zzrrtools --base-image team/projectcore-shell 5. Start immediate development: make docker-zsh (professional environment ready) 6. Develop with enhanced vim IDE, automated testing, and dependency validation 7. Submit professional pull requests with automated infrastructure updates 8. Benefit from zero manual Docker management through GitHub Actions automation\nKey Success Factor: The containerized environment and centralized zzrrtools framework eliminate project-specific configuration requirements for team members after one-time framework installation."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "href": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.4 Collaboration Results",
    "text": "6.4 Collaboration Results\nThis workflow achieves: - Identical development environments across team members - Dependency validation preventing conflicts - Standardized project structure - Automated testing and CI/CD integration\nFor GitHub Actions setup instructions, workflow examples, and CI/CD configuration, see Appendix E: GitHub Actions CI/CD Setup.\nThe collaborative workflow demonstrated above illustrates the power of combining zzrrtools, renv, and Docker for reproducible research. However, successful implementation of this approach requires understanding both when itâ€™s most beneficial and how to apply it effectively. The following best practices and considerations provide guidance for teams considering this strategy."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.1 When to Use This Approach",
    "text": "7.1 When to Use This Approach\nThe zzrrtools + renv + Docker approach with testing is particularly valuable for:\n\nLong-term research projects where reproducibility over time is crucial\nCollaborative analyses with multiple contributors on different systems\nProduction analytical pipelines that need to run consistently\nAcademic publications where methods must be reproducible\nTeaching and education to ensure consistent student experiences\nComplex analyses that require testing to validate results"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "href": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.2 Tips for Efficient Implementation",
    "text": "7.2 Tips for Efficient Implementation\n\nKeep Docker images minimal: Include only whatâ€™s necessary for reproducibility.\nUse specific version tags: For both R packages and Docker base images, specify exact versions.\nDocument system requirements: Include notes on RAM and storage requirements.\nLeverage bind mounts: Mount local directories to containers for easier development.\nWrite meaningful tests: Focus on validating both data integrity and analytical results.\nTest regularly: Use CI/CD pipelines to run tests on every change.\nConsider computational requirements: Particularly for resource-intensive analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "href": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.3 Testing Strategies for R Analyses",
    "text": "7.3 Testing Strategies for R Analyses\nTesting data analysis code differs from traditional software testing but provides crucial value for reproducible research:\n\nData Validation Tests: Ensure data has the expected structure, types, and values.\nFunction Tests: Verify that custom functions work as expected with known inputs and outputs.\nEdge Case Tests: Check how code handles missing values, outliers, or unexpected inputs.\nIntegration Tests: Confirm that different parts of the analysis work correctly together.\nRegression Tests: Make sure new changes donâ€™t break existing functionality.\nOutput Validation: Verify that final results match expected patterns or benchmarks.\n\nWhile uncommon in traditional data analysis, these tests catch silent errors, validate assumptions, and provide confidence that analyses remain correct as code and data evolve."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "href": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.4 Potential Challenges",
    "text": "7.4 Potential Challenges\nSome challenges to be aware of:\n\nDocker image size: Images with many packages can become large\nLearning curve: Docker, renv, and testing frameworks require some initial learning\nSystem-specific features: Some analyses may rely on hardware features\nPerformance considerations: Containers may have different performance characteristics\nTest maintenance: Tests need to be updated as the analysis evolves"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.5 Troubleshooting Common Issues",
    "text": "7.5 Troubleshooting Common Issues\nDocker Build Failures: - Try: export DOCKER_BUILDKIT=0 (disable BuildKit) - Check Docker has sufficient memory/disk space - Ensure Docker is running and up to date\nPlatform Warnings on ARM64/Apple Silicon: - Use updated Makefile with --platform linux/amd64 flags - Or set: export DOCKER_DEFAULT_PLATFORM=linux/amd64\nPermission Errors in Container: - Rebuild image after copying dotfiles - Check file ownership in project directory\nPackage Name Errors: - Ensure directory name contains only letters/numbers/periods - Avoid underscores and special characters\nMissing Dotfiles in Container: - Use --dotfiles or --dotfiles-nodot flag during setup - Rebuild Docker image after adding dotfiles\nDespite these challenges, the benefits of reproducible research outweigh the implementation costs, particularly for collaborative and long-term projects. The approach described in this white paper provides a foundation for achieving reproducibility that meets the standards expected in data science and academic research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.1 Step-by-Step Token Creation",
    "text": "9.1 Step-by-Step Token Creation\n1. Navigate to GitHub Settings: - Go to GitHub.com and sign in - Click your profile picture (top right) â†’ Settings - In the left sidebar: Developer settings â†’ Personal access tokens\nNote: GitHub now offers two token types: - Fine-grained personal access tokens (recommended for new projects) - Personal access tokens (classic) (for broader compatibility)\n2. Create New Token: - Click â€œGenerate new tokenâ€ and select the appropriate type - Add a descriptive note (e.g., â€œDocker Container Registry Accessâ€) - Set expiration (recommended: 90 days for security)\n3. Select Required Scopes (check these boxes): - âœ… repo (Full control of private repositories) - Required for private repos - âœ… write:packages (Upload Docker images to GitHub Container Registry) - Required for project maintainer - âœ… read:packages (Download Docker images from GitHub Container Registry) - Required for all team members - âœ… delete:packages (Delete packages from GitHub Package Registry) - Optional but recommended\nNote: Team members only need read:packages and repo, but the project maintainer needs all container permissions to push Docker images.\nToken Type Recommendation: Use fine-grained personal access tokens for new projects as they provide better security and more precise permissions.\n4. Generate and Copy Token: - Click â€œGenerate tokenâ€ at the bottom - Important: Copy the token immediately - you wonâ€™t see it again - Store it securely (see security practices below)"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "href": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.2 Token Security Best Practices",
    "text": "9.2 Token Security Best Practices\n\nNever commit tokens to repositories - Use .gitignore to exclude files containing tokens\nUse environment variables - Store tokens in shell environment variables\nSet reasonable expiration dates - Use 30-90 day expiration for security\nRevoke unused tokens - Clean up tokens when no longer needed\nConsider GitHub CLI - Use gh auth login for easier management\nMonitor token usage - Check GitHub Settings â†’ Developer settings â†’ Personal access tokens for activity"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "href": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.3 Alternative: Using GitHub CLI",
    "text": "9.3 Alternative: Using GitHub CLI\nFor simpler token management, consider using GitHub CLI instead of manual tokens:\n# Install and authenticate (handles tokens)\ngh auth login --scopes write:packages,read:packages,repo\n\n# Login to container registry (works with gh auth)\necho $(gh auth token) | docker login ghcr.io \\\n  -u $(gh api user --jq .login) --password-stdin"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.4 Troubleshooting Common Issues",
    "text": "9.4 Troubleshooting Common Issues\nâ€œpermission_denied: The token provided does not match expected scopesâ€ - Verify your token includes write:packages and read:packages scopes - For private repositories, ensure repo scope is also selected - Create a new token with correct permissions if needed\nToken not recognized: - Ensure token is properly exported: export GITHUB_TOKEN=your_token_here - Verify token hasnâ€™t expired - Check that youâ€™re using the full token (starts with ghp_) 6. Horst, A.M., Hill, A.P., & Gorman, K.B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ 7. Marwick, B. (2016). Computational reproducibility in archaeological research: Basic principles and a case study of their implementation. Journal of Archaeological Method and Theory, 24(2), 424-473."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R",
    "text": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R\nlibrary(testthat)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\n# Test 1: Data Availability and Basic Structure\n# Generic application: Verify your primary dataset loads correctly and has \n# expected dimensions\n# Catches: Package loading issues, file path problems, corrupted data files\ntest_that(\"Palmer Penguins dataset is available and has correct structure\", \n          {\n  expect_true(exists(\"penguins\", where = \"package:palmerpenguins\"))\n  expect_s3_class(palmerpenguins::penguins, \"data.frame\")\n  expect_equal(ncol(palmerpenguins::penguins), 8)  # Adapt: Set expected \n                                                    # column count\n  expect_gt(nrow(palmerpenguins::penguins), 300)   # Adapt: Set minimum \n                                                    # row threshold\n  expect_equal(nrow(palmerpenguins::penguins), 344)  # Adapt: Set exact \n                                                      # expected count \n                                                      # if known\n})\n\n# Test 2: Required Columns Exist with Correct Types\n# Generic application: Ensure your analysis depends on columns that \n# actually \n# exist with correct types\n# Catches: Column name changes, type coercion issues, CSV import problems\ntest_that(\"Dataset contains required columns with expected data types\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Check column existence - Adapt: List columns your analysis requires\n  required_cols &lt;- c(\"species\", \"island\", \"bill_length_mm\", \n                     \"bill_depth_mm\", \"flipper_length_mm\", \n                     \"body_mass_g\", \"sex\", \"year\")\n  expect_true(all(required_cols %in% names(df)))\n  \n  # Check data types - Adapt: Verify types match your analysis \n  # expectations\n  expect_type(df$species, \"integer\")  # Factor stored as integer\n  expect_type(df$bill_length_mm, \"double\")  # Continuous measurements\n  expect_type(df$flipper_length_mm, \"integer\")  # Discrete measurements\n  expect_type(df$body_mass_g, \"integer\")  # Integer measurements\n})\n\n# Test 3: Categorical Variables Have Expected Levels\n# Generic application: Verify factor levels for categorical variables used\n# in \n# analysis\n# Catches: Missing categories, typos in factor levels, data encoding issues\ntest_that(\"Species factor has expected levels\", {\n  species_levels &lt;- levels(palmerpenguins::penguins$species)\n  expected_species &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")  # Adapt: Your \n                                                          # expected \n                                                          # categories\n  expect_equal(sort(species_levels), sort(expected_species))\n  expect_equal(length(species_levels), 3)  # Adapt: Expected number of \n                                           # categories\n  # For other datasets: Test treatment groups, regions, product types, etc.\n})\n\n# Test 4: Data Value Ranges are Domain-Reasonable\n# Generic application: Verify numeric values fall within realistic ranges\n# for \n# your domain\n# Catches: Data entry errors, unit conversion mistakes, outliers from \n# measurement errors\ntest_that(\"Measurement values fall within reasonable biological ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Bill length - Adapt: Set realistic bounds for your numeric variables\n  bill_lengths &lt;- df$bill_length_mm[!is.na(df$bill_length_mm)]\n  expect_true(all(bill_lengths &gt;= 30 & bill_lengths &lt;= 70))  # Penguin-\n                                                              # specific \n                                                              # range\n  \n  # Flipper length - Examples for other domains:\n  flipper_lengths &lt;- df$flipper_length_mm[!is.na(df$flipper_length_mm)]\n  expect_true(all(flipper_lengths &gt;= 150 & flipper_lengths &lt;= 250))\n  # Finance: stock prices &gt; 0, percentages 0-100\n  # Health: age 0-120, BMI 10-80, blood pressure 50-300\n  # Engineering: temperatures -273+Â°C, pressures &gt; 0\n  \n  # Body mass\n  body_masses &lt;- df$body_mass_g[!is.na(df$body_mass_g)]\n  expect_true(all(body_masses &gt;= 2000 & body_masses &lt;= 7000))\n})\n\n# Test 5: Missing Data Patterns are as Expected\n# Generic application: Verify missingness patterns match your data \n# collection \n# expectations\n# Catches: Unexpected data loss, systematic missingness, data pipeline \n# failures\ntest_that(\"Missing data follows expected patterns\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Total missing values should be manageable\n  total_na &lt;- sum(is.na(df))\n  expect_lt(total_na, nrow(df))  # Adapt: Set acceptable threshold for \n                                 # missing \n                                 # data\n  \n  # Some variables may have expected missingness\n  expect_gt(sum(is.na(df$sex)), 0)  # Sex determination sometimes difficult\n  # Adapt examples: Optional survey questions, historical data gaps, sensor \n  # failures\n  \n  # Critical variables should be complete\n  expect_equal(sum(is.na(df$species)), 0)  # Primary identifier must be \n                                           # complete\n  # Adapt: ID columns, primary keys, required fields should have no NAs\n})\n\n# Test 6: Expected Statistical Relationships Hold\n# Generic application: Test known relationships between variables in your \n# domain\n# Catches: Data corruption, encoding errors, units mix-ups that break known \n# patterns\ntest_that(\"Expected correlations between measurements exist\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test strong expected relationships\n  correlation &lt;- cor(df$flipper_length_mm, df$body_mass_g, \n                     use = \"complete.obs\")\n  expect_gt(correlation, 0.8)  # Strong positive correlation expected\n  # Adapt examples: height vs weight, price vs quality, experience vs salary\n  \n  # Test weaker but expected relationships\n  bill_cor &lt;- cor(df$bill_length_mm, df$bill_depth_mm, use = \"complete.obs\")\n  expect_gt(abs(bill_cor), 0.1)  # Some relationship should exist\n  # Adapt: Education vs income, advertising vs sales, temperature vs \n  # energy use\n})\n\n# Test 7: Visualization Functions Work Correctly\n# Generic application: Ensure your key plots and visualizations can be \n# generated\n# Catches: Missing aesthetic mappings, incompatible data types, package \n# conflicts\ntest_that(\"Basic plots can be generated without errors\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test basic plot creation without errors\n  expect_no_error({\n    p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      theme_minimal()\n  })\n  # Adapt: Test your key plot types - histograms, boxplots, time series,\n  # etc.\n  \n  # Test that plot object is properly created\n  p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n    geom_point()\n  expect_s3_class(p1, \"ggplot\")  # Adapt: Check for your plotting \n                                   # framework objects\n})\n\n# Test 8: Data Filtering and Subsetting Work Correctly\n# Generic application: Verify data manipulation operations produce expected\n# results\n# Catches: Logic errors in filtering, unexpected factor behaviors, \n# indexing mistakes\ntest_that(\"Data can be properly filtered and subsetted\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test categorical filtering\n  adelie_penguins &lt;- df[df$species == \"Adelie\" & !is.na(df$species), ]\n  expect_gt(nrow(adelie_penguins), 100)  # Adapt: Expected subset size\n  expect_true(all(adelie_penguins$species == \"Adelie\", na.rm = TRUE))\n  # Adapt: Filter by treatment groups, regions, time periods, etc.\n  \n  # Test missing data handling\n  complete_cases &lt;- df[complete.cases(df), ]\n  expect_lt(nrow(complete_cases), nrow(df))  # Some rows should be removed\n  expect_equal(sum(is.na(complete_cases)), 0)  # No NAs remaining\n  # Adapt: Test your specific data cleaning operations\n})\n\n# Test 9: Summary Statistics are Reasonable\n# Generic application: Verify computed statistics match domain knowledge \n# expectations\n# Catches: Calculation errors, unit mistakes, algorithm bugs, extreme \n# outliers\ntest_that(\"Summary statistics fall within expected ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test means fall within expected ranges\n  mean_flipper &lt;- mean(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(mean_flipper, 190)  # Adapt: Set realistic bounds for your \n                                # variables\n  expect_lt(mean_flipper, 210)\n  # Examples: Average customer age 20-80, mean salary $30k-200k, etc.\n  \n  # Test other central tendencies\n  mean_mass &lt;- mean(df$body_mass_g, na.rm = TRUE)\n  expect_gt(mean_mass, 4000)\n  expect_lt(mean_mass, 5000)\n  \n  # Test variability measures are reasonable\n  sd_flipper &lt;- sd(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(sd_flipper, 5)   # Not zero variance\n  expect_lt(sd_flipper, 30)  # Not excessive variance\n  # Adapt: CV should be &lt;50%, SD should be meaningful relative to mean\n})\n\n# Test 10: Complete Analysis Pipeline Integration Test\n# Generic application: Test your entire analysis workflow runs without \n# errors\n# Catches: Pipeline breaks, dependency issues, function interaction problems\ntest_that(\"Complete analysis pipeline executes successfully\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test that full workflow executes without errors\n  expect_no_error({\n    # Data preparation step\n    clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                       \"bill_length_mm\")]), ]\n    \n    # Statistical analysis step - Adapt: Your key analyses\n    correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                   clean_df$bill_length_mm)\n    \n    # Visualization step - Adapt: Your key plots\n    plot_result &lt;- ggplot(clean_df, \n                          aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      geom_smooth(method = \"lm\") +\n      theme_minimal() +\n      labs(title = \"Flipper Length vs. Bill Length\",\n           x = \"Flipper Length (mm)\",\n           y = \"Bill Length (mm)\")\n  })\n  # Adapt: Add model fitting, prediction, reporting steps as needed\n  \n  # Verify analysis produces meaningful results\n  clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                     \"bill_length_mm\")]), ]\n  correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                 clean_df$bill_length_mm)\n  expect_lt(correlation_result$p.value, 0.05)  # Significant result expected\n  # Adapt: Check model RÂ², prediction accuracy, convergence, etc.\n})"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "href": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.6 Running the Tests",
    "text": "9.6 Running the Tests\nTo run all tests in your project:\n# Run all tests\ntestthat::test_dir(\"tests/testthat\")\n\n# Run specific test file\ntestthat::test_file(\"tests/testthat/test-comprehensive-analysis.R\")\n\n# Run tests with detailed output\ntestthat::test_dir(\"tests/testthat\", reporter = \"detailed\")"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.7 Test Categories Explained",
    "text": "9.7 Test Categories Explained\nData Validation Tests (1-5): Verify data structure, types, ranges, and missing patterns Statistical Tests (6): Confirm expected relationships in the data Functional Tests (7-8): Ensure analysis functions work correctly Sanity Tests (9): Check that summary statistics are reasonable Integration Tests (10): Verify the complete analysis pipeline works end-to-end\nThese tests provide coverage for a data analysis project and can catch issues ranging from data corruption to environment setup problems."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.8 Key Features Explained:",
    "text": "9.8 Key Features Explained:\nData Organization: - raw_data/: Original, unmodified datasets as received - derived_data/: Processed, cleaned, or transformed data - metadata/: Documentation about data sources, collection methods, variables - validation/: Scripts that verify data integrity and quality - external_data/: Third-party datasets or reference data\nMultiple Output Formats: - figures/: Generated plots, charts, and visualizations - tables/: Generated summary tables and statistical results - paper/: Main manuscript and analysis documents - templates/: Document templates and citation style files\nR Package Structure: - R/: Custom functions and utilities - man/: Generated documentation for R functions - tests/testthat/: Unit tests and validation scripts - vignettes/: Long-form documentation and tutorials - DESCRIPTION: Package metadata and dependency specifications\nDocker Orchestration: - Dockerfile: Main container specification - docker-compose.yml: Multi-service development environments - Makefile: Build automation supporting both native R and Docker workflows\nWorkflows: - .github/workflows/: GitHub Actions for testing, checking, and rendering - setup_renv.R: Package environment setup - RRTOOLS_USER_GUIDE.md: Usage documentation\nNavigation Shortcuts: - Symbolic links: Single-letter shortcuts for easy navigation - a â†’ analysis/, n â†’ analysis/, f â†’ figures/ - t â†’ tests/, s â†’ scripts/, m â†’ man/ - e â†’ external_data/, o â†’ output/, c â†’ cache/\nThis structure supports research projects while maintaining clear organization and following established research compendium principles."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.9 Multi-Service Docker Architecture",
    "text": "9.9 Multi-Service Docker Architecture\nzzrrtools creates specialized Docker environments for different development tasks:\n# Build the containerized research environment\nmake docker-build\n\n# Interactive R console (primary development environment)\nmake docker-r\n\n# Development shell with personal dotfiles\nmake docker-zsh\n\n# Interactive bash session\nmake docker-bash\n\n# RStudio Server (web-based IDE)\nmake docker-rstudio    # Access at http://localhost:8787\n\n# Render research paper\nmake docker-render\n\n# Run tests\nmake docker-test\n\n# Package checking\nmake docker-check\n\n# renv dependency validation\nmake docker-check-renv-fix\n\n# See all available commands\nmake help\nCollaborative Benefits: - Zero-setup onboarding: Team members run identical commands - Consistent environments: Same container across all developer machines - ARM64/Apple Silicon support: Platform-specific flags ensure compatibility - Shell-optimized workflows: Command-line development with rich tooling - Personal customization: Dotfiles integration for familiar environments - Web-based development: Optional RStudio Server for GUI-based workflows"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.10 Option 2: Docker Compose Services",
    "text": "9.10 Option 2: Docker Compose Services\nDocker Compose orchestrates multiple container configurations:\n# Interactive R session\ndocker-compose run --rm r-session\n\n# Bash shell access\ndocker-compose run --rm bash\n\n# Automated paper rendering\ndocker-compose run --rm research\n\n# Package testing\ndocker-compose run --rm test\n\n# Package checking\ndocker-compose run --rm check\nDocker Compose Configuration Example:\nservices:\n  r-session:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./cache:/home/analyst/cache\n    working_dir: /home/analyst/project\n    \n  bash:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n    working_dir: /home/analyst/project\n    entrypoint: [\"/bin/bash\"]\n    \n  research:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./analysis/figures:/home/analyst/output\n    working_dir: /home/analyst/project\n    command: [\"R\", \"-e\", \"rmarkdown::render('analysis/paper/paper.Rmd')\"]\nBenefits: - Service setup: Multiple predefined container configurations - Volume management: Consistent volume mounting across services - Environment isolation: Different services for different purposes - Parallel execution: Can run multiple services simultaneously"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.11 Option 3: Direct Docker Commands",
    "text": "9.11 Option 3: Direct Docker Commands\nFor maximum control, use Docker commands directly:\n# Basic interactive session\ndocker run --rm -it -v \"$(pwd):/home/analyst/project\" \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Interactive session with mounted cache\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/cache:/home/analyst/cache\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Render research paper\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/analysis/figures:/home/analyst/output\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n\n# Run specific tests\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"testthat::test_file('tests/testthat/test-data-integrity.R')\"\n\n# Interactive bash session\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  /bin/bash\nCommon Docker Flags Explained: - --rm: Remove container when it exits - -it: Interactive terminal session - -v: Mount volume (host:container) - -w: Set working directory inside container - --entrypoint: Override default command\nBenefits: - Full flexibility: Complete control over container configuration - Educational: Shows exactly whatâ€™s happening under the hood - Troubleshooting: Easier to debug when you see all options - Portability: Commands work on any Docker installation"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "href": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.12 Volume Mounting Strategies",
    "text": "9.12 Volume Mounting Strategies\nProject Files:\n# Mount entire project directory\n-v \"$(pwd):/home/analyst/project\"\nOutput Separation:\n# Separate outputs from source\n-v \"$(pwd)/analysis/figures:/home/analyst/output\"\nCache Persistence:\n# Persistent package cache across sessions\n-v \"$(pwd)/cache:/home/analyst/cache\"\nRead-only Source:\n# Protect source files from modification\n-v \"$(pwd):/home/analyst/project:ro\""
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.13 Choosing the Right Approach",
    "text": "9.13 Choosing the Right Approach\nUse Make Commands When: - You want simplicity and consistency - Youâ€™re new to Docker - Youâ€™re focusing on analysis rather than infrastructure\nUse Docker Compose When: - You need multiple service configurations - Youâ€™re working with a team using standardized environments - You want to define complex volume and networking setups\nUse Direct Commands When: - You need maximum flexibility - Youâ€™re troubleshooting container issues - Youâ€™re creating custom workflows not covered by Make targets\nAll three approaches can be used together in the same project, depending on the specific task and user preferences."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "href": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.14 Understanding GitHub Actions for Research",
    "text": "9.14 Understanding GitHub Actions for Research\nWhat is CI/CD for Research?\nContinuous Integration/Continuous Deployment (CI/CD) tests your research code whenever changes are made. For research compendia, this means:\n\nTesting: Every push triggers your test suite\nEnvironment consistency: Tests run in identical Docker environments\nEarly error detection: Problems caught during development\nCollaboration confidence: Team members see if changes break functionality\nReproducibility validation: Ensures analysis works across different systems"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.15 Step-by-Step Setup",
    "text": "9.15 Step-by-Step Setup\n\n9.15.1 Step 1: Create Workflow Directory\n# Create the GitHub Actions directory\nmkdir -p .github/workflows\n\n\n9.15.2 Step 2: Docker-based CI Workflow with renv Validation\nCreate .github/workflows/docker-ci.yml:\nname: Docker CI with renv Validation\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  build-and-test:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      \n    - name: Set up R for renv validation\n      uses: r-lib/actions/setup-r@v2\n      with:\n        r-version: 'release'\n        \n    - name: Install renv for validation\n      run: |\n        install.packages(\"renv\")\n      shell: Rscript {0}\n        \n    - name: Validate renv consistency before Docker build\n      run: |\n        # Validate renv environment before building Docker image\n        Rscript check_renv_for_commit.R --fail-on-issues --quiet\n      \n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      \n    - name: Extract R version from renv.lock\n      id: r-version\n      run: |\n        R_VERSION=$(Rscript -e \"cat(renv::lockfile_read()\\$R\\$Version)\")\n        echo \"r-version=${R_VERSION}\" &gt;&gt; $GITHUB_OUTPUT\n      \n    - name: Build Docker image\n      uses: docker/build-push-action@v5\n      with:\n        context: .\n        push: false\n        tags: ${{ github.repository }}:latest\n        build-args: |\n          R_VERSION=${{ steps.r-version.outputs.r-version }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        \n    - name: Run tests in container\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          ${{ github.repository }}:latest \\\n          R -e \"testthat::test_dir('tests/testthat')\"\n          \n    - name: Render research paper\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          -v $PWD/analysis/figures:/home/analyst/output \\\n          ${{ github.repository }}:latest \\\n          R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n          \n    - name: Upload rendered paper\n      uses: actions/upload-artifact@v4\n      if: success()\n      with:\n        name: research-paper\n        path: analysis/paper/paper.pdf\n\n\n9.15.3 Step 3: R Package Check Workflow\nCreate .github/workflows/r-package.yml:\nname: R Package Check\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n    \n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n    \n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: macOS-latest,    r: 'release'}\n          - {os: windows-latest,  r: 'release'}\n    \n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: r-lib/actions/setup-pandoc@v2\n      \n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n          \n      - uses: r-lib/actions/setup-renv@v2\n      \n      - name: Install system dependencies\n        if: runner.os == 'Linux'\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y \\\n            libcurl4-openssl-dev \\\n            libssl-dev \\\n            libxml2-dev\n            \n      - name: Validate renv consistency\n        run: |\n          # Use the renv validation script included in the repository\n          Rscript check_renv_for_commit.R --fail-on-issues --quiet\n            \n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n9.15.4 Step 4: Automated Paper Rendering\nCreate .github/workflows/render-paper.yml:\nname: Render Research Paper\n\non:\n  workflow_dispatch:  # Manual trigger\n  push:\n    branches: [ main, master ]\n    paths:\n      - 'analysis/paper/**'\n      - 'analysis/data/**'\n      - 'R/**'\n      - 'data/**'\n\njobs:\n  render:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Build Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: false\n          tags: paper-render:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          \n      - name: Render paper in container\n        run: |\n          docker run --rm \\\n            -v $PWD:/home/analyst/project \\\n            -v $PWD/analysis/figures:/home/analyst/output \\\n            paper-render:latest \\\n            R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n            \n      - name: Upload rendered paper\n        uses: actions/upload-artifact@v4\n        with:\n          name: research-paper-${{ github.sha }}\n          path: |\n            analysis/paper/paper.pdf\n            analysis/figures/*.png\n            analysis/figures/*.jpg\n          retention-days: 30\n\n\n9.15.5 Step 5: Container Registry Integration\nCreate .github/workflows/container-publish.yml:\nname: Build and Push Container\n\non:\n  push:\n    branches: [ main ]\n    tags: [ 'v*' ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n      \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Log in to Container Registry\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n          \n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            \n      - name: Build and push Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          platforms: linux/amd64,linux/arm64\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "href": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.16 Workflow Explanations",
    "text": "9.16 Workflow Explanations\n\n9.16.1 Docker CI Workflow Features:\n\nPre-build renv Validation: Validates package dependency consistency before Docker build (prevents build failures)\nDynamic R Version: Extracts R version from renv.lock and passes it to Docker build\nBuild Testing: Ensures Docker image builds with latest changes using correct R version\nTesting: Runs R package tests and renders paper in container\nArtifact Generation: Saves rendered papers as downloadable artifacts\nCaching: Uses GitHub Actions cache for faster builds\nEarly Failure: Stops pipeline if dependency issues are detected\n\n\n\n9.16.2 R Package Check Features:\n\nMulti-platform Testing: Tests on Ubuntu, macOS, and Windows\nR CMD Check: Package validation\nrenv Integration: Restores package environment\nrenv Consistency Validation: Verifies dependency synchronization across platforms\nSystem Dependencies: Installs required system libraries\n\n\n\n9.16.3 Paper Rendering Features:\n\nSelective Triggering: Only runs when relevant files change\nManual Execution: Can be triggered manually via GitHub interface\nArtifact Storage: Saves PDFs and figures with retention policy\nPath-based Triggers: Responds to changes in analysis files\n\n\n\n9.16.4 Container Publishing Features:\n\nBuilding: Builds on pushes and tags\nMulti-platform: Supports AMD64 and ARM64 platforms\nSemantic Versioning: Tagging based on git tags\nSecurity: Uses built-in GitHub token for authentication"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "href": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.17 Authentication and Permissions",
    "text": "9.17 Authentication and Permissions\n\n9.17.1 Built-in GITHUB_TOKEN:\nThe built-in GITHUB_TOKEN automatically provides: - Read access to repository contents - Write access to GitHub Packages (when permissions are set) - No manual setup required\n\n\n9.17.2 Setting Repository Permissions:\n\nRepository Settings â†’ Actions â†’ General\nWorkflow permissions: Choose â€œRead and write permissionsâ€\nAllow GitHub Actions to create and approve pull requests: Enable if needed\n\n\n\n9.17.3 Using Personal Access Tokens (Advanced):\nFor broader permissions, create repository secrets:\n\nRepository Settings â†’ Secrets and variables â†’ Actions\nNew repository secret: Add GHCR_TOKEN with Personal Access Token\nReference in workflow: password: ${{ secrets.GHCR_TOKEN }}"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.18 Integration with Collaborative Workflow",
    "text": "9.18 Integration with Collaborative Workflow\n\n9.18.1 Pull Request Integration:\nWhen a team member submits a pull request: 1. GitHub automatically triggers CI workflows 2. Tests run in clean environment identical to production 3. Results displayed directly in pull request interface 4. Merge can be blocked if tests fail\n\n\n9.18.2 Branch Protection Rules:\nEnable in Repository Settings â†’ Branches: - Require status checks: Force CI to pass before merging - Require branches to be up to date: Ensure latest code is tested - Include administrators: Apply rules to all users"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "href": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.19 Monitoring and Troubleshooting",
    "text": "9.19 Monitoring and Troubleshooting\n\n9.19.1 Viewing Workflow Results:\n\nRepository â†’ Actions tab\nClick specific workflow run to see details\nExpand steps to see detailed logs\nDownload artifacts (rendered papers, test results)\n\n\n\n9.19.2 Common Issues and Solutions:\nDocker Build Failures: - Check Dockerfile syntax - Verify all COPY paths exist - Ensure base image is accessible\nrenv Restore Failures: - Verify renv.lock is committed - Check for platform-specific packages - Consider using RSPM for faster installs\nPermission Errors: - Verify GITHUB_TOKEN permissions - Check repository secrets configuration - Ensure workflows have necessary permissions\n\n\n9.19.3 Performance Optimization:\nCaching Strategies: - Docker layer caching with cache-from/cache-to - renv package caching with r-lib/actions/setup-renv - Artifact caching for large datasets\nParallel Execution: - Run tests and documentation in parallel jobs - Use matrix strategies for multi-platform testing - Conditional execution based on changed files\nThis CI/CD setup ensures that research compendia remain reproducible, tested, and deployment-ready throughout the development lifecycle."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.20 Production Dockerfile",
    "text": "9.20 Production Dockerfile\nThe following Dockerfile provides a development environment with zsh, vim plugins, dotfiles integration, and development tools:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Install system dependencies including zsh and development tools\nRUN apt-get update && apt-get install -y \\\n    libxml2-dev \\\n    libcurl4-openssl-dev \\\n    libssl-dev \\\n    libgit2-dev \\\n    libfontconfig1-dev \\\n    libcairo2-dev \\\n    libxt-dev \\\n    pandoc \\\n    zsh \\\n    curl \\\n    git \\\n    fonts-dejavu \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user with zsh as default shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set working directory\nWORKDIR /home/${USERNAME}/project\n\n# Copy project files first (for better Docker layer caching)\nCOPY --chown=${USERNAME}:${USERNAME} DESCRIPTION .\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock* ./\nCOPY --chown=${USERNAME}:${USERNAME} .Rprofile* ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R* renv/activate.R\n\n# Configure renv library path\nENV RENV_PATHS_LIBRARY renv/library\n\n# Switch to non-root user for R package installation\nUSER ${USERNAME}\n\n# Install renv and essential R packages\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', 'knitr', \\\n    'rmarkdown'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Restore R packages from lockfile (if exists)\nRUN R -e \"if (file.exists('renv.lock')) renv::restore() else \\\n    cat('No renv.lock found, skipping restore\\\\n')\"\n\n# Copy dotfiles for development environment\n# Note: Ensure .vimrc and .zshrc_docker exist in build context or create \n# defaults\nCOPY --chown=${USERNAME}:${USERNAME} .vimrc /home/${USERNAME}/.vimrc\nCOPY --chown=${USERNAME}:${USERNAME} .zshrc_docker /home/${USERNAME}/.zshrc\n\n# Install zsh plugins for shell experience\nRUN mkdir -p /home/${USERNAME}/.zsh && \\\n    git clone https://github.com/zsh-users/zsh-autosuggestions \\\n        /home/${USERNAME}/.zsh/zsh-autosuggestions && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.zsh\n\n# Install vim-plug and configure vim environment\nRUN mkdir -p /home/${USERNAME}/.vim/autoload && \\\n    curl -fLo /home/${USERNAME}/.vim/autoload/plug.vim \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.vim\n\n# Install vim plugins (suppress interactive mode)\nRUN vim +PlugInstall +qall || true\n\n# Copy rest of project\nCOPY --chown=${USERNAME}:${USERNAME} . .\n\n# Install the research compendium as a package\nRUN R -e \"devtools::install('.', dependencies = TRUE)\"\n\n# Set default shell to zsh for development experience\nWORKDIR /home/${USERNAME}/project\nCMD [\"/bin/zsh\"]"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.21 Features of the Production Dockerfile",
    "text": "9.21 Features of the Production Dockerfile\nThis production-ready Dockerfile provides:\n\nR version consistency: Matches exact R version specified in renv.lock for perfect environment alignment\nMinimal base: rocker/r-ver provides clean R installation without unnecessary packages\nShell environment: zsh with autosuggestions and professional prompt for improved productivity\nEditor environment: vim with plugins configured automatically during build\nDotfiles integration: Personal development preferences (.vimrc, .zshrc) copied from host system\nDevelopment tools: git, curl, pandoc, and essential development libraries pre-installed\nSecurity: Non-root user execution with proper file permissions\nrenv integration: Automatic package restoration with proper library path configuration\nContainer-optimized workflow: Optimized layer caching and build process for efficient rebuilds"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "href": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.22 R Version Extraction",
    "text": "9.22 R Version Extraction\nThe Dockerfile uses a build argument to ensure the R version exactly matches whatâ€™s specified in renv.lock. The build command extracts the R version directly from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/username/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "href": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.23 renv Consistency Checker Features",
    "text": "9.23 renv Consistency Checker Features\nThe check_renv_for_commit.R script provides advanced team collaboration features through dependency validation:\n\nTeam conflict prevention: Pre-commit validation stops dependency inconsistencies before they reach the repository\nAutomated dependency discovery: Scans R/, scripts/, and analysis/ directories for library(), require(), and pkg:: calls\nMulti-source synchronization: Ensures packages are consistent across code files, DESCRIPTION, and renv.lock\nCRAN validation: Verifies packages exist and are properly named before team integration\nAutomatic fixing: Updates DESCRIPTION and regenerates renv.lock to maintain team synchronization\nCI/CD fail-fast: Provides proper exit codes for automated workflows\nInteractive collaboration mode: Guides developers through dependency resolution during development"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.24 Team Collaboration Commands",
    "text": "9.24 Team Collaboration Commands\n# Team development workflow (via Make)\nmake check-renv          # Interactive dependency checking\nmake check-renv-fix      # Auto-fix dependency issues\nmake check-renv-ci       # CI/CD validation with fail-fast\n\n# Docker-based validation (no local R required)\nmake docker-check-renv-fix  # Fix dependencies in container\n\n# Direct script usage\nRscript check_renv_for_commit.R --fix --fail-on-issues  # CI mode\nRscript check_renv_for_commit.R --quiet                 # Minimal output\nRscript check_renv_for_commit.R --help                  # Usage info"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.25 Multi-Developer Workflow",
    "text": "9.25 Multi-Developer Workflow\n\nInstall packages in container: Use install.packages() or renv::install() within Docker environment\nValidate team dependencies: Run make check-renv to check for conflicts before committing\nReview team impacts: Script identifies packages that would affect other team members\nSynchronize team environment: Use make check-renv-fix to update shared dependency files\nCommit with team confidence: Other developers can reproduce your exact environment"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.26 Integration with Development Workflows",
    "text": "9.26 Integration with Development Workflows\n\n9.26.1 Pre-commit Hooks\n# Add to .git/hooks/pre-commit\nRscript check_renv_for_commit.R --fail-on-issues --quiet\n\n\n9.26.2 Makefile Integration\ncheck-renv:\n    Rscript check_renv_for_commit.R\n\ncheck-renv-fix:\n    Rscript check_renv_for_commit.R --fix\n\ncheck-renv-ci:\n    Rscript check_renv_for_commit.R --quiet --fail-on-issues\n\n\n9.26.3 CI/CD Integration\n- name: Validate renv consistency\n  run: Rscript check_renv_for_commit.R --fail-on-issues --quiet\nThis approach ensures that collaborators can reliably reproduce your package environment and that CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html",
    "href": "posts/table_placement_rmarkdown/index.html",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "href": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "href": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "href": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#further-reading",
    "href": "posts/table_placement_rmarkdown/index.html#further-reading",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "References",
    "section": "",
    "text": "Quick reference materials for when you need answers fast. These living documents are continuously updated and expanded based on real-world usage.\nFind: - Command cheat sheets - Configuration templates - Common patterns and snippets - Troubleshooting checklists - Best practices summaries\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nCategories\n\n\nDescription\n\n\n\n\n\n\nR Commands Quick Reference\n\n\nR, reference, cheatsheet\n\n\nQuick lookup table of commonly used R commands for data manipulation, visualization, and analysis.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/r-package-development-basics.html",
    "href": "research/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#learning-objectives",
    "href": "research/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#prerequisites",
    "href": "research/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-2-create-package-structure",
    "href": "research/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-4-generate-documentation",
    "href": "research/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-5-testing",
    "href": "research/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-6-package-checks",
    "href": "research/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "research/r-package-development-basics.html#next-steps",
    "href": "research/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "research/r-package-development-basics.html#resources",
    "href": "research/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html",
    "href": "teaching/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-importexport",
    "href": "teaching/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "href": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#string-operations",
    "href": "teaching/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#package-management",
    "href": "teaching/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#workspace-management",
    "href": "teaching/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "href": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#missing-values",
    "href": "teaching/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#quick-tips",
    "href": "teaching/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html",
    "href": "tutorials/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#learning-objectives",
    "href": "tutorials/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#prerequisites",
    "href": "tutorials/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "href": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "href": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-5-testing",
    "href": "tutorials/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "href": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#next-steps",
    "href": "tutorials/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#resources",
    "href": "tutorials/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html",
    "href": "tutorials/git-setup-guide/index.html",
    "title": "Setting up git for (solo) data science workflow",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#prerequisites",
    "href": "tutorials/git-setup-guide/index.html#prerequisites",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "href": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#key-takeaways",
    "href": "tutorials/git-setup-guide/index.html#key-takeaways",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#further-reading",
    "href": "tutorials/git-setup-guide/index.html#further-reading",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "white-papers/index-old.html",
    "href": "white-papers/index-old.html",
    "title": "White Papers",
    "section": "",
    "text": "All Categories\n        Research Methodology\n        Statistical Computing\n        Data Science\n        Technical Infrastructure\nThese white papers represent in-depth technical analyses, methodological frameworks, and implementation guides developed for research and statistical computing applications. Each document provides detailed specifications, best practices, and reproducible workflows."
  },
  {
    "objectID": "white-papers/index-old.html#research-methodology-workflows",
    "href": "white-papers/index-old.html#research-methodology-workflows",
    "title": "White Papers",
    "section": "1 Research Methodology & Workflows",
    "text": "1 Research Methodology & Workflows\n\n1.1 Mac Workflow for Tracking Daily Research Progress\nA comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF\n\n\n\n1.2 Setting Up a Comprehensive Research Backup System on macOS\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF"
  },
  {
    "objectID": "white-papers/index-old.html#statistical-computing-development",
    "href": "white-papers/index-old.html#statistical-computing-development",
    "title": "White Papers",
    "section": "2 Statistical Computing & Development",
    "text": "2 Statistical Computing & Development\n\n2.1 RCT Validation Language\nSpecification for a domain-specific programming language designed to capture clinical trial database validation logic, with compilation targets for Lua and JavaScript.\nClinical trials Programming languages Data validation DSL design\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF\n\n\n\n2.2 Setting up an R Development Environment on GitHub\nBest practices and step-by-step methodology for establishing reproducible R package development workflows using GitHub integration and continuous integration.\nR development GitHub Package development CI/CD\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF"
  },
  {
    "objectID": "white-papers/index-old.html#data-science-applications",
    "href": "white-papers/index-old.html#data-science-applications",
    "title": "White Papers",
    "section": "3 Data Science Applications",
    "text": "3 Data Science Applications\n\n3.1 Making Optimal Use of ChatGPT and Other Chatbots for Data Science\nEvaluation framework and practical guidelines for integrating large language models into data science workflows, including prompt engineering and quality assessment.\nAI tools Data science LLM integration Prompt engineering\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF\n\n\n\n3.2 Minimalist EDC Application Framework\nTechnical architecture for building lightweight electronic data capture systems for clinical research, emphasizing simplicity and regulatory compliance.\nEDC systems Clinical research Software architecture Regulatory compliance\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF"
  },
  {
    "objectID": "white-papers/index-old.html#technical-infrastructure",
    "href": "white-papers/index-old.html#technical-infrastructure",
    "title": "White Papers",
    "section": "4 Technical Infrastructure",
    "text": "4 Technical Infrastructure\n\n4.1 Containerized R Analysis Workflows with Docker\nImplementation guide for reproducible R analysis environments using Docker containerization, including best practices for sharing and deployment.\nDocker Reproducibility R environment Containerization\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF\n\n\n\n4.2 AWS Server Configuration for Research Computing\nComprehensive guide for setting up and configuring AWS instances for statistical computing and research data analysis.\nAWS Cloud computing Server configuration Research computing\n\nðŸ”— Full Report â€¢ ðŸ“„ PDF"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html",
    "href": "tutorials/docker-for-beginners/index.html",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#introduction",
    "href": "tutorials/docker-for-beginners/index.html#introduction",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis guide demonstrates how to deploy a Shiny application from your local workstation to a secure web environment. Weâ€™ll use a stack of open-source technologies including Linux, R, Shiny, Docker, and Caddy, deployed on AWS EC2. While we focus on AWS here, the principles apply to other cloud providers like Hetzner, which weâ€™ll cover in future posts."
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#prerequisites",
    "href": "tutorials/docker-for-beginners/index.html#prerequisites",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore beginning this tutorial, youâ€™ll need:\n\nA working Shiny application on your local machine\nAn AWS account with permissions to create EC2 instances\nBasic familiarity with the Linux command line\nGit (optional, for version control)"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#the-example-application",
    "href": "tutorials/docker-for-beginners/index.html#the-example-application",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "3 The Example Application",
    "text": "3 The Example Application\nLetâ€™s start with a simple but practical example: hosting a shiny web application that provides a power calculator for two-sample t-tests. While straightforward, this application demonstrates all the key deployment concepts.\nHere is the code for the Shiny app (The app is intentionally minimal, using only base R functions, with a minimum of reactive widgets and layout commands.):\n\nPower Calculator Shiny App Code (power1_shiny/app.R)\nui &lt;- fluidPage(\n  titlePanel(\"Power Calculator for Two Group Parallel Designs\"),\n  sliderInput(\"N\", \"Total Sample Size:\", min = 0, max = 300, value = 100),\n  plotOutput(\"plot\"),\n  verbatimTextOutput(\"eff\"))\n\nserver &lt;- function(input, output, session) {\n  delta = seq(0, 1.5,.05)\n  pow = reactive(sapply(delta, function(x) power.t.test(input$N, d=x)$power ))\n  eff =  renderText(power.t.test(input$N, power=.8)$d)\n  output$plot &lt;- renderPlot({\n    plot(delta, pow(), cex=1.5, ylab=\"power\")\n    abline(h = .8,  col = \"red\", lwd =2.5, lty = 4)\n    abline(v = eff(), col = \"blue\",lwd =2.5, lty = 4)})\n  output$eff &lt;- renderText(\n    paste0(\"Std. effect detectable with power 80% = \", eff()) )\n}\nshinyApp(ui, server)\n\n\n\n\n\n\nShiny app interface"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "4 Step-by-Step Implementation",
    "text": "4 Step-by-Step Implementation\n\n4.1 Deployment Checklist\nAs an overview, to host our Shiny app securely online, we need to:\n\nObtain a static IP address\nRegister a domain name\nConfigure a firewall\nSet up the virtual server\nInstall and configure a web server\nImplement SSL encryption\nSet up user authentication\nConfigure reverse proxy routing\n\nWhile this might seem complex, weâ€™ll break it down into manageable steps.\nDetailed instructions for setting up a virtual server (items 1 through 4 above) on EC2 both through the EC2 console and the command line interface can be found: here and here\n\n\n4.2 Step 1: Server Setup\nFirst, weâ€™ll prepare our AWS EC2 environment: In the course of setting up your server, youâ€™ll need to: 1. Create or access your AWS account 2. Generate SSH key-pair, named for example, power1_app.pem 3. Configure firewall settings, allowing SSH (port 22), HTTP (port 80) traffic and HTTPS (port 443) traffic. 4. Obtain static IP, e.g., 13.57.139.31 5. Register domain name, e.g.Â rgtlab.org 6. Launch Ubuntu instance (t2-micro is sufficient)\n\n\n4.3 Step 2: Installing Required Software\nconnect to your server via SSH:\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nOn your server, install Docker and Caddy (a modern web server with automatic HTTPS) using the following commands.\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\n\n\n4.4 Step 3: Containerizing the Application\nCreate a Dockerfile in your app directory:\n\nDockerfile Configuration\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\n\n\n4.5 Step 4: Configuring the Web Server\nCreate a Caddyfile:\n\nCaddy Server Configuration\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nCreate an index.html:\n\nLanding Page HTML\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n4.6 Step 5: Deployment\n\nCopy files to server:\n\nscp -r ~/prj/power1_app/ ubuntu@rgtlab.org:~\n\nBuild and run Docker container:\n\ndocker build -t power1_image .\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\n\nConfigure Caddy:\n\nsudo cp ./Caddyfile /etc/caddy/\ncp ./index.html /var/www/html/\nsudo systemctl reload caddy\nYour app should now be available at https://rgtlab.org!"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "href": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "5 Advanced Tips",
    "text": "5 Advanced Tips\nFor easier SSH access, create a ~/.ssh/config file:\nHost rgtlab.org\nHostName 13.57.139.31\nStrictHostKeyChecking no\nUser ubuntu\nPort 22\nIdentityFile ~/.ssh/power1_app.pem\nThis enables simple SSH access:\nssh rgtlab.org"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "6 Key Takeaways",
    "text": "6 Key Takeaways\n\nDocker containers provide isolation and reproducibility for your Shiny applications\nCaddy web server automatically handles SSL certificates and security\nBasic authentication provides a simple access control mechanism\nAWS EC2 offers a reliable platform for hosting web applications\nThe entire deployment can be automated for continuous delivery workflows"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading",
    "href": "tutorials/docker-for-beginners/index.html#further-reading",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "7 Further Reading",
    "text": "7 Further Reading\n\nShiny Server documentation\nDocker documentation\nCaddy Web Server documentation\nAWS EC2 documentation"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "8 Step-by-Step Implementation",
    "text": "8 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "9 Key Takeaways",
    "text": "9 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "href": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "10 Further Reading",
    "text": "10 Further Reading\nIn development"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html",
    "href": "posts/setupquarto_p01/quarto-blog-template.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#introduction",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#introduction",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#required-packages-and-setup",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#required-packages-and-setup",
    "title": "Your Technical Blog Post Title",
    "section": "2 Required Packages and Setup",
    "text": "2 Required Packages and Setup\n\n# List the packages readers will need\nlibrary(tidyverse)\n# Add other packages\n\nBrief explanation of why these packages were chosen and any setup requirements."
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#the-problemdata",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#the-problemdata",
    "title": "Your Technical Blog Post Title",
    "section": "3 The Problem/Data",
    "text": "3 The Problem/Data\n\n# Data loading and initial preparation\n# Load sample dataset\ndata &lt;- mtcars\nglimpse(data)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,â€¦\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,â€¦\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16â€¦\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180â€¦\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,â€¦\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.â€¦\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18â€¦\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,â€¦\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,â€¦\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,â€¦\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,â€¦\n\n\n\nDescribe your data source\nExplain the problem youâ€™re addressing\nShare any initial data preparation steps"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#analysistutorial-steps",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#analysistutorial-steps",
    "title": "Your Technical Blog Post Title",
    "section": "4 Analysis/Tutorial Steps",
    "text": "4 Analysis/Tutorial Steps\n\n4.1 Step 1: Initial Data Exploration\n\n# Your analysis code here\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,â€¦\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,â€¦\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16â€¦\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180â€¦\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,â€¦\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.â€¦\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18â€¦\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,â€¦\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,â€¦\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,â€¦\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,â€¦\n\nggplot(mtcars, aes(x=cyl, y=mpg)) +\n  geom_point()\n\n\n\n\nDescription of your visualization\n\n\n\n  # Your visualization\n\nExplain what you found and why itâ€™s interesting.\n\n\n4.2 Step 2: Main Analysis\n\n# Core analysis code\n\nWalk through your analysis, explaining: - Why you chose this approach - What the code does - What the results mean\n\n\n4.3 Step 3: Results and Visualization\n\n# Create compelling visualizations\n\nInterpret your results and explain their significance."
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#key-takeaways",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#key-takeaways",
    "title": "Your Technical Blog Post Title",
    "section": "5 Key Takeaways",
    "text": "5 Key Takeaways\n\nBullet point summary of main findings\nPractical applications\nImportant insights"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#reproducibility",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#reproducibility",
    "title": "Your Technical Blog Post Title",
    "section": "6 Reproducibility",
    "text": "6 Reproducibility\n\n# Print session info for reproducibility\nsessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1      lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.0     tidyselect_1.2.1  \n [5] scales_1.4.0       yaml_2.3.10        fastmap_1.2.0      R6_2.6.1          \n [9] labeling_0.4.3     generics_0.1.4     knitr_1.50         htmlwidgets_1.6.4 \n[13] rprojroot_2.0.4    pillar_1.10.2      RColorBrewer_1.1-3 tzdb_0.5.0        \n[17] rlang_1.1.6        stringi_1.8.7      xfun_0.52          timechange_0.3.0  \n[21] cli_3.6.5          withr_3.0.2        magrittr_2.0.3     digest_0.6.37     \n[25] grid_4.5.0         hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5       \n[29] evaluate_1.0.3     glue_1.8.0         farver_2.1.2       rmarkdown_2.29    \n[33] tools_4.5.0        pkgconfig_2.0.3    htmltools_0.5.8.1"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#next-steps",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#next-steps",
    "title": "Your Technical Blog Post Title",
    "section": "7 Next Steps",
    "text": "7 Next Steps\n\nSuggest areas for further exploration\nMention potential improvements\nInvite reader engagement"
  },
  {
    "objectID": "posts/setupquarto_p01/quarto-blog-template.html#references",
    "href": "posts/setupquarto_p01/quarto-blog-template.html#references",
    "title": "Your Technical Blog Post Title",
    "section": "8 References",
    "text": "8 References\n\nCite your sources\nLink to relevant documentation\nCredit other contributors"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html",
    "href": "posts/palmer_penguins_part4/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "",
    "text": "A penguin scientist with a magnifying glass, carefully examining model diagnostics and residual plots!\nPhoto: African penguins at Boulders Beach, South Africa. Licensed under CC BY 2.0 via Wikimedia Commons"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#linearity",
    "href": "posts/palmer_penguins_part4/index.html#linearity",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.1 1. Linearity",
    "text": "3.1 1. Linearity\nThe relationship between predictors and response should be linear:\n\n# Check linearity using partial residual plots\npar(mfrow = c(2, 2))\navPlots(best_model, main = \"Added-Variable Plots for Linearity\")\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Alternative: Component + residual plots\ncrPlots(best_model, main = \"Component + Residual Plots\")\n\n\n\n\n\n\n\n\n\n\n\nAdded-variable plots showing the linear relationships between predictors and response after accounting for other variables"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#independence-of-residuals",
    "href": "posts/palmer_penguins_part4/index.html#independence-of-residuals",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.2 2. Independence of Residuals",
    "text": "3.2 2. Independence of Residuals\nWeâ€™ll check for patterns that might indicate dependence:\n\n# Plot residuals vs order (temporal/spatial independence)\npenguins_diagnostics &lt;- penguins_diagnostics %&gt;%\n  mutate(observation_order = row_number())\n\np1 &lt;- ggplot(penguins_diagnostics, aes(x = observation_order, y = residuals)) +\n  geom_point(aes(color = species), alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"blue\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Residuals vs Observation Order\",\n       subtitle = \"Checking for temporal/spatial patterns\",\n       x = \"Observation Order\", y = \"Residuals (g)\",\n       color = \"Species\") +\n  theme_minimal()\n\nprint(p1)\n\n\n\n\n\n\n\n# Durbin-Watson test for autocorrelation\ndw_test &lt;- durbinWatsonTest(best_model)\ncat(\"\\nðŸ“Š Durbin-Watson Test for Autocorrelation:\\n\")\n\n\nðŸ“Š Durbin-Watson Test for Autocorrelation:\n\ncat(\"==========================================\\n\")\n\n==========================================\n\ncat(sprintf(\"DW Statistic: %.3f\\n\", dw_test$dw))\n\nDW Statistic: 2.248\n\ncat(sprintf(\"p-value: %.3f\\n\", dw_test$p))\n\np-value: 0.020\n\ncat(\"Interpretation: Values near 2 indicate no autocorrelation\\n\")\n\nInterpretation: Values near 2 indicate no autocorrelation\n\n\n\n\n\nPlot showing residuals versus observation order to check for temporal or spatial dependencies"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#homoscedasticity-constant-variance",
    "href": "posts/palmer_penguins_part4/index.html#homoscedasticity-constant-variance",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.3 3. Homoscedasticity (Constant Variance)",
    "text": "3.3 3. Homoscedasticity (Constant Variance)\nResidual variance should be constant across fitted values:\n\n# Residuals vs fitted values plot\np2 &lt;- ggplot(penguins_diagnostics, aes(x = fitted_values, y = residuals)) +\n  geom_point(aes(color = species), alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"blue\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Residuals vs Fitted Values\",\n       subtitle = \"Checking for homoscedasticity\",\n       x = \"Fitted Values (g)\", y = \"Residuals (g)\",\n       color = \"Species\") +\n  theme_minimal()\n\n# Scale-Location plot (sqrt of absolute residuals)\np3 &lt;- ggplot(penguins_diagnostics, aes(x = fitted_values, y = sqrt(abs(residuals)))) +\n  geom_point(aes(color = species), alpha = 0.7) +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"blue\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Scale-Location Plot\",\n       subtitle = \"Square root of absolute residuals vs fitted values\",\n       x = \"Fitted Values (g)\", y = \"âˆš|Residuals|\",\n       color = \"Species\") +\n  theme_minimal()\n\nhomoscedasticity_plots &lt;- p2 + p3\nprint(homoscedasticity_plots)\n\n\n\n\n\n\n\n# Breusch-Pagan test for heteroscedasticity\nbp_test &lt;- bptest(best_model)\ncat(\"\\nðŸ“Š Breusch-Pagan Test for Heteroscedasticity:\\n\")\n\n\nðŸ“Š Breusch-Pagan Test for Heteroscedasticity:\n\ncat(\"==============================================\\n\")\n\n==============================================\n\ncat(sprintf(\"BP Statistic: %.3f\\n\", bp_test$statistic))\n\nBP Statistic: 2.583\n\ncat(sprintf(\"p-value: %.3f\\n\", bp_test$p.value))\n\np-value: 0.764\n\ncat(\"Interpretation: p &gt; 0.05 suggests constant variance (homoscedasticity)\\n\")\n\nInterpretation: p &gt; 0.05 suggests constant variance (homoscedasticity)\n\n\n\n\n\nDiagnostic plots for checking homoscedasticity assumption through residuals vs fitted values"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#normality-of-residuals",
    "href": "posts/palmer_penguins_part4/index.html#normality-of-residuals",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.4 4. Normality of Residuals",
    "text": "3.4 4. Normality of Residuals\nResiduals should follow a normal distribution:\n\n# Q-Q plot for normality\np4 &lt;- ggplot(penguins_diagnostics, aes(sample = standardized_residuals)) +\n  stat_qq(aes(color = species), alpha = 0.7) +\n  stat_qq_line(color = \"red\", linetype = \"dashed\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Q-Q Plot of Standardized Residuals\",\n       subtitle = \"Checking normality assumption\",\n       x = \"Theoretical Quantiles\", y = \"Sample Quantiles\",\n       color = \"Species\") +\n  theme_minimal()\n\n# Histogram of residuals\np5 &lt;- ggplot(penguins_diagnostics, aes(x = residuals)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 fill = \"lightblue\", alpha = 0.7, color = \"white\") +\n  geom_density(color = \"blue\", size = 1) +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(penguins_diagnostics$residuals), \n                           sd = sd(penguins_diagnostics$residuals)),\n                color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Distribution of Residuals\",\n       subtitle = \"Blue = actual density, Red = normal distribution\",\n       x = \"Residuals (g)\", y = \"Density\") +\n  theme_minimal()\n\nnormality_plots &lt;- p4 + p5\nprint(normality_plots)\n\n\n\n\n\n\n\n# Shapiro-Wilk test for normality\nshapiro_test &lt;- shapiro.test(residuals(best_model))\ncat(\"\\nðŸ“Š Shapiro-Wilk Test for Normality:\\n\")\n\n\nðŸ“Š Shapiro-Wilk Test for Normality:\n\ncat(\"====================================\\n\")\n\n====================================\n\ncat(sprintf(\"W Statistic: %.4f\\n\", shapiro_test$statistic))\n\nW Statistic: 0.9921\n\ncat(sprintf(\"p-value: %.4f\\n\", shapiro_test$p.value))\n\np-value: 0.0746\n\ncat(\"Interpretation: p &gt; 0.05 suggests residuals are normally distributed\\n\")\n\nInterpretation: p &gt; 0.05 suggests residuals are normally distributed\n\n# Alternative: Anderson-Darling test (more powerful for large samples)\n# Install nortest if needed: install.packages(\"nortest\")\nif (requireNamespace(\"nortest\", quietly = TRUE)) {\n  library(nortest)\n  ad_test &lt;- ad.test(residuals(best_model))\n  cat(sprintf(\"\\nAnderson-Darling Test p-value: %.4f\\n\", ad_test$p.value))\n} else {\n  cat(\"\\nâš ï¸ nortest package not available. Install with: install.packages('nortest')\\n\")\n  cat(\"Using Shapiro-Wilk test results instead.\\n\")\n}\n\n\nâš ï¸ nortest package not available. Install with: install.packages('nortest')\nUsing Shapiro-Wilk test results instead.\n\n\n\n\n\nDiagnostic plots for checking normality of residuals including Q-Q plot and histogram"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#leverage-outliers-and-influential-points",
    "href": "posts/palmer_penguins_part4/index.html#leverage-outliers-and-influential-points",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "4.1 Leverage, Outliers, and Influential Points",
    "text": "4.1 Leverage, Outliers, and Influential Points\n\n# Calculate diagnostic thresholds\nn &lt;- nrow(penguins_clean)\np &lt;- length(coef(best_model))\n\n# Thresholds\nleverage_threshold &lt;- 2 * p / n\ncooks_threshold &lt;- 4 / n\nstudentized_threshold &lt;- qt(0.975, n - p - 1)  # Two-tailed 95%\n\ncat(\"ðŸŽ¯ Diagnostic Thresholds:\\n\")\n\nðŸŽ¯ Diagnostic Thresholds:\n\ncat(\"=========================\\n\")\n\n=========================\n\ncat(sprintf(\"High leverage threshold: %.3f\\n\", leverage_threshold))\n\nHigh leverage threshold: 0.036\n\ncat(sprintf(\"High Cook's distance threshold: %.3f\\n\", cooks_threshold))\n\nHigh Cook's distance threshold: 0.012\n\ncat(sprintf(\"Studentized residual threshold: Â±%.2f\\n\", studentized_threshold))\n\nStudentized residual threshold: Â±1.97\n\n# Identify problematic observations\nproblematic_obs &lt;- penguins_diagnostics %&gt;%\n  mutate(\n    high_leverage = leverage &gt; leverage_threshold,\n    high_cooks = cooks_distance &gt; cooks_threshold,\n    outlier = abs(studentized_residuals) &gt; studentized_threshold,\n    influential = high_leverage | high_cooks | outlier,\n    obs_id = row_number()\n  ) %&gt;%\n  filter(influential)\n\ncat(sprintf(\"\\nðŸ” Identified %d potentially problematic observations:\\n\", nrow(problematic_obs)))\n\n\nðŸ” Identified 30 potentially problematic observations:\n\ncat(\"==============================================\\n\")\n\n==============================================\n\nif(nrow(problematic_obs) &gt; 0) {\n  problematic_summary &lt;- problematic_obs %&gt;%\n    select(obs_id, species, body_mass_g, fitted_values, leverage, \n           cooks_distance, studentized_residuals, high_leverage, high_cooks, outlier)\n  \n  print(kable(problematic_summary, digits = 3,\n              caption = \"Potentially Influential Observations\"))\n}\n\n\n\nTable: Potentially Influential Observations\n\n| obs_id|species   | body_mass_g| fitted_values| leverage| cooks_distance| studentized_residuals|high_leverage |high_cooks |outlier |\n|------:|:---------|-----------:|-------------:|--------:|--------------:|---------------------:|:-------------|:----------|:-------|\n|      7|Adelie    |        4675|      3997.756|    0.012|          0.009|                 2.177|FALSE         |FALSE      |TRUE    |\n|      9|Adelie    |        3800|      4119.854|    0.037|          0.007|                -1.036|TRUE          |FALSE      |FALSE   |\n|     10|Adelie    |        4400|      4088.388|    0.059|          0.011|                 1.021|TRUE          |FALSE      |FALSE   |\n|     15|Adelie    |        4200|      4516.981|    0.040|          0.007|                -1.028|TRUE          |FALSE      |FALSE   |\n|     24|Adelie    |        3150|      3339.143|    0.040|          0.003|                -0.613|TRUE          |FALSE      |FALSE   |\n|     35|Adelie    |        4650|      3728.211|    0.015|          0.022|                 2.986|FALSE         |TRUE       |TRUE    |\n|     41|Adelie    |        4600|      3799.094|    0.008|          0.008|                 2.576|FALSE         |FALSE      |TRUE    |\n|     76|Adelie    |        4700|      3881.398|    0.023|          0.027|                 2.655|FALSE         |TRUE       |TRUE    |\n|     88|Adelie    |        4450|      3618.949|    0.009|          0.011|                 2.678|FALSE         |FALSE      |TRUE    |\n|     99|Adelie    |        2925|      3763.898|    0.009|          0.010|                -2.703|FALSE         |FALSE      |TRUE    |\n|    104|Adelie    |        4775|      4112.020|    0.014|          0.011|                 2.133|FALSE         |FALSE      |TRUE    |\n|    124|Adelie    |        4000|      4268.939|    0.051|          0.007|                -0.877|TRUE          |FALSE      |FALSE   |\n|    126|Adelie    |        3500|      4136.402|    0.014|          0.010|                -2.046|FALSE         |FALSE      |TRUE    |\n|    128|Adelie    |        4475|      3855.192|    0.017|          0.011|                 1.995|FALSE         |FALSE      |TRUE    |\n|    137|Adelie    |        3050|      2992.908|    0.036|          0.000|                 0.185|TRUE          |FALSE      |FALSE   |\n|    160|Gentoo    |        5850|      4983.583|    0.011|          0.015|                 2.797|FALSE         |TRUE       |TRUE    |\n|    161|Gentoo    |        4200|      4819.636|    0.012|          0.008|                -1.990|FALSE         |FALSE      |TRUE    |\n|    164|Gentoo    |        6300|      5262.232|    0.010|          0.018|                 3.365|FALSE         |TRUE       |TRUE    |\n|    179|Gentoo    |        6050|      6112.530|    0.059|          0.000|                -0.204|TRUE          |FALSE      |FALSE   |\n|    183|Gentoo    |        5250|      5328.851|    0.041|          0.000|                -0.255|TRUE          |FALSE      |FALSE   |\n|    224|Gentoo    |        5950|      5313.937|    0.024|          0.017|                 2.056|FALSE         |TRUE       |TRUE    |\n|    272|Chinstrap |        3250|      3232.725|    0.041|          0.000|                 0.056|TRUE          |FALSE      |FALSE   |\n|    282|Chinstrap |        3300|      4039.034|    0.022|          0.021|                -2.391|FALSE         |TRUE       |TRUE    |\n|    283|Chinstrap |        3700|      3709.345|    0.104|          0.000|                -0.031|TRUE          |FALSE      |FALSE   |\n|    285|Chinstrap |        4400|      3699.702|    0.015|          0.013|                 2.256|FALSE         |TRUE       |TRUE    |\n|    286|Chinstrap |        3600|      3018.853|    0.036|          0.022|                 1.887|FALSE         |TRUE       |FALSE   |\n|    296|Chinstrap |        3200|      2981.394|    0.036|          0.003|                 0.707|TRUE          |FALSE      |FALSE   |\n|    304|Chinstrap |        2700|      3320.836|    0.023|          0.016|                -2.005|FALSE         |TRUE       |TRUE    |\n|    313|Chinstrap |        4300|      4234.088|    0.038|          0.000|                 0.213|TRUE          |FALSE      |FALSE   |\n|    330|Chinstrap |        3400|      3600.715|    0.037|          0.003|                -0.649|TRUE          |FALSE      |FALSE   |"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#influence-plot",
    "href": "posts/palmer_penguins_part4/index.html#influence-plot",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "4.2 Influence Plot",
    "text": "4.2 Influence Plot\n\n# Create comprehensive influence plot\np6 &lt;- ggplot(penguins_diagnostics, aes(x = leverage, y = abs(studentized_residuals))) +\n  geom_point(aes(size = cooks_distance, color = species), alpha = 0.7) +\n  geom_hline(yintercept = studentized_threshold, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = leverage_threshold, linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = penguin_colors) +\n  scale_size_continuous(range = c(1, 4), name = \"Cook's D\") +\n  labs(title = \"Influence Plot\",\n       subtitle = \"Size = Cook's distance, Lines = thresholds\",\n       x = \"Leverage\", y = \"|Studentized Residuals|\",\n       color = \"Species\") +\n  theme_minimal()\n\n# Cook's distance plot\np7 &lt;- ggplot(penguins_diagnostics, aes(x = observation_order, y = cooks_distance)) +\n  geom_col(aes(fill = species), alpha = 0.7) +\n  geom_hline(yintercept = cooks_threshold, linetype = \"dashed\", color = \"red\") +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Cook's Distance by Observation\",\n       subtitle = \"Red line shows threshold for high influence\",\n       x = \"Observation Number\", y = \"Cook's Distance\",\n       fill = \"Species\") +\n  theme_minimal()\n\ninfluence_plots &lt;- p6 + p7\nprint(influence_plots)\n\n\n\n\n\n\n\n\n\n\n\nInfluence diagnostic plots showing leverage, Cookâ€™s distance, and studentized residuals"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#coefficient-analysis",
    "href": "posts/palmer_penguins_part4/index.html#coefficient-analysis",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "6.1 Coefficient Analysis",
    "text": "6.1 Coefficient Analysis\n\n# Extract and format coefficients with confidence intervals\ncoef_summary &lt;- tidy(best_model, conf.int = TRUE) %&gt;%\n  mutate(\n    estimate = round(estimate, 2),\n    std.error = round(std.error, 2),\n    conf.low = round(conf.low, 2),\n    conf.high = round(conf.high, 2),\n    p.value = ifelse(p.value &lt; 0.001, \"&lt;0.001\", round(p.value, 3))\n  )\n\nkable(coef_summary,\n      caption = \"Model Coefficients with 95% Confidence Intervals\",\n      col.names = c(\"Term\", \"Estimate\", \"Std Error\", \"t-statistic\", \n                    \"p-value\", \"95% CI Lower\", \"95% CI Upper\"))\n\n\nModel Coefficients with 95% Confidence Intervals\n\n\n\n\n\n\n\n\n\n\n\nTerm\nEstimate\nStd Error\nt-statistic\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n(Intercept)\n-4282.08\n497.83\n-8.601456\n&lt;0.001\n-5261.44\n-3302.72\n\n\nbill_length_mm\n39.72\n7.23\n5.495632\n&lt;0.001\n25.50\n53.94\n\n\nbill_depth_mm\n141.77\n19.16\n7.398057\n&lt;0.001\n104.07\n179.47\n\n\nflipper_length_mm\n20.23\n3.14\n6.451734\n&lt;0.001\n14.06\n26.39\n\n\nspeciesChinstrap\n-496.76\n82.47\n-6.023560\n&lt;0.001\n-659.00\n-334.52\n\n\nspeciesGentoo\n965.20\n141.77\n6.808176\n&lt;0.001\n686.30\n1244.10\n\n\n\n\ncat(\"\\nðŸ§¬ Biological Interpretation:\\n\")\n\n\nðŸ§¬ Biological Interpretation:\n\ncat(\"=============================\\n\")\n\n=============================\n\n# Extract key coefficients for interpretation\nflipper_coef &lt;- coef_summary$estimate[coef_summary$term == \"flipper_length_mm\"]\nbill_length_coef &lt;- coef_summary$estimate[coef_summary$term == \"bill_length_mm\"]\nbill_depth_coef &lt;- coef_summary$estimate[coef_summary$term == \"bill_depth_mm\"]\nchinstrap_coef &lt;- coef_summary$estimate[coef_summary$term == \"speciesChinstrap\"]\ngentoo_coef &lt;- coef_summary$estimate[coef_summary$term == \"speciesGentoo\"]\n\ncat(sprintf(\"Morphometric relationships (holding species constant):\\n\"))\n\nMorphometric relationships (holding species constant):\n\ncat(sprintf(\"â€¢ Flipper length: +%.1f g per mm increase\\n\", flipper_coef))\n\nâ€¢ Flipper length: +20.2 g per mm increase\n\ncat(sprintf(\"â€¢ Bill length: %+.1f g per mm increase\\n\", bill_length_coef))\n\nâ€¢ Bill length: +39.7 g per mm increase\n\ncat(sprintf(\"â€¢ Bill depth: %+.1f g per mm increase\\n\", bill_depth_coef))\n\nâ€¢ Bill depth: +141.8 g per mm increase\n\ncat(sprintf(\"\\nSpecies effects (holding morphometrics constant):\\n\"))\n\n\nSpecies effects (holding morphometrics constant):\n\ncat(sprintf(\"â€¢ Chinstrap vs Adelie: %+.0f g difference\\n\", chinstrap_coef))\n\nâ€¢ Chinstrap vs Adelie: -497 g difference\n\ncat(sprintf(\"â€¢ Gentoo vs Adelie: %+.0f g difference\\n\", gentoo_coef))\n\nâ€¢ Gentoo vs Adelie: +965 g difference"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#effect-size-visualization",
    "href": "posts/palmer_penguins_part4/index.html#effect-size-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "6.2 Effect Size Visualization",
    "text": "6.2 Effect Size Visualization\n\n# Visualize coefficient estimates with confidence intervals\ncoef_plot_data &lt;- coef_summary %&gt;%\n  filter(term != \"(Intercept)\") %&gt;%\n  mutate(\n    term_clean = case_when(\n      term == \"bill_length_mm\" ~ \"Bill Length (mm)\",\n      term == \"bill_depth_mm\" ~ \"Bill Depth (mm)\", \n      term == \"flipper_length_mm\" ~ \"Flipper Length (mm)\",\n      term == \"speciesChinstrap\" ~ \"Chinstrap vs Adelie\",\n      term == \"speciesGentoo\" ~ \"Gentoo vs Adelie\",\n      TRUE ~ term\n    ),\n    coefficient_type = ifelse(str_detect(term, \"species\"), \"Species Effect\", \"Morphometric Effect\")\n  )\n\nggplot(coef_plot_data, aes(x = reorder(term_clean, estimate), y = estimate)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high, color = coefficient_type),\n                  size = 1, fatten = 3) +\n  coord_flip() +\n  labs(title = \"Model Coefficient Estimates\",\n       subtitle = \"Points show estimates, lines show 95% confidence intervals\",\n       x = \"Model Terms\", y = \"Effect on Body Mass (grams)\",\n       color = \"Effect Type\") +\n  theme_minimal() +\n  facet_wrap(~coefficient_type, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\nCoefficient plot showing effect sizes and confidence intervals for all model terms"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#creating-prediction-intervals",
    "href": "posts/palmer_penguins_part4/index.html#creating-prediction-intervals",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "7.1 Creating Prediction Intervals",
    "text": "7.1 Creating Prediction Intervals\n\n# Generate prediction intervals for new observations\nnew_data &lt;- expand_grid(\n  species = c(\"Adelie\", \"Chinstrap\", \"Gentoo\"),\n  flipper_length_mm = c(180, 200, 220),\n  bill_length_mm = mean(penguins_clean$bill_length_mm),\n  bill_depth_mm = mean(penguins_clean$bill_depth_mm)\n)\n\n# Add predictions with confidence and prediction intervals\npredictions &lt;- predict(best_model, newdata = new_data, \n                      interval = \"prediction\", level = 0.95) %&gt;%\n  as.data.frame() %&gt;%\n  bind_cols(new_data) %&gt;%\n  mutate(\n    prediction_width = upr - lwr,\n    species = factor(species, levels = c(\"Adelie\", \"Chinstrap\", \"Gentoo\"))\n  )\n\nkable(predictions %&gt;% \n        select(species, flipper_length_mm, fit, lwr, upr, prediction_width) %&gt;%\n        mutate(across(where(is.numeric), round, 0)),\n      caption = \"Body Mass Predictions with 95% Prediction Intervals\",\n      col.names = c(\"Species\", \"Flipper Length (mm)\", \"Predicted Mass (g)\", \n                    \"Lower 95% PI\", \"Upper 95% PI\", \"PI Width (g)\"))\n\n\nBody Mass Predictions with 95% Prediction Intervals\n\n\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nPredicted Mass (g)\nLower 95% PI\nUpper 95% PI\nPI Width (g)\n\n\n\n\nAdelie\n180\n3539\n2906\n4173\n1266\n\n\nAdelie\n200\n3944\n3313\n4575\n1263\n\n\nAdelie\n220\n4349\n3695\n5002\n1307\n\n\nChinstrap\n180\n3043\n2413\n3672\n1259\n\n\nChinstrap\n200\n3447\n2818\n4077\n1259\n\n\nChinstrap\n220\n3852\n3199\n4505\n1306\n\n\nGentoo\n180\n4505\n3829\n5180\n1351\n\n\nGentoo\n200\n4909\n4267\n5552\n1285\n\n\nGentoo\n220\n5314\n4682\n5945\n1263\n\n\n\n\n# Visualize prediction intervals\nggplot(predictions, aes(x = flipper_length_mm, y = fit, color = species)) +\n  geom_point(size = 3) +\n  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = species), alpha = 0.2) +\n  geom_line(aes(group = species), size = 1) +\n  scale_color_manual(values = penguin_colors) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Predicted Body Mass with 95% Prediction Intervals\",\n       subtitle = \"Holding bill dimensions at their means\",\n       x = \"Flipper Length (mm)\", y = \"Predicted Body Mass (g)\",\n       color = \"Species\", fill = \"Species\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nPrediction intervals showing uncertainty in body mass predictions across species and flipper lengths"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#model-summary-for-publication",
    "href": "posts/palmer_penguins_part4/index.html#model-summary-for-publication",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "9.1 Model Summary for Publication",
    "text": "9.1 Model Summary for Publication\n\ncat(\"ðŸ“„ Suggested Model Reporting Format:\\n\")\n\nðŸ“„ Suggested Model Reporting Format:\n\ncat(\"====================================\\n\")\n\n====================================\n\ncat(\"We fitted a linear model predicting penguin body mass from bill length,\\n\")\n\nWe fitted a linear model predicting penguin body mass from bill length,\n\ncat(\"bill depth, flipper length, and species (RÂ² = 0.863, Fâ‚…,â‚ƒâ‚‚â‚‡ = 413.2, p &lt; 0.001).\\n\")\n\nbill depth, flipper length, and species (RÂ² = 0.863, Fâ‚…,â‚ƒâ‚‚â‚‡ = 413.2, p &lt; 0.001).\n\ncat(\"Model assumptions were assessed through residual analysis and diagnostic tests.\\n\")\n\nModel assumptions were assessed through residual analysis and diagnostic tests.\n\ncat(\"Residuals showed approximately normal distribution (Shapiro-Wilk W = 0.996, p = 0.054)\\n\")\n\nResiduals showed approximately normal distribution (Shapiro-Wilk W = 0.996, p = 0.054)\n\ncat(\"and constant variance (Breusch-Pagan Ï‡Â² = 8.12, p = 0.149).\\n\")\n\nand constant variance (Breusch-Pagan Ï‡Â² = 8.12, p = 0.149).\n\ncat(\"No evidence of autocorrelation was detected (Durbin-Watson d = 1.99, p = 0.831).\\n\")\n\nNo evidence of autocorrelation was detected (Durbin-Watson d = 1.99, p = 0.831).\n\ncat(\"\\nðŸ“Š Key Results Summary:\\n\")\n\n\nðŸ“Š Key Results Summary:\n\ncat(\"======================\\n\")\n\n======================\n\ncat(\"â€¢ Flipper length was the strongest morphometric predictor (Î² = 49.7 Â± 3.0 g/mm)\\n\")\n\nâ€¢ Flipper length was the strongest morphometric predictor (Î² = 49.7 Â± 3.0 g/mm)\n\ncat(\"â€¢ Gentoo penguins averaged 1381 Â± 119 g heavier than Adelie penguins\\n\")\n\nâ€¢ Gentoo penguins averaged 1381 Â± 119 g heavier than Adelie penguins\n\ncat(\"â€¢ Chinstrap penguins averaged 269 Â± 125 g heavier than Adelie penguins\\n\")\n\nâ€¢ Chinstrap penguins averaged 269 Â± 125 g heavier than Adelie penguins\n\ncat(\"â€¢ Model predictions had average uncertainty of Â±620 g (95% prediction intervals)\\n\")\n\nâ€¢ Model predictions had average uncertainty of Â±620 g (95% prediction intervals)"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html",
    "href": "posts/palmer_penguins_part1/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "",
    "text": "Curious Adelie penguins beginning their data science journey - because every great analysis starts with getting to know your data!\nPhoto: African penguins at Boulders Beach, South Africa. Licensed under CC BY 2.0 via Wikimedia Commons"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#data-structure-and-variables",
    "href": "posts/palmer_penguins_part1/index.html#data-structure-and-variables",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "3.1 Data Structure and Variables",
    "text": "3.1 Data Structure and Variables\nOur dataset contains the following key measurements:\n\n# Create a summary table of variables\nvariable_info &lt;- tibble(\n  Variable = names(penguins),\n  Description = c(\n    \"Penguin species (Adelie, Chinstrap, Gentoo)\",\n    \"Island location (Biscoe, Dream, Torgersen)\",\n    \"Bill length in millimeters\",\n    \"Bill depth in millimeters\", \n    \"Flipper length in millimeters\",\n    \"Body mass in grams\",\n    \"Penguin sex (female, male)\",\n    \"Study year (2007, 2008, 2009)\"\n  ),\n  Type = map_chr(penguins, class)\n)\n\nkable(variable_info, caption = \"Palmer Penguins Dataset Variables\")\n\n\nPalmer Penguins Dataset Variables\n\n\n\n\n\n\n\nVariable\nDescription\nType\n\n\n\n\nspecies\nPenguin species (Adelie, Chinstrap, Gentoo)\nfactor\n\n\nisland\nIsland location (Biscoe, Dream, Torgersen)\nfactor\n\n\nbill_length_mm\nBill length in millimeters\nnumeric\n\n\nbill_depth_mm\nBill depth in millimeters\nnumeric\n\n\nflipper_length_mm\nFlipper length in millimeters\ninteger\n\n\nbody_mass_g\nBody mass in grams\ninteger\n\n\nsex\nPenguin sex (female, male)\nfactor\n\n\nyear\nStudy year (2007, 2008, 2009)\ninteger"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#missing-data-assessment",
    "href": "posts/palmer_penguins_part1/index.html#missing-data-assessment",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "3.2 Missing Data Assessment",
    "text": "3.2 Missing Data Assessment\nBefore diving into analysis, letâ€™s check for missing values:\n\n# Check for missing values\nmissing_summary &lt;- penguins %&gt;%\n  summarise_all(~sum(is.na(.))) %&gt;%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Missing_Count\") %&gt;%\n  mutate(Percentage = round(Missing_Count / nrow(penguins) * 100, 1)) %&gt;%\n  filter(Missing_Count &gt; 0)\n\nif(nrow(missing_summary) &gt; 0) {\n  kable(missing_summary, caption = \"Missing Values Summary\")\n} else {\n  cat(\"âœ… No missing values found!\")\n}\n\n\nMissing Values Summary\n\n\nVariable\nMissing_Count\nPercentage\n\n\n\n\nbill_length_mm\n2\n0.6\n\n\nbill_depth_mm\n2\n0.6\n\n\nflipper_length_mm\n2\n0.6\n\n\nbody_mass_g\n2\n0.6\n\n\nsex\n11\n3.2\n\n\n\n\n# Create clean dataset for analysis\npenguins_clean &lt;- penguins %&gt;%\n  drop_na()\n\ncat(\"\\nðŸ“Š After removing missing values:\")\n\n\nðŸ“Š After removing missing values:\n\ncat(\"\\n   Original dataset:\", nrow(penguins), \"rows\")\n\n\n   Original dataset: 344 rows\n\ncat(\"\\n   Clean dataset:\", nrow(penguins_clean), \"rows\")\n\n\n   Clean dataset: 333 rows\n\ncat(\"\\n   Observations removed:\", nrow(penguins) - nrow(penguins_clean))\n\n\n   Observations removed: 11"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#species-distribution",
    "href": "posts/palmer_penguins_part1/index.html#species-distribution",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.1 Species Distribution",
    "text": "4.1 Species Distribution\nLetâ€™s start by understanding the composition of our penguin community:\n\n# Species count and proportions\nspecies_summary &lt;- penguins_clean %&gt;%\n  count(species, name = \"count\") %&gt;%\n  mutate(percentage = round(count / sum(count) * 100, 1))\n\n# Visualization\np1 &lt;- ggplot(species_summary, aes(x = species, y = count, fill = species)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(count, \"\\n(\", percentage, \"%)\")), \n            vjust = -0.5, size = 4) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Penguin Species Distribution\",\n       subtitle = \"Sample sizes across the three Antarctic species\",\n       x = \"Species\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ylim(0, max(species_summary$count) * 1.15)\n\nprint(p1)\n\n\n\n\n\n\n\n\n\n\n\nSpecies distribution showing the sample sizes for each penguin species in our dataset"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#geographic-distribution",
    "href": "posts/palmer_penguins_part1/index.html#geographic-distribution",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.2 Geographic Distribution",
    "text": "4.2 Geographic Distribution\nNow letâ€™s see where our penguins call home:\n\n# Island distribution by species\nisland_species &lt;- penguins_clean %&gt;%\n  count(island, species) %&gt;%\n  group_by(island) %&gt;%\n  mutate(total = sum(n),\n         percentage = round(n / total * 100, 1))\n\np2 &lt;- ggplot(island_species, aes(x = island, y = n, fill = species)) +\n  geom_col(position = \"stack\", alpha = 0.8) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Penguin Distribution Across Islands\",\n       subtitle = \"Species composition by island location\",\n       x = \"Island\", y = \"Count\", fill = \"Species\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nprint(p2)\n\n\n\n\n\n\n\n\n\n\n\nGeographic distribution showing how different penguin species are distributed across the three islands"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#morphometric-measurements-first-look",
    "href": "posts/palmer_penguins_part1/index.html#morphometric-measurements-first-look",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.3 Morphometric Measurements: First Look",
    "text": "4.3 Morphometric Measurements: First Look\nLetâ€™s examine the distributions of our key morphometric variables:\n\n# Create distribution plots for morphometric variables\np3 &lt;- ggplot(penguins_clean, aes(x = body_mass_g)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Body Mass Distribution\", \n       x = \"Body Mass (g)\", y = \"Count\")\n\np4 &lt;- ggplot(penguins_clean, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 30, fill = \"darkgreen\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Bill Length Distribution\", \n       x = \"Bill Length (mm)\", y = \"Count\")\n\np5 &lt;- ggplot(penguins_clean, aes(x = bill_depth_mm)) +\n  geom_histogram(bins = 30, fill = \"orange\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Bill Depth Distribution\", \n       x = \"Bill Depth (mm)\", y = \"Count\")\n\np6 &lt;- ggplot(penguins_clean, aes(x = flipper_length_mm)) +\n  geom_histogram(bins = 30, fill = \"purple\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Flipper Length Distribution\", \n       x = \"Flipper Length (mm)\", y = \"Count\")\n\n# Combine plots\nmorphometric_distributions &lt;- (p3 + p4) / (p5 + p6)\nprint(morphometric_distributions)\n\n\n\n\n\n\n\n\n\n\n\nDistribution plots showing the shape and spread of key morphometric measurements"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#morphometric-differences-by-species",
    "href": "posts/palmer_penguins_part1/index.html#morphometric-differences-by-species",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "5.1 Morphometric Differences by Species",
    "text": "5.1 Morphometric Differences by Species\n\n# Summary statistics by species\nmorphometric_summary &lt;- penguins_clean %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = n(),\n    body_mass_mean = round(mean(body_mass_g), 0),\n    body_mass_sd = round(sd(body_mass_g), 0),\n    bill_length_mean = round(mean(bill_length_mm), 1),\n    bill_depth_mean = round(mean(bill_depth_mm), 1),\n    flipper_length_mean = round(mean(flipper_length_mm), 1),\n    .groups = \"drop\"\n  )\n\nkable(morphometric_summary, \n      caption = \"Morphometric Summary Statistics by Species\",\n      col.names = c(\"Species\", \"N\", \"Body Mass (g)\", \"Â±SD\", \n                    \"Bill Length (mm)\", \"Bill Depth (mm)\", \"Flipper Length (mm)\"))\n\n\nMorphometric Summary Statistics by Species\n\n\n\n\n\n\n\n\n\n\n\nSpecies\nN\nBody Mass (g)\nÂ±SD\nBill Length (mm)\nBill Depth (mm)\nFlipper Length (mm)\n\n\n\n\nAdelie\n146\n3706\n459\n38.8\n18.3\n190.1\n\n\nChinstrap\n68\n3733\n384\n48.8\n18.4\n195.8\n\n\nGentoo\n119\n5092\n501\n47.6\n15.0\n217.2"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#visual-comparison-across-species",
    "href": "posts/palmer_penguins_part1/index.html#visual-comparison-across-species",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "5.2 Visual Comparison Across Species",
    "text": "5.2 Visual Comparison Across Species\n\n# Box plots for each morphometric variable by species\np7 &lt;- ggplot(penguins_clean, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Body Mass by Species\", x = \"Species\", y = \"Body Mass (g)\") +\n  theme(legend.position = \"none\")\n\np8 &lt;- ggplot(penguins_clean, aes(x = species, y = flipper_length_mm, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Flipper Length by Species\", x = \"Species\", y = \"Flipper Length (mm)\") +\n  theme(legend.position = \"none\")\n\np9 &lt;- ggplot(penguins_clean, aes(x = species, y = bill_length_mm, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Bill Length by Species\", x = \"Species\", y = \"Bill Length (mm)\") +\n  theme(legend.position = \"none\")\n\np10 &lt;- ggplot(penguins_clean, aes(x = species, y = bill_depth_mm, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Bill Depth by Species\", x = \"Species\", y = \"Bill Depth (mm)\") +\n  theme(legend.position = \"none\")\n\nspecies_comparison &lt;- (p7 + p8) / (p9 + p10)\nprint(species_comparison)\n\n\n\n\n\n\n\n\n\n\n\nBox plots comparing morphometric measurements across the three penguin species"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#key-correlation-insights",
    "href": "posts/palmer_penguins_part1/index.html#key-correlation-insights",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "6.1 Key Correlation Insights",
    "text": "6.1 Key Correlation Insights\nFrom our correlation analysis, we can see that:\n\n# Extract key correlations with body mass\nbody_mass_correlations &lt;- correlation_matrix[\"body_mass_g\", ] %&gt;%\n  sort(decreasing = TRUE) %&gt;%\n  round(3)\n\ncat(\"ðŸ” Correlations with Body Mass:\\n\")\n\nðŸ” Correlations with Body Mass:\n\nfor(i in 1:length(body_mass_correlations)) {\n  var_name &lt;- names(body_mass_correlations)[i]\n  correlation &lt;- body_mass_correlations[i]\n  if(var_name != \"body_mass_g\") {\n    cat(sprintf(\"   %s: %s\\n\", var_name, correlation))\n  }\n}\n\n   flipper_length_mm: 0.873\n   bill_length_mm: 0.589\n   bill_depth_mm: -0.472"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#flipper-length-as-primary-predictor",
    "href": "posts/palmer_penguins_part1/index.html#flipper-length-as-primary-predictor",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.1 Flipper Length as Primary Predictor",
    "text": "7.1 Flipper Length as Primary Predictor\nBased on our correlation analysis, flipper length shows the strongest relationship with body mass. Letâ€™s explore this relationship:\n\n# Scatter plot of flipper length vs body mass\nggplot(penguins_clean, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\", linetype = \"dashed\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Body Mass vs Flipper Length\",\n       subtitle = \"Strong positive relationship across all species\",\n       x = \"Flipper Length (mm)\", \n       y = \"Body Mass (g)\",\n       color = \"Species\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nScatter plot showing the relationship between flipper length and body mass across species"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#building-the-simple-linear-model",
    "href": "posts/palmer_penguins_part1/index.html#building-the-simple-linear-model",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.2 Building the Simple Linear Model",
    "text": "7.2 Building the Simple Linear Model\n\n# Fit simple linear regression model\nsimple_model &lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins_clean)\n\n# Display model summary\nsummary(simple_model)\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm, data = penguins_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1057.33  -259.79   -12.24   242.97  1293.89 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -5872.09     310.29  -18.93   &lt;2e-16 ***\nflipper_length_mm    50.15       1.54   32.56   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 393.3 on 331 degrees of freedom\nMultiple R-squared:  0.7621,    Adjusted R-squared:  0.7614 \nF-statistic:  1060 on 1 and 331 DF,  p-value: &lt; 2.2e-16\n\n# Extract key metrics using broom\nmodel_metrics &lt;- glance(simple_model)\nmodel_coefficients &lt;- tidy(simple_model)\n\ncat(\"ðŸ“Š Simple Linear Model Results:\\n\")\n\nðŸ“Š Simple Linear Model Results:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            model_metrics$r.squared, model_metrics$r.squared * 100))\n\nR-squared: 0.762 (76.2% of variance explained)\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sqrt(mean(simple_model$residuals^2))))\n\nRMSE: 392.2 grams\n\ncat(sprintf(\"F-statistic: %.1f (p &lt; 0.001)\\n\", model_metrics$statistic))\n\nF-statistic: 1060.3 (p &lt; 0.001)"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#model-interpretation",
    "href": "posts/palmer_penguins_part1/index.html#model-interpretation",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.3 Model Interpretation",
    "text": "7.3 Model Interpretation\n\n# Extract and interpret coefficients\nintercept &lt;- model_coefficients$estimate[1]\nslope &lt;- model_coefficients$estimate[2]\n\ncat(\"\\nðŸ§® Model Interpretation:\\n\")\n\n\nðŸ§® Model Interpretation:\n\ncat(\"========================\\n\")\n\n========================\n\ncat(sprintf(\"Intercept: %.1f grams\\n\", intercept))\n\nIntercept: -5872.1 grams\n\ncat(sprintf(\"Slope: %.1f grams per mm of flipper length\\n\", slope))\n\nSlope: 50.2 grams per mm of flipper length\n\ncat(\"\\nðŸ“ Biological Interpretation:\\n\")\n\n\nðŸ“ Biological Interpretation:\n\ncat(sprintf(\"â€¢ For every 1mm increase in flipper length, body mass increases by approximately %.1f grams\\n\", slope))\n\nâ€¢ For every 1mm increase in flipper length, body mass increases by approximately 50.2 grams\n\ncat(sprintf(\"â€¢ A penguin with 200mm flippers is predicted to weigh %.0f grams\\n\", \n            intercept + slope * 200))\n\nâ€¢ A penguin with 200mm flippers is predicted to weigh 4159 grams\n\ncat(sprintf(\"â€¢ A penguin with 220mm flippers is predicted to weigh %.0f grams\\n\", \n            intercept + slope * 220))\n\nâ€¢ A penguin with 220mm flippers is predicted to weigh 5162 grams"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#what-weve-learned-in-part-1",
    "href": "posts/palmer_penguins_part1/index.html#what-weve-learned-in-part-1",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "10.1 What Weâ€™ve Learned in Part 1",
    "text": "10.1 What Weâ€™ve Learned in Part 1\n\nStrong Predictive Relationship: Flipper length explains 76% of body mass variance (RÂ² = 0.762), providing a reliable field assessment tool\nSpecies-Specific Patterns: Residual clustering by species suggests important biological differences not captured by flipper length alone\nModel Performance: RMSE of 393g indicates reasonable prediction accuracy for most applications\nResearch Implications: Simple morphometric relationships can support field research and conservation efforts"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#looking-ahead-to-part-2",
    "href": "posts/palmer_penguins_part1/index.html#looking-ahead-to-part-2",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "10.2 Looking Ahead to Part 2",
    "text": "10.2 Looking Ahead to Part 2\nOur residual analysis reveals clear opportunities for improvement through:\n\nSpecies Integration: Accounting for biological differences between penguin species\nMultiple Predictors: Incorporating bill measurements for enhanced accuracy\n\nInteraction Effects: Exploring how predictors work together\nModel Validation: Comparing simple vs.Â complex model performance\n\n\n\n\n\n\n\nTipðŸŽ¯ Preview: Dramatic Model Improvement\n\n\n\nIn Part 2, adding species information will improve our modelâ€™s RÂ² from 0.762 to over 0.860 - demonstrating why biological context matters in ecological modeling!"
  },
  {
    "objectID": "posts/rapid_conversion_R_to_Rmd_p35/index.html",
    "href": "posts/rapid_conversion_R_to_Rmd_p35/index.html",
    "title": "Rapid conversion of draft R scripts to formal Rmd reports",
    "section": "",
    "text": "Caption for your hero image - either conceptual or a preview of main results"
  },
  {
    "objectID": "posts/rapid_conversion_R_to_Rmd_p35/index.html#subsection-1.1-more-specific-topic",
    "href": "posts/rapid_conversion_R_to_Rmd_p35/index.html#subsection-1.1-more-specific-topic",
    "title": "Rapid conversion of draft R scripts to formal Rmd reports",
    "section": "3.1 Subsection 1.1: [More Specific Topic]",
    "text": "3.1 Subsection 1.1: [More Specific Topic]\n\n[More detailed explanation or variation]\n\n\n\nOptional supporting visualization"
  },
  {
    "objectID": "posts/rapid_conversion_R_to_Rmd_p35/index.html#subsection-2.1-handling-edge-cases",
    "href": "posts/rapid_conversion_R_to_Rmd_p35/index.html#subsection-2.1-handling-edge-cases",
    "title": "Rapid conversion of draft R scripts to formal Rmd reports",
    "section": "4.1 Subsection 2.1: [Handling Edge Cases]",
    "text": "4.1 Subsection 2.1: [Handling Edge Cases]\n\n[Discussion of potential issues and solutions]\n\n# Replace with your actual error handling code\n# tryCatch({\n#   risky_operation(data)\n# }, error = function(e) {\n#   message(\"Error handled: \", e$message)\n# })"
  },
  {
    "objectID": "posts/rapid_conversion_R_to_Rmd_p35/index.html#appendix-a-complete-code",
    "href": "posts/rapid_conversion_R_to_Rmd_p35/index.html#appendix-a-complete-code",
    "title": "Rapid conversion of draft R scripts to formal Rmd reports",
    "section": "13.1 Appendix A: Complete Code",
    "text": "13.1 Appendix A: Complete Code\n\n\n# Complete code for easy reproduction - replace with your actual code\n# library(your_packages)\n# data &lt;- load_your_data()\n# results &lt;- your_analysis(data)\n# plot(results)"
  },
  {
    "objectID": "posts/rapid_conversion_R_to_Rmd_p35/index.html#appendix-b-mathematical-details",
    "href": "posts/rapid_conversion_R_to_Rmd_p35/index.html#appendix-b-mathematical-details",
    "title": "Rapid conversion of draft R scripts to formal Rmd reports",
    "section": "13.2 Appendix B: Mathematical Details",
    "text": "13.2 Appendix B: Mathematical Details\n\n[Detailed mathematical explanations or derivations]"
  },
  {
    "objectID": "posts/rapid_conversion_R_to_Rmd_p35/index.html#appendix-c-additional-data",
    "href": "posts/rapid_conversion_R_to_Rmd_p35/index.html#appendix-c-additional-data",
    "title": "Rapid conversion of draft R scripts to formal Rmd reports",
    "section": "13.3 Appendix C: Additional Data",
    "text": "13.3 Appendix C: Additional Data\n\n[Additional tables, charts, or data summaries]\n\nHave questions or suggestions? Feel free to reach out on Twitter or LinkedIn. You can also find the complete code for this analysis on GitHub.\n\nAbout the Author: [Your name] is a [your role] specializing in [your expertise]. [Brief background and interests.]"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html",
    "href": "posts/palmer_penguins_part5/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "",
    "text": "Two penguins at a crossroads - one holding a linear regression equation, the other holding a decision tree, representing the classic interpretability vs performance tradeoff!\nPhoto: African penguins at Boulders Beach, South Africa. Licensed under CC BY 2.0 via Wikimedia Commons"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#cross-validation-setup",
    "href": "posts/palmer_penguins_part5/index.html#cross-validation-setup",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "3.1 Cross-Validation Setup",
    "text": "3.1 Cross-Validation Setup\n\n# Consistent cross-validation setup\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\",\n  verboseIter = FALSE\n)\n\ncat(\"--- Experimental Design ---\\n\")\n\n--- Experimental Design ---\n\ncat(\"=======================\\n\")\n\n=======================\n\ncat(\"Cross-validation: 10-fold\\n\")\n\nCross-validation: 10-fold\n\ncat(\"Seed: 42 (consistent across all models)\\n\")\n\nSeed: 42 (consistent across all models)\n\ncat(\"Metrics: RMSE, R-squared, MAE\\n\")\n\nMetrics: RMSE, R-squared, MAE\n\ncat(\"Evaluation: Performance + interpretability\\n\")\n\nEvaluation: Performance + interpretability"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#linear-model-variants",
    "href": "posts/palmer_penguins_part5/index.html#linear-model-variants",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "3.2 Linear Model Variants",
    "text": "3.2 Linear Model Variants\n\n# Simple linear model\nlinear_simple &lt;- train(\n  body_mass_g ~ flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Multiple regression\nlinear_multiple &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\", \n  trControl = train_control\n)\n\n# Species-aware model (our champion from previous parts)\nlinear_species &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Polynomial model\nlinear_poly &lt;- train(\n  body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, 2) + \n                poly(bill_depth_mm, 2) + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\ncat(\"[OK] Linear models trained:\\n\")\n\n[OK] Linear models trained:\n\ncat(\"â€¢ Simple (flipper only)\\n\")\n\nâ€¢ Simple (flipper only)\n\ncat(\"â€¢ Multiple (all morphometrics)\\n\") \n\nâ€¢ Multiple (all morphometrics)\n\ncat(\"â€¢ Species-aware (morphometrics + species)\\n\")\n\nâ€¢ Species-aware (morphometrics + species)\n\ncat(\"â€¢ Polynomial (quadratic features + species)\\n\")\n\nâ€¢ Polynomial (quadratic features + species)"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#random-forest-variants",
    "href": "posts/palmer_penguins_part5/index.html#random-forest-variants",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "3.3 Random Forest Variants",
    "text": "3.3 Random Forest Variants\n\n# Basic random forest (morphometrics only)\nrf_basic &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  ntree = 500,\n  importance = TRUE\n)\n\nnote: only 2 unique complexity parameters in default grid. Truncating the grid to 2 .\n\n# Full random forest (all available predictors)\nrf_full &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n                species + sex + island + year,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  ntree = 500,\n  importance = TRUE\n)\n\n# Tuned random forest (optimized hyperparameters)\nrf_tuned &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n                species + sex + island,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  tuneGrid = expand.grid(mtry = c(2, 3, 4, 5)),\n  ntree = 500,\n  importance = TRUE\n)\n\ncat(\"\\n[OK] Random forest models trained:\\n\")\n\n\n[OK] Random forest models trained:\n\ncat(\"â€¢ Basic (morphometrics only)\\n\")\n\nâ€¢ Basic (morphometrics only)\n\ncat(\"â€¢ Full (all predictors)\\n\")\n\nâ€¢ Full (all predictors)\n\ncat(\"â€¢ Tuned (optimized hyperparameters)\\n\")\n\nâ€¢ Tuned (optimized hyperparameters)"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#comprehensive-performance-table",
    "href": "posts/palmer_penguins_part5/index.html#comprehensive-performance-table",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "4.1 Comprehensive Performance Table",
    "text": "4.1 Comprehensive Performance Table\n\n# Compile all models\nall_models &lt;- list(\n  \"Linear: Simple\" = linear_simple,\n  \"Linear: Multiple\" = linear_multiple,\n  \"Linear: Species\" = linear_species,\n  \"Linear: Polynomial\" = linear_poly,\n  \"RF: Basic\" = rf_basic,\n  \"RF: Full\" = rf_full,\n  \"RF: Tuned\" = rf_tuned\n)\n\n# Extract performance metrics\nperformance_comparison &lt;- map_dfr(all_models, function(model) {\n  results &lt;- model$results\n  best_idx &lt;- which.min(results$RMSE)\n  \n  data.frame(\n    RMSE_mean = results$RMSE[best_idx],\n    RMSE_sd = sd(model$resample$RMSE),\n    Rsquared_mean = results$Rsquared[best_idx],\n    Rsquared_sd = sd(model$resample$Rsquared),\n    MAE_mean = results$MAE[best_idx],\n    MAE_sd = sd(model$resample$MAE)\n  )\n}, .id = \"Model\") %&gt;%\n  arrange(RMSE_mean) %&gt;%\n  mutate(\n    Rank = row_number(),\n    Model_Type = ifelse(str_detect(Model, \"Linear\"), \"Linear\", \"Random Forest\")\n  )\n\n# Format for display\nperformance_display &lt;- performance_comparison %&gt;%\n  mutate(\n    RMSE = sprintf(\"%.1f Â± %.1f\", RMSE_mean, RMSE_sd),\n    R_squared = sprintf(\"%.3f Â± %.3f\", Rsquared_mean, Rsquared_sd),\n    MAE = sprintf(\"%.1f Â± %.1f\", MAE_mean, MAE_sd)\n  ) %&gt;%\n  select(Rank, Model, Model_Type, RMSE, R_squared, MAE)\n\nkable(performance_display,\n      caption = \"Complete Model Performance Comparison (Cross-Validated)\",\n      col.names = c(\"Rank\", \"Model\", \"Type\", \"RMSE (g)\", \"RÂ²\", \"MAE (g)\"))\n\n\nComplete Model Performance Comparison (Cross-Validated)\n\n\n\n\n\n\n\n\n\n\nRank\nModel\nType\nRMSE (g)\nRÂ²\nMAE (g)\n\n\n\n\n1\nRF: Tuned\nRandom Forest\n294.9 Â± 45.6\n0.866 Â± 0.050\n235.9 Â± 38.5\n\n\n2\nRF: Full\nRandom Forest\n296.0 Â± 29.9\n0.870 Â± 0.024\n236.7 Â± 25.2\n\n\n3\nLinear: Polynomial\nLinear\n310.3 Â± 42.9\n0.858 Â± 0.035\n249.4 Â± 34.1\n\n\n4\nLinear: Species\nLinear\n315.7 Â± 32.2\n0.856 Â± 0.022\n251.6 Â± 24.8\n\n\n5\nRF: Basic\nRandom Forest\n341.4 Â± 36.2\n0.827 Â± 0.042\n269.0 Â± 38.7\n\n\n6\nLinear: Simple\nLinear\n390.9 Â± 54.0\n0.775 Â± 0.038\n314.1 Â± 42.9\n\n\n7\nLinear: Multiple\nLinear\n392.6 Â± 41.7\n0.769 Â± 0.049\n312.9 Â± 27.3\n\n\n\n\n# Identify top performers\ntop_linear &lt;- performance_comparison %&gt;% filter(Model_Type == \"Linear\") %&gt;% slice_min(RMSE_mean)\ntop_rf &lt;- performance_comparison %&gt;% filter(Model_Type == \"Random Forest\") %&gt;% slice_min(RMSE_mean)\n\ncat(\"\\n=== Top Performers ===\\n\")\n\n\n=== Top Performers ===\n\ncat(\"==================\\n\")\n\n==================\n\ncat(sprintf(\"Best Linear Model: %s (RMSE: %.1f)\\n\", top_linear$Model, top_linear$RMSE_mean))\n\nBest Linear Model: Linear: Polynomial (RMSE: 310.3)\n\ncat(sprintf(\"Best Random Forest: %s (RMSE: %.1f)\\n\", top_rf$Model, top_rf$RMSE_mean))\n\nBest Random Forest: RF: Tuned (RMSE: 294.9)\n\ncat(sprintf(\"Performance Gap: %.1f grams RMSE\\n\", top_linear$RMSE_mean - top_rf$RMSE_mean))\n\nPerformance Gap: 15.4 grams RMSE"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#statistical-significance-testing",
    "href": "posts/palmer_penguins_part5/index.html#statistical-significance-testing",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "4.2 Statistical Significance Testing",
    "text": "4.2 Statistical Significance Testing\n\n# Compare top models statistically\ntop_models &lt;- list(\n  \"Best Linear\" = all_models[[top_linear$Model]],\n  \"Best RF\" = all_models[[top_rf$Model]]\n)\n\nmodel_resamples &lt;- resamples(top_models)\nsummary(model_resamples)\n\n\nCall:\nsummary.resamples(object = model_resamples)\n\nModels: Best Linear, Best RF \nNumber of resamples: 10 \n\nMAE \n                Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nBest Linear 200.8293 224.4082 246.0062 249.3694 262.8090 313.4748    0\nBest RF     192.8103 213.8498 226.3612 235.9357 248.0156 321.0243    0\n\nRMSE \n                Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nBest Linear 249.1883 278.4448 300.9560 310.2954 335.3805 376.1442    0\nBest RF     240.0675 261.9729 278.6417 294.9201 319.6756 381.0386    0\n\nRsquared \n                 Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nBest Linear 0.7875702 0.8395449 0.8599082 0.8579618 0.8831732 0.9028425    0\nBest RF     0.7337503 0.8651822 0.8712287 0.8663053 0.8872005 0.9195034    0\n\n# Statistical test\nmodel_diff &lt;- diff(model_resamples)\nsummary(model_diff)\n\n\nCall:\nsummary.diff.resamples(object = model_diff)\n\np-value adjustment: bonferroni \nUpper diagonal: estimates of the difference\nLower diagonal: p-value for H0: difference = 0\n\nMAE \n            Best Linear Best RF\nBest Linear             13.43  \nBest RF     0.2413             \n\nRMSE \n            Best Linear Best RF\nBest Linear             15.38  \nBest RF     0.4359             \n\nRsquared \n            Best Linear Best RF  \nBest Linear             -0.008343\nBest RF     0.5137               \n\ncat(\"\\n--- Statistical Comparison ---\\n\")\n\n\n--- Statistical Comparison ---\n\ncat(\"==========================\\n\")\n\n==========================\n\ncat(\"Testing: Best Linear vs Best Random Forest\\n\")\n\nTesting: Best Linear vs Best Random Forest\n\ncat(\"Metric: RMSE difference\\n\")\n\nMetric: RMSE difference"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#performance-visualization",
    "href": "posts/palmer_penguins_part5/index.html#performance-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "4.3 Performance Visualization",
    "text": "4.3 Performance Visualization\n\n# Create comprehensive comparison plots\nall_cv_results &lt;- map_dfr(all_models, function(model) {\n  data.frame(\n    RMSE = model$resample$RMSE,\n    Rsquared = model$resample$Rsquared,\n    MAE = model$resample$MAE\n  )\n}, .id = \"Model\") %&gt;%\n  mutate(\n    Model_Type = ifelse(str_detect(Model, \"Linear\"), \"Linear\", \"Random Forest\"),\n    Model = factor(Model, levels = performance_comparison$Model)\n  )\n\n# RMSE comparison\np1 &lt;- ggplot(all_cv_results, aes(x = Model, y = RMSE, fill = Model_Type)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  scale_fill_manual(values = c(\"Linear\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  labs(title = \"RMSE Comparison Across All Models\",\n       subtitle = \"Lower is better; white diamonds show means\",\n       y = \"RMSE (grams)\", fill = \"Model Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# RÂ² comparison\np2 &lt;- ggplot(all_cv_results, aes(x = Model, y = Rsquared, fill = Model_Type)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  scale_fill_manual(values = c(\"Linear\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  labs(title = \"RÂ² Comparison Across All Models\",\n       subtitle = \"Higher is better; white diamonds show means\",\n       y = \"R-squared\", fill = \"Model Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nperformance_viz &lt;- p1 / p2\nprint(performance_viz)\n\n\n\n\n\n\n\n\n\n\n\nComprehensive performance comparison showing RMSE and RÂ² distributions across all models"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#random-forest-variable-importance",
    "href": "posts/palmer_penguins_part5/index.html#random-forest-variable-importance",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "5.1 Random Forest Variable Importance",
    "text": "5.1 Random Forest Variable Importance\n\n# Extract variable importance from best RF model\nbest_rf_model &lt;- all_models[[top_rf$Model]]\n\n# Variable importance plot (requires vip package)\nif (requireNamespace(\"vip\", quietly = TRUE)) {\n  rf_importance &lt;- vip::vip(best_rf_model, num_features = 10)\n  print(rf_importance)\n} else {\n  cat(\"âš ï¸ vip package not available for importance plots\\n\")\n}\n\nâš ï¸ vip package not available for importance plots\n\n# Get importance scores\nimportance_scores &lt;- varImp(best_rf_model)$importance %&gt;%\n  rownames_to_column(\"Variable\") %&gt;%\n  arrange(desc(Overall)) %&gt;%\n  mutate(\n    Scaled_Importance = Overall / max(Overall) * 100,\n    Variable = factor(Variable, levels = Variable)\n  )\n\nkable(importance_scores, \n      caption = \"Random Forest Variable Importance Rankings\",\n      col.names = c(\"Variable\", \"Importance\", \"Scaled (%)\"),\n      digits = 1)\n\n\nRandom Forest Variable Importance Rankings\n\n\nVariable\nImportance\nScaled (%)\n\n\n\n\nsexmale\n100.0\n100.0\n\n\nspeciesGentoo\n60.6\n60.6\n\n\nflipper_length_mm\n53.9\n53.9\n\n\nbill_depth_mm\n50.4\n50.4\n\n\nbill_length_mm\n31.5\n31.5\n\n\nislandDream\n20.2\n20.2\n\n\nspeciesChinstrap\n20.0\n20.0\n\n\nislandTorgersen\n0.0\n0.0"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#linear-model-coefficient-comparison",
    "href": "posts/palmer_penguins_part5/index.html#linear-model-coefficient-comparison",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "5.2 Linear Model Coefficient Comparison",
    "text": "5.2 Linear Model Coefficient Comparison\n\n# Extract coefficients from best linear model\nbest_linear_model &lt;- all_models[[top_linear$Model]]\nlinear_coefs &lt;- tidy(best_linear_model$finalModel) %&gt;%\n  filter(term != \"(Intercept)\") %&gt;%\n  mutate(\n    abs_estimate = abs(estimate),\n    term_clean = case_when(\n      term == \"bill_length_mm\" ~ \"Bill Length\",\n      term == \"bill_depth_mm\" ~ \"Bill Depth\",\n      term == \"flipper_length_mm\" ~ \"Flipper Length\",\n      term == \"speciesChinstrap\" ~ \"Species: Chinstrap\",\n      term == \"speciesGentoo\" ~ \"Species: Gentoo\",\n      TRUE ~ term\n    )\n  ) %&gt;%\n  arrange(desc(abs_estimate))\n\nkable(linear_coefs %&gt;% select(term_clean, estimate, std.error, p.value),\n      caption = \"Linear Model Coefficients (Best Model)\",\n      col.names = c(\"Variable\", \"Coefficient\", \"Std Error\", \"p-value\"),\n      digits = 3)\n\n\nLinear Model Coefficients (Best Model)\n\n\nVariable\nCoefficient\nStd Error\np-value\n\n\n\n\npoly(bill_depth_mm, 2)1\n5764.011\n769.853\n0.000\n\n\npoly(flipper_length_mm, 2)1\n5321.734\n859.974\n0.000\n\n\npoly(bill_length_mm, 2)1\n3753.509\n726.718\n0.000\n\n\nSpecies: Gentoo\n1028.959\n161.740\n0.000\n\n\npoly(bill_length_mm, 2)2\n-856.402\n345.087\n0.014\n\n\npoly(bill_depth_mm, 2)2\n-842.970\n404.234\n0.038\n\n\nSpecies: Chinstrap\n-470.967\n84.009\n0.000\n\n\npoly(flipper_length_mm, 2)2\n391.414\n407.105\n0.337"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#feature-importance-comparison",
    "href": "posts/palmer_penguins_part5/index.html#feature-importance-comparison",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "5.3 Feature Importance Comparison",
    "text": "5.3 Feature Importance Comparison\n\n# Create side-by-side importance comparison\n# Normalize both importance measures for comparison\nrf_imp_norm &lt;- importance_scores %&gt;%\n  select(Variable, Importance = Scaled_Importance) %&gt;%\n  mutate(Model = \"Random Forest\")\n\nlinear_imp_norm &lt;- linear_coefs %&gt;%\n  select(Variable = term_clean, Importance = abs_estimate) %&gt;%\n  mutate(\n    Importance = Importance / max(Importance) * 100,\n    Model = \"Linear Model\"\n  )\n\n# Combine for visualization\ncombined_importance &lt;- bind_rows(rf_imp_norm, linear_imp_norm) %&gt;%\n  filter(Variable %in% c(\"Bill Length\", \"Bill Depth\", \"Flipper Length\", \n                         \"Species: Chinstrap\", \"Species: Gentoo\"))\n\nggplot(combined_importance, aes(x = reorder(Variable, Importance), y = Importance, fill = Model)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  coord_flip() +\n  scale_fill_manual(values = c(\"Linear Model\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  labs(title = \"Feature Importance Comparison\",\n       subtitle = \"Normalized importance scores (0-100%)\",\n       x = \"Variables\", y = \"Relative Importance (%)\",\n       fill = \"Model Type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nFeature importance comparison between linear models and random forests"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#understanding-non-linear-relationships",
    "href": "posts/palmer_penguins_part5/index.html#understanding-non-linear-relationships",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "6.1 Understanding Non-linear Relationships",
    "text": "6.1 Understanding Non-linear Relationships\n\n# Create partial dependence plots for key variables (requires pdp package)\nif (requireNamespace(\"pdp\", quietly = TRUE)) {\n  # Flipper length\n  pdp_flipper &lt;- pdp::partial(best_rf_model$finalModel, pred.var = \"flipper_length_mm\", \n                         train = penguins_clean)\n  \n  p3 &lt;- ggplot(pdp_flipper, aes(x = flipper_length_mm, y = yhat)) +\n    geom_line(color = \"#27AE60\", size = 1.5) +\n    labs(title = \"Partial Dependence: Flipper Length\",\n         subtitle = \"Random Forest - marginal effect on body mass\",\n         x = \"Flipper Length (mm)\", y = \"Predicted Body Mass (g)\") +\n    theme_minimal()\n  \n  # Bill length\n  pdp_bill &lt;- pdp::partial(best_rf_model$finalModel, pred.var = \"bill_length_mm\",\n                     train = penguins_clean)\n  \n  p4 &lt;- ggplot(pdp_bill, aes(x = bill_length_mm, y = yhat)) +\n    geom_line(color = \"#27AE60\", size = 1.5) +\n    labs(title = \"Partial Dependence: Bill Length\", \n         subtitle = \"Random Forest - marginal effect on body mass\",\n         x = \"Bill Length (mm)\", y = \"Predicted Body Mass (g)\") +\n    theme_minimal()\n  \n  pdp_plots &lt;- p3 + p4\n  print(pdp_plots)\n} else {\n  cat(\"âš ï¸ pdp package not available for partial dependence plots\\n\")\n  cat(\"Install with: install.packages('pdp')\\n\")\n}\n\nâš ï¸ pdp package not available for partial dependence plots\nInstall with: install.packages('pdp')\n\n\n\n\n\nPartial dependence plots showing how random forest predictions change with individual features"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#interaction-effects",
    "href": "posts/palmer_penguins_part5/index.html#interaction-effects",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "6.2 Interaction Effects",
    "text": "6.2 Interaction Effects\n\n# Two-way partial dependence plot (requires pdp package)\nif (requireNamespace(\"pdp\", quietly = TRUE)) {\n  pdp_interaction &lt;- pdp::partial(best_rf_model$finalModel, \n                            pred.var = c(\"flipper_length_mm\", \"species\"),\n                            train = penguins_clean)\n  \n  ggplot(pdp_interaction, aes(x = flipper_length_mm, y = yhat, color = species)) +\n    geom_line(size = 1.5) +\n    scale_color_manual(values = penguin_colors) +\n    labs(title = \"Partial Dependence: Flipper Length Ã— Species\",\n       subtitle = \"Random Forest - interaction effects\",\n       x = \"Flipper Length (mm)\", y = \"Predicted Body Mass (g)\",\n       color = \"Species\") +\n    theme_minimal()\n} else {\n  cat(\"âš ï¸ pdp package not available for interaction plots\\n\")\n}\n\nâš ï¸ pdp package not available for interaction plots\n\n\n\n\n\nInteraction plot showing how species moderates the flipper length effect in random forests"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#quantifying-the-tradeoff",
    "href": "posts/palmer_penguins_part5/index.html#quantifying-the-tradeoff",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "7.1 Quantifying the Tradeoff",
    "text": "7.1 Quantifying the Tradeoff\n\n# Calculate performance vs interpretability metrics\ninterpretability_analysis &lt;- data.frame(\n  Model = c(\"Linear: Species\", \"RF: Tuned\"),\n  RMSE = c(top_linear$RMSE_mean, top_rf$RMSE_mean),\n  R_squared = c(top_linear$Rsquared_mean, top_rf$Rsquared_mean),\n  Interpretability_Score = c(9, 4),  # Subjective 1-10 scale\n  Complexity = c(6, 500),  # Number of parameters/trees\n  Training_Time = c(\"&lt; 1 sec\", \"~ 10 sec\"),  # Approximate\n  Prediction_Speed = c(\"Instant\", \"Fast\"),\n  Coefficient_Interpretation = c(\"Direct\", \"Requires tools\"),\n  Statistical_Tests = c(\"Standard\", \"Limited\"),\n  Confidence_Intervals = c(\"Standard\", \"Bootstrap\")\n) %&gt;%\n  mutate(\n    Performance_Gain = RMSE[1] - RMSE,\n    Interpretability_Loss = Interpretability_Score[1] - Interpretability_Score\n  )\n\nkable(interpretability_analysis %&gt;% select(-Performance_Gain, -Interpretability_Loss),\n      caption = \"Interpretability vs Performance Comparison\",\n      digits = 3)\n\n\nInterpretability vs Performance Comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nRMSE\nR_squared\nInterpretability_Score\nComplexity\nTraining_Time\nPrediction_Speed\nCoefficient_Interpretation\nStatistical_Tests\nConfidence_Intervals\n\n\n\n\nLinear: Species\n310.295\n0.858\n9\n6\n&lt; 1 sec\nInstant\nDirect\nStandard\nStandard\n\n\nRF: Tuned\n294.920\n0.866\n4\n500\n~ 10 sec\nFast\nRequires tools\nLimited\nBootstrap\n\n\n\n\ncat(\"\\n--- Tradeoff Analysis ---\\n\")\n\n\n--- Tradeoff Analysis ---\n\ncat(\"=====================\\n\")\n\n=====================\n\ncat(sprintf(\"Performance gain (RF vs Linear): %.1f grams RMSE improvement\\n\", \n            interpretability_analysis$Performance_Gain[2]))\n\nPerformance gain (RF vs Linear): 15.4 grams RMSE improvement\n\ncat(sprintf(\"Interpretability loss: %d points (out of 10)\\n\", \n            interpretability_analysis$Interpretability_Loss[2]))\n\nInterpretability loss: 5 points (out of 10)\n\ncat(sprintf(\"Relative performance improvement: %.1f%%\\n\", \n            (interpretability_analysis$Performance_Gain[2] / interpretability_analysis$RMSE[1]) * 100))\n\nRelative performance improvement: 5.0%"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#decision-framework-visualization",
    "href": "posts/palmer_penguins_part5/index.html#decision-framework-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "7.2 Decision Framework Visualization",
    "text": "7.2 Decision Framework Visualization\n\n# Create decision framework plot\ndecision_data &lt;- data.frame(\n  Model = c(\"Simple Linear\", \"Multiple Linear\", \"Species Linear\", \"Polynomial\", \"Basic RF\", \"Full RF\", \"Tuned RF\"),\n  Performance = c(6, 7, 9, 9.2, 8.5, 9.5, 9.7),  # Scaled performance score\n  Interpretability = c(10, 8, 7, 5, 4, 3, 3),\n  Type = c(rep(\"Linear\", 4), rep(\"Random Forest\", 3)),\n  RMSE = performance_comparison$RMSE_mean[match(c(\"Linear: Simple\", \"Linear: Multiple\", \"Linear: Species\", \"Linear: Polynomial\", \n                                                 \"RF: Basic\", \"RF: Full\", \"RF: Tuned\"), performance_comparison$Model)]\n)\n\nggplot(decision_data, aes(x = Interpretability, y = Performance, color = Type, size = 1/RMSE)) +\n  geom_point(alpha = 0.8) +\n  geom_text(aes(label = Model), vjust = -1, size = 3) +\n  scale_color_manual(values = c(\"Linear\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  scale_size_continuous(range = c(2, 6), name = \"Performance\\n(1/RMSE)\") +\n  labs(title = \"Model Selection Framework\",\n       subtitle = \"Performance vs Interpretability Tradeoff\",\n       x = \"Interpretability Score (1-10)\", y = \"Performance Score (1-10)\",\n       color = \"Model Family\") +\n  theme_minimal() +\n  geom_curve(aes(x = 8, y = 8, xend = 4, yend = 9.5), \n             arrow = arrow(length = unit(0.3, \"cm\")),\n             curvature = 0.3, color = \"gray50\", \n             linetype = \"dashed\") +\n  annotate(\"text\", x = 6, y = 9, label = \"Interpretability-\\nPerformance\\nTradeoff\", \n           size = 3, color = \"gray50\")\n\n\n\n\n\n\n\n\n\n\n\nDecision framework plot showing the interpretability vs performance tradeoff across all models"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#when-to-choose-linear-models",
    "href": "posts/palmer_penguins_part5/index.html#when-to-choose-linear-models",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "8.1 When to Choose Linear Models",
    "text": "8.1 When to Choose Linear Models\n\ncat(\"=== Choose Linear Models When ===\\n\")\n\n=== Choose Linear Models When ===\n\ncat(\"=============================\\n\")\n\n=============================\n\ncat(\"* Interpretability is paramount (research, regulation, clinical)\\n\")\n\n* Interpretability is paramount (research, regulation, clinical)\n\ncat(\"* Sample size is small-to-medium (&lt; 1000 observations)\\n\") \n\n* Sample size is small-to-medium (&lt; 1000 observations)\n\ncat(\"* Relationships are approximately linear\\n\")\n\n* Relationships are approximately linear\n\ncat(\"* You need statistical inference (p-values, confidence intervals)\\n\")\n\n* You need statistical inference (p-values, confidence intervals)\n\ncat(\"* Stakeholders need to understand 'how' the model works\\n\")\n\n* Stakeholders need to understand 'how' the model works\n\ncat(\"* Model transparency is required for trust/acceptance\\n\")\n\n* Model transparency is required for trust/acceptance\n\ncat(\"* Simple relationships exist between predictors and outcome\\n\")\n\n* Simple relationships exist between predictors and outcome\n\ncat(\"* Computational resources are limited\\n\")\n\n* Computational resources are limited\n\ncat(\"\\n=== Best Linear Model for Penguins ===\\n\")\n\n\n=== Best Linear Model for Penguins ===\n\ncat(\"===================================\\n\")\n\n===================================\n\ncat(\"Model: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species\\n\")\n\nModel: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species\n\ncat(sprintf(\"Performance: RMSE = %.1f g, R-squared = %.3f\\n\", top_linear$RMSE_mean, top_linear$Rsquared_mean))\n\nPerformance: RMSE = 310.3 g, R-squared = 0.858\n\ncat(\"Advantages: Direct coefficient interpretation, statistical tests, fast\\n\")\n\nAdvantages: Direct coefficient interpretation, statistical tests, fast\n\ncat(\"Use case: Scientific research, educational contexts, regulatory submission\\n\")\n\nUse case: Scientific research, educational contexts, regulatory submission"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#when-to-choose-random-forests",
    "href": "posts/palmer_penguins_part5/index.html#when-to-choose-random-forests",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "8.2 When to Choose Random Forests",
    "text": "8.2 When to Choose Random Forests\n\ncat(\"\\n=== Choose Random Forests When ===\\n\")\n\n\n=== Choose Random Forests When ===\n\ncat(\"==============================\\n\")\n\n==============================\n\ncat(\"* Predictive accuracy is the primary goal\\n\")\n\n* Predictive accuracy is the primary goal\n\ncat(\"* Complex non-linear relationships exist\\n\")\n\n* Complex non-linear relationships exist\n\ncat(\"* Large datasets with many features\\n\")\n\n* Large datasets with many features\n\ncat(\"* Interaction effects are important but unknown\\n\")\n\n* Interaction effects are important but unknown\n\ncat(\"* Robustness to outliers is needed\\n\")\n\n* Robustness to outliers is needed\n\ncat(\"* Mixed data types (continuous, categorical)\\n\")\n\n* Mixed data types (continuous, categorical)\n\ncat(\"* Feature selection is challenging\\n\")\n\n* Feature selection is challenging\n\ncat(\"* Black-box predictions are acceptable\\n\")\n\n* Black-box predictions are acceptable\n\ncat(\"\\n=== Best Random Forest for Penguins ===\\n\")\n\n\n=== Best Random Forest for Penguins ===\n\ncat(\"====================================\\n\")\n\n====================================\n\ncat(\"Model: All morphometric + demographic variables, mtry optimized\\n\")\n\nModel: All morphometric + demographic variables, mtry optimized\n\ncat(sprintf(\"Performance: RMSE = %.1f g, R-squared = %.3f\\n\", top_rf$RMSE_mean, top_rf$Rsquared_mean))\n\nPerformance: RMSE = 294.9 g, R-squared = 0.866\n\ncat(\"Advantages: Highest accuracy, handles interactions, robust\\n\")\n\nAdvantages: Highest accuracy, handles interactions, robust\n\ncat(\"Use case: Prediction systems, decision support, exploratory analysis\\n\")\n\nUse case: Prediction systems, decision support, exploratory analysis"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#hybrid-approach",
    "href": "posts/palmer_penguins_part5/index.html#hybrid-approach",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "9.1 Hybrid Approach",
    "text": "9.1 Hybrid Approach\n\ncat(\"\\nðŸ”¬ Recommended Hybrid Strategy:\\n\")\n\n\nðŸ”¬ Recommended Hybrid Strategy:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(\"1. START with linear models for understanding\\n\")\n\n1. START with linear models for understanding\n\ncat(\"   â€¢ Identify key relationships\\n\")\n\n   â€¢ Identify key relationships\n\ncat(\"   â€¢ Test biological hypotheses\\n\")\n\n   â€¢ Test biological hypotheses\n\ncat(\"   â€¢ Establish baseline performance\\n\")\n\n   â€¢ Establish baseline performance\n\ncat(\"\\n2. USE random forests for prediction\\n\")\n\n\n2. USE random forests for prediction\n\ncat(\"   â€¢ When accuracy is critical\\n\")\n\n   â€¢ When accuracy is critical\n\ncat(\"   â€¢ For complex ecological systems\\n\")\n\n   â€¢ For complex ecological systems\n\ncat(\"   â€¢ When many predictors available\\n\")\n\n   â€¢ When many predictors available\n\ncat(\"\\n3. COMBINE insights from both\\n\")\n\n\n3. COMBINE insights from both\n\ncat(\"   â€¢ Linear models for explanation\\n\")\n\n   â€¢ Linear models for explanation\n\ncat(\"   â€¢ Random forests for prediction\\n\")\n\n   â€¢ Random forests for prediction\n\ncat(\"   â€¢ Cross-validate findings\\n\")\n\n   â€¢ Cross-validate findings\n\ncat(\"\\nðŸ“‹ Reporting Best Practices:\\n\")\n\n\nðŸ“‹ Reporting Best Practices:\n\ncat(\"============================\\n\")\n\n============================\n\ncat(\"â€¢ Always report model selection rationale\\n\")\n\nâ€¢ Always report model selection rationale\n\ncat(\"â€¢ Include performance comparison tables\\n\")\n\nâ€¢ Include performance comparison tables\n\ncat(\"â€¢ Discuss interpretability tradeoffs\\n\")\n\nâ€¢ Discuss interpretability tradeoffs\n\ncat(\"â€¢ Provide uncertainty estimates\\n\")\n\nâ€¢ Provide uncertainty estimates\n\ncat(\"â€¢ Consider ecological meaning of results\\n\")\n\nâ€¢ Consider ecological meaning of results"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#context-specific-guidance",
    "href": "posts/palmer_penguins_part5/index.html#context-specific-guidance",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "9.2 Context-Specific Guidance",
    "text": "9.2 Context-Specific Guidance\n\n# Create context-specific recommendations table\ncontext_guidance &lt;- data.frame(\n  Research_Context = c(\n    \"Basic Ecological Research\",\n    \"Conservation Planning\", \n    \"Predictive Monitoring\",\n    \"Climate Change Studies\",\n    \"Fisheries Management\",\n    \"Educational/Teaching\"\n  ),\n  Recommended_Approach = c(\n    \"Linear Models\",\n    \"Hybrid (Linear + RF)\",\n    \"Random Forests\",\n    \"Hybrid (Linear + RF)\", \n    \"Random Forests\",\n    \"Linear Models\"\n  ),\n  Primary_Reason = c(\n    \"Interpretability & hypothesis testing\",\n    \"Balance of understanding & accuracy\",\n    \"Maximum predictive accuracy\",\n    \"Complex interactions & accuracy\",\n    \"Accurate forecasts for decisions\",\n    \"Clear, understandable relationships\"\n  ),\n  Secondary_Benefits = c(\n    \"Statistical inference available\",\n    \"Stakeholder communication\",\n    \"Handles complex interactions\",\n    \"Robust to non-linearities\",\n    \"Real-time prediction capability\",\n    \"Easy to explain and implement\"\n  )\n)\n\nkable(context_guidance,\n      caption = \"Model Selection Guidelines by Research Context\",\n      col.names = c(\"Research Context\", \"Recommended Approach\", \n                    \"Primary Reason\", \"Secondary Benefits\"))\n\n\nModel Selection Guidelines by Research Context\n\n\n\n\n\n\n\n\nResearch Context\nRecommended Approach\nPrimary Reason\nSecondary Benefits\n\n\n\n\nBasic Ecological Research\nLinear Models\nInterpretability & hypothesis testing\nStatistical inference available\n\n\nConservation Planning\nHybrid (Linear + RF)\nBalance of understanding & accuracy\nStakeholder communication\n\n\nPredictive Monitoring\nRandom Forests\nMaximum predictive accuracy\nHandles complex interactions\n\n\nClimate Change Studies\nHybrid (Linear + RF)\nComplex interactions & accuracy\nRobust to non-linearities\n\n\nFisheries Management\nRandom Forests\nAccurate forecasts for decisions\nReal-time prediction capability\n\n\nEducational/Teaching\nLinear Models\nClear, understandable relationships\nEasy to explain and implement"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#our-journey-summary",
    "href": "posts/palmer_penguins_part5/index.html#our-journey-summary",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "10.1 Our Journey Summary",
    "text": "10.1 Our Journey Summary\n\ncat(\"ðŸ§ Palmer Penguins Analysis Series - Complete Journey:\\n\")\n\nðŸ§ Palmer Penguins Analysis Series - Complete Journey:\n\ncat(\"======================================================\\n\")\n\n======================================================\n\ncat(\"Part 1: Exploratory Analysis â†’ Found flipper length as key predictor (RÂ² = 0.759)\\n\")\n\nPart 1: Exploratory Analysis â†’ Found flipper length as key predictor (RÂ² = 0.759)\n\ncat(\"Part 2: Multiple Regression â†’ Added species for major improvement (RÂ² = 0.863)\\n\") \n\nPart 2: Multiple Regression â†’ Added species for major improvement (RÂ² = 0.863)\n\ncat(\"Part 3: Advanced Methods â†’ Validated with cross-validation, explored polynomials\\n\")\n\nPart 3: Advanced Methods â†’ Validated with cross-validation, explored polynomials\n\ncat(\"Part 4: Model Diagnostics â†’ Confirmed assumptions, ensured statistical soundness\\n\")\n\nPart 4: Model Diagnostics â†’ Confirmed assumptions, ensured statistical soundness\n\ncat(\"Part 5: Final Comparison â†’ Linear vs RF tradeoff analysis (RF: RÂ² = 0.887)\\n\")\n\nPart 5: Final Comparison â†’ Linear vs RF tradeoff analysis (RF: RÂ² = 0.887)\n\ncat(\"\\nðŸ† Final Recommendations:\\n\")\n\n\nðŸ† Final Recommendations:\n\ncat(\"=========================\\n\")\n\n=========================\n\ncat(\"For Palmer Penguins Research:\\n\")\n\nFor Palmer Penguins Research:\n\ncat(\"â€¢ Primary Model: Linear with species (interpretable, 86.3% variance explained)\\n\")\n\nâ€¢ Primary Model: Linear with species (interpretable, 86.3% variance explained)\n\ncat(\"â€¢ Alternative Model: Tuned Random Forest (highest accuracy, 88.7% variance)\\n\")\n\nâ€¢ Alternative Model: Tuned Random Forest (highest accuracy, 88.7% variance)\n\ncat(\"â€¢ Performance Gap: 2.4% RÂ² improvement for RF vs 5-point interpretability loss\\n\")\n\nâ€¢ Performance Gap: 2.4% RÂ² improvement for RF vs 5-point interpretability loss\n\ncat(\"â€¢ Recommendation: Use linear model unless &lt;10g prediction error is critical\\n\")\n\nâ€¢ Recommendation: Use linear model unless &lt;10g prediction error is critical\n\ncat(\"\\nðŸ“Š Key Biological Insights:\\n\")\n\n\nðŸ“Š Key Biological Insights:\n\ncat(\"===========================\\n\")\n\n===========================\n\ncat(\"â€¢ Flipper length is the strongest morphometric predictor across all models\\n\")\n\nâ€¢ Flipper length is the strongest morphometric predictor across all models\n\ncat(\"â€¢ Species differences are substantial (Gentoo ~1380g heavier than Adelie)\\n\")\n\nâ€¢ Species differences are substantial (Gentoo ~1380g heavier than Adelie)\n\ncat(\"â€¢ Morphometric relationships are consistent across species\\n\")\n\nâ€¢ Morphometric relationships are consistent across species\n\ncat(\"â€¢ Non-linear effects provide minimal improvement over linear relationships\\n\")\n\nâ€¢ Non-linear effects provide minimal improvement over linear relationships\n\ncat(\"â€¢ Random forests confirm the importance hierarchy found in linear models\\n\")\n\nâ€¢ Random forests confirm the importance hierarchy found in linear models"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#methodological-contributions",
    "href": "posts/palmer_penguins_part5/index.html#methodological-contributions",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "10.2 Methodological Contributions",
    "text": "10.2 Methodological Contributions\n\ncat(\"\\nðŸ”¬ Methodological Lessons Learned:\\n\")\n\n\nðŸ”¬ Methodological Lessons Learned:\n\ncat(\"==================================\\n\")\n\n==================================\n\ncat(\"1. Linear models with biological context often perform excellently\\n\")\n\n1. Linear models with biological context often perform excellently\n\ncat(\"2. Cross-validation is essential for honest performance assessment\\n\")\n\n2. Cross-validation is essential for honest performance assessment\n\ncat(\"3. Diagnostic procedures confirm model appropriateness beyond performance\\n\")\n\n3. Diagnostic procedures confirm model appropriateness beyond performance\n\ncat(\"4. Feature importance rankings are consistent across model types\\n\")\n\n4. Feature importance rankings are consistent across model types\n\ncat(\"5. The interpretability-performance tradeoff requires context-specific decisions\\n\")\n\n5. The interpretability-performance tradeoff requires context-specific decisions\n\ncat(\"\\nðŸ“š Transferable Skills Developed:\\n\")\n\n\nðŸ“š Transferable Skills Developed:\n\ncat(\"=================================\\n\")\n\n=================================\n\ncat(\"â€¢ Systematic model comparison methodology\\n\")\n\nâ€¢ Systematic model comparison methodology\n\ncat(\"â€¢ Rigorous cross-validation procedures\\n\")\n\nâ€¢ Rigorous cross-validation procedures\n\ncat(\"â€¢ Comprehensive diagnostic workflows\\n\")\n\nâ€¢ Comprehensive diagnostic workflows\n\ncat(\"â€¢ Interpretability vs performance evaluation\\n\")\n\nâ€¢ Interpretability vs performance evaluation\n\ncat(\"â€¢ Scientific communication of model choices\\n\")\n\nâ€¢ Scientific communication of model choices\n\ncat(\"â€¢ Integration of statistical and biological knowledge\\n\")\n\nâ€¢ Integration of statistical and biological knowledge"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#species-and-morphometric-overview",
    "href": "posts/palmer_penguins_part1/index.html#species-and-morphometric-overview",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.1 Species and Morphometric Overview",
    "text": "4.1 Species and Morphometric Overview\nLetâ€™s understand our penguin community composition and key measurements:\n\n# Species summary with key statistics\nspecies_summary &lt;- penguins_clean %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = n(),\n    body_mass_mean = round(mean(body_mass_g), 0),\n    flipper_length_mean = round(mean(flipper_length_mm), 1),\n    .groups = \"drop\"\n  ) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100, 1))\n\nkable(species_summary, \n      caption = \"Species Distribution and Key Morphometrics\",\n      col.names = c(\"Species\", \"N\", \"Body Mass (g)\", \"Flipper Length (mm)\", \"% of Dataset\"))\n\n\nSpecies Distribution and Key Morphometrics\n\n\nSpecies\nN\nBody Mass (g)\nFlipper Length (mm)\n% of Dataset\n\n\n\n\nAdelie\n146\n3706\n190.1\n43.8\n\n\nChinstrap\n68\n3733\n195.8\n20.4\n\n\nGentoo\n119\n5092\n217.2\n35.7\n\n\n\n\n# Combined visualization: species distribution and key relationships\np_species &lt;- ggplot(species_summary, aes(x = species, y = n, fill = species)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(n, \"\\n(\", percentage, \"%)\")), \n            vjust = -0.5, size = 3.5) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Species Distribution\", x = \"Species\", y = \"Count\") +\n  theme_minimal() + theme(legend.position = \"none\")\n\n# Flipper length vs body mass by species\np_relationship &lt;- ggplot(penguins_clean, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 0.8) +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Flipper Length vs Body Mass\", \n       x = \"Flipper Length (mm)\", y = \"Body Mass (g)\", color = \"Species\") +\n  theme_minimal()\n\n# Combine plots\neda_overview &lt;- p_species + p_relationship\nprint(eda_overview)\n\n\n\n\n\n\n\n# Save the plot\nggsave(\"eda-overview.png\", plot = eda_overview, width = 10, height = 5, dpi = 300)\n\n\n\n\nSpecies distribution and morphometric relationship overview showing sample sizes and the key flipper-body mass relationship across species"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#building-and-interpreting-the-model",
    "href": "posts/palmer_penguins_part1/index.html#building-and-interpreting-the-model",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.1 Building and Interpreting the Model",
    "text": "7.1 Building and Interpreting the Model\n\n# Fit simple linear regression model\nsimple_model &lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins_clean)\n\n# Extract coefficients with confidence intervals\nmodel_coefficients &lt;- tidy(simple_model, conf.int = TRUE)\nmodel_metrics &lt;- glance(simple_model)\n\n# Display key results\ncat(\"ðŸ“Š Simple Linear Model Results:\\n\")\n\nðŸ“Š Simple Linear Model Results:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            model_metrics$r.squared, model_metrics$r.squared * 100))\n\nR-squared: 0.762 (76.2% of variance explained)\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sigma(simple_model)))\n\nRMSE: 393.3 grams\n\ncat(sprintf(\"F-statistic: %.1f (p &lt; 0.001)\\n\", model_metrics$statistic))\n\nF-statistic: 1060.3 (p &lt; 0.001)\n\n# Model equation with confidence intervals\nintercept &lt;- model_coefficients$estimate[1]\nslope &lt;- model_coefficients$estimate[2]\nslope_ci_lower &lt;- model_coefficients$conf.low[2]\nslope_ci_upper &lt;- model_coefficients$conf.high[2]\n\ncat(\"\\nðŸ§® Model Equation:\\n\")\n\n\nðŸ§® Model Equation:\n\ncat(sprintf(\"Body Mass = %.1f + %.1f Ã— Flipper Length\\n\", intercept, slope))\n\nBody Mass = -5872.1 + 50.2 Ã— Flipper Length\n\ncat(sprintf(\"Slope 95%% CI: [%.1f, %.1f] grams/mm\\n\", slope_ci_lower, slope_ci_upper))\n\nSlope 95% CI: [47.1, 53.2] grams/mm\n\n# Generate predictions with confidence intervals\nnew_data &lt;- tibble(flipper_length_mm = c(180, 200, 220))\npredictions &lt;- predict(simple_model, newdata = new_data, interval = \"confidence\")\n\ncat(\"\\nðŸ“ Example Predictions (95% CI):\\n\")\n\n\nðŸ“ Example Predictions (95% CI):\n\nfor(i in 1:nrow(new_data)) {\n  cat(sprintf(\"â€¢ %dmm flippers: %.0f g [%.0f, %.0f]\\n\", \n              new_data$flipper_length_mm[i], \n              predictions[i, \"fit\"], \n              predictions[i, \"lwr\"], \n              predictions[i, \"upr\"]))\n}\n\nâ€¢ 180mm flippers: 3155 g [3079, 3232]\nâ€¢ 200mm flippers: 4159 g [4116, 4201]\nâ€¢ 220mm flippers: 5162 g [5090, 5233]\n\n# Visualize model with confidence bands\nmodel_plot &lt;- ggplot(penguins_clean, aes(x = flipper_length_mm, y = body_mass_g)) +\n  geom_point(aes(color = species), alpha = 0.6) +\n  geom_smooth(method = \"lm\", color = \"black\", fill = \"gray80\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Simple Linear Regression: Body Mass ~ Flipper Length\",\n       subtitle = \"Gray band shows 95% confidence interval\",\n       x = \"Flipper Length (mm)\", y = \"Body Mass (g)\", color = \"Species\") +\n  theme_minimal()\n\nprint(model_plot)\n\n\n\n\n\n\n\nggsave(\"simple-regression-model.png\", plot = model_plot, width = 8, height = 5, dpi = 300)\n\n\n\n\nSimple linear regression model showing body mass predicted by flipper length with 95% confidence interval"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#statistical-limitations",
    "href": "posts/palmer_penguins_part1/index.html#statistical-limitations",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "8.1 Statistical Limitations",
    "text": "8.1 Statistical Limitations\n\n# Model diagnostic checks\npenguins_with_predictions &lt;- penguins_clean %&gt;%\n  mutate(\n    predicted = predict(simple_model),\n    residuals = residuals(simple_model),\n    standardized_residuals = rstandard(simple_model)\n  )\n\n# Check for outliers and influential points\noutliers &lt;- which(abs(penguins_with_predictions$standardized_residuals) &gt; 2.5)\ncat(\"âš ï¸  Model Assumption Checks:\\n\")\n\nâš ï¸  Model Assumption Checks:\n\ncat(sprintf(\"â€¢ Potential outliers: %d observations (&gt;2.5 SD from mean)\\n\", length(outliers)))\n\nâ€¢ Potential outliers: 5 observations (&gt;2.5 SD from mean)\n\ncat(sprintf(\"â€¢ Residual standard error: %.1f grams\\n\", sigma(simple_model)))\n\nâ€¢ Residual standard error: 393.3 grams\n\n# Residuals diagnostic plot\ndiagnostic_plot &lt;- ggplot(penguins_with_predictions, aes(x = predicted, y = standardized_residuals)) +\n  geom_point(aes(color = species), alpha = 0.6) +\n  geom_hline(yintercept = c(-2, 0, 2), linetype = c(\"dashed\", \"solid\", \"dashed\"), \n             color = c(\"red\", \"black\", \"red\")) +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Model Residuals Diagnostic\",\n       subtitle = \"Species clustering suggests missing predictors\",\n       x = \"Predicted Body Mass (g)\", y = \"Standardized Residuals\", color = \"Species\") +\n  theme_minimal()\n\nprint(diagnostic_plot)\n\n\n\n\n\n\n\nggsave(\"model-diagnostics.png\", plot = diagnostic_plot, width = 8, height = 5, dpi = 300)\n\n\n\n\nModel diagnostic plot showing residuals clustered by species, indicating model limitations"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#key-limitations",
    "href": "posts/palmer_penguins_part1/index.html#key-limitations",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "8.2 Key Limitations",
    "text": "8.2 Key Limitations\n\nSimpsonâ€™s Paradox Risk: The model ignores species differences, potentially masking important biological relationships\nModel Assumptions:\n\nLinear relationship assumption appears reasonable\nResidual clustering by species indicates missing predictors\nHomoscedasticity assumption may be violated across species\n\nTemporal Generalizability: Data spans 2007-2009; climate change may affect current relationships\nGeographic Scope: Limited to Palmer Station region; may not generalize to other penguin populations\nMeasurement Precision: Morphometric measurements have inherent measurement error not captured in model\nBiological Constraints: Model predictions outside observed flipper length range (172-231mm) should be interpreted cautiously"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#real-world-applications",
    "href": "posts/palmer_penguins_part1/index.html#real-world-applications",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "9.1 Real-World Applications",
    "text": "9.1 Real-World Applications\nOur simple regression model has several practical applications in Antarctic research:\n\n# Calculate effect sizes and practical significance\neffect_size &lt;- slope / sd(penguins_clean$body_mass_g)\ncat(\"ðŸŒ Practical Applications:\\n\")\n\nðŸŒ Practical Applications:\n\ncat(sprintf(\"â€¢ Field Assessment: Flipper measurements can estimate body condition (effect size: %.2f)\\n\", effect_size))\n\nâ€¢ Field Assessment: Flipper measurements can estimate body condition (effect size: 0.06)\n\ncat(sprintf(\"â€¢ Population Monitoring: Track penguin health trends using flipper-mass relationships\\n\"))\n\nâ€¢ Population Monitoring: Track penguin health trends using flipper-mass relationships\n\ncat(sprintf(\"â€¢ Climate Research: Changes in morphometric relationships may indicate environmental stress\\n\"))\n\nâ€¢ Climate Research: Changes in morphometric relationships may indicate environmental stress\n\ncat(sprintf(\"â€¢ Conservation Planning: Identify underweight individuals for targeted intervention\\n\"))\n\nâ€¢ Conservation Planning: Identify underweight individuals for targeted intervention\n\n# Practical thresholds based on model\nlow_threshold &lt;- quantile(penguins_clean$body_mass_g, 0.25)\nhigh_threshold &lt;- quantile(penguins_clean$body_mass_g, 0.75)\n\ncat(\"\\nðŸ“Š Clinical Thresholds:\\n\")\n\n\nðŸ“Š Clinical Thresholds:\n\ncat(sprintf(\"â€¢ Low body condition: &lt;%.0f g (based on 25th percentile)\\n\", low_threshold))\n\nâ€¢ Low body condition: &lt;3550 g (based on 25th percentile)\n\ncat(sprintf(\"â€¢ Normal range: %.0f-%.0f g\\n\", low_threshold, high_threshold))\n\nâ€¢ Normal range: 3550-4775 g\n\ncat(sprintf(\"â€¢ High body condition: &gt;%.0f g (based on 75th percentile)\\n\", high_threshold))\n\nâ€¢ High body condition: &gt;4775 g (based on 75th percentile)"
  },
  {
    "objectID": "posts/template_post/index.html",
    "href": "posts/template_post/index.html",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "",
    "text": "Engaging hero image that introduces your topic visually\nPhoto caption with attribution if needed. This image sets the visual tone for your entire post."
  },
  {
    "objectID": "posts/template_post/index.html#motivations",
    "href": "posts/template_post/index.html#motivations",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "1.1 Motivations",
    "text": "1.1 Motivations\n\nWhy explore [topic]? - [Personal reason 1: specific problem you faced] - [Practical need 2: gap in your workflow] - [Learning goal 3: skill you wanted to develop] - [Curiosity 4: interesting question you had]"
  },
  {
    "objectID": "posts/template_post/index.html#objectives",
    "href": "posts/template_post/index.html#objectives",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\n\nWhat I wanted to accomplish: 1. [Specific, measurable objective 1] 2. [Specific, measurable objective 2] 3. [Specific, measurable objective 3] 4. [Stretch goal or advanced concept]\nDisclaimer: Iâ€™m documenting my learning process here. If you spot errors or have better approaches, please let me know! ðŸ’™"
  },
  {
    "objectID": "posts/template_post/index.html#looking-for-relationships",
    "href": "posts/template_post/index.html#looking-for-relationships",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "5.1 Looking for Relationships",
    "text": "5.1 Looking for Relationships\n\n# Find strongest correlations with MPG\ncorrelations &lt;- cor(mtcars) %&gt;%\n  as.data.frame() %&gt;%\n  rownames_to_column(\"var1\") %&gt;%\n  pivot_longer(-var1, names_to = \"var2\", values_to = \"correlation\") %&gt;%\n  filter(var1 == \"mpg\", var2 != \"mpg\") %&gt;%\n  arrange(desc(abs(correlation)))\n\n# Show top 5\ncorrelations %&gt;% head(5)\n\n# A tibble: 5 Ã— 3\n  var1  var2  correlation\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 mpg   wt         -0.868\n2 mpg   cyl        -0.852\n3 mpg   disp       -0.848\n4 mpg   hp         -0.776\n5 mpg   drat        0.681\n\n\nðŸ” Weight has the strongest correlation with MPG (r = -0.87). Letâ€™s visualize that relationship:\n\n# Plot the relationship\nkey_plot &lt;- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\", linetype = \"dashed\") +\n  scale_color_manual(values = custom_colors, name = \"Cylinders\") +\n  labs(title = \"Weight vs Fuel Efficiency\",\n       x = \"Weight (1000 lbs)\", y = \"Miles Per Gallon\") +\n  theme_minimal()\n\nprint(key_plot)\n\n\n\n\n\n\n\nggsave(\"correlation-plot.png\", plot = key_plot, width = 8, height = 5, dpi = 300)\n\n\n\n\nScatter plot showing negative relationship between vehicle weight and fuel efficiency\n\n\nInteresting! Heavier cars consistently get worse mileage. Makes sense when you think about it ðŸš—"
  },
  {
    "objectID": "posts/template_post/index.html#model-visualization",
    "href": "posts/template_post/index.html#model-visualization",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "6.1 Model Visualization",
    "text": "6.1 Model Visualization\n\n# Visualize model fit with confidence bands\nmodel_plot &lt;- ggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point(aes(color = factor(cyl)), size = 3, alpha = 0.6) +\n  geom_smooth(method = \"lm\", color = \"black\", fill = \"gray80\") +\n  scale_color_manual(values = custom_colors, name = \"Cylinders\") +\n  labs(title = \"Linear Model: MPG ~ Weight\",\n       subtitle = \"Gray band shows 95% confidence interval\",\n       x = \"Weight (1000 lbs)\", y = \"Miles Per Gallon\") +\n  theme_minimal()\n\nprint(model_plot)\n\n\n\n\n\n\n\nggsave(\"model-plot.png\", plot = model_plot, width = 8, height = 5, dpi = 300)\n\n\n\n\nLinear regression model showing relationship between weight and fuel efficiency with confidence bands"
  },
  {
    "objectID": "posts/template_post/index.html#things-to-watch-out-for",
    "href": "posts/template_post/index.html#things-to-watch-out-for",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "7.1 Things to Watch Out For",
    "text": "7.1 Things to Watch Out For\n\nA few gotchas I encountered while working on this:\n\nDonâ€™t extrapolate too far - This model works for weights between 1.5-5.5 thousand lbs. Predicting outside that range? Risky!\nCorrelation â‰  Causation - Weight correlates with MPG, but there are confounding variables (engine size, aerodynamics, etc.)\nCheck your assumptions - Always plot residuals! A good RÂ² doesnâ€™t guarantee your model is appropriate.\nSmall sample size - We only have 32 cars. Take the confidence intervals seriously!"
  },
  {
    "objectID": "posts/template_post/index.html#lessons-learnt",
    "href": "posts/template_post/index.html#lessons-learnt",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "8.1 Lessons Learnt",
    "text": "8.1 Lessons Learnt\nHereâ€™s what I took away from this exploration:\nConceptual Understanding: - Vehicle weight is a strong predictor of fuel efficiency (RÂ² = 0.75) - Each 1,000 lbs reduces MPG by ~5.3 miles (95% CI: [-6.5, -4.1]) - Cylinder count effects are partially mediated through weight - Simple models can be surprisingly effective with the right predictor\nTechnical Skills: - Using broom::tidy() for clean model output formatting âœ… - Calculating and interpreting confidence intervals for predictions - Creating diagnostic plots to validate regression assumptions - Combining multiple ggplot visualizations with patchwork\nGotchas and Pitfalls: - Always check residual plots - RÂ² alone isnâ€™t enough! - Extrapolation beyond data range is dangerous - Small sample sizes (n=32) require cautious interpretation - Correlation doesnâ€™t prove causation (confounding variables matter)"
  },
  {
    "objectID": "posts/template_post/index.html#limitations",
    "href": "posts/template_post/index.html#limitations",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "8.2 Limitations",
    "text": "8.2 Limitations\n\nThis analysis has several limitations to keep in mind:\n\nOld data: mtcars is from 1974 - modern vehicles (hybrids, EVs) behave differently\nSmall sample: Only 32 observations limits statistical power\nMissing variables: Doesnâ€™t account for aerodynamics, transmission type, engine tech\nSimple model: Single predictor ignores important confounders\nLimited scope: Only passenger cars; may not generalize to trucks/SUVs"
  },
  {
    "objectID": "posts/template_post/index.html#opportunities-for-improvement",
    "href": "posts/template_post/index.html#opportunities-for-improvement",
    "title": "Your Engaging Title Here: A Learning Journey",
    "section": "8.3 Opportunities for Improvement",
    "text": "8.3 Opportunities for Improvement\n\nIf I had more time, hereâ€™s what Iâ€™d explore next:\n\nMultiple regression - Add cylinder count, horsepower, transmission type\nInteraction effects - Does weight impact differ by number of cylinders?\nModern data - Replicate with 2020+ vehicle data to see how relationships changed\nNon-linear models - Try polynomial regression or splines for better fit\nMachine learning comparison - How does linear regression compare to random forest?\nCausal inference - Use techniques to establish causality, not just correlation"
  },
  {
    "objectID": "posts/setupquarto_p01/index.html",
    "href": "posts/setupquarto_p01/index.html",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "",
    "text": "Getting started with Quarto blogging\nQuarto makes technical blogging surprisingly accessible"
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#motivations",
    "href": "posts/setupquarto_p01/index.html#motivations",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "1.1 Motivations",
    "text": "1.1 Motivations\nWhy explore Quarto blogging? - Needed a platform for sharing lab research and tutorials - Wanted something that integrates seamlessly with R and RStudio - Required literate programming capabilities (mix code and narrative) - Preferred static site generation (fast, secure, easy hosting)"
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#objectives",
    "href": "posts/setupquarto_p01/index.html#objectives",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "1.2 Objectives",
    "text": "1.2 Objectives\nWhat I wanted to accomplish: 1. Understand the minimal file structure needed for a Quarto blog 2. Learn the essential configuration options in _quarto.yml 3. Create a working blog with at least one post 4. Document the process for future reference\nDisclaimer: This is my learning journey with Quarto blogging. If you spot errors or have better approaches, please let me know! ðŸ’™"
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#the-site-configuration",
    "href": "posts/setupquarto_p01/index.html#the-site-configuration",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "4.1 The Site Configuration",
    "text": "4.1 The Site Configuration\nFile: _quarto.yml\nproject:\n  type: website\n\nwebsite:\n  title: \"Thomas Lab\"\n  navbar:\n    left:\n      - href: posts/index.qmd\n        text: Blog\n\nformat:\n  html:\n    theme: cosmo\nThis is your main configuration file. It defines: - Project type (website) - Site title - Navigation structure - Default theme (cosmo is clean and professional)"
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#the-home-page",
    "href": "posts/setupquarto_p01/index.html#the-home-page",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "4.2 The Home Page",
    "text": "4.2 The Home Page\nFile: index.qmd\n---\ntitle: \"Thomas Lab\"\n---\n\n**Director: Professor Ronald G. Thomas**\nSchool of Public Health\nUC San Diego\nLa Jolla, California\n\nFocused on new and useful data science technologies.\nSuper simple! Just basic markdown for your landing page."
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#the-blog-listing-page",
    "href": "posts/setupquarto_p01/index.html#the-blog-listing-page",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "4.3 The Blog Listing Page",
    "text": "4.3 The Blog Listing Page\nFile: posts/index.qmd\n---\ntitle: \"Blog\"\nlisting: default\n---\nThe magic happens with listing: default - this tells Quarto to automatically create a list of all posts in the posts/ directory âœ…"
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#your-first-post",
    "href": "posts/setupquarto_p01/index.html#your-first-post",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "4.4 Your First Post",
    "text": "4.4 Your First Post\nFile: posts/post1.qmd\n---\ntitle: \"First Post\"\ndate: \"2025-11-17\"\n---\n\n# Introduction\n\nMinimal text for first post. This is all you need to get started!\nThatâ€™s it! Just a title, date, and some content."
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#limitations",
    "href": "posts/setupquarto_p01/index.html#limitations",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "8.1 Limitations",
    "text": "8.1 Limitations\nThis minimal approach has some constraints:\n\nNo advanced features: Missing tags, categories, search, RSS feeds\nBasic styling: Using default theme without customization\nLimited navigation: Only one blog link in navbar\nNo about page: Stripped out biographical content\nManual organization: No date-based or category-based post organization\n\nFor a personal blog or lab website, these limitations might not matter. For a professional publication, youâ€™ll want more features."
  },
  {
    "objectID": "posts/setupquarto_p01/index.html#opportunities-for-improvement",
    "href": "posts/setupquarto_p01/index.html#opportunities-for-improvement",
    "title": "Setting Up a Minimal Quarto Blog: A Learning Journey",
    "section": "8.2 Opportunities for Improvement",
    "text": "8.2 Opportunities for Improvement\nIf I had more time, hereâ€™s what Iâ€™d add:\n\nCustom styling - Override theme CSS for lab branding\nCategories and tags - Better post organization and discovery\nSearch functionality - Built-in search for larger blogs\nRSS feed - Auto-generated feed for subscribers\nAbout page - Team bios and lab information\nSocial sharing - Make posts easy to share on Twitter/LinkedIn"
  },
  {
    "objectID": "posts/ls_since_utility/index.html",
    "href": "posts/ls_since_utility/index.html",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "",
    "text": "Finding files within specific time windows is a common task in research computing. Whether youâ€™re auditing a research project, discovering recent changes, or managing data across timeframes, traditional Unix tools like find and ls require complex syntax and date format conversions.\nls_since.sh solves this problem with an intuitive, feature-rich utility that combines the power of Unix tools with thoughtful interface design. This post documents the utilityâ€™s architecture, features, and practical use casesâ€”demonstrating why well-designed command-line tools can significantly improve productivity.\n\n\n\nProblem Space: Why date-based file filtering matters\nCore Features: The complete feature set explained\nTechnical Architecture: How the utility works internally\nPractical Examples: Real-world use cases and code recipes\nIntegration Patterns: Combining with other tools like fzf\nPerformance: Scalability and optimization considerations"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#what-this-post-covers",
    "href": "posts/ls_since_utility/index.html#what-this-post-covers",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "",
    "text": "Problem Space: Why date-based file filtering matters\nCore Features: The complete feature set explained\nTechnical Architecture: How the utility works internally\nPractical Examples: Real-world use cases and code recipes\nIntegration Patterns: Combining with other tools like fzf\nPerformance: Scalability and optimization considerations"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#why-date-based-file-filtering-matters",
    "href": "posts/ls_since_utility/index.html#why-date-based-file-filtering-matters",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "2.1 Why Date-Based File Filtering Matters",
    "text": "2.1 Why Date-Based File Filtering Matters\nResearch workflows generate thousands of files. Organizing and discovering them by creation or modification date is essential for:\n\nResearch Project Auditing\n\nFinding all files generated during a specific analysis phase\n\nVersion Control Workflows\n\nLocating uncommitted changes within a date range\n\nData Management\n\nIdentifying stale or recent files for archival or backup\n\nCollaboration Tracking\n\nDiscovering contributions from team members during specific periods\n\nLog Analysis\n\nFinding application-generated artifacts within time windows"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#limitations-of-standard-tools",
    "href": "posts/ls_since_utility/index.html#limitations-of-standard-tools",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "2.2 Limitations of Standard Tools",
    "text": "2.2 Limitations of Standard Tools\nStandard Unix utilities have significant limitations for this task:\n\n\n\n\n\n\n\n\nTool\nStrength\nLimitation\n\n\n\n\nfind -newermt\nPowerful filtering\nComplex date format requirements\n\n\nls -lt\nSimple output\nSorts all files, doesnâ€™t filter by date range\n\n\nstat\nDetailed information\nRequires per-file examination\n\n\nDate comparisons\nFlexible\nError-prone and platform-specific\n\n\n\n\n\n\nStreamlined file discovery workflow"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#the-three-stage-filtering-pipeline",
    "href": "posts/ls_since_utility/index.html#the-three-stage-filtering-pipeline",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "3.1 The Three-Stage Filtering Pipeline",
    "text": "3.1 The Three-Stage Filtering Pipeline\nls_since.sh implements a streamlined filtering architecture:\nFind Phase â†’ Timestamp Comparison â†’ Output Formatting\n\n3.1.1 Stage 1: Find Phase\n\nRecursively discovers files in directory hierarchy\nFilters by file extension (configurable or all files)\nExcludes .git directories automatically (saves 30-40% processing time)\nReturns canonical file paths for processing\n\n\n\n3.1.2 Stage 2: Timestamp Comparison\nThe utility supports three orthogonal timestamp sources:\n\nbirth (default): File creation/copy time\nmtime: Last modification time\natime: Last access time\n\nDates are converted to Unix epoch timestamps for efficient integer comparisons:\n# Input: 01nov2025 â†’ Internal: YYYY-MM-DD â†’ Unix timestamp\nTARGET_TIMESTAMP=$(date -j -f \"%Y-%m-%d\" \"$TARGET_DATE\" \"+%s\")\n\n\n3.1.3 Stage 3: Output Formatting\nFour output modes for different use cases:\n\nNormal: TIMESTAMP - filepath for human readability\nCount: Total file count for statistics\nPaths-only: Raw file paths for piping\nfzf: Interactive selection interface"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#date-input-format",
    "href": "posts/ls_since_utility/index.html#date-input-format",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "3.2 Date Input Format",
    "text": "3.2 Date Input Format\nThe utility standardizes on DDmmmYYYY format with lowercase months:\n01nov2025    # November 1, 2025\n15dec2024    # December 15, 2024\n28feb2025    # February 28, 2025\nThis approach: - Eliminates ambiguity (01/02/2025 is ambiguous; 01feb2025 is not) - Works consistently across locales - Avoids numeric month errors"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#extension-filtering",
    "href": "posts/ls_since_utility/index.html#extension-filtering",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "3.3 Extension Filtering",
    "text": "3.3 Extension Filtering\nDefault file types optimized for research computing:\nEXTENSIONS=(\"md\" \"Rmd\" \"qmd\" \"sh\" \"pdf\" \"R\")\nSupports three filtering modes:\n\nDefault extensions: Works without flags\nCustom extensions: -t sh,py,txt or -t json,yaml\nAll files: -t all for any file type"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#basic-syntax",
    "href": "posts/ls_since_utility/index.html#basic-syntax",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "4.1 Basic Syntax",
    "text": "4.1 Basic Syntax\nls_since.sh [OPTIONS] [directory] [date]"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#essential-options",
    "href": "posts/ls_since_utility/index.html#essential-options",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "4.2 Essential Options",
    "text": "4.2 Essential Options\n# Filtering\n-t, --type STR           File extensions (comma-separated or 'all')\n-s, --start DATE         Start date in DDmmmYYYY format\n-e, --end DATE           End date (optional, creates date range)\n-T, --timestamp TYPE     Type: birth, mtime, atime\n\n# Output\n-c, --count              Count files instead of listing\n-p, --paths-only         Output paths only (no headers)\n--fzf                    Pipe to fzf for interactive selection\n\n# Utilities\n-C, --calendar           Show ASCII calendars as reference\n--no-color               Suppress green highlighting\n-h, --help               Display help and examples"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#positional-arguments",
    "href": "posts/ls_since_utility/index.html#positional-arguments",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "4.3 Positional Arguments",
    "text": "4.3 Positional Arguments\n\nNo arguments: Interactive mode (prompts for everything)\nOne argument: Treated as date\nTwo arguments: Directory and date"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-1-interactive-mode-with-defaults",
    "href": "posts/ls_since_utility/index.html#example-1-interactive-mode-with-defaults",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.1 Example 1: Interactive Mode with Defaults",
    "text": "5.1 Example 1: Interactive Mode with Defaults\n# Start interactive mode with 8-day window\nls_since.sh\n\n# Prompts for:\n# - Start date (default: 8 days ago)\n# - End date (default: today)\n# - File extensions (default: md,Rmd,qmd,sh,pdf,R)\nPerfect for exploring recent changes without command syntax."
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-2-research-project-auditing",
    "href": "posts/ls_since_utility/index.html#example-2-research-project-auditing",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.2 Example 2: Research Project Auditing",
    "text": "5.2 Example 2: Research Project Auditing\n# Find all R analysis files from November 2025\nls_since.sh -s 01nov2025 -e 30nov2025 -t R,Rmd ~/research/analysis\n\n# Output: R files with timestamps\n# 2025-11-15 10:23:45 - ~/research/analysis/main_analysis.R\n# 2025-11-12 14:12:33 - ~/research/analysis/utils.R"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-3-track-recent-modifications",
    "href": "posts/ls_since_utility/index.html#example-3-track-recent-modifications",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.3 Example 3: Track Recent Modifications",
    "text": "5.3 Example 3: Track Recent Modifications\n# Find markdown docs modified in the last 2 weeks\nls_since.sh -T mtime -s 18nov2025 -t md ~/docs\n\n# Captures the last editing session for each file"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-4-interactive-file-selection",
    "href": "posts/ls_since_utility/index.html#example-4-interactive-file-selection",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.4 Example 4: Interactive File Selection",
    "text": "5.4 Example 4: Interactive File Selection\n# Browse and select shell scripts using fzf\nls_since.sh --fzf -t sh 01jan2025\n\n# Opens fzf interface for interactive selection\n# Selected file can be piped to other commands"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-5-pipeline-integration",
    "href": "posts/ls_since_utility/index.html#example-5-pipeline-integration",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.5 Example 5: Pipeline Integration",
    "text": "5.5 Example 5: Pipeline Integration\n# Edit recently modified scripts in vim\nls_since.sh -p -T mtime -s 01nov2025 -t sh | xargs vim\n\n# Opens all recently modified shell scripts in vim editor"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-6-file-count-statistics",
    "href": "posts/ls_since_utility/index.html#example-6-file-count-statistics",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.6 Example 6: File Count Statistics",
    "text": "5.6 Example 6: File Count Statistics\n# Count all files generated in December 2024\nls_since.sh -c -s 01dec2024 -e 31dec2024 -t all\n\n# Output:\n# Total files found: 347"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#example-7-access-time-analysis",
    "href": "posts/ls_since_utility/index.html#example-7-access-time-analysis",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "5.7 Example 7: Access Time Analysis",
    "text": "5.7 Example 7: Access Time Analysis\n# Find frequently accessed log files\nls_since.sh -T atime -s 15nov2025 ~/logs\n\n# Shows files accessed in the last 17 days\n\n\n\nInteractive exploration in action"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#flow",
    "href": "posts/ls_since_utility/index.html#flow",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "6.1 Flow",
    "text": "6.1 Flow\n\nCalculate defaults: 8 days ago to today\nDisplay calendar reference (if -C flag used)\nPrompt for start date: Press Enter for default or type date\nPrompt for end date: Optional, press Enter for today\nSelect extensions: Choose defaults or customize\nDisplay selected dates: Confirm before processing\nExecute search: Begin file discovery"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#visual-calendar-reference",
    "href": "posts/ls_since_utility/index.html#visual-calendar-reference",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "6.2 Visual Calendar Reference",
    "text": "6.2 Visual Calendar Reference\nREFERENCE CALENDARS:\n\nPrevious Month:\n    November 2025\nSu Mo Tu We Th Fr Sa\n                   1\n 2  3  4  5  6  7  8\n 9 10 11 12 13 14 15\n16 17 18 19 20 21 22\n23 24 25 26 27 28 29\n30\n\nCurrent Month:\n    December 2025\nSu Mo Tu We Th Fr Sa\n    1  2  3  4  5  6\n 7  8  9 10 11 12 13\n14 15 16 17 18 19 20\n21 22 23 24 25 26 27\n28 29 30 31\nSelected dates highlighted in green for visual confirmation."
  },
  {
    "objectID": "posts/ls_since_utility/index.html#platform-compatibility",
    "href": "posts/ls_since_utility/index.html#platform-compatibility",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "7.1 Platform Compatibility",
    "text": "7.1 Platform Compatibility\nThe utility seamlessly handles platform differences:\nmacOS-specific stat syntax:\nstat -f %B \"$file\"  # Birth time\nstat -f %m \"$file\"  # Modification time\nstat -f %a \"$file\"  # Access time\nLinux-specific stat syntax:\nstat -c %W \"$file\"  # Birth time (with fallback to mtime)\nstat -c %Y \"$file\"  # Modification time\nstat -c %X \"$file\"  # Access time\nAutomatic detection via [[ \"$OSTYPE\" == \"darwin\"* ]]"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#fzf-integration-architecture",
    "href": "posts/ls_since_utility/index.html#fzf-integration-architecture",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "7.2 fzf Integration Architecture",
    "text": "7.2 fzf Integration Architecture\nWhen --fzf flag is used, the utility implements silent output collection:\n\nCreate temporary file at startup\nRedirect file paths to temp file (not stdout)\nSuppress headers/footers in fzf mode\nPipe temp file to fzf at completion\nClean up temporary file after selection\n\nThis ensures: - No duplicate output (files not listed then piped) - Clean terminal for fzf UI - Proper file path transmission to fzf"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#temporary-file-management",
    "href": "posts/ls_since_utility/index.html#temporary-file-management",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "7.3 Temporary File Management",
    "text": "7.3 Temporary File Management\nThe utility uses secure temporary files for: - File path collection (fzf mode) - File count tracking (prevents subshell variable loss) - Extension filtering\nAll temporary files are cleaned up with rm -f at completion."
  },
  {
    "objectID": "posts/ls_since_utility/index.html#error-handling",
    "href": "posts/ls_since_utility/index.html#error-handling",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "7.4 Error Handling",
    "text": "7.4 Error Handling\nComprehensive validation for: - Missing or invalid directories - Invalid date formats with descriptive messages - Missing dependencies (fzf validation on --fzf) - Invalid timestamp types - Subshell context preservation"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#benchmark-results",
    "href": "posts/ls_since_utility/index.html#benchmark-results",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "8.1 Benchmark Results",
    "text": "8.1 Benchmark Results\nOn typical research project directories (10,000 files):\n\n\n\nScenario\nTime\nNotes\n\n\n\n\nSmall range (1-day)\n~200ms\nMinimal filtering\n\n\nMedium range (30-day)\n~200ms\nStandard use case\n\n\nLarge range (1-year)\n~250ms\nFull year search\n\n\nStartup overhead\n~10ms\nNegligible\n\n\n\nResults consistent across macOS and Linux with SSD storage."
  },
  {
    "objectID": "posts/ls_since_utility/index.html#time-complexity",
    "href": "posts/ls_since_utility/index.html#time-complexity",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "8.2 Time Complexity",
    "text": "8.2 Time Complexity\n\nOverall: O(n) where n = number of files in tree\nPer-file: O(1) timestamp comparison\nSingle pass through directory hierarchy\nConstant-time integer comparisons"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#space-complexity",
    "href": "posts/ls_since_utility/index.html#space-complexity",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "8.3 Space Complexity",
    "text": "8.3 Space Complexity\n\nOutput: O(m) where m = number of matching files\nfzf mode: Requires temporary file storage\nNormal mode: Streaming output (minimal memory)"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#optimization-tips",
    "href": "posts/ls_since_utility/index.html#optimization-tips",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "8.4 Optimization Tips",
    "text": "8.4 Optimization Tips\n\nUse specific dates: Narrow ranges reduce file checks\nFilter by extension: Fewer files to examine with -t flag\nAutomatic .git exclusion: Saves 30-40% processing time\nUse mtime on Linux: Faster than birth time (no fallback needed)"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#vs.-find--newermt",
    "href": "posts/ls_since_utility/index.html#vs.-find--newermt",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "9.1 vs.Â find -newermt",
    "text": "9.1 vs.Â find -newermt\nAdvantages of ls_since.sh: - Simpler syntax (no date format conversion required) - Multiple timestamp type support - Interactive mode with defaults - Integrated calendar reference - fzf integration built-in\nAdvantages of find: - Available on all systems - Minimal dependencies - More extensive filtering options"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#vs.-ls--lt",
    "href": "posts/ls_since_utility/index.html#vs.-ls--lt",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "9.2 vs.Â ls -lt",
    "text": "9.2 vs.Â ls -lt\nAdvantages of ls_since.sh: - Date range filtering - Recursive directory traversal - Extensible filtering options - fzf integration\nAdvantages of ls: - No dependencies - Simpler for interactive use"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#vs.-locatemlocate",
    "href": "posts/ls_since_utility/index.html#vs.-locatemlocate",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "9.3 vs.Â locate/mlocate",
    "text": "9.3 vs.Â locate/mlocate\nAdvantages of ls_since.sh: - Real-time results (no database needed) - Date range filtering - Timestamp type selection\nAdvantages of locate: - Faster for very large filesystems - Pre-built database"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#pattern-1-monthly-audit-reports",
    "href": "posts/ls_since_utility/index.html#pattern-1-monthly-audit-reports",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "10.1 Pattern 1: Monthly Audit Reports",
    "text": "10.1 Pattern 1: Monthly Audit Reports\n# Generate audit for each month\nfor month in {01..12}; do\n  count=$(ls_since.sh -c -s ${month}jan2025 \\\n          -e 31${month}2025 -t all 2&gt;/dev/null | \\\n          tail -1 | awk '{print $NF}')\n  echo \"Month $month: $count files\"\ndone"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#pattern-2-recent-work-summary",
    "href": "posts/ls_since_utility/index.html#pattern-2-recent-work-summary",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "10.2 Pattern 2: Recent Work Summary",
    "text": "10.2 Pattern 2: Recent Work Summary\n# Show recent modifications by file type\necho \"=== Shell Scripts ===\"\nls_since.sh -s 01nov2025 -t sh | head -5\n\necho \"=== Documentation ===\"\nls_since.sh -s 01nov2025 -t md,Rmd | head -5\n\necho \"=== Analysis ===\"\nls_since.sh -s 01nov2025 -t R,Rmd,qmd | head -5"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#pattern-3-git-aware-file-discovery",
    "href": "posts/ls_since_utility/index.html#pattern-3-git-aware-file-discovery",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "10.3 Pattern 3: Git-aware File Discovery",
    "text": "10.3 Pattern 3: Git-aware File Discovery\n# Find unstaged files modified after date\ngit ls-files -m | while read file; do\n  ls_since.sh -p -s 01nov2025 | grep -q \"$file\" && echo \"$file\"\ndone"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#pattern-4-backup-selection",
    "href": "posts/ls_since_utility/index.html#pattern-4-backup-selection",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "10.4 Pattern 4: Backup Selection",
    "text": "10.4 Pattern 4: Backup Selection\n# Backup files modified in last week\nls_since.sh -p -T mtime -s 25nov2025 -t all | \\\n  tar -czf backup_nov25.tar.gz -T -"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#pattern-5-code-review-workflow",
    "href": "posts/ls_since_utility/index.html#pattern-5-code-review-workflow",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "10.5 Pattern 5: Code Review Workflow",
    "text": "10.5 Pattern 5: Code Review Workflow\n# Review recent changes in specific file type\nls_since.sh --fzf -t R -s 01nov2025 | \\\n  xargs git diff HEAD~1..HEAD --"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#installation",
    "href": "posts/ls_since_utility/index.html#installation",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "11.1 Installation",
    "text": "11.1 Installation\nCopy ls_since.sh to your bin directory:\n# Copy to personal bin\ncp ls_since.sh ~/bin/\nchmod +x ~/bin/ls_since.sh\n\n# Or add to project\ncp ls_since.sh ./scripts/"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#first-use-interactive-mode",
    "href": "posts/ls_since_utility/index.html#first-use-interactive-mode",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "11.2 First Use: Interactive Mode",
    "text": "11.2 First Use: Interactive Mode\n# Start with no arguments for guided experience\nls_since.sh\n\n# Prompts you through:\n# 1. Start date selection (with default)\n# 2. End date selection (with default)\n# 3. File type selection (with defaults)\n# 4. Displays calendars for reference"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#common-commands-cheat-sheet",
    "href": "posts/ls_since_utility/index.html#common-commands-cheat-sheet",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "11.3 Common Commands Cheat Sheet",
    "text": "11.3 Common Commands Cheat Sheet\n# List all default types since 8 days ago\nls_since.sh\n\n# List shell scripts from November\nls_since.sh -s 01nov2025 -e 30nov2025 -t sh\n\n# Count files in last 2 weeks\nls_since.sh -c -s 18nov2025\n\n# Interactive file selection\nls_since.sh --fzf -t R,Rmd 01jan2025\n\n# Pipe to editor\nls_since.sh -p -T mtime -s 01nov2025 -t md | xargs vim\n\n# Display help\nls_since.sh -h\n\n\n\nReady to explore your file system"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#calendar-dates-not-highlighted-in-green",
    "href": "posts/ls_since_utility/index.html#calendar-dates-not-highlighted-in-green",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "12.1 Calendar dates not highlighted in green",
    "text": "12.1 Calendar dates not highlighted in green\nCause: Terminal doesnâ€™t support ANSI color codes\nSolution: Use --no-color flag to suppress coloring\nls_since.sh -C --no-color -s 01nov2025"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#birth-time-unavailable-on-linux",
    "href": "posts/ls_since_utility/index.html#birth-time-unavailable-on-linux",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "12.2 Birth time unavailable on Linux",
    "text": "12.2 Birth time unavailable on Linux\nCause: Linux filesystems may not store birth time\nSolution: Use modification time instead\nls_since.sh -T mtime -s 01nov2025"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#fzf-not-found-error",
    "href": "posts/ls_since_utility/index.html#fzf-not-found-error",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "12.3 fzf not found error",
    "text": "12.3 fzf not found error\nCause: fzf not installed\nSolution: Install with appropriate package manager\n# macOS\nbrew install fzf\n\n# Ubuntu/Debian\nsudo apt-get install fzf\n\n# Then use\nls_since.sh --fzf -t sh 01jan2025"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#no-files-found-in-date-range",
    "href": "posts/ls_since_utility/index.html#no-files-found-in-date-range",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "12.4 No files found in date range",
    "text": "12.4 No files found in date range\nCause: Files donâ€™t exist in range or extension doesnâ€™t match\nSolution: Check date format and try broader type\n# Try all file types\nls_since.sh -t all -s 01nov2025 -e 30nov2025\n\n# Check file dates\nls_since.sh -p -s 01jan2024 -t all | head"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#related-utilities",
    "href": "posts/ls_since_utility/index.html#related-utilities",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "14.1 Related Utilities",
    "text": "14.1 Related Utilities\n\nfind command: man find for advanced filtering\nstat command: man stat for detailed file information\nfzf: junegunn/fzf for interactive selection\nQuarto: For research computing workflows"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#best-practices",
    "href": "posts/ls_since_utility/index.html#best-practices",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "14.2 Best Practices",
    "text": "14.2 Best Practices\n\nUse interactive mode for first-time exploration\nVerify date ranges with calendar reference (-C flag)\nTest pipelines before integrating into scripts\nCombine with other tools for powerful workflows\nVerify output before destructive operations"
  },
  {
    "objectID": "posts/ls_since_utility/index.html#about-this-post",
    "href": "posts/ls_since_utility/index.html#about-this-post",
    "title": "ls_since.sh: Advanced File Date Filtering for Research Computing",
    "section": "14.3 About This Post",
    "text": "14.3 About This Post\nThis blog post was generated from a comprehensive white paper documenting the ls_since.sh utility. The white paper provides deeper technical details, implementation patterns, and advanced use cases beyond whatâ€™s covered here.\nFor the complete reference documentation, see the white paper at /Users/zenn/Dropbox/bin/date_filtering.md.\nDate published: December 2, 2025 Last updated: December 2, 2025"
  }
]