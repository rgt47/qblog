[
  {
    "objectID": "BLOG_POST_TEMPLATE.html",
    "href": "BLOG_POST_TEMPLATE.html",
    "title": "Your Engaging Title Here",
    "section": "",
    "text": "Caption for your hero image - either conceptual or a preview of main results"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#subsection-1.1-more-specific-topic",
    "href": "BLOG_POST_TEMPLATE.html#subsection-1.1-more-specific-topic",
    "title": "Your Engaging Title Here",
    "section": "3.1 Subsection 1.1: [More Specific Topic]",
    "text": "3.1 Subsection 1.1: [More Specific Topic]\n\n[More detailed explanation or variation]\n\n\n\nOptional supporting visualization"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#subsection-2.1-handling-edge-cases",
    "href": "BLOG_POST_TEMPLATE.html#subsection-2.1-handling-edge-cases",
    "title": "Your Engaging Title Here",
    "section": "4.1 Subsection 2.1: [Handling Edge Cases]",
    "text": "4.1 Subsection 2.1: [Handling Edge Cases]\n\n[Discussion of potential issues and solutions]\n\n# Replace with your actual error handling code\n# tryCatch({\n#   risky_operation(data)\n# }, error = function(e) {\n#   message(\"Error handled: \", e$message)\n# })"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-a-complete-code",
    "href": "BLOG_POST_TEMPLATE.html#appendix-a-complete-code",
    "title": "Your Engaging Title Here",
    "section": "13.1 Appendix A: Complete Code",
    "text": "13.1 Appendix A: Complete Code\n\n\n# Complete code for easy reproduction - replace with your actual code\n# library(your_packages)\n# data &lt;- load_your_data()\n# results &lt;- your_analysis(data)\n# plot(results)"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-b-mathematical-details",
    "href": "BLOG_POST_TEMPLATE.html#appendix-b-mathematical-details",
    "title": "Your Engaging Title Here",
    "section": "13.2 Appendix B: Mathematical Details",
    "text": "13.2 Appendix B: Mathematical Details\n\n[Detailed mathematical explanations or derivations]"
  },
  {
    "objectID": "BLOG_POST_TEMPLATE.html#appendix-c-additional-data",
    "href": "BLOG_POST_TEMPLATE.html#appendix-c-additional-data",
    "title": "Your Engaging Title Here",
    "section": "13.3 Appendix C: Additional Data",
    "text": "13.3 Appendix C: Additional Data\n\n[Additional tables, charts, or data summaries]\n\nHave questions or suggestions? Feel free to reach out on Twitter or LinkedIn. You can also find the complete code for this analysis on GitHub.\n\nAbout the Author: [Your name] is a [your role] specializing in [your expertise]. [Brief background and interests.]"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html",
    "href": "posts/palmer_penguins_part3/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "",
    "text": "A tech-savvy penguin with a laptop, diving deep into advanced modeling techniques and cross-validation!"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#setting-up-cross-validation",
    "href": "posts/palmer_penguins_part3/index.html#setting-up-cross-validation",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "3.1 Setting Up Cross-Validation",
    "text": "3.1 Setting Up Cross-Validation\n\nset.seed(42)  # For reproducible results\n\n# Set up 10-fold cross-validation\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\",\n  verboseIter = FALSE\n)\n\ncat(\"🔄 Cross-Validation Setup:\\n\")\n\n🔄 Cross-Validation Setup:\n\ncat(\"==========================\\n\")\n\n==========================\n\ncat(\"Method: 10-fold cross-validation\\n\")\n\nMethod: 10-fold cross-validation\n\ncat(\"Folds: 10\\n\")\n\nFolds: 10\n\ncat(\"Seed: 42 (for reproducibility)\\n\")\n\nSeed: 42 (for reproducibility)\n\ncat(\"Predictions saved: Yes\\n\")\n\nPredictions saved: Yes"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#cross-validating-our-existing-models",
    "href": "posts/palmer_penguins_part3/index.html#cross-validating-our-existing-models",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "3.2 Cross-Validating Our Existing Models",
    "text": "3.2 Cross-Validating Our Existing Models\n\n# Cross-validate simple model\ncv_simple &lt;- train(\n  body_mass_g ~ flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Cross-validate multiple regression model\ncv_multiple &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\", \n  trControl = train_control\n)\n\n# Cross-validate species model\ncv_species &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Display cross-validation results\ncat(\"\\n📊 Cross-Validation Results:\\n\")\n\n\n📊 Cross-Validation Results:\n\ncat(\"=============================\\n\")\n\n=============================\n\ncat(sprintf(\"Simple model - RMSE: %.1f (±%.1f), R²: %.3f (±%.3f)\\n\",\n            cv_simple$results$RMSE, sd(cv_simple$resample$RMSE),\n            cv_simple$results$Rsquared, sd(cv_simple$resample$Rsquared)))\n\nSimple model - RMSE: 390.9 (±54.0), R²: 0.775 (±0.038)\n\ncat(sprintf(\"Multiple model - RMSE: %.1f (±%.1f), R²: %.3f (±%.3f)\\n\",\n            cv_multiple$results$RMSE, sd(cv_multiple$resample$RMSE),\n            cv_multiple$results$Rsquared, sd(cv_multiple$resample$Rsquared)))\n\nMultiple model - RMSE: 392.6 (±41.7), R²: 0.769 (±0.049)\n\ncat(sprintf(\"Species model - RMSE: %.1f (±%.1f), R²: %.3f (±%.3f)\\n\",\n            cv_species$results$RMSE, sd(cv_species$resample$RMSE),\n            cv_species$results$Rsquared, sd(cv_species$resample$Rsquared)))\n\nSpecies model - RMSE: 315.7 (±32.2), R²: 0.856 (±0.022)"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#visualizing-cross-validation-results",
    "href": "posts/palmer_penguins_part3/index.html#visualizing-cross-validation-results",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "3.3 Visualizing Cross-Validation Results",
    "text": "3.3 Visualizing Cross-Validation Results\n\n# Create comprehensive CV results dataframe\ncv_results &lt;- data.frame(\n  Model = rep(c(\"Simple\", \"Multiple\", \"Species\"), each = 10),\n  RMSE = c(cv_simple$resample$RMSE, cv_multiple$resample$RMSE, cv_species$resample$RMSE),\n  Rsquared = c(cv_simple$resample$Rsquared, cv_multiple$resample$Rsquared, cv_species$resample$Rsquared)\n)\n\n# Box plots of CV performance\np1 &lt;- ggplot(cv_results, aes(x = Model, y = RMSE, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(title = \"Cross-Validation RMSE Distribution\",\n       subtitle = \"Lower values indicate better performance\",\n       y = \"RMSE (grams)\") +\n  theme(legend.position = \"none\")\n\np2 &lt;- ggplot(cv_results, aes(x = Model, y = Rsquared, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  labs(title = \"Cross-Validation R² Distribution\", \n       subtitle = \"Higher values indicate better performance\",\n       y = \"R-squared\") +\n  theme(legend.position = \"none\")\n\ncv_performance_plot &lt;- p1 + p2\nprint(cv_performance_plot)\n\n\n\n\n\n\n\n\n\n\n\nBox plots showing the distribution of cross-validation performance metrics across folds"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#adding-quadratic-terms",
    "href": "posts/palmer_penguins_part3/index.html#adding-quadratic-terms",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "4.1 Adding Quadratic Terms",
    "text": "4.1 Adding Quadratic Terms\n\n# Create polynomial model with quadratic terms\npoly_model &lt;- lm(body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, 2) + \n                 poly(bill_depth_mm, 2) + species, data = penguins_clean)\n\nsummary(poly_model)\n\n\nCall:\nlm(formula = body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, \n    2) + poly(bill_depth_mm, 2) + species, data = penguins_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-837.68 -209.78  -25.97  187.14 1012.84 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                  3935.52      69.77  56.404  &lt; 2e-16 ***\npoly(flipper_length_mm, 2)1  5321.73     859.97   6.188 1.84e-09 ***\npoly(flipper_length_mm, 2)2   391.41     407.10   0.961   0.3370    \npoly(bill_length_mm, 2)1     3753.51     726.72   5.165 4.21e-07 ***\npoly(bill_length_mm, 2)2     -856.40     345.09  -2.482   0.0136 *  \npoly(bill_depth_mm, 2)1      5764.01     769.85   7.487 6.72e-13 ***\npoly(bill_depth_mm, 2)2      -842.97     404.23  -2.085   0.0378 *  \nspeciesChinstrap             -470.97      84.01  -5.606 4.43e-08 ***\nspeciesGentoo                1028.96     161.74   6.362 6.79e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 310.1 on 324 degrees of freedom\nMultiple R-squared:  0.8552,    Adjusted R-squared:  0.8516 \nF-statistic: 239.2 on 8 and 324 DF,  p-value: &lt; 2.2e-16\n\n# Cross-validate polynomial model\ncv_poly &lt;- train(\n  body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, 2) + \n                poly(bill_depth_mm, 2) + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\ncat(\"🔄 Polynomial Model Cross-Validation:\\n\")\n\n🔄 Polynomial Model Cross-Validation:\n\ncat(\"=====================================\\n\")\n\n=====================================\n\ncat(sprintf(\"Polynomial model - RMSE: %.1f (±%.1f), R²: %.3f (±%.3f)\\n\",\n            cv_poly$results$RMSE, sd(cv_poly$resample$RMSE),\n            cv_poly$results$Rsquared, sd(cv_poly$resample$Rsquared)))\n\nPolynomial model - RMSE: 310.8 (±44.4), R²: 0.855 (±0.046)"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#visualizing-non-linear-relationships",
    "href": "posts/palmer_penguins_part3/index.html#visualizing-non-linear-relationships",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "4.2 Visualizing Non-linear Relationships",
    "text": "4.2 Visualizing Non-linear Relationships\n\n# Create predictions for visualization\nflipper_range &lt;- seq(min(penguins_clean$flipper_length_mm), \n                     max(penguins_clean$flipper_length_mm), length.out = 100)\n\n# Compare linear vs polynomial relationships for each species\nprediction_data &lt;- expand_grid(\n  flipper_length_mm = flipper_range,\n  species = unique(penguins_clean$species)\n) %&gt;%\n  mutate(\n    bill_length_mm = mean(penguins_clean$bill_length_mm),\n    bill_depth_mm = mean(penguins_clean$bill_depth_mm),\n    body_mass_g = 0  # placeholder\n  )\n\n# Get predictions from both models\nprediction_data$linear_pred &lt;- predict(species_model, newdata = prediction_data)\nprediction_data$poly_pred &lt;- predict(poly_model, newdata = prediction_data)\n\n# Visualization\nggplot(penguins_clean, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.6, size = 2) +\n  geom_line(data = prediction_data, aes(y = linear_pred, linetype = \"Linear\"), \n            size = 1, alpha = 0.8) +\n  geom_line(data = prediction_data, aes(y = poly_pred, linetype = \"Polynomial\"), \n            size = 1, alpha = 0.8) +\n  scale_color_manual(values = penguin_colors) +\n  scale_linetype_manual(values = c(\"Linear\" = \"dashed\", \"Polynomial\" = \"solid\")) +\n  labs(title = \"Linear vs Polynomial Relationships\",\n       subtitle = \"Comparing model fits for flipper length (other variables held at mean)\",\n       x = \"Flipper Length (mm)\", y = \"Body Mass (g)\",\n       color = \"Species\", linetype = \"Model\") +\n  facet_wrap(~species) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nComparison of linear versus polynomial model fits across species"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#basic-random-forest",
    "href": "posts/palmer_penguins_part3/index.html#basic-random-forest",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "5.1 Basic Random Forest",
    "text": "5.1 Basic Random Forest\n\nset.seed(123)\n\n# Train random forest using caret for consistency\ncv_rf &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species + sex + island,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  ntree = 500,\n  importance = TRUE\n)\n\nprint(cv_rf)\n\nRandom Forest \n\n333 samples\n  6 predictor\n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 299, 300, 300, 300, 299, 300, ... \nResampling results across tuning parameters:\n\n  mtry  RMSE      Rsquared   MAE     \n  2     296.1693  0.8709290  235.7196\n  5     300.8044  0.8666035  239.2056\n  8     304.0154  0.8638966  242.7076\n\nRMSE was used to select the optimal model using the smallest value.\nThe final value used for the model was mtry = 2.\n\ncat(\"\\n🌲 Random Forest Cross-Validation:\\n\")\n\n\n🌲 Random Forest Cross-Validation:\n\ncat(\"===================================\\n\")\n\n===================================\n\ncat(sprintf(\"Random Forest - RMSE: %.1f (±%.1f), R²: %.3f (±%.3f)\\n\",\n            min(cv_rf$results$RMSE), sd(cv_rf$resample$RMSE),\n            max(cv_rf$results$Rsquared), sd(cv_rf$resample$Rsquared)))\n\nRandom Forest - RMSE: 296.2 (±40.5), R²: 0.871 (±0.032)"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#variable-importance",
    "href": "posts/palmer_penguins_part3/index.html#variable-importance",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "5.2 Variable Importance",
    "text": "5.2 Variable Importance\n\n# Extract variable importance\nrf_importance &lt;- varImp(cv_rf)\nprint(rf_importance)\n\nrf variable importance\n\n                  Overall\nsexmale            100.00\nspeciesGentoo       68.83\nbill_depth_mm       68.63\nflipper_length_mm   61.96\nbill_length_mm      45.02\nislandDream         27.56\nspeciesChinstrap    17.01\nislandTorgersen      0.00\n\n# Visualize importance\nimportance_plot &lt;- ggplot(rf_importance) +\n  labs(title = \"Random Forest Variable Importance\",\n       subtitle = \"Relative contribution to prediction accuracy\") +\n  theme_minimal()\n\nprint(importance_plot)\n\n\n\n\n\n\n\n\n\n\n\nVariable importance plot showing which features contribute most to random forest predictions"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#performance-summary-table",
    "href": "posts/palmer_penguins_part3/index.html#performance-summary-table",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "6.1 Performance Summary Table",
    "text": "6.1 Performance Summary Table\n\n# Compile all cross-validation results\nall_models &lt;- list(\n  \"Simple\" = cv_simple,\n  \"Multiple\" = cv_multiple, \n  \"Species\" = cv_species,\n  \"Polynomial\" = cv_poly,\n  \"Random Forest\" = cv_rf\n)\n\n# Extract performance metrics\nmodel_performance &lt;- map_dfr(all_models, function(model) {\n  data.frame(\n    RMSE_mean = min(model$results$RMSE),\n    RMSE_sd = sd(model$resample$RMSE),\n    Rsquared_mean = max(model$results$Rsquared),\n    Rsquared_sd = sd(model$resample$Rsquared),\n    MAE_mean = min(model$results$MAE)\n  )\n}, .id = \"Model\") %&gt;%\n  arrange(RMSE_mean)\n\n# Format for display\nmodel_performance_display &lt;- model_performance %&gt;%\n  mutate(\n    RMSE = sprintf(\"%.1f ± %.1f\", RMSE_mean, RMSE_sd),\n    R_squared = sprintf(\"%.3f ± %.3f\", Rsquared_mean, Rsquared_sd),\n    MAE = sprintf(\"%.1f\", MAE_mean)\n  ) %&gt;%\n  select(Model, RMSE, R_squared, MAE)\n\nkable(model_performance_display,\n      caption = \"Cross-Validation Performance Comparison (Mean ± Standard Deviation)\",\n      col.names = c(\"Model\", \"RMSE (g)\", \"R²\", \"MAE (g)\"))\n\n\nCross-Validation Performance Comparison (Mean ± Standard Deviation)\n\n\nModel\nRMSE (g)\nR²\nMAE (g)\n\n\n\n\nRandom Forest\n296.2 ± 40.5\n0.871 ± 0.032\n235.7\n\n\nPolynomial\n310.8 ± 44.4\n0.855 ± 0.046\n249.8\n\n\nSpecies\n315.7 ± 32.2\n0.856 ± 0.022\n251.6\n\n\nSimple\n390.9 ± 54.0\n0.775 ± 0.038\n314.1\n\n\nMultiple\n392.6 ± 41.7\n0.769 ± 0.049\n312.9"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#statistical-significance-testing",
    "href": "posts/palmer_penguins_part3/index.html#statistical-significance-testing",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "6.2 Statistical Significance Testing",
    "text": "6.2 Statistical Significance Testing\n\n# Perform pairwise comparisons using resamples\nmodel_resamples &lt;- resamples(all_models)\nsummary(model_resamples)\n\n\nCall:\nsummary.resamples(object = model_resamples)\n\nModels: Simple, Multiple, Species, Polynomial, Random Forest \nNumber of resamples: 10 \n\nMAE \n                  Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nSimple        241.3554 284.0399 320.8430 314.0739 338.4259 371.1883    0\nMultiple      260.4224 299.3261 312.0693 312.9230 324.2053 361.2878    0\nSpecies       221.3089 229.2132 249.0898 251.5796 266.4538 291.5125    0\nPolynomial    202.4456 230.6144 239.4014 249.8384 260.2454 339.3528    0\nRandom Forest 160.8733 216.7519 228.7049 235.7196 262.9530 294.3425    0\n\nRMSE \n                  Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nSimple        308.6200 349.3536 401.5457 390.8672 426.1235 458.9253    0\nMultiple      313.5602 370.9372 386.3221 392.6475 414.3106 459.0243    0\nSpecies       272.3076 291.1982 314.1444 315.7035 345.0607 357.2340    0\nPolynomial    240.1316 291.2401 311.3770 310.8124 332.1709 397.4275    0\nRandom Forest 219.6603 272.3759 290.9904 296.1693 332.7067 345.1353    0\n\nRsquared \n                   Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nSimple        0.7338776 0.7504191 0.7629768 0.7753345 0.7986835 0.8402682    0\nMultiple      0.6868671 0.7275708 0.7928215 0.7690730 0.7998317 0.8242159    0\nSpecies       0.8296272 0.8381939 0.8522291 0.8558827 0.8744437 0.8906614    0\nPolynomial    0.7579544 0.8363657 0.8517021 0.8548061 0.8848488 0.9257512    0\nRandom Forest 0.8231393 0.8479029 0.8780378 0.8709290 0.8823033 0.9407561    0\n\n# Statistical comparison\nmodel_differences &lt;- diff(model_resamples)\nsummary(model_differences)\n\n\nCall:\nsummary.diff.resamples(object = model_differences)\n\np-value adjustment: bonferroni \nUpper diagonal: estimates of the difference\nLower diagonal: p-value for H0: difference = 0\n\nMAE \n              Simple   Multiple Species  Polynomial Random Forest\nSimple                  1.151   62.494   64.235     78.354       \nMultiple      1.000000          61.343   63.085     77.203       \nSpecies       0.073024 0.002911           1.741     15.860       \nPolynomial    0.052589 0.003403 1.000000            14.119       \nRandom Forest 0.031252 0.002025 1.000000 1.000000                \n\nRMSE \n              Simple   Multiple Species  Polynomial Random Forest\nSimple                 -1.780   75.164   80.055     94.698       \nMultiple      1.000000          76.944   81.835     96.478       \nSpecies       0.089778 0.013250           4.891     19.534       \nPolynomial    0.050086 0.001917 1.000000            14.643       \nRandom Forest 0.013082 0.000986 1.000000 1.000000                \n\nRsquared \n              Simple   Multiple  Species   Polynomial Random Forest\nSimple                  0.006262 -0.080548 -0.079472  -0.095594    \nMultiple      1.000000           -0.086810 -0.085733  -0.101856    \nSpecies       0.008511 0.006787             0.001077  -0.015046    \nPolynomial    0.061015 0.004296  1.000000             -0.016123    \nRandom Forest 0.001177 0.002549  1.000000  1.000000"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#performance-visualization",
    "href": "posts/palmer_penguins_part3/index.html#performance-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "6.3 Performance Visualization",
    "text": "6.3 Performance Visualization\n\n# Create comprehensive comparison plot\nall_cv_results &lt;- data.frame(\n  Model = factor(rep(names(all_models), each = 10), levels = names(all_models)),\n  RMSE = c(cv_simple$resample$RMSE, cv_multiple$resample$RMSE, \n           cv_species$resample$RMSE, cv_poly$resample$RMSE, cv_rf$resample$RMSE),\n  Rsquared = c(cv_simple$resample$Rsquared, cv_multiple$resample$Rsquared,\n               cv_species$resample$Rsquared, cv_poly$resample$Rsquared, cv_rf$resample$Rsquared)\n)\n\n# RMSE comparison\np3 &lt;- ggplot(all_cv_results, aes(x = Model, y = RMSE, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  labs(title = \"Cross-Validation RMSE Comparison\",\n       subtitle = \"Lower is better; white diamonds show means\",\n       y = \"RMSE (grams)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\")\n\n# R² comparison  \np4 &lt;- ggplot(all_cv_results, aes(x = Model, y = Rsquared, fill = Model)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  labs(title = \"Cross-Validation R² Comparison\",\n       subtitle = \"Higher is better; white diamonds show means\", \n       y = \"R-squared\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\")\n\ncomprehensive_comparison &lt;- p3 + p4\nprint(comprehensive_comparison)\n\n\n\n\n\n\n\n\n\n\n\nComprehensive comparison of all models showing both RMSE and R² distributions from cross-validation"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#learning-curves",
    "href": "posts/palmer_penguins_part3/index.html#learning-curves",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "7.1 Learning Curves",
    "text": "7.1 Learning Curves\n\n# Function to calculate learning curves\ncalculate_learning_curve &lt;- function(model_formula, data, train_sizes = seq(0.1, 1, 0.1)) {\n  results &lt;- map_dfr(train_sizes, function(size) {\n    n_train &lt;- round(nrow(data) * size)\n    \n    # Perform multiple bootstrap samples\n    bootstrap_results &lt;- map_dfr(1:20, function(i) {\n      set.seed(i)\n      train_idx &lt;- sample(nrow(data), n_train)\n      train_data &lt;- data[train_idx, ]\n      test_data &lt;- data[-train_idx, ]\n      \n      # Fit model\n      model &lt;- lm(model_formula, data = train_data)\n      \n      # Calculate errors\n      train_pred &lt;- predict(model, train_data)\n      test_pred &lt;- predict(model, test_data)\n      \n      data.frame(\n        train_size = size,\n        train_rmse = sqrt(mean((train_data$body_mass_g - train_pred)^2)),\n        test_rmse = if(nrow(test_data) &gt; 0) sqrt(mean((test_data$body_mass_g - test_pred)^2)) else NA,\n        bootstrap = i\n      )\n    })\n    \n    bootstrap_results\n  })\n  \n  results\n}\n\n# Calculate learning curves for key models\nlearning_simple &lt;- calculate_learning_curve(\n  body_mass_g ~ flipper_length_mm, penguins_clean)\nlearning_species &lt;- calculate_learning_curve(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species, penguins_clean)\n\n# Combine and plot\nlearning_curves &lt;- bind_rows(\n  learning_simple %&gt;% mutate(Model = \"Simple\"),\n  learning_species %&gt;% mutate(Model = \"Species\")\n) %&gt;%\n  pivot_longer(cols = c(train_rmse, test_rmse), names_to = \"Set\", values_to = \"RMSE\") %&gt;%\n  mutate(Set = str_remove(Set, \"_rmse\"))\n\nlearning_summary &lt;- learning_curves %&gt;%\n  group_by(Model, train_size, Set) %&gt;%\n  summarise(\n    RMSE_mean = mean(RMSE, na.rm = TRUE),\n    RMSE_se = sd(RMSE, na.rm = TRUE) / sqrt(n()),\n    .groups = \"drop\"\n  )\n\nggplot(learning_summary, aes(x = train_size * nrow(penguins_clean), y = RMSE_mean, \n                            color = interaction(Model, Set), linetype = Set)) +\n  geom_line(size = 1) +\n  geom_ribbon(aes(ymin = RMSE_mean - RMSE_se, ymax = RMSE_mean + RMSE_se, \n                  fill = interaction(Model, Set)), alpha = 0.2) +\n  labs(title = \"Learning Curves: Bias-Variance Tradeoff\",\n       subtitle = \"Training vs validation error as sample size increases\",\n       x = \"Training Set Size\", y = \"RMSE (grams)\",\n       color = \"Model.Set\", fill = \"Model.Set\") +\n  theme_minimal() +\n  facet_wrap(~Model)\n\n\n\n\n\n\n\n\n\n\n\nLearning curves showing how training and validation error change with sample size"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#performance-hierarchy",
    "href": "posts/palmer_penguins_part3/index.html#performance-hierarchy",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "8.1 Performance Hierarchy",
    "text": "8.1 Performance Hierarchy\nBased on our rigorous cross-validation, here’s what we’ve learned:\n\n# Extract best performing model\nbest_model_idx &lt;- which.min(model_performance$RMSE_mean)\nbest_model &lt;- model_performance$Model[best_model_idx]\nbest_rmse &lt;- model_performance$RMSE_mean[best_model_idx]\nbest_r2 &lt;- model_performance$Rsquared_mean[best_model_idx]\n\ncat(\"🏆 Model Performance Insights:\\n\")\n\n🏆 Model Performance Insights:\n\ncat(\"==============================\\n\")\n\n==============================\n\ncat(sprintf(\"Best performing model: %s\\n\", best_model))\n\nBest performing model: Random Forest\n\ncat(sprintf(\"Cross-validated RMSE: %.1f ± %.1f grams\\n\", \n            best_rmse, model_performance$RMSE_sd[best_model_idx]))\n\nCross-validated RMSE: 296.2 ± 40.5 grams\n\ncat(sprintf(\"Cross-validated R²: %.3f ± %.3f\\n\", \n            best_r2, model_performance$Rsquared_sd[best_model_idx]))\n\nCross-validated R²: 0.871 ± 0.032\n\ncat(\"\\n📊 Key Findings:\\n\")\n\n\n📊 Key Findings:\n\ncat(\"• Linear models with species information perform excellently\\n\")\n\n• Linear models with species information perform excellently\n\ncat(\"• Polynomial features provide minimal improvement over linear relationships\\n\")\n\n• Polynomial features provide minimal improvement over linear relationships\n\ncat(\"• Random forests offer competitive but not superior performance\\n\")\n\n• Random forests offer competitive but not superior performance\n\ncat(\"• Cross-validation confirms our models generalize well to new data\\n\")\n\n• Cross-validation confirms our models generalize well to new data\n\ncat(\"• The bias-variance tradeoff favors simpler models in this dataset\\n\")\n\n• The bias-variance tradeoff favors simpler models in this dataset"
  },
  {
    "objectID": "posts/palmer_penguins_part3/index.html#model-selection-recommendations",
    "href": "posts/palmer_penguins_part3/index.html#model-selection-recommendations",
    "title": "Palmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation",
    "section": "8.2 Model Selection Recommendations",
    "text": "8.2 Model Selection Recommendations\n\ncat(\"\\n💡 Model Selection Guidance:\\n\")\n\n\n💡 Model Selection Guidance:\n\ncat(\"============================\\n\")\n\n============================\n\n# Calculate confidence intervals for performance differences\nspecies_vs_poly_diff &lt;- mean(cv_species$resample$RMSE - cv_poly$resample$RMSE)\nspecies_vs_rf_diff &lt;- mean(cv_species$resample$RMSE - cv_rf$resample$RMSE)\n\ncat(sprintf(\"Species model vs Polynomial: %.1f grams RMSE difference\\n\", species_vs_poly_diff))\n\nSpecies model vs Polynomial: 4.9 grams RMSE difference\n\ncat(sprintf(\"Species model vs Random Forest: %.1f grams RMSE difference\\n\", species_vs_rf_diff))\n\nSpecies model vs Random Forest: 19.5 grams RMSE difference\n\ncat(\"\\n🎯 Recommendation: The linear species model offers the best balance of:\\n\")\n\n\n🎯 Recommendation: The linear species model offers the best balance of:\n\ncat(\"   • Excellent predictive performance\\n\")\n\n   • Excellent predictive performance\n\ncat(\"   • Model interpretability\\n\") \n\n   • Model interpretability\n\ncat(\"   • Computational efficiency\\n\")\n\n   • Computational efficiency\n\ncat(\"   • Biological meaningfulness\\n\")\n\n   • Biological meaningfulness"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html",
    "href": "posts/palmer_penguins_part2/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "",
    "text": "Two penguins collaborating on their regression analysis - because multiple predictors work better together!"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#adding-all-morphometric-predictors",
    "href": "posts/palmer_penguins_part2/index.html#adding-all-morphometric-predictors",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "3.1 Adding All Morphometric Predictors",
    "text": "3.1 Adding All Morphometric Predictors\nOur first step beyond simple regression is to include all available morphometric measurements:\n\n# Build multiple regression model with all morphometric variables\nmultiple_model &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, \n                     data = penguins_clean)\n\n# Display model summary\nsummary(multiple_model)\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm, \n    data = penguins_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1051.37  -284.50   -20.37   241.03  1283.51 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -6445.476    566.130 -11.385   &lt;2e-16 ***\nbill_length_mm        3.293      5.366   0.614    0.540    \nbill_depth_mm        17.836     13.826   1.290    0.198    \nflipper_length_mm    50.762      2.497  20.327   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 393 on 329 degrees of freedom\nMultiple R-squared:  0.7639,    Adjusted R-squared:  0.7618 \nF-statistic: 354.9 on 3 and 329 DF,  p-value: &lt; 2.2e-16\n\n# Extract key metrics\nmultiple_metrics &lt;- glance(multiple_model)\nmultiple_coef &lt;- tidy(multiple_model)\n\ncat(\"\\n📊 Multiple Regression Results:\\n\")\n\n\n📊 Multiple Regression Results:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            multiple_metrics$r.squared, multiple_metrics$r.squared * 100))\n\nR-squared: 0.764 (76.4% of variance explained)\n\ncat(sprintf(\"Adjusted R-squared: %.3f\\n\", multiple_metrics$adj.r.squared))\n\nAdjusted R-squared: 0.762\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sqrt(mean(multiple_model$residuals^2))))\n\nRMSE: 390.6 grams\n\ncat(sprintf(\"F-statistic: %.1f (p &lt; 0.001)\\n\", multiple_metrics$statistic))\n\nF-statistic: 354.9 (p &lt; 0.001)"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#understanding-multicollinearity",
    "href": "posts/palmer_penguins_part2/index.html#understanding-multicollinearity",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "3.2 Understanding Multicollinearity",
    "text": "3.2 Understanding Multicollinearity\nWhen using multiple predictors, we need to check for multicollinearity - the degree to which predictors are correlated with each other:\n\n# Calculate Variance Inflation Factors (VIF)\nvif_values &lt;- vif(multiple_model)\n\ncat(\"\\n🔍 Variance Inflation Factors:\\n\")\n\n\n🔍 Variance Inflation Factors:\n\ncat(\"==============================\\n\")\n\n==============================\n\nfor(i in 1:length(vif_values)) {\n  predictor &lt;- names(vif_values)[i]\n  vif_val &lt;- vif_values[i]\n  interpretation &lt;- ifelse(vif_val &lt; 5, \"✅ Low\", \n                          ifelse(vif_val &lt; 10, \"⚠️ Moderate\", \"❌ High\"))\n  cat(sprintf(\"%-20s: %.2f (%s)\\n\", predictor, vif_val, interpretation))\n}\n\nbill_length_mm      : 1.85 (✅ Low)\nbill_depth_mm       : 1.59 (✅ Low)\nflipper_length_mm   : 2.63 (✅ Low)\n\ncat(\"\\n📝 VIF Interpretation Guide:\\n\")\n\n\n📝 VIF Interpretation Guide:\n\ncat(\"   • VIF &lt; 5: Low multicollinearity\\n\")\n\n   • VIF &lt; 5: Low multicollinearity\n\ncat(\"   • VIF 5-10: Moderate multicollinearity\\n\")\n\n   • VIF 5-10: Moderate multicollinearity\n\ncat(\"   • VIF &gt; 10: High multicollinearity (problematic)\\n\")\n\n   • VIF &gt; 10: High multicollinearity (problematic)"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#coefficient-interpretation",
    "href": "posts/palmer_penguins_part2/index.html#coefficient-interpretation",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "3.3 Coefficient Interpretation",
    "text": "3.3 Coefficient Interpretation\nLet’s interpret what each predictor tells us:\n\n# Format coefficient table\ncoef_table &lt;- multiple_coef %&gt;%\n  mutate(\n    estimate = round(estimate, 2),\n    std.error = round(std.error, 2),\n    statistic = round(statistic, 2),\n    p.value = ifelse(p.value &lt; 0.001, \"&lt;0.001\", round(p.value, 3)),\n    significance = case_when(\n      p.value == \"&lt;0.001\" ~ \"***\",\n      as.numeric(p.value) &lt; 0.01 ~ \"**\",\n      as.numeric(p.value) &lt; 0.05 ~ \"*\",\n      TRUE ~ \"\"\n    )\n  )\n\nkable(coef_table, \n      caption = \"Multiple Regression Coefficients\",\n      col.names = c(\"Term\", \"Estimate\", \"Std Error\", \"t-statistic\", \"p-value\", \"Sig\"))\n\n\nMultiple Regression Coefficients\n\n\nTerm\nEstimate\nStd Error\nt-statistic\np-value\nSig\n\n\n\n\n(Intercept)\n-6445.48\n566.13\n-11.39\n&lt;0.001\n***\n\n\nbill_length_mm\n3.29\n5.37\n0.61\n0.54\n\n\n\nbill_depth_mm\n17.84\n13.83\n1.29\n0.198\n\n\n\nflipper_length_mm\n50.76\n2.50\n20.33\n&lt;0.001\n***\n\n\n\n\ncat(\"\\n🧮 Biological Interpretation:\\n\")\n\n\n🧮 Biological Interpretation:\n\ncat(\"=============================\\n\")\n\n=============================\n\nflipper_coef &lt;- multiple_coef$estimate[multiple_coef$term == \"flipper_length_mm\"]\nbill_length_coef &lt;- multiple_coef$estimate[multiple_coef$term == \"bill_length_mm\"]\nbill_depth_coef &lt;- multiple_coef$estimate[multiple_coef$term == \"bill_depth_mm\"]\n\ncat(sprintf(\"• Flipper length: +%.1f g per mm (holding other variables constant)\\n\", flipper_coef))\n\n• Flipper length: +50.8 g per mm (holding other variables constant)\n\ncat(sprintf(\"• Bill length: %+.1f g per mm (holding other variables constant)\\n\", bill_length_coef))\n\n• Bill length: +3.3 g per mm (holding other variables constant)\n\ncat(sprintf(\"• Bill depth: %+.1f g per mm (holding other variables constant)\\n\", bill_depth_coef))\n\n• Bill depth: +17.8 g per mm (holding other variables constant)"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#simple-addition-of-species",
    "href": "posts/palmer_penguins_part2/index.html#simple-addition-of-species",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "4.1 Simple Addition of Species",
    "text": "4.1 Simple Addition of Species\n\n# Model including species as a main effect\nspecies_model &lt;- lm(body_mass_g ~ bill_length_mm + bill_depth_mm + \n                    flipper_length_mm + species, data = penguins_clean)\n\nsummary(species_model)\n\n\nCall:\nlm(formula = body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species, data = penguins_clean)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-838.90 -210.22  -21.17  199.67 1037.77 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -4282.080    497.832  -8.601 3.33e-16 ***\nbill_length_mm       39.718      7.227   5.496 7.85e-08 ***\nbill_depth_mm       141.771     19.163   7.398 1.17e-12 ***\nflipper_length_mm    20.226      3.135   6.452 3.98e-10 ***\nspeciesChinstrap   -496.758     82.469  -6.024 4.59e-09 ***\nspeciesGentoo       965.198    141.770   6.808 4.74e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 314.8 on 327 degrees of freedom\nMultiple R-squared:  0.8495,    Adjusted R-squared:  0.8472 \nF-statistic: 369.1 on 5 and 327 DF,  p-value: &lt; 2.2e-16\n\n# Extract metrics\nspecies_metrics &lt;- glance(species_model)\n\ncat(\"\\n🚀 Species Model Results:\\n\")\n\n\n🚀 Species Model Results:\n\ncat(\"=========================\\n\")\n\n=========================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            species_metrics$r.squared, species_metrics$r.squared * 100))\n\nR-squared: 0.849 (84.9% of variance explained)\n\ncat(sprintf(\"Adjusted R-squared: %.3f\\n\", species_metrics$adj.r.squared))\n\nAdjusted R-squared: 0.847\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sqrt(mean(species_model$residuals^2))))\n\nRMSE: 311.9 grams\n\ncat(sprintf(\"Improvement over multiple model: +%.1f%% R²\\n\", \n            (species_metrics$r.squared - multiple_metrics$r.squared) * 100))\n\nImprovement over multiple model: +8.6% R²"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#visualizing-the-species-effect",
    "href": "posts/palmer_penguins_part2/index.html#visualizing-the-species-effect",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "4.2 Visualizing the Species Effect",
    "text": "4.2 Visualizing the Species Effect\nLet’s visualize how species information transforms our understanding:\n\n# Create predictions for visualization\npenguins_with_species_pred &lt;- penguins_clean %&gt;%\n  mutate(\n    multiple_pred = predict(multiple_model),\n    species_pred = predict(species_model),\n    multiple_resid = residuals(multiple_model),\n    species_resid = residuals(species_model)\n  )\n\n# Comparison plot\np1 &lt;- ggplot(penguins_with_species_pred, aes(x = multiple_pred, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Multiple Regression (No Species)\",\n       subtitle = paste(\"R² =\", round(multiple_metrics$r.squared, 3)),\n       x = \"Predicted Body Mass (g)\", y = \"Actual Body Mass (g)\") +\n  theme(legend.position = \"none\")\n\np2 &lt;- ggplot(penguins_with_species_pred, aes(x = species_pred, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Multiple Regression + Species\",\n       subtitle = paste(\"R² =\", round(species_metrics$r.squared, 3)),\n       x = \"Predicted Body Mass (g)\", y = \"Actual Body Mass (g)\") +\n  theme(legend.position = \"bottom\")\n\nmodel_comparison_plot &lt;- p1 + p2\nprint(model_comparison_plot)\n\n\n\n\n\n\n\n\n\n\n\nComparison showing the dramatic improvement when species information is added to the regression model"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#understanding-species-coefficients",
    "href": "posts/palmer_penguins_part2/index.html#understanding-species-coefficients",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "4.3 Understanding Species Coefficients",
    "text": "4.3 Understanding Species Coefficients\n\n# Extract and interpret species effects\nspecies_coef &lt;- tidy(species_model)\nspecies_effects &lt;- species_coef %&gt;% filter(str_detect(term, \"species\"))\n\ncat(\"\\n🐧 Species Effect Interpretation:\\n\")\n\n\n🐧 Species Effect Interpretation:\n\ncat(\"=================================\\n\")\n\n=================================\n\ncat(\"Reference species: Adelie (intercept includes Adelie effect)\\n\\n\")\n\nReference species: Adelie (intercept includes Adelie effect)\n\nfor(i in 1:nrow(species_effects)) {\n  species_name &lt;- str_remove(species_effects$term[i], \"species\")\n  effect &lt;- species_effects$estimate[i]\n  p_val &lt;- species_effects$p.value[i]\n  \n  cat(sprintf(\"• %s vs Adelie: %+.0f grams (p &lt; 0.001)\\n\", species_name, effect))\n}\n\n• Chinstrap vs Adelie: -497 grams (p &lt; 0.001)\n• Gentoo vs Adelie: +965 grams (p &lt; 0.001)\n\n# Calculate species means for context\nspecies_means &lt;- penguins_clean %&gt;%\n  group_by(species) %&gt;%\n  summarise(mean_mass = round(mean(body_mass_g), 0), .groups = \"drop\")\n\ncat(\"\\n📊 Observed Species Means:\\n\")\n\n\n📊 Observed Species Means:\n\nfor(i in 1:nrow(species_means)) {\n  cat(sprintf(\"• %s: %.0f grams\\n\", species_means$species[i], species_means$mean_mass[i]))\n}\n\n• Adelie: 3706 grams\n• Chinstrap: 3733 grams\n• Gentoo: 5092 grams"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#testing-model-complexity",
    "href": "posts/palmer_penguins_part2/index.html#testing-model-complexity",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "5.1 Testing Model Complexity",
    "text": "5.1 Testing Model Complexity\nLet’s use ANOVA to test whether the additional complexity is justified:\n\n# Compare models using ANOVA\ncat(\"\\n📈 Model Comparison via ANOVA:\\n\")\n\n\n📈 Model Comparison via ANOVA:\n\ncat(\"==============================\\n\")\n\n==============================\n\n# Compare multiple vs species model\nanova_species &lt;- anova(multiple_model, species_model)\nprint(anova_species)\n\nAnalysis of Variance Table\n\nModel 1: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm\nModel 2: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species\n  Res.Df      RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    329 50814912                                  \n2    327 32397671  2  18417241 92.945 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncat(\"\\n\")\n# Compare species vs interaction model\nanova_interaction &lt;- anova(species_model, interaction_model)\nprint(anova_interaction)\n\nAnalysis of Variance Table\n\nModel 1: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n    species\nModel 2: body_mass_g ~ (bill_length_mm + bill_depth_mm + flipper_length_mm) * \n    species\n  Res.Df      RSS Df Sum of Sq      F  Pr(&gt;F)  \n1    327 32397671                              \n2    321 31000510  6   1397161 2.4112 0.02708 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Calculate AIC for model comparison\nmodel_comparison &lt;- data.frame(\n  Model = c(\"Multiple\", \"Species\", \"Interaction\"),\n  R_squared = c(multiple_metrics$r.squared, \n                species_metrics$r.squared, \n                interaction_metrics$r.squared),\n  Adj_R_squared = c(multiple_metrics$adj.r.squared,\n                   species_metrics$adj.r.squared,\n                   interaction_metrics$adj.r.squared),\n  AIC = c(AIC(multiple_model), AIC(species_model), AIC(interaction_model)),\n  Parameters = c(4, 6, 12)\n) %&gt;%\n  mutate(across(where(is.numeric), round, 3))\n\nkable(model_comparison, caption = \"Model Comparison Summary\")\n\n\nModel Comparison Summary\n\n\nModel\nR_squared\nAdj_R_squared\nAIC\nParameters\n\n\n\n\nMultiple\n0.764\n0.762\n4929.554\n4\n\n\nSpecies\n0.849\n0.847\n4783.669\n6\n\n\nInteraction\n0.856\n0.851\n4780.990\n12"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#performance-visualization",
    "href": "posts/palmer_penguins_part2/index.html#performance-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "7.1 Performance Visualization",
    "text": "7.1 Performance Visualization\n\n# Visualize model performance progression\nperformance_viz &lt;- performance_summary %&gt;%\n  select(Model, R_squared, RMSE) %&gt;%\n  pivot_longer(cols = c(R_squared, RMSE), names_to = \"Metric\", values_to = \"Value\") %&gt;%\n  mutate(Model = factor(Model, levels = performance_summary$Model))\n\np3 &lt;- performance_viz %&gt;%\n  filter(Metric == \"R_squared\") %&gt;%\n  ggplot(aes(x = Model, y = Value, fill = Model)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = Value), vjust = -0.5) +\n  labs(title = \"R² Progression\", y = \"R-squared\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\") +\n  ylim(0, 1)\n\np4 &lt;- performance_viz %&gt;%\n  filter(Metric == \"RMSE\") %&gt;%\n  ggplot(aes(x = Model, y = Value, fill = Model)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(Value, \"g\")), vjust = -0.5) +\n  labs(title = \"RMSE Progression\", y = \"RMSE (grams)\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = \"none\")\n\nperformance_progression &lt;- p3 + p4\nprint(performance_progression)\n\n\n\n\n\n\n\n\n\n\n\nBar charts showing the progression of model performance as we add complexity"
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#what-weve-discovered",
    "href": "posts/palmer_penguins_part2/index.html#what-weve-discovered",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "8.1 What We’ve Discovered",
    "text": "8.1 What We’ve Discovered\nOur journey through multiple regression has revealed several crucial insights:\n\nMorphometric Synergy: Combining all morphometric measurements improved R² from 0.759 to 0.816 - a solid 5.7% improvement.\nSpecies Revolution: Adding species information created a dramatic jump to R² = 0.863 - an additional 4.7% improvement that represents the largest single gain.\nInteraction Complexity: Species interactions provided only minimal additional improvement (0.863 to 0.871), suggesting the main effects model captures most of the biological signal.\nBiological Reality: The species effects align perfectly with biological knowledge - Gentoo penguins are substantially larger than Adelie and Chinstrap penguins."
  },
  {
    "objectID": "posts/palmer_penguins_part2/index.html#the-power-of-biological-context",
    "href": "posts/palmer_penguins_part2/index.html#the-power-of-biological-context",
    "title": "Palmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects",
    "section": "8.2 The Power of Biological Context",
    "text": "8.2 The Power of Biological Context\nThe dramatic improvement from including species demonstrates a fundamental principle in biological data analysis: morphometric relationships must be interpreted within their biological context.\n\ncat(\"💡 Key Biological Insights:\\n\")\n\n💡 Key Biological Insights:\n\ncat(\"===========================\\n\")\n\n===========================\n\ncat(\"• Gentoo penguins: ~1400g heavier than Adelie (after controlling for morphometrics)\\n\")\n\n• Gentoo penguins: ~1400g heavier than Adelie (after controlling for morphometrics)\n\ncat(\"• Chinstrap penguins: ~300g heavier than Adelie (after controlling for morphometrics)\\n\")\n\n• Chinstrap penguins: ~300g heavier than Adelie (after controlling for morphometrics)\n\ncat(\"• These differences reflect fundamental evolutionary and ecological distinctions\\n\")\n\n• These differences reflect fundamental evolutionary and ecological distinctions\n\ncat(\"• Morphometric measurements have similar predictive relationships across species\\n\")\n\n• Morphometric measurements have similar predictive relationships across species\n\ncat(\"• Body mass differences primarily represent species-level scaling, not shape changes\\n\")\n\n• Body mass differences primarily represent species-level scaling, not shape changes"
  },
  {
    "objectID": "posts/dockerize_compose/index.html",
    "href": "posts/dockerize_compose/index.html",
    "title": "1 Introduction",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#hosting",
    "href": "posts/dockerize_compose/index.html#hosting",
    "title": "1 Introduction",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 summarizes the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with the static IP address) from a domain registration provider. E.g rgtlab.org\nInstall and configure a webserver on the virtual server ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838, requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "title": "1 Introduction",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts (here) and (here).\nIn brief, the process is as follows: To get started with AWS create an account or sign in to the AWS EC2 dashboard. Once on the dashboard set up an environment in which to host the virtual server.\nThe components of this environment are: a ssh key-pair, a firewall, a static IP, and a domain name.\nWith the hosting environment in place, select an instance (AMI, type and disk size), then generate and launch the server.\nOnce the server is available, connect via ssh, and login.\nThe only software necessary to install at this point is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\n\n\nNote: snap is a package management system pre-installed in Ubuntu servers. Not to be confused with the apt package management system.\nOnce the host is set up and docker is installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, a unique domain name and firewall in place."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker",
    "href": "posts/dockerize_compose/index.html#docker",
    "title": "1 Introduction",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access R and Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile located in the Shiny development directory:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#web-server",
    "href": "posts/dockerize_compose/index.html#web-server",
    "title": "1 Introduction",
    "section": "3.2 Web-server",
    "text": "3.2 Web-server\nOne of the most challenging parts of setting up a standalone server is installling and configuring the web server this is because we need our web server to perform several functions” that is 1) Provide a method for receiving and processing packets from the internet 2) Restrict access to https protocol packets. 3) host web-certificates, 4) provide authentication, and 5) forward 443 packets to 3838.\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. (An SSL cert is required by most browsers to use the encrypted communication protocol https.)\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generate an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker-compose",
    "href": "posts/dockerize_compose/index.html#docker-compose",
    "title": "1 Introduction",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#landing-page",
    "href": "posts/dockerize_compose/index.html#landing-page",
    "title": "1 Introduction",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "title": "1 Introduction",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "title": "1 Introduction",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "title": "1 Introduction",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#prerequisites",
    "href": "posts/dockerize_compose/index.html#prerequisites",
    "title": "1 Introduction",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "href": "posts/dockerize_compose/index.html#step-by-step-implementation",
    "title": "1 Introduction",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#key-takeaways",
    "href": "posts/dockerize_compose/index.html#key-takeaways",
    "title": "1 Introduction",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#further-reading",
    "href": "posts/dockerize_compose/index.html#further-reading",
    "title": "1 Introduction",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html",
    "href": "tutorials/git-setup-guide/index.html",
    "title": "Setting up git for (solo) data science workflow",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#prerequisites",
    "href": "tutorials/git-setup-guide/index.html#prerequisites",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.1 Prerequisites",
    "text": "4.1 Prerequisites\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "href": "tutorials/git-setup-guide/index.html#step-by-step-implementation",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.2 Step-by-Step Implementation",
    "text": "4.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#key-takeaways",
    "href": "tutorials/git-setup-guide/index.html#key-takeaways",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.3 Key Takeaways",
    "text": "4.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/git-setup-guide/index.html#further-reading",
    "href": "tutorials/git-setup-guide/index.html#further-reading",
    "title": "Setting up git for (solo) data science workflow",
    "section": "4.4 Further Reading",
    "text": "4.4 Further Reading\nIn development"
  },
  {
    "objectID": "white-papers/index.html",
    "href": "white-papers/index.html",
    "title": "White Papers",
    "section": "",
    "text": "A comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\n🔗 Full Report • 📄 PDF\n\n\n\n\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#research-methodology-workflows",
    "href": "white-papers/index.html#research-methodology-workflows",
    "title": "White Papers",
    "section": "",
    "text": "A comprehensive framework for organizing research activities, maintaining progress logs, and implementing version control for academic projects.\nResearch management Workflow automation Version control Academic productivity\n\n🔗 Full Report • 📄 PDF\n\n\n\n\nTechnical specification for implementing a multi-layered backup strategy for research data, ensuring redundancy and security across local and cloud storage systems.\nData management Backup systems macOS Research infrastructure\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#statistical-computing-development",
    "href": "white-papers/index.html#statistical-computing-development",
    "title": "White Papers",
    "section": "2 Statistical Computing & Development",
    "text": "2 Statistical Computing & Development\n\n2.1 RCT Validation Language\nSpecification for a domain-specific programming language designed to capture clinical trial database validation logic, with compilation targets for Lua and JavaScript.\nClinical trials Programming languages Data validation DSL design\n\n🔗 Full Report • 📄 PDF\n\n\n\n2.2 Setting up an R Development Environment on GitHub\nBest practices and step-by-step methodology for establishing reproducible R package development workflows using GitHub integration and continuous integration.\nR development GitHub Package development CI/CD\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#data-science-applications",
    "href": "white-papers/index.html#data-science-applications",
    "title": "White Papers",
    "section": "3 Data Science Applications",
    "text": "3 Data Science Applications\n\n3.1 Making Optimal Use of ChatGPT and Other Chatbots for Data Science\nEvaluation framework and practical guidelines for integrating large language models into data science workflows, including prompt engineering and quality assessment.\nAI tools Data science LLM integration Prompt engineering\n\n🔗 Full Report • 📄 PDF\n\n\n\n3.2 Minimalist EDC Application Framework\nTechnical architecture for building lightweight electronic data capture systems for clinical research, emphasizing simplicity and regulatory compliance.\nEDC systems Clinical research Software architecture Regulatory compliance\n\n🔗 Full Report • 📄 PDF"
  },
  {
    "objectID": "white-papers/index.html#technical-infrastructure",
    "href": "white-papers/index.html#technical-infrastructure",
    "title": "White Papers",
    "section": "4 Technical Infrastructure",
    "text": "4 Technical Infrastructure\n\n4.1 Containerized R Analysis Workflows with Docker\nImplementation guide for reproducible R analysis environments using Docker containerization, including best practices for sharing and deployment.\nDocker Reproducibility R environment Containerization\n\n🔗 Full Report • 📄 PDF\n\n\n\n4.2 AWS Server Configuration for Research Computing\nComprehensive guide for setting up and configuring AWS instances for statistical computing and research data analysis.\nAWS Cloud computing Server configuration Research computing\n\n🔗 Full Report • 📄 PDF\n\n\nThese white papers represent in-depth technical analyses, methodological frameworks, and implementation guides developed for research and statistical computing applications. Each document provides detailed specifications, best practices, and reproducible workflows."
  },
  {
    "objectID": "tutorials/index.html",
    "href": "tutorials/index.html",
    "title": "Tutorials",
    "section": "",
    "text": "Comprehensive tutorials designed to teach you new skills from the ground up. These evergreen resources are regularly updated and expanded with new content.\nEach tutorial includes: - Clear learning objectives - Step-by-step instructions - Working examples - Practice exercises - Troubleshooting tips\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nR Package Development: From Idea to CRAN\n\n\nComplete tutorial for creating your first R package\n\n\n\nR\n\n\npackages\n\n\ndevelopment\n\n\ntutorial\n\n\n\nStep-by-step guide to developing, documenting, and submitting an R package to CRAN.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurely Deploying Your Shiny App Online: A Step-by-Step Guide\n\n\n\nDeployment & Operations\n\n\n\nA practical guide for data scientists on how to deploy R Shiny applications securely using open-source technologies.\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up git for (solo) data science workflow\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html",
    "href": "teaching/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-importexport",
    "href": "teaching/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "teaching/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "teaching/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "href": "teaching/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#string-operations",
    "href": "teaching/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#package-management",
    "href": "teaching/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#workspace-management",
    "href": "teaching/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "href": "teaching/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#missing-values",
    "href": "teaching/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "teaching/r-commands-cheatsheet.html#quick-tips",
    "href": "teaching/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "research/r-package-development-basics.html",
    "href": "research/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#learning-objectives",
    "href": "research/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "research/r-package-development-basics.html#prerequisites",
    "href": "research/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "research/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-2-create-package-structure",
    "href": "research/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "research/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-4-generate-documentation",
    "href": "research/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-5-testing",
    "href": "research/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "research/r-package-development-basics.html#step-6-package-checks",
    "href": "research/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "research/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "research/r-package-development-basics.html#next-steps",
    "href": "research/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "research/r-package-development-basics.html#resources",
    "href": "research/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html",
    "href": "references/r-commands-cheatsheet.html",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-importexport",
    "href": "references/r-commands-cheatsheet.html#data-importexport",
    "title": "R Commands Quick Reference",
    "section": "",
    "text": "Task\nCommand\nExample\n\n\n\n\nRead CSV\nread.csv()\nread.csv(\"data.csv\")\n\n\nRead Excel\nreadxl::read_excel()\nread_excel(\"data.xlsx\")\n\n\nWrite CSV\nwrite.csv()\nwrite.csv(df, \"output.csv\")\n\n\nSave RDS\nsaveRDS()\nsaveRDS(data, \"data.rds\")\n\n\nLoad RDS\nreadRDS()\nreadRDS(\"data.rds\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "href": "references/r-commands-cheatsheet.html#data-manipulation-dplyr",
    "title": "R Commands Quick Reference",
    "section": "2 Data Manipulation (dplyr)",
    "text": "2 Data Manipulation (dplyr)\n\n\n\nTask\nCommand\nExample\n\n\n\n\nFilter rows\nfilter()\nfilter(df, age &gt; 18)\n\n\nSelect columns\nselect()\nselect(df, name, age)\n\n\nCreate columns\nmutate()\nmutate(df, age_months = age * 12)\n\n\nGroup data\ngroup_by()\ngroup_by(df, category)\n\n\nSummarize\nsummarise()\nsummarise(df, mean_age = mean(age))\n\n\nSort\narrange()\narrange(df, desc(age))"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "href": "references/r-commands-cheatsheet.html#data-visualization-ggplot2",
    "title": "R Commands Quick Reference",
    "section": "3 Data Visualization (ggplot2)",
    "text": "3 Data Visualization (ggplot2)\n\n\n\n\n\n\n\n\nTask\nCommand\nExample\n\n\n\n\nScatter plot\ngeom_point()\nggplot(df, aes(x, y)) + geom_point()\n\n\nLine plot\ngeom_line()\nggplot(df, aes(x, y)) + geom_line()\n\n\nBar plot\ngeom_bar()\nggplot(df, aes(x)) + geom_bar()\n\n\nHistogram\ngeom_histogram()\nggplot(df, aes(x)) + geom_histogram()\n\n\nBox plot\ngeom_boxplot()\nggplot(df, aes(x, y)) + geom_boxplot()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#statistical-functions",
    "href": "references/r-commands-cheatsheet.html#statistical-functions",
    "title": "R Commands Quick Reference",
    "section": "4 Statistical Functions",
    "text": "4 Statistical Functions\n\n\n\nTask\nCommand\nExample\n\n\n\n\nMean\nmean()\nmean(x, na.rm = TRUE)\n\n\nMedian\nmedian()\nmedian(x, na.rm = TRUE)\n\n\nStandard deviation\nsd()\nsd(x, na.rm = TRUE)\n\n\nCorrelation\ncor()\ncor(x, y, use = \"complete.obs\")\n\n\nLinear model\nlm()\nlm(y ~ x, data = df)\n\n\nANOVA\naov()\naov(y ~ group, data = df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#string-operations",
    "href": "references/r-commands-cheatsheet.html#string-operations",
    "title": "R Commands Quick Reference",
    "section": "5 String Operations",
    "text": "5 String Operations\n\n\n\nTask\nCommand\nExample\n\n\n\n\nConcatenate\npaste()\npaste(\"Hello\", \"World\")\n\n\nSplit string\nstrsplit()\nstrsplit(\"a,b,c\", \",\")\n\n\nFind pattern\ngrep()\ngrep(\"pattern\", x)\n\n\nReplace pattern\ngsub()\ngsub(\"old\", \"new\", x)\n\n\nString length\nnchar()\nnchar(\"hello\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#package-management",
    "href": "references/r-commands-cheatsheet.html#package-management",
    "title": "R Commands Quick Reference",
    "section": "6 Package Management",
    "text": "6 Package Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nInstall package\ninstall.packages()\ninstall.packages(\"dplyr\")\n\n\nLoad package\nlibrary()\nlibrary(dplyr)\n\n\nUpdate packages\nupdate.packages()\nupdate.packages()\n\n\nList packages\ninstalled.packages()\ninstalled.packages()"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#workspace-management",
    "href": "references/r-commands-cheatsheet.html#workspace-management",
    "title": "R Commands Quick Reference",
    "section": "7 Workspace Management",
    "text": "7 Workspace Management\n\n\n\nTask\nCommand\nExample\n\n\n\n\nList objects\nls()\nls()\n\n\nRemove objects\nrm()\nrm(x, y)\n\n\nClear workspace\nrm(list = ls())\nrm(list = ls())\n\n\nWorking directory\ngetwd()\ngetwd()\n\n\nSet directory\nsetwd()\nsetwd(\"/path/to/dir\")"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#data-types-structure",
    "href": "references/r-commands-cheatsheet.html#data-types-structure",
    "title": "R Commands Quick Reference",
    "section": "8 Data Types & Structure",
    "text": "8 Data Types & Structure\n\n\n\nTask\nCommand\nExample\n\n\n\n\nData type\nclass()\nclass(x)\n\n\nStructure\nstr()\nstr(df)\n\n\nDimensions\ndim()\ndim(df)\n\n\nColumn names\nnames()\nnames(df)\n\n\nSummary\nsummary()\nsummary(df)\n\n\nFirst rows\nhead()\nhead(df, 10)\n\n\nLast rows\ntail()\ntail(df, 10)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#missing-values",
    "href": "references/r-commands-cheatsheet.html#missing-values",
    "title": "R Commands Quick Reference",
    "section": "9 Missing Values",
    "text": "9 Missing Values\n\n\n\nTask\nCommand\nExample\n\n\n\n\nCheck for NA\nis.na()\nis.na(x)\n\n\nRemove NA\nna.omit()\nna.omit(df)\n\n\nComplete cases\ncomplete.cases()\ncomplete.cases(df)"
  },
  {
    "objectID": "references/r-commands-cheatsheet.html#quick-tips",
    "href": "references/r-commands-cheatsheet.html#quick-tips",
    "title": "R Commands Quick Reference",
    "section": "10 Quick Tips",
    "text": "10 Quick Tips\n\nUse ?function_name to get help\nUse Tab for auto-completion in RStudio\nUse Ctrl+Shift+M for pipe operator %&gt;%\nUse Ctrl+Shift+C to comment/uncomment code"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html",
    "href": "misc/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "href": "misc/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "misc/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesn’t exist or package isn’t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#data-type-errors",
    "href": "misc/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#subsetting-errors",
    "href": "misc/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesn’t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#missing-values-issues",
    "href": "misc/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions can’t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#file-reading-errors",
    "href": "misc/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R can’t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#memory-issues",
    "href": "misc/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#package-installation-issues",
    "href": "misc/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package won’t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "href": "misc/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "misc/fixing-common-r-errors.html#prevention-strategies",
    "href": "misc/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "guides/index.html",
    "href": "guides/index.html",
    "title": "Guides",
    "section": "",
    "text": "Practical guides for solving specific problems and accomplishing particular tasks. These step-by-step instructions help you tackle real-world challenges.\nEach guide provides: - Clear problem definition - Prerequisites and assumptions - Detailed implementation steps - Alternative approaches - Common pitfalls and solutions\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nFixing Common R Errors: A Troubleshooting Guide\n\n\nStep-by-step solutions for frequent R programming problems\n\n\n\nR\n\n\ntroubleshooting\n\n\ndebugging\n\n\nguide\n\n\n\nPractical solutions for the most common R errors encountered by data scientists and analysts.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/research-management/index.html",
    "href": "blog/research-management/index.html",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "href": "blog/research-management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by",
    "text": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by\nrunning this bash script to copy a prelude to the chatGPT prompt to your clipboard: Call it dp (dictation prompt).\n#!/bin/bash\n\n# Get current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Define the prompt with explicit instructions\nprompt=\"I'm an academic biostatistician. I'm working on a data analysis project.\nI'm about to dictate daily research progress notes.  \nWhen I'm done, provide a concise summary that includes:  \n\n1. The date  and time of dictation ($current_time).  The line with date and time\nshould be the second line of the summary. The first line should be blank. The\ndate and time line shound be enclosed in a box of ascii characters to set it apart.\n2. The name of the current research project directory ($current_dir).  \n3. Each line of the summary including the blank line and the date and time line\nand enclosing box lines should begin with \\\"$current_dir:\\\" so that it can be\nextracted using ripgrep.  \n\nThe notes start here: \"\n\n# Copy the prompt to clipboard (MacOS pbcopy)\necho -n \"$prompt\" | pbcopy\n\n# Notify the user\necho \"Prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "blog/research-management/index.html#step-3.2-dictating-notes",
    "href": "blog/research-management/index.html#step-3.2-dictating-notes",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nOpen ChatGPT (done automatically by “dp” script) and follow these steps:\ncopy text from clipboard into the prompt box.\nsubmit prompt to prep chatGPT for summarization.\nClick chatGPT microphone and Dictate your research notes.\nWhen finished dictating submit prompt to ChatGPT for summarization.\nCopy and generated summary onto the clipboard.\n\nUse the following script to append the summary to your daily log: and push the changes to daily_log.md to the remote repository on GitHub.\n#!/bin/bash\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Get the current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the clipboard content (MacOS pbpaste)\nclipboard_content=$(pbpaste)\n\n# Echo the output\n#\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"\" &gt;&gt; ~/prj/research_update/daily_log.md\n\n# Confirm success\necho \"Update for $current_dir appended to daily_log.md in ~/prj/research_update\"\ncd ~/prj/research_update\n  git add .\n    git commit -a -m \"Daily log update $(date +'%Y-%m-%d')\"\n    git push"
  },
  {
    "objectID": "blog/research-management/index.html#prerequisites",
    "href": "blog/research-management/index.html#prerequisites",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.1 Prerequisites",
    "text": "7.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#step-by-step-implementation",
    "href": "blog/research-management/index.html#step-by-step-implementation",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.2 Step-by-Step Implementation",
    "text": "7.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#key-takeaways",
    "href": "blog/research-management/index.html#key-takeaways",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.3 Key Takeaways",
    "text": "7.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/research-management/index.html#further-reading",
    "href": "blog/research-management/index.html#further-reading",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "7.4 Further Reading",
    "text": "7.4 Further Reading\nIn development"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Thomas Lab",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     GitHub\n  \n  \n    \n     Email\n  \n\n  \n  \nThe Thomas Lab in the Herbert Wertheim School of Public Health and Human Longevity Science at UC San Diego focuses on developing data science methodology and educational materials. Our work spans statistical computing, reproducible research practices, and modern tools for data analysis."
  },
  {
    "objectID": "about/index.html#research-focus",
    "href": "about/index.html#research-focus",
    "title": "About Thomas Lab",
    "section": "1 Research Focus",
    "text": "1 Research Focus\nOur lab specializes in:\n\nStatistical methodologies for health research\nR package development for specialized analysis needs\nReproducible research workflows and best practices\nEducational materials for data science skills in public health\nApplications of machine learning in longitudinal studies"
  },
  {
    "objectID": "about/index.html#tools-expertise",
    "href": "about/index.html#tools-expertise",
    "title": "About Thomas Lab",
    "section": "2 Tools & Expertise",
    "text": "2 Tools & Expertise\n\n\n2.1 R Programming\n\nPackage development\nStatistical modeling\nData visualization\nReproducible reporting\n\n\n\n2.2 Research Computing\n\nDocker containerization\nCloud-based computing\nHigh-performance computing\nCollaborative workflows\n\n\n\n2.3 Education\n\nWorkshop development\nTutorial creation\nOpen educational resources\nMentoring and guidance"
  },
  {
    "objectID": "about/index.html#team",
    "href": "about/index.html#team",
    "title": "About Thomas Lab",
    "section": "3 Team",
    "text": "3 Team\nOur interdisciplinary team brings together expertise in statistics, computer science, and public health research to address complex challenges in health data analysis."
  },
  {
    "objectID": "about/index.html#collaborations",
    "href": "about/index.html#collaborations",
    "title": "About Thomas Lab",
    "section": "4 Collaborations",
    "text": "4 Collaborations\nWe actively collaborate with researchers across disciplines to apply novel methodological approaches to real-world health and longevity challenges. If you’re interested in working together, please get in touch!"
  },
  {
    "objectID": "about/index.html#publications",
    "href": "about/index.html#publications",
    "title": "About Thomas Lab",
    "section": "5 Publications",
    "text": "5 Publications\nSelected recent publications:\n\nAuthor A, Author B, Thomas RG (2024). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor C, Author D, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages.\nAuthor E, Author F, Thomas RG (2023). Title of paper. Journal Name, Volume(Issue), pages."
  },
  {
    "objectID": "about/index.html#contact",
    "href": "about/index.html#contact",
    "title": "About Thomas Lab",
    "section": "6 Contact",
    "text": "6 Contact\nFor inquiries about collaboration, research opportunities, or educational resources, please reach out through the social media links above or email us directly."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html",
    "href": "blog/2025-01-01-year-ahead.html",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "",
    "text": "As we start 2025, I’m excited to share some thoughts on where I’m heading with R programming, data science tools, and research computing workflows."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "href": "blog/2025-01-01-year-ahead.html#this-years-focus-areas",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "1 This Year’s Focus Areas",
    "text": "1 This Year’s Focus Areas\nPackage Development: Planning to release two new R packages focusing on statistical visualization and research workflow automation.\nDocker Integration: Expanding my containerization work to include more complex multi-service setups for data science teams.\nAI-Assisted Coding: Exploring how LLMs can enhance R development workflows without replacing fundamental programming skills."
  },
  {
    "objectID": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "href": "blog/2025-01-01-year-ahead.html#whats-coming-to-the-blog",
    "title": "Looking Ahead: 2025 Plans for R and Data Science",
    "section": "2 What’s Coming to the Blog",
    "text": "2 What’s Coming to the Blog\nYou’ll see more content in our new structure: - Tutorials on advanced R topics - References for quick command lookups\n- Guides for solving specific problems - Blog posts like this for timely thoughts and updates\nLooking forward to sharing the journey!"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to my blog! Here you’ll find my latest thoughts on R programming, data science, statistical computing, and research workflows.\n\n\n\n\n📚 Latest Posts\n\n\n\n\nBlog\n\n\nJuly 01, 2025\n\n\nLatest thoughts, updates, and discoveries\n\nRead More →\n\n\n\nPalmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison\n\n\nJanuary 05, 2025\n\n\nThe final part of our 5-part series comparing linear models with random forests and providing guidance for model selection in ecological research\n\n\nR Programming Data Science Statistical Computing Machine Learning Random Forest Model Comparison Palmer Penguins\n\nRead More →\n\n\n\nPalmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation\n\n\nJanuary 04, 2025\n\n\nPart 4 of our 5-part series focusing on rigorous diagnostic procedures, assumption checking, and biological interpretation of our penguin models\n\n\nR Programming Data Science Statistical Computing Model Diagnostics Regression Analysis Palmer Penguins\n\nRead More →\n\n\n\nPalmer Penguins Data Analysis Series (Part 3): Advanced Models and Cross-Validation\n\n\nJanuary 03, 2025\n\n\nPart 3 of our 5-part series where we rigorously validate our models and introduce polynomial features and random forest competitors\n\n\nR Programming Data Science Statistical Computing Cross-Validation Machine Learning Palmer Penguins\n\nRead More →\n\n\n\nPalmer Penguins Data Analysis Series (Part 2): Multiple Regression and Species Effects\n\n\nJanuary 02, 2025\n\n\nPart 2 of our 5-part series exploring how multiple predictors and species information dramatically improve penguin body mass predictions\n\n\nR Programming Data Science Statistical Computing Multiple Regression Palmer Penguins\n\nRead More →\n\n\n\nPalmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression\n\n\nJanuary 01, 2025\n\n\nPart 1 of a comprehensive 5-part series exploring Palmer penguin morphometrics through exploratory data analysis and simple regression modeling\n\n\nR Programming Data Science Statistical Computing Exploratory Data Analysis Palmer Penguins\n\nRead More →\n\n\n\nMaking optimal use of ChatGPT and other chatbots for data science\n\n\nNA\n\nRead More →\n\n\n\nCoding with Generative AI\n\n\nNA\n\n\nHow to effectively use AI tools like ChatGPT and GitHub Copilot for coding while maintaining good practices\n\n\nAI-Automation Programming-Development\n\nRead More →\n\n\n\ncoding with genAI\n\n\nNA\n\nRead More →\n\n\n\nMac Workflow for Tracking Daily Research Progress\n\n\nNA\n\nRead More →\n\n\n\nMac Workflow for Tracking Daily Research Progress\n\n\nNA\n\nRead More →\n\n\n\nResearch Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy\n\n\nNA\n\nRead More →\n\n\n\nA simple shiny app to explore Palmer Penguin data using ChatGPT to draft: true prototype.\n\n\nNA\n\nRead More →\n\n\n\nConverting R data.frames to pdf for better placement control in latex draft: true pdf report\n\n\nNA\n\nRead More →\n\n\n\nConverting R data.frames to pdf for better placement control in latex draft: true pdf report\n\n\nNA\n\nRead More →\n\n\n\n\n\n\n\n🔍 Filter by Category\n\n\nShow All\n\n\nAI\n\n\nAI-Automation\n\n\nautomation\n\n\nCross-Validation\n\n\nData Science\n\n\ndata-science\n\n\nExploratory Data Analysis\n\n\nMachine Learning\n\n\nModel Comparison\n\n\nModel Diagnostics\n\n\nMultiple Regression\n\n\nPalmer Penguins\n\n\nProgramming-Development\n\n\nR\n\n\nR Programming\n\n\nRandom Forest\n\n\nRegression Analysis\n\n\nStatistical Computing\n\n\n\n\n📊 Blog Stats\n\n\nTotal Posts: 15\n\n\nShowing: All"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html",
    "href": "guides/fixing-common-r-errors.html",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "href": "guides/fixing-common-r-errors.html#object-not-found-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "",
    "text": "Problem: R can’t find the variable or function you’re trying to use.\nCommon Causes: - Typo in variable name (R is case-sensitive) - Variable not created yet - Variable created in different environment\nSolutions:\n\nCheck spelling and case:\n# Wrong\nmyData &lt;- data.frame(x = 1:5)\nprint(mydata)  # Error: object 'mydata' not found\n\n# Correct\nprint(myData)\nList current objects:\nls()  # See what objects exist\nCheck if package is loaded:\n# If using dplyr functions\nlibrary(dplyr)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "href": "guides/fixing-common-r-errors.html#packagefunction-not-found",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "2 Package/Function Not Found",
    "text": "2 Package/Function Not Found\n\n2.1 Error: could not find function \"function_name\"\nProblem: Function doesn’t exist or package isn’t loaded.\nSolutions:\n\nInstall missing package:\ninstall.packages(\"package_name\")\nlibrary(package_name)\nUse package::function notation:\n# Instead of loading entire package\ndplyr::filter(data, condition)\nCheck function spelling:\n# Wrong\nsummery(data)\n\n# Correct\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#data-type-errors",
    "href": "guides/fixing-common-r-errors.html#data-type-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "3 Data Type Errors",
    "text": "3 Data Type Errors\n\n3.1 Error: non-numeric argument to mathematical function\nProblem: Trying to do math on text or factor data.\nSolutions:\n\nCheck data types:\nstr(data)          # See structure\nclass(data$column) # Check specific column\nConvert to numeric:\n# If column should be numeric\ndata$column &lt;- as.numeric(data$column)\n\n# Handle warnings about NAs\ndata$column &lt;- as.numeric(as.character(data$column))\nRemove non-numeric characters:\n# Remove dollar signs, commas, etc.\ndata$price &lt;- as.numeric(gsub(\"[^0-9.]\", \"\", data$price_text))"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#subsetting-errors",
    "href": "guides/fixing-common-r-errors.html#subsetting-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "4 Subsetting Errors",
    "text": "4 Subsetting Errors\n\n4.1 Error: subscript out of bounds\nProblem: Trying to access row/column that doesn’t exist.\nSolutions:\n\nCheck dimensions:\ndim(data)        # Rows and columns\nnrow(data)       # Number of rows\nncol(data)       # Number of columns\nUse safe subsetting:\n# Instead of data[100, ] which might not exist\nif (nrow(data) &gt;= 100) {\n  result &lt;- data[100, ]\n}\nCheck column names:\nnames(data)      # See actual column names\n\"column_name\" %in% names(data)  # Check if column exists"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#missing-values-issues",
    "href": "guides/fixing-common-r-errors.html#missing-values-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "5 Missing Values Issues",
    "text": "5 Missing Values Issues\n\n5.1 Error: missing values in object\nProblem: Functions can’t handle NA values.\nSolutions:\n\nRemove NAs explicitly:\nmean(data$column, na.rm = TRUE)\nsum(data$column, na.rm = TRUE)\nCheck for missing values:\nsum(is.na(data$column))    # Count NAs\ncomplete.cases(data)       # Rows without NAs\nHandle missing data:\n# Remove rows with any NA\nclean_data &lt;- na.omit(data)\n\n# Remove rows with NA in specific column\nclean_data &lt;- data[!is.na(data$column), ]"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#file-reading-errors",
    "href": "guides/fixing-common-r-errors.html#file-reading-errors",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "6 File Reading Errors",
    "text": "6 File Reading Errors\n\n6.1 Error: cannot open the connection\nProblem: R can’t find or access the file.\nSolutions:\n\nCheck file path:\ngetwd()                    # Current directory\nfile.exists(\"filename.csv\") # Check if file exists\nUse correct path separators:\n# Windows - use forward slashes or double backslashes\ndata &lt;- read.csv(\"C:/Users/name/data.csv\")\n# or\ndata &lt;- read.csv(\"C:\\\\Users\\\\name\\\\data.csv\")\nCheck file permissions:\n# Make sure file isn't open in Excel\n# Check that you have read permissions"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#memory-issues",
    "href": "guides/fixing-common-r-errors.html#memory-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "7 Memory Issues",
    "text": "7 Memory Issues\n\n7.1 Error: cannot allocate vector of size X\nProblem: Not enough memory for the operation.\nSolutions:\n\nCheck memory usage:\nmemory.size()      # Current usage (Windows)\nobject.size(data)  # Size of specific object\nFree up memory:\nrm(large_object)   # Remove unneeded objects\ngc()               # Force garbage collection\nWork with smaller chunks:\n# Read file in chunks\nlibrary(readr)\ndata &lt;- read_csv_chunked(\"large_file.csv\", \n                        chunk_size = 1000,\n                        callback = DataFrameCallback$new())"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#package-installation-issues",
    "href": "guides/fixing-common-r-errors.html#package-installation-issues",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "8 Package Installation Issues",
    "text": "8 Package Installation Issues\n\n8.1 Error: package installation failed\nProblem: Package won’t install due to dependencies or system issues.\nSolutions:\n\nUpdate R and packages:\nupdate.packages(ask = FALSE)\nInstall from different repository:\n# Try different CRAN mirror\ninstall.packages(\"package_name\", repos = \"https://cloud.r-project.org\")\n\n# Install from GitHub\ndevtools::install_github(\"user/package\")\nInstall dependencies manually:\n# Install suggested dependencies\ninstall.packages(\"package_name\", dependencies = TRUE)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "href": "guides/fixing-common-r-errors.html#general-debugging-tips",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "9 General Debugging Tips",
    "text": "9 General Debugging Tips\n\nUse debugging tools:\ntraceback()        # See where error occurred\ndebug(function)    # Step through function\nBreak down complex operations:\n# Instead of chaining everything\nresult &lt;- data %&gt;% filter(...) %&gt;% mutate(...) %&gt;% summarise(...)\n\n# Do step by step\nstep1 &lt;- filter(data, ...)\nstep2 &lt;- mutate(step1, ...)\nresult &lt;- summarise(step2, ...)\nCheck intermediate results:\n# Print intermediate steps\nprint(dim(data))\nhead(data)\nsummary(data)"
  },
  {
    "objectID": "guides/fixing-common-r-errors.html#prevention-strategies",
    "href": "guides/fixing-common-r-errors.html#prevention-strategies",
    "title": "Fixing Common R Errors: A Troubleshooting Guide",
    "section": "10 Prevention Strategies",
    "text": "10 Prevention Strategies\n\nAlways check data structure after reading files\nUse meaningful variable names to avoid confusion\nComment your code to remember what you were doing\nSave your work frequently in case R crashes\nUse version control (Git) to track changes"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Thomas Lab",
    "section": "",
    "text": "I’m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub • Twitter • About"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Thomas Lab",
    "section": "",
    "text": "I’m Ronald G. Thomas, a researcher and data scientist focused on statistical methods, reproducible research, and computational tools. I write about R programming, statistical analysis, research workflows, and modern data science practices.\nThis site organizes content into focused areas:\n\nBlog - Technical articles and explorations\nWhite Papers - In-depth technical reports and methodological frameworks\nResearch - Publications and academic work\nTeaching - Courses, workshops, and educational materials\nMisc - Tools, references, and other useful resources\n\n\n\n\nCoding with Generative AI - Best practices for AI-assisted programming\nResearch Management Workflows - Organizing academic projects\nR Package Development - Building robust R packages\n\n\n\n\nGitHub • Twitter • About"
  },
  {
    "objectID": "misc/index.html",
    "href": "misc/index.html",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#software-and-tools",
    "href": "misc/index.html#software-and-tools",
    "title": "Misc",
    "section": "",
    "text": "Editor configurations and setups\nWorkflow automation scripts\nProductivity tools and tips\nSystem administration guides\n\n\n\n\n\nPackage recommendations\nConfiguration templates\nDevelopment workflows\nCommunity resources"
  },
  {
    "objectID": "misc/index.html#resources-and-references",
    "href": "misc/index.html#resources-and-references",
    "title": "Misc",
    "section": "2 Resources and References",
    "text": "2 Resources and References\n\n2.1 Quick References\n\nCommand cheat sheets\nConfiguration snippets\nCommon patterns\nTroubleshooting guides\n\n\n\n2.2 External Links\n\nUseful websites and tools\nCommunity forums and discussions\nDocumentation and manuals\nProfessional resources"
  },
  {
    "objectID": "misc/index.html#personal-projects",
    "href": "misc/index.html#personal-projects",
    "title": "Misc",
    "section": "3 Personal Projects",
    "text": "3 Personal Projects\n\n3.1 Open Source Contributions\n\nSoftware packages and libraries\nDocumentation improvements\nBug fixes and feature requests\nCommunity support\n\n\n\n3.2 Experimental Work\n\nProof-of-concept implementations\nTechnology explorations\nSide projects and demos\nLearning exercises\n\n\nThis section contains miscellaneous content that doesn’t fit neatly into other categories - tools, references, personal projects, and various resources that might be useful to others."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim is a powerful and efficient text editor that, with the right setup, can serve as a productive environment for data science work in Python, Julia, and R. This guide will walk you through the essential plugins and configurations to transform Vim into a fully functional IDE for data science.\n\n\n\nLightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage.\n\n\n\n\nA plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins.\n\n\n\nPlug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim\n\n\n\nPlug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']\n\n\n\nPlug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle\n\n\n\n\nPlug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1\n\n\n\nPlug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline.\n\n\n\nPlug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code.\n\n\n\nPlug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets.\n\n\n\nPlug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R.\n\n\n\nPlug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode\n\n\n\n\nScreenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science.\n\n\n\n\nWith this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!\n\n\n\n\n\n\nVim Editor"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Lightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "A plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Screenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "With this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim Editor"
  },
  {
    "objectID": "posts/drafts.html",
    "href": "posts/drafts.html",
    "title": "Draft Posts",
    "section": "",
    "text": "No Draft Posts Currently\n\n\n\nThere are currently no draft posts in development. Posts marked with draft: true in their YAML frontmatter will appear here instead of the main blog listing."
  },
  {
    "objectID": "posts/drafts.html#how-to-create-draft-posts",
    "href": "posts/drafts.html#how-to-create-draft-posts",
    "title": "Draft Posts",
    "section": "1 How to Create Draft Posts",
    "text": "1 How to Create Draft Posts\nPosts marked as drafts are excluded from: - Main blog listing - RSS feeds\n- Site search indexing - External link sharing\nTo create a draft post: 1. Add draft: true to the post’s YAML frontmatter 2. The post will appear on this page instead of the main blog\nTo publish a draft: 1. Remove the draft: true line from the post’s YAML frontmatter 2. The post will appear on the main blog listing\nUsing the draft management script:\n# Mark a post as draft\n./manage_drafts.sh draft posts/my-post/\n\n# Publish a draft\n./manage_drafts.sh publish posts/my-post/"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html",
    "href": "posts/share_R_code_via_docker_p25/index.html",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "",
    "text": "Reproducibility is key to conducting data analysis, yet in practice, achieving it consistently with R workflows can be quite challenging. R projects frequently break when transferred between computers due to mismatched R versions, package dependencies, or inconsistent project organization. This white paper describes an approach to solving this problem by combining three tools: zzrrtools for creating structured research compendia, renv for R package management, and Docker for containerizing the computing environment. Together, these tools ensure that an R workflow runs identically across different computers by providing standardized project structure, identical R packages and versions, consistent R versions, and the same operating system libraries as the original setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "href": "posts/share_R_code_via_docker_p25/index.html#the-challenge-of-reproducibility-in-r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "1.1 The Challenge of Reproducibility in R",
    "text": "1.1 The Challenge of Reproducibility in R\nR has become a standard tool for data science and statistical analysis across numerous scientific disciplines. However, as R projects grow in complexity, they often develop complex webs of dependencies that can make sharing and reproducing analyses difficult. Some common challenges include:\n\nDifferent R versions across machines\nIncompatible package versions\nMissing system-level dependencies\nOperating system differences (macOS vs. Windows vs. Linux)\nConflicts with other installed packages\nR startup files (.Rprofile, .Renviron, .RData) that can affect code behavior\n\nThese challenges often manifest as the frustrating “it works on my machine” problem, where analysis code runs perfectly for the original author but fails when others attempt to use it. This undermines the scientific and collaborative potential of R-based analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "href": "posts/share_R_code_via_docker_p25/index.html#a-three-level-solution",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "1.2 A Three-Level Solution",
    "text": "1.2 A Three-Level Solution\nTo address these challenges, we need to tackle reproducibility at three distinct levels:\n\nProject-level reproducibility: Ensuring consistent project structure and organization using research compendium standards\nPackage-level reproducibility: Ensuring exact package versions and dependencies are maintained\nSystem-level reproducibility: Guaranteeing consistent R versions, operating system, and system libraries\n\nThe strategy presented in this white paper leverages zzrrtools for project-level structure, renv for package-level consistency, and Docker for system-level consistency. When combined, they provide a framework for end-to-end reproducible R workflows with proper research compendium organization.\nWith this three-level framework established, we can now examine how each tool addresses its specific layer of reproducibility. We begin with zzrrtools, which tackles the foundational challenge of project-level organization and provides the structural framework upon which package and system-level reproducibility can be built."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.1 What is zzrrtools?",
    "text": "2.1 What is zzrrtools?\nzzrrtools is a Docker-first framework that creates reproducible research compendia with containerized development workflows. The framework extends the research compendium concept introduced by Ben Marwick’s rrtools, adding container-based development and automated dependency validation. Team members install zzrrtools once on their system, then can create or join any zzrrtools-based project using the same framework. A research compendium organizes digital research materials to enable others to inspect, reproduce, and extend the research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-zzrrtools",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.2 Key Features of zzrrtools",
    "text": "2.2 Key Features of zzrrtools\nzzrrtools creates containerized research compendia with these key features:\n\nDocker-first development: All workflows operate within containers, eliminating “works on my machine” issues\nCentralized framework: One-time zzrrtools installation enables consistent project creation and team collaboration\nMulti-service architecture: Provides specialized Docker environments for interactive R sessions, shell development, and paper rendering\nFlexible base images: Choice of minimal (rocker/r-ver) or pre-packaged (rgt47/r-pluspackages) Docker templates with common R packages\nAdvanced dependency validation: Automated renv consistency checking with CRAN verification and pre-commit validation\nShell-based workflows: Optimized for command-line development with rich automation via Make targets\nTeam collaboration focus: Designed for multi-developer teams working on shared research projects"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-self-replicating-collaboration",
    "href": "posts/share_R_code_via_docker_p25/index.html#zzrrtools-workflow-self-replicating-collaboration",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.3 zzrrtools Workflow: Self-Replicating Collaboration",
    "text": "2.3 zzrrtools Workflow: Self-Replicating Collaboration\nThe zzrrtools workflow is designed for team collaboration:\n# Project creator initializes the research compendium\n~/prj/zzrrtools/zzrrtools.sh [OPTIONS]\n\n# Available options:\n#   --dotfiles DIR       Copy personal dotfiles (with leading dots)\n#   --dotfiles-nodot DIR Copy dotfiles (without leading dots) \n#   --base-image NAME    Use custom Docker base image (default: rocker/r-ver)\n#                        Popular options: rgt47/r-pluspackages (includes tidyverse)\n#   --no-docker          Skip Docker image build\n#   --next-steps         Show workflow guidance\nThis creates a Docker-first research compendium with:\n\nFramework-based setup using centrally installed zzrrtools for consistent project creation\nMulti-service Docker architecture for interactive R, shell, and rendering\nAdvanced renv validation with CRAN verification and pre-commit checking\nDual-track automation supporting both native R and Docker workflows\nNavigation shortcuts via symbolic links (a→data, p→paper, s→scripts)\nDeveloper environment integration with personal dotfiles support\nTeam synchronization via automated dependency validation\n\nTeam members can collaborate after one-time zzrrtools installation:\n# One-time zzrrtools installation\ngit clone zzrrtools-repo ~/prj/zzrrtools\ncd ~/prj/zzrrtools && ./install.sh  # Creates zzrrtools command in PATH\n\n# Per-project workflow\ngit clone project-repo && cd project-repo\nzzrrtools  # Set up project environment (command available anywhere)\nmake docker-r   # Start interactive R session\n\n2.3.1 Integrated renv Consistency Checking\nThe workflow includes advanced renv management through the check_renv_for_commit.R script, which provides automated dependency validation and team conflict prevention. This script:\n\nScans multiple directories (R/, scripts/, analysis/) for package dependencies\nValidates against CRAN to ensure packages exist and are properly named\n\nSynchronizes dependencies across code files, DESCRIPTION, and renv.lock\nProvides automated fixes to maintain team environment consistency\nIntegrates with CI/CD for fail-fast validation workflows\n\nUsage examples:\n# Interactive dependency checking (development)\nRscript check_renv_for_commit.R\n\n# Auto-fix dependency issues\nRscript check_renv_for_commit.R --fix\n\n# CI/CD validation with fail-fast\nRscript check_renv_for_commit.R --fix --fail-on-issues --quiet\n\n# Via Make targets (recommended)\nmake check-renv          # Check dependencies\nmake check-renv-fix      # Fix dependency issues\nmake docker-check-renv-fix  # Fix in container\nThis approach ensures collaborators can reliably reproduce package environments and CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "href": "posts/share_R_code_via_docker_p25/index.html#research-compendium-structure",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.4 Research Compendium Structure",
    "text": "2.4 Research Compendium Structure\nThe zzrrtools setup creates a directory structure that follows research compendium best practices. The structure includes organized data folders, analysis directories, testing frameworks, and workflows.\nKey organizational principles:\n\nData management: Separate folders for raw, derived, and external data with proper documentation\nAnalysis workflow: Dedicated spaces for papers, figures, tables, and working scripts\n\nPackage structure: R package organization with documentation and testing\nIntegration support: Works with Docker, GitHub Actions, and build systems\n\nThis organizational framework provides the foundation for reproducible research while supporting team collaboration and automated workflows."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#iterative-development-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "2.5 Iterative Development Workflow",
    "text": "2.5 Iterative Development Workflow\nFor collaborative analysis development, the research compendium structure supports a phased approach that balances rapid iteration with publication-quality outputs:\n\n2.5.1 Phase 1: Exploration & Development (scripts/)\nDuring active analysis development, team members should work primarily in the scripts/ directory:\nscripts/\n├── 01_data_exploration.R\n├── 02_penguin_correlations.R  \n├── 03_species_analysis.R\n├── 04_body_mass_analysis.R    # Additional analysis\n└── 05_visualization_experiments.R\nBenefits of script-based development: - Fast iteration: No need to knit/render documents during development - Interactive debugging: Can run code line-by-line in R console - Version control friendly: Pure R files produce clean diffs in Git - Easy collaboration: Contributors can add numbered script files - Flexible experimentation: Quick to test ideas and approaches\n\n\n2.5.2 Phase 2: Function Extraction (R/)\nAs analysis patterns emerge, extract reusable functions to the R/ directory:\n# R/penguin_utils.R\ncalculate_species_correlation &lt;- function(data, x_var, y_var, \n                                          species_filter = NULL) {\n  # Reusable function extracted from scripts\n  if (!is.null(species_filter)) {\n    data &lt;- data[data$species == species_filter, ]\n  }\n  cor(data[[x_var]], data[[y_var]], use = \"complete.obs\")\n}\n\ncreate_species_plot &lt;- function(data, x_var, y_var) {\n  # Standardized plotting function\n  ggplot(data, aes_string(x = x_var, y = y_var, \n                          color = \"species\")) +\n    geom_point() +\n    theme_minimal()\n}\n\n\n2.5.3 Phase 3: Publication Integration (analysis/paper/)\nOnce analysis approaches stabilize, integrate polished results into the manuscript:\n# In analysis/paper/paper.Rmd\n# Option 1: Source complete scripts\nsource(\"../../scripts/02_penguin_correlations.R\")\nsource(\"../../scripts/04_body_mass_analysis.R\")\n\n# Option 2: Use extracted functions\nlibrary(here)\nsource(here(\"R\", \"penguin_utils.R\"))\n\ncorrelation_result &lt;- calculate_species_correlation(\n  penguins, \"flipper_length_mm\", \"bill_length_mm\"\n)\n\n\n2.5.4 Recommended Collaborative Workflow:\n\nProject initialization: Project maintainer runs zzrrtools.sh to create project structure\nImmediate containerization: Build Docker container and switch to container-based development from day one\nInitial development: Create exploratory scripts in scripts/ directory inside the container\nCollaborative iteration: Team members clone repo, build identical container, add additional script files through pull requests from within the container\nCode review in scripts: Both developers refine analysis logic in script files while working in identical Docker environments\nFunction extraction: Move stable, reusable code to R/ directory\nPaper integration: Source scripts or use functions in analysis/paper/paper.Rmd\nContinuous validation: All development and testing occurs within the containerized environment\n\nWhy this container-first approach works:\n\nReproducibility: Eliminates “works on my machine” problems from day one\nIdentical environments: All collaborators work in exactly the same computational environment\nNo environment drift: Cannot occur when everyone develops within containers\nSpeed: Script development is faster than R Markdown knitting\nModularity: Each script can focus on a specific analysis aspect\nTestability: Functions in R/ can be easily unit tested in the same environment they’ll run in production\nSimple collaboration: Environment setup becomes a one-time docker build command for all contributors\nDevelopment-production parity: The development environment IS the production environment\n\nThis container-first, phased approach gives collaborators the speed of script-based development during exploration while maintaining the reproducibility and narrative flow of literate programming for final outputs. Most importantly, it ensures that all development occurs within the exact computational environment that will be used for final analysis and publication.\nWhile zzrrtools establishes the organizational foundation for reproducible research, it relies on consistent R package environments to function effectively across different systems. The directory structure and R package framework created by zzrrtools becomes most useful when combined with precise dependency management. This is where renv becomes essential, providing the package-level consistency that complements zzrrtools’ structural approach."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.1 What is renv?",
    "text": "3.1 What is renv?\nrenv (Reproducible Environment) is an R package designed to create isolated, project-specific library environments. Instead of relying on a shared system-wide R library that might change over time, renv gives each project its own separate collection of packages with specific versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-of-renv",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.2 Key Features of renv",
    "text": "3.2 Key Features of renv\n\nIsolated project library: renv creates a project-specific library (typically in renv/library) containing only the packages used by that project. This isolation ensures that updates or changes to packages in one project won’t affect others.\nLockfile for dependencies: When you finish installing or updating packages, renv::snapshot() produces a renv.lock file - a JSON document listing each package and its exact version and source. This lockfile is designed to be committed to version control and shared.\nEnvironment restoration: On a new machine (or when reproducing past results), renv::restore() installs the exact versions of packages specified in the lockfile. This creates an R package environment identical to the one that created the lockfile, provided the same R version is available. The R version is important since critical components of the R system, such as random number generation, and default factor handling policy vary between versions."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#basic-renv-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "3.3 Basic renv Workflow",
    "text": "3.3 Basic renv Workflow\nThe typical workflow with renv involves:\n# One-time installation of renv\ninstall.packages(\"renv\")\n\n# Initialize renv for the project\nrenv::init()  # Creates renv infrastructure\n\n# Install project-specific packages\n# ...\n\n# Save the package state to renv.lock\nrenv::snapshot()\n\n# Later or on another system...\nrenv::restore()  # Restore packages from renv.lock\nWhile renv successfully addresses package-level reproducibility by ensuring identical R package versions across environments, even perfect package consistency cannot prevent analyses from failing or producing different results due to variations in R versions, operating systems, or system-level dependencies. A complete reproducibility solution requires addressing these system-level differences, which is where Docker containerization becomes essential."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "href": "posts/share_R_code_via_docker_p25/index.html#what-is-docker",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.1 What is Docker?",
    "text": "4.1 What is Docker?\nDocker is a platform that allows you to package software into standardized units called containers. A Docker container is like a lightweight virtual machine that includes everything needed to run an application: the code, runtime, system tools, libraries, and settings."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "href": "posts/share_R_code_via_docker_p25/index.html#dockers-role-in-reproducibility",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.2 Docker’s Role in Reproducibility",
    "text": "4.2 Docker’s Role in Reproducibility\nWhile renv handles R packages, Docker ensures consistency for:\n\nOperating system: The specific Linux distribution or OS version\nR interpreter: The exact R version\nSystem libraries: Required C/C++ libraries and other dependencies\nComputational environment: Memory limits, CPU configuration, etc.\nExternal tools: pandoc, LaTeX, and other utilities needed for R Markdown\n\nBy running an R Markdown project in Docker, you eliminate differences in OS or R installation as potential sources of irreproducibility. Any machine running Docker will execute the container in an identical environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#docker-components-for-r-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#docker-components-for-r-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "4.3 Docker Components for R Workflows",
    "text": "4.3 Docker Components for R Workflows\nFor R-based projects, a typical Docker approach involves:\n\nBase image: Starting from a pre-configured R image (e.g., from the Rocker project)\nDependencies: Adding system and R package dependencies\nConfiguration: Setting working directories and environment variables\nContent: Adding project files\nExecution: Defining how the project should run\n\nThe zzrrtools setup uses a streamlined Dockerfile based on rocker/r-ver with TinyTeX for LaTeX support. The R version is matched to the renv.lock file:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Prevent interactive prompts\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install minimal system dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    pandoc \\\n    vim \\\n    git \\\n    curl \\\n    fonts-dejavu \\\n    && apt-get clean && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/bash ${USERNAME}\n\n# Set user R library path\nENV R_LIBS_USER=/home/${USERNAME}/R/library\n\n# Create user R library directory and assign permissions\nRUN mkdir -p /home/${USERNAME}/R/library && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/R\n\n# Set working directory\nWORKDIR /home/${USERNAME}\n\n# Copy renv files with correct ownership\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R ./renv/\n\n# Switch to non-root user\nUSER ${USERNAME}\n\n# Install base R packages to user library\nRUN Rscript -e '.libPaths(Sys.getenv(\"R_LIBS_USER\")); \\\n    install.packages(c(\"tinytex\", \"rmarkdown\", \"renv\"), \\\n    repos = \"https://cloud.r-project.org\")'\n\n# Install TinyTeX in user directory\nRUN Rscript -e 'tinytex::install_tinytex()'\n\n# Add TinyTeX binaries to PATH\nENV PATH=/home/${USERNAME}/.TinyTeX/bin/x86_64-linux:$PATH\n\n# Restore R packages via renv\nRUN Rscript -e '.libPaths(Sys.getenv(\"R_LIBS_USER\")); \\\n    renv::restore()'\n\n# Default to interactive shell\nCMD [\"/bin/bash\"]\nThis configuration provides a minimal R installation with LaTeX support for PDF rendering and secure non-root user execution.\nDocker Compose Integration:\nThe setup also includes a docker-compose.yml that provides multiple development environments:\n# Multiple services for different workflows\nservices:\n  r-session:   # Interactive R session  \n  bash:        # Bash shell access\n  research:    # Automated paper rendering\n  test:        # Package testing\n  check:       # Package checking\nThis allows developers to choose their preferred development environment while maintaining identical package dependencies and system configuration."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "href": "posts/share_R_code_via_docker_p25/index.html#why-use-all-three",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "5.1 Why Use All Three?",
    "text": "5.1 Why Use All Three?\nUsing any single tool improves reproducibility, but combining all three provides the most complete solution:\n\nzzrrtools provides standardized project structure and research compendium organization\nrenv guarantees the R packages and their versions\nDocker guarantees the OS and R version\nTogether they achieve end-to-end reproducibility from project organization through package dependencies to operating system consistency\n\nThis approach creates a fully portable, well-organized research compendium that can be shared and will produce identical results across different computers while following established research best practices."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-governance-model",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-strategy-with-governance-model",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "5.2 Integration Strategy with Governance Model",
    "text": "5.2 Integration Strategy with Governance Model\nThe workflow integrates zzrrtools, renv, and Docker with a clear governance structure suitable for multi-developer research teams:\nProject Maintainer Role: - Creates and maintains the research compendium structure - Manages renv environment and package dependencies using consistency checking - Updates and maintains Docker images - Reviews and approves contributor changes - Runs renv validation before accepting pull requests\nContributor Role (Other Developers): - Access the private research compendium as invited collaborators - Add analysis content, papers, and documentation using feature branches - Propose new package dependencies through contributions - Submit changes via pull requests from feature branches\nWorkflow Steps:\n\nInitialize Research Compendium (Maintainer):\n\nCreate standardized project structure using zzrrtools framework\nSet up analysis directories with data organization\nInitialize renv environment with renv::init()\nCreate Dockerfile with container configuration\n\nEstablish Development Environment (Maintainer):\n\nInstall required packages and develop initial analysis\nCreate tests for analytical functions\nUse the renv consistency checker to validate and create initial lockfile:\n# Validate dependencies and create snapshot\nRscript check_renv_for_commit.R --fix\nBuild and test Docker image locally\n\nMaintain Infrastructure (Maintainer):\n\nReview contributor pull requests for package additions\nUse renv consistency checker to validate and update dependencies:\n# Validate contributor's package requirements\nRscript check_renv_for_commit.R --fail-on-issues\n\n# If validation passes, update environment\nRscript check_renv_for_commit.R --fix\nUpdate renv.lock by selectively incorporating new dependencies\nRebuild Docker images when system dependencies change\nPush updated images to container registry (Docker Hub, GitHub Container Registry)\n\nCollaborative Development (All Developers):\nResearch Compendium Files in GitHub Repository:\n\nProject Structure: DESCRIPTION, LICENSE, README.qmd (zzrrtools-generated)\nAnalysis Content: Files in analysis/paper/ directory (R Markdown manuscripts)\nDependencies: renv.lock (managed by maintainer), renv/activate.R\nInfrastructure: Dockerfile (maintained by project maintainer)\nCode: R/ directory (utility functions), tests/ directory\nDocumentation: Generated README files and project documentation\nConfiguration: .gitignore, .github/ (CI/CD workflows)\n\nSharing the Docker image using Docker Hub:\nDocker Hub provides public image hosting that enables reproducible research by sharing computational environments while protecting private research code in GitHub.\nDocker Hub (Recommended for Reproducible Research)\n# Build the image with GitHub Container Registry URL\ndocker build -t ghcr.io/username/penguins_analysis:v1.0 .\n\n# Login to GitHub Container Registry (using GitHub Personal Access Token)\necho $GITHUB_TOKEN | docker login ghcr.io -u username \\\n  --password-stdin\n\n# Push to GitHub Container Registry (automatically private)\ndocker push ghcr.io/username/penguins_analysis:v1.0\nSetting up GitHub Personal Access Token:\nCreate a Personal Access Token with the required permissions for container registry operations. The token must include write:packages and read:packages scopes, plus repo access for private repositories.\nFor detailed step-by-step instructions, see Appendix A: GitHub Personal Access Token Setup.\n# Export token as environment variable (replace with your actual token)\nexport GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n\n# Login and push\necho $GITHUB_TOKEN | docker login ghcr.io -u username \\\n  --password-stdin\ndocker build -t ghcr.io/username/penguins_analysis:v1.0 .\ndocker push ghcr.io/username/penguins_analysis:v1.0\nNote: If you get a “permission_denied” error when pushing, ensure your token includes the correct scopes (see Appendix A for details).\nGitHub Container Registry Benefits:\n\nFree tier: 0.5GB storage included, no billing currently active\nAutomatic access control: Inherits repository permissions\nIntegrated with GitHub Actions: Direct authentication in CI/CD\nSimple team sharing: Repository collaborators automatically have access\nPackage management: Integrated with GitHub Packages ecosystem\n\nDocker Workflow:\nThe zzrrtools setup provides multiple approaches for working with containers, from simple Make commands to direct Docker execution. Make commands offer simplicity:\n# Build and run with Make (recommended)\nmake docker-build    # Build the container\nmake docker-r        # Interactive R session\nmake docker-render   # Render research paper\nFor Docker workflow options including Docker Compose and direct commands, see Appendix D: Docker Workflow Options.\nExecute consistently:\n\nRun analyses in the Docker container for guaranteed reproducibility\nUse volume mounts to access local files while maintaining environment consistency\nRun tests within the container to verify functionality\n\n\nThis strategy ensures that your R Markdown documents and analyses will run identically for anyone who has access to your Docker container, regardless of their local setup."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "href": "posts/share_R_code_via_docker_p25/index.html#project-scenario",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.1 Project Scenario",
    "text": "6.1 Project Scenario\nA team of data scientists collaborates on Palmer Penguins analysis using zzrrtools’ Docker-first workflow that eliminates environment setup friction:\n\nJoe (joe): Project maintainer who initializes the repository\nSam (sam): Contributor who extends the analysis\n\nAdditional team members: Can join without any local R installation\n\nThe collaboration model emphasizes zero-setup team onboarding through self-replicating project distribution and containerized development environments.\n\nCollaboration Philosophy: - Self-contained projects: Each repository includes its own setup script - Container-first development: All work happens in identical Docker environments - Automated dependency validation: Pre-commit checks prevent conflicts - Shell-based workflows: Command-line tools for maximum flexibility\n\nKey Workflow Principles: - Joe initializes with zzrrtools and commits the setup script to the repository - Team members run the included script - no separate installation required - All development occurs in containers for perfect environment consistency - Dependency changes are validated before commits to prevent team conflicts - Each developer works in identical environments regardless of host system"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "href": "posts/share_R_code_via_docker_p25/index.html#implementation-example",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.2 Implementation Example",
    "text": "6.2 Implementation Example\n\n6.2.1 Project Maintainer Setup (Joe)\nJoe initializes a private GitHub repository and creates the containerized research environment:\n# Create repository and initialize zzrrtools\ngit clone https://github.com/joe/penguins_analysis.git\ncd penguins_analysis\n~/prj/zzrrtools/zzrrtools.sh --dotfiles ~/.config/shell \\\n                             --base-image rgt47/r-pluspackages\nThis creates: - Research compendium directory structure - Docker container configuration - renv dependency management - Automated validation scripts - GitHub Actions workflows\nFor a detailed view of the complete directory structure created by zzrrtools, see Appendix C: Directory Structure.\nJoe completes the setup and begins development:\n# Validate dependencies and build container\nmake check-renv\nmake docker-build\n\n# Start container-based development\nmake docker-r\nFor detailed information on renv dependency validation, troubleshooting, and team collaboration workflows, see Appendix G: renv Management and Validation.\nThe validation script ensures package environment consistency by verifying dependencies across code files, DESCRIPTION, and renv.lock, preventing common collaboration issues where team members have mismatched environments.\nStep 4: Create Initial Analysis Paper\nJoe creates an initial analysis examining flipper length vs. bill length relationships in the Palmer Penguins dataset, implementing basic visualization and statistical exploration within the research compendium structure.\nStep 5: Create Tests for Analysis Functions\nJoe implements testing to ensure reproducible research through data validation, error detection, and environment verification. Testing provides collaboration confidence and supports publication standards by validating data integrity, statistical relationships, and pipeline functionality.\nJoe sets up the testing framework and creates basic data validation tests to verify dataset availability, dimensions, and required columns. These tests ensure the analysis environment is correctly configured and catch data-related issues early in the development process.\nFor a complete test suite with data validation, statistical tests, and integration tests, see Appendix B: Test Suite.\nStep 6: Create a .gitignore file\nJoe configures version control to track source code and dependencies while excluding generated outputs and temporary files. The principle: track the “recipe” (code + dependencies), not the “meal” (outputs).\nJoe creates a .gitignore file excluding renv libraries, generated outputs, temporary files, and system artifacts. This keeps the repository lightweight while ensuring collaborators can recreate the complete environment from tracked dependencies.\nStep 7: Create a Dockerfile\nzzrrtools generates a Dockerfile with multiple template options. The standard template uses rocker/r-ver, while the pluspackages template includes common R packages like tidyverse. Both provide:\n\nR version consistency: Matches exact R version specified in renv.lock\nDevelopment environment: Includes zsh, vim, tmux, Node.js for plugin support\nSecurity: Non-root user execution with proper file permissions\nTinyTeX integration: LaTeX support for PDF rendering (pluspackages template)\nPre-installed packages: Common packages like tidyverse, DT, testthat (pluspackages template)\n\nThe generated Dockerfile includes development tools and optimizations:\nARG R_VERSION=latest\nFROM rocker/r-ver:${R_VERSION}\n\n# Install comprehensive development environment\nRUN apt-get update && apt-get install -y \\\n    git ssh curl wget vim tmux zsh build-essential \\\n    libcurl4-openssl-dev libssl-dev libxml2-dev \\\n    libfontconfig1-dev libharfbuzz-dev libfribidi-dev \\\n    libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev \\\n    man-db pandoc \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Node.js for vim plugins\nRUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \\\n    apt-get install -y nodejs\n\n# Create non-root user with zsh shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set up R environment with renv\nWORKDIR /home/${USERNAME}/project\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock ./\nUSER ${USERNAME}\nRUN R -e \"install.packages('renv'); renv::restore()\"\n\n# Copy project files and install\nCOPY --chown=${USERNAME}:${USERNAME} . .\nRUN R -e \"devtools::install('.')\"\n\nCMD [\"/bin/zsh\"]\nAlternative: Pre-packaged Template\nFor projects using common packages, the pluspackages template includes TinyTeX and popular R packages:\n# Install TinyTeX for PDF rendering\nRUN R -e \"install.packages('tinytex')\" && \\\n    R -e \"tinytex::install_tinytex()\" && \\\n    /root/.TinyTeX/bin/*/tlmgr path add\n\n# Install common R packages (cached layer)\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', \\\n    'testthat', 'naniar', 'DT', 'conflicted', 'ggthemes', \\\n    'datapasta', 'janitor', 'kableExtra', 'tidytuesdayR', \\\n    'tidyverse'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Give user write permissions to R library\nRUN chown -R ${USERNAME}:${USERNAME} /usr/local/lib/R/site-library\nFor production Dockerfiles with development environment configuration (zsh, vim plugins, dotfiles integration), see Appendix F: Docker Configuration Examples.\nR Version Synchronization:\nThe Dockerfile uses a build argument to ensure the R version exactly matches what’s specified in renv.lock. This eliminates potential issues from R version mismatches between the package environment and the underlying R interpreter. The build command extracts the R version from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/joe/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment.\nStep 8: Container-Based Development\nJoe performs all development work inside the Docker container, ensuring consistent environments and immediate visibility of changes to the host system through volume mounting. The container provides a complete development environment with package management, editing tools, and validation utilities.\nStep 9: Update and Share Environment\nWhen package dependencies change, GitHub Actions automatically rebuilds the Docker image with updated renv.lock specifications and pushes the updated environment to Docker Hub for team access. This ensures collaborators have access to the identical development environment.\nStep 10: Prepare for Team Handoff\nBefore handing off to team members, Joe must complete several critical steps:\n# 1. Validate all dependencies are properly captured\nmake check-renv-fix\n\n# 2. Run complete test suite to ensure everything works\nmake docker-test\n\n# 3. Render paper to verify end-to-end workflow\nmake docker-render\n\n# 4. Build and tag the Docker image\nmake docker-build\ndocker tag penguins_analysis ghcr.io/joe/penguins_analysis:v1.0\n\n# 5. Push Docker image to Docker Hub for team access\necho $GITHUB_TOKEN | docker login ghcr.io -u joe --password-stdin\ndocker push ghcr.io/joe/penguins_analysis:v1.0\n\n# 6. Commit all setup files and push to repository\ngit add .\ngit commit -m \"Initial research compendium setup with Docker environment\"\ngit push origin main\nStep 11: Enable Team Access\nJoe configures repository permissions for team collaboration:\n\nRepository Settings → Collaborators → Add team members\nGrant “Write” access to enable forking and pull requests\nShare repository URL and Docker Hub image name with team\nDocument onboarding process in README or team communication\n\nAt this point, Joe has established a reproducible research framework ready for collaborative development. The containerized environment is available via the registry, and team members can join with zero local setup requirements.\n\n\n6.2.2 Team Member Onboarding (Sam)\nWhat Sam Receives from Joe: - Repository URL: https://github.com/joe/penguins_analysis - Container registry access (GitHub Personal Access Token) - Brief project overview and development guidelines\nSam’s Onboarding Process:\n# 1. Clone the zzrrtools framework\ngit clone https://github.com/username/zzrrtools.git ~/prj/zzrrtools\ncd ~/prj/zzrrtools\n./install.sh  # Creates zzrrtools command in PATH\n\n# 2. Fork and clone the project repository\ngit clone https://github.com/sam/penguins_analysis.git  # Sam's fork\ncd penguins_analysis\n\n# 3. Run zzrrtools setup with personal preferences\nzzrrtools --dotfiles ~/.config/shell  # Customize with personal dotfiles\n# Or use other options:\n# zzrrtools --base-image rgt47/r-pluspackages  # Use pre-packaged template\n# zzrrtools --no-docker                       # Skip Docker build\n# zzrrtools --next-steps                      # Show workflow guidance\n\n# 4. Pull the pre-built Docker environment\ndocker pull ghcr.io/joe/penguins_analysis:v1.0\n\n# 5. Start development in identical environment\nmake docker-r\nKey Advantage: After one-time zzrrtools installation, Sam has access to the framework for all future projects. The development environment setup becomes a simple script execution.\nSam develops new analysis components within the same containerized environment, ensuring identical results across team members.\nStep 5: Paper Integration and Testing\nSam integrates the new analysis into the research paper, combining Joe’s original visualizations with the new body mass analysis. Sam also creates tests to validate the new functionality and ensure package dependencies are properly documented.\nStep 6: Validation and Quality Assurance\nSam creates tests for the new body mass analysis, validates data integrity and statistical relationships, then runs the complete test suite and verifies paper rendering to ensure no regressions before submission.\nStep 7: Contribution Submission\nWhen Sam completes the analysis iteration, the submission process follows these steps:\n\nValidate dependencies: Run make docker-check-renv-fix to ensure package consistency\nRun complete test suite: Execute make docker-test to verify all tests pass\nVerify paper rendering: Run make docker-render to confirm analysis integrates properly\nCommit changes:\ngit add .\ngit commit -m \"Add body mass analysis and associated tests\"\ngit push origin feature/body-mass-analysis\nCreate pull request: Submit pull request from Sam’s fork to Joe’s original repository\nNotify Joe: Alert project maintainer about new packages or Docker changes needed\n\nNote: Only Joe (project maintainer) can accept pull requests. The official Docker image is automatically rebuilt and pushed to Docker Hub by GitHub Actions when package dependencies change.\nCI Feedback Loop: If the CI workflow fails (e.g., renv validation issues), Sam receives automatic GitHub notifications and can view detailed failure logs to fix the issues before Joe reviews the PR.\nSam commits the completed analysis, tests, and documentation to their feature branch and creates a cross-repository pull request to the original repository. This ensures proper code review and governance while maintaining clear attribution of contributions.\nAt this point, Sam has successfully contributed new analysis through the collaborative workflow. Joe reviews the pull request, tests the changes in the containerized environment, and merges the contribution while maintaining project governance and quality standards."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "href": "posts/share_R_code_via_docker_p25/index.html#complete-handoff-workflow-summary",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.3 Complete Handoff Workflow Summary",
    "text": "6.3 Complete Handoff Workflow Summary\nInitiating Developer (Joe) Responsibilities: 1. Run zzrrtools.sh to create research compendium 2. Develop initial analysis and create tests 3. Validate dependencies with make check-renv-fix\n4. Build initial Docker image and configure automated rebuilds via GitHub Actions 5. Push team Docker image to Docker Hub (public registry for reproducibility) 6. Commit all files and push to repository 7. Grant team member repository access\n8. Share repository URL and Docker Hub image name\nJoining Developer (Sam) Process: 1. Receive repository URL and Docker Hub image name from Joe 2. Clone zzrrtools framework: git clone zzrrtools ~/prj/zzrrtools 3. Install zzrrtools: cd ~/prj/zzrrtools && ./install.sh (creates zzrrtools command in PATH) 4. Fork and clone project repository 5. Pull pre-built team Docker image: docker pull [TEAM]/project:latest (from Docker Hub) 6. Start development immediately: make docker-r (no local setup needed) 7. Submit contributions via pull requests to private repository\nKey Success Factor: The containerized environment and centralized zzrrtools framework eliminate project-specific configuration requirements for team members after one-time framework installation."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "href": "posts/share_R_code_via_docker_p25/index.html#collaboration-results",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "6.4 Collaboration Results",
    "text": "6.4 Collaboration Results\nThis workflow achieves: - Identical development environments across team members - Dependency validation preventing conflicts - Standardized project structure - Automated testing and CI/CD integration\nFor GitHub Actions setup instructions, workflow examples, and CI/CD configuration, see Appendix E: GitHub Actions CI/CD Setup.\nThe collaborative workflow demonstrated above illustrates the power of combining zzrrtools, renv, and Docker for reproducible research. However, successful implementation of this approach requires understanding both when it’s most beneficial and how to apply it effectively. The following best practices and considerations provide guidance for teams considering this strategy."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#when-to-use-this-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.1 When to Use This Approach",
    "text": "7.1 When to Use This Approach\nThe zzrrtools + renv + Docker approach with testing is particularly valuable for:\n\nLong-term research projects where reproducibility over time is crucial\nCollaborative analyses with multiple contributors on different systems\nProduction analytical pipelines that need to run consistently\nAcademic publications where methods must be reproducible\nTeaching and education to ensure consistent student experiences\nComplex analyses that require testing to validate results"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "href": "posts/share_R_code_via_docker_p25/index.html#tips-for-efficient-implementation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.2 Tips for Efficient Implementation",
    "text": "7.2 Tips for Efficient Implementation\n\nKeep Docker images minimal: Include only what’s necessary for reproducibility.\nUse specific version tags: For both R packages and Docker base images, specify exact versions.\nDocument system requirements: Include notes on RAM and storage requirements.\nLeverage bind mounts: Mount local directories to containers for easier development.\nWrite meaningful tests: Focus on validating both data integrity and analytical results.\nTest regularly: Use CI/CD pipelines to run tests on every change.\nConsider computational requirements: Particularly for resource-intensive analyses."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "href": "posts/share_R_code_via_docker_p25/index.html#testing-strategies-for-r-analyses",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.3 Testing Strategies for R Analyses",
    "text": "7.3 Testing Strategies for R Analyses\nTesting data analysis code differs from traditional software testing but provides crucial value for reproducible research:\n\nData Validation Tests: Ensure data has the expected structure, types, and values.\nFunction Tests: Verify that custom functions work as expected with known inputs and outputs.\nEdge Case Tests: Check how code handles missing values, outliers, or unexpected inputs.\nIntegration Tests: Confirm that different parts of the analysis work correctly together.\nRegression Tests: Make sure new changes don’t break existing functionality.\nOutput Validation: Verify that final results match expected patterns or benchmarks.\n\nWhile uncommon in traditional data analysis, these tests catch silent errors, validate assumptions, and provide confidence that analyses remain correct as code and data evolve."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "href": "posts/share_R_code_via_docker_p25/index.html#potential-challenges",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.4 Potential Challenges",
    "text": "7.4 Potential Challenges\nSome challenges to be aware of:\n\nDocker image size: Images with many packages can become large\nLearning curve: Docker, renv, and testing frameworks require some initial learning\nSystem-specific features: Some analyses may rely on hardware features\nPerformance considerations: Containers may have different performance characteristics\nTest maintenance: Tests need to be updated as the analysis evolves"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "7.5 Troubleshooting Common Issues",
    "text": "7.5 Troubleshooting Common Issues\nDocker Build Failures: - Try: export DOCKER_BUILDKIT=0 (disable BuildKit) - Check Docker has sufficient memory/disk space - Ensure Docker is running and up to date\nPlatform Warnings on ARM64/Apple Silicon: - Use updated Makefile with --platform linux/amd64 flags - Or set: export DOCKER_DEFAULT_PLATFORM=linux/amd64\nPermission Errors in Container: - Rebuild image after copying dotfiles - Check file ownership in project directory\nPackage Name Errors: - Ensure directory name contains only letters/numbers/periods - Avoid underscores and special characters\nMissing Dotfiles in Container: - Use --dotfiles or --dotfiles-nodot flag during setup - Rebuild Docker image after adding dotfiles\nDespite these challenges, the benefits of reproducible research outweigh the implementation costs, particularly for collaborative and long-term projects. The approach described in this white paper provides a foundation for achieving reproducibility that meets the standards expected in data science and academic research."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-token-creation",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.1 Step-by-Step Token Creation",
    "text": "9.1 Step-by-Step Token Creation\n1. Navigate to GitHub Settings: - Go to GitHub.com and sign in - Click your profile picture (top right) → Settings - In the left sidebar: Developer settings → Personal access tokens\nNote: GitHub now offers two token types: - Fine-grained personal access tokens (recommended for new projects) - Personal access tokens (classic) (for broader compatibility)\n2. Create New Token: - Click “Generate new token” and select the appropriate type - Add a descriptive note (e.g., “Docker Container Registry Access”) - Set expiration (recommended: 90 days for security)\n3. Select Required Scopes (check these boxes): - ✅ repo (Full control of private repositories) - Required for private repos - ✅ write:packages (Upload Docker images to GitHub Container Registry) - Required for project maintainer - ✅ read:packages (Download Docker images from GitHub Container Registry) - Required for all team members - ✅ delete:packages (Delete packages from GitHub Package Registry) - Optional but recommended\nNote: Team members only need read:packages and repo, but the project maintainer needs all container permissions to push Docker images.\nToken Type Recommendation: Use fine-grained personal access tokens for new projects as they provide better security and more precise permissions.\n4. Generate and Copy Token: - Click “Generate token” at the bottom - Important: Copy the token immediately - you won’t see it again - Store it securely (see security practices below)"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "href": "posts/share_R_code_via_docker_p25/index.html#token-security-best-practices",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.2 Token Security Best Practices",
    "text": "9.2 Token Security Best Practices\n\nNever commit tokens to repositories - Use .gitignore to exclude files containing tokens\nUse environment variables - Store tokens in shell environment variables\nSet reasonable expiration dates - Use 30-90 day expiration for security\nRevoke unused tokens - Clean up tokens when no longer needed\nConsider GitHub CLI - Use gh auth login for easier management\nMonitor token usage - Check GitHub Settings → Developer settings → Personal access tokens for activity"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "href": "posts/share_R_code_via_docker_p25/index.html#alternative-using-github-cli",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.3 Alternative: Using GitHub CLI",
    "text": "9.3 Alternative: Using GitHub CLI\nFor simpler token management, consider using GitHub CLI instead of manual tokens:\n# Install and authenticate (handles tokens)\ngh auth login --scopes write:packages,read:packages,repo\n\n# Login to container registry (works with gh auth)\necho $(gh auth token) | docker login ghcr.io \\\n  -u $(gh api user --jq .login) --password-stdin"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "href": "posts/share_R_code_via_docker_p25/index.html#troubleshooting-common-issues-1",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.4 Troubleshooting Common Issues",
    "text": "9.4 Troubleshooting Common Issues\n“permission_denied: The token provided does not match expected scopes” - Verify your token includes write:packages and read:packages scopes - For private repositories, ensure repo scope is also selected - Create a new token with correct permissions if needed\nToken not recognized: - Ensure token is properly exported: export GITHUB_TOKEN=your_token_here - Verify token hasn’t expired - Check that you’re using the full token (starts with ghp_) 6. Horst, A.M., Hill, A.P., & Gorman, K.B. (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/ 7. Marwick, B. (2016). Computational reproducibility in archaeological research: Basic principles and a case study of their implementation. Journal of Archaeological Method and Theory, 24(2), 424-473."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-file-teststestthattest-comprehensive-analysis.r",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R",
    "text": "9.5 Test File: tests/testthat/test-comprehensive-analysis.R\nlibrary(testthat)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\n# Test 1: Data Availability and Basic Structure\n# Generic application: Verify your primary dataset loads correctly and has \n# expected dimensions\n# Catches: Package loading issues, file path problems, corrupted data files\ntest_that(\"Palmer Penguins dataset is available and has correct structure\", \n          {\n  expect_true(exists(\"penguins\", where = \"package:palmerpenguins\"))\n  expect_s3_class(palmerpenguins::penguins, \"data.frame\")\n  expect_equal(ncol(palmerpenguins::penguins), 8)  # Adapt: Set expected \n                                                    # column count\n  expect_gt(nrow(palmerpenguins::penguins), 300)   # Adapt: Set minimum \n                                                    # row threshold\n  expect_equal(nrow(palmerpenguins::penguins), 344)  # Adapt: Set exact \n                                                      # expected count \n                                                      # if known\n})\n\n# Test 2: Required Columns Exist with Correct Types\n# Generic application: Ensure your analysis depends on columns that \n# actually \n# exist with correct types\n# Catches: Column name changes, type coercion issues, CSV import problems\ntest_that(\"Dataset contains required columns with expected data types\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Check column existence - Adapt: List columns your analysis requires\n  required_cols &lt;- c(\"species\", \"island\", \"bill_length_mm\", \n                     \"bill_depth_mm\", \"flipper_length_mm\", \n                     \"body_mass_g\", \"sex\", \"year\")\n  expect_true(all(required_cols %in% names(df)))\n  \n  # Check data types - Adapt: Verify types match your analysis \n  # expectations\n  expect_type(df$species, \"integer\")  # Factor stored as integer\n  expect_type(df$bill_length_mm, \"double\")  # Continuous measurements\n  expect_type(df$flipper_length_mm, \"integer\")  # Discrete measurements\n  expect_type(df$body_mass_g, \"integer\")  # Integer measurements\n})\n\n# Test 3: Categorical Variables Have Expected Levels\n# Generic application: Verify factor levels for categorical variables used\n# in \n# analysis\n# Catches: Missing categories, typos in factor levels, data encoding issues\ntest_that(\"Species factor has expected levels\", {\n  species_levels &lt;- levels(palmerpenguins::penguins$species)\n  expected_species &lt;- c(\"Adelie\", \"Chinstrap\", \"Gentoo\")  # Adapt: Your \n                                                          # expected \n                                                          # categories\n  expect_equal(sort(species_levels), sort(expected_species))\n  expect_equal(length(species_levels), 3)  # Adapt: Expected number of \n                                           # categories\n  # For other datasets: Test treatment groups, regions, product types, etc.\n})\n\n# Test 4: Data Value Ranges are Domain-Reasonable\n# Generic application: Verify numeric values fall within realistic ranges\n# for \n# your domain\n# Catches: Data entry errors, unit conversion mistakes, outliers from \n# measurement errors\ntest_that(\"Measurement values fall within reasonable biological ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Bill length - Adapt: Set realistic bounds for your numeric variables\n  bill_lengths &lt;- df$bill_length_mm[!is.na(df$bill_length_mm)]\n  expect_true(all(bill_lengths &gt;= 30 & bill_lengths &lt;= 70))  # Penguin-\n                                                              # specific \n                                                              # range\n  \n  # Flipper length - Examples for other domains:\n  flipper_lengths &lt;- df$flipper_length_mm[!is.na(df$flipper_length_mm)]\n  expect_true(all(flipper_lengths &gt;= 150 & flipper_lengths &lt;= 250))\n  # Finance: stock prices &gt; 0, percentages 0-100\n  # Health: age 0-120, BMI 10-80, blood pressure 50-300\n  # Engineering: temperatures -273+°C, pressures &gt; 0\n  \n  # Body mass\n  body_masses &lt;- df$body_mass_g[!is.na(df$body_mass_g)]\n  expect_true(all(body_masses &gt;= 2000 & body_masses &lt;= 7000))\n})\n\n# Test 5: Missing Data Patterns are as Expected\n# Generic application: Verify missingness patterns match your data \n# collection \n# expectations\n# Catches: Unexpected data loss, systematic missingness, data pipeline \n# failures\ntest_that(\"Missing data follows expected patterns\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Total missing values should be manageable\n  total_na &lt;- sum(is.na(df))\n  expect_lt(total_na, nrow(df))  # Adapt: Set acceptable threshold for \n                                 # missing \n                                 # data\n  \n  # Some variables may have expected missingness\n  expect_gt(sum(is.na(df$sex)), 0)  # Sex determination sometimes difficult\n  # Adapt examples: Optional survey questions, historical data gaps, sensor \n  # failures\n  \n  # Critical variables should be complete\n  expect_equal(sum(is.na(df$species)), 0)  # Primary identifier must be \n                                           # complete\n  # Adapt: ID columns, primary keys, required fields should have no NAs\n})\n\n# Test 6: Expected Statistical Relationships Hold\n# Generic application: Test known relationships between variables in your \n# domain\n# Catches: Data corruption, encoding errors, units mix-ups that break known \n# patterns\ntest_that(\"Expected correlations between measurements exist\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test strong expected relationships\n  correlation &lt;- cor(df$flipper_length_mm, df$body_mass_g, \n                     use = \"complete.obs\")\n  expect_gt(correlation, 0.8)  # Strong positive correlation expected\n  # Adapt examples: height vs weight, price vs quality, experience vs salary\n  \n  # Test weaker but expected relationships\n  bill_cor &lt;- cor(df$bill_length_mm, df$bill_depth_mm, use = \"complete.obs\")\n  expect_gt(abs(bill_cor), 0.1)  # Some relationship should exist\n  # Adapt: Education vs income, advertising vs sales, temperature vs \n  # energy use\n})\n\n# Test 7: Visualization Functions Work Correctly\n# Generic application: Ensure your key plots and visualizations can be \n# generated\n# Catches: Missing aesthetic mappings, incompatible data types, package \n# conflicts\ntest_that(\"Basic plots can be generated without errors\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test basic plot creation without errors\n  expect_no_error({\n    p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      theme_minimal()\n  })\n  # Adapt: Test your key plot types - histograms, boxplots, time series,\n  # etc.\n  \n  # Test that plot object is properly created\n  p1 &lt;- ggplot(df, aes(x = flipper_length_mm, y = bill_length_mm)) +\n    geom_point()\n  expect_s3_class(p1, \"ggplot\")  # Adapt: Check for your plotting \n                                   # framework objects\n})\n\n# Test 8: Data Filtering and Subsetting Work Correctly\n# Generic application: Verify data manipulation operations produce expected\n# results\n# Catches: Logic errors in filtering, unexpected factor behaviors, \n# indexing mistakes\ntest_that(\"Data can be properly filtered and subsetted\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test categorical filtering\n  adelie_penguins &lt;- df[df$species == \"Adelie\" & !is.na(df$species), ]\n  expect_gt(nrow(adelie_penguins), 100)  # Adapt: Expected subset size\n  expect_true(all(adelie_penguins$species == \"Adelie\", na.rm = TRUE))\n  # Adapt: Filter by treatment groups, regions, time periods, etc.\n  \n  # Test missing data handling\n  complete_cases &lt;- df[complete.cases(df), ]\n  expect_lt(nrow(complete_cases), nrow(df))  # Some rows should be removed\n  expect_equal(sum(is.na(complete_cases)), 0)  # No NAs remaining\n  # Adapt: Test your specific data cleaning operations\n})\n\n# Test 9: Summary Statistics are Reasonable\n# Generic application: Verify computed statistics match domain knowledge \n# expectations\n# Catches: Calculation errors, unit mistakes, algorithm bugs, extreme \n# outliers\ntest_that(\"Summary statistics fall within expected ranges\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test means fall within expected ranges\n  mean_flipper &lt;- mean(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(mean_flipper, 190)  # Adapt: Set realistic bounds for your \n                                # variables\n  expect_lt(mean_flipper, 210)\n  # Examples: Average customer age 20-80, mean salary $30k-200k, etc.\n  \n  # Test other central tendencies\n  mean_mass &lt;- mean(df$body_mass_g, na.rm = TRUE)\n  expect_gt(mean_mass, 4000)\n  expect_lt(mean_mass, 5000)\n  \n  # Test variability measures are reasonable\n  sd_flipper &lt;- sd(df$flipper_length_mm, na.rm = TRUE)\n  expect_gt(sd_flipper, 5)   # Not zero variance\n  expect_lt(sd_flipper, 30)  # Not excessive variance\n  # Adapt: CV should be &lt;50%, SD should be meaningful relative to mean\n})\n\n# Test 10: Complete Analysis Pipeline Integration Test\n# Generic application: Test your entire analysis workflow runs without \n# errors\n# Catches: Pipeline breaks, dependency issues, function interaction problems\ntest_that(\"Complete analysis pipeline executes successfully\", {\n  df &lt;- palmerpenguins::penguins\n  \n  # Test that full workflow executes without errors\n  expect_no_error({\n    # Data preparation step\n    clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                       \"bill_length_mm\")]), ]\n    \n    # Statistical analysis step - Adapt: Your key analyses\n    correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                   clean_df$bill_length_mm)\n    \n    # Visualization step - Adapt: Your key plots\n    plot_result &lt;- ggplot(clean_df, \n                          aes(x = flipper_length_mm, y = bill_length_mm)) +\n      geom_point() +\n      geom_smooth(method = \"lm\") +\n      theme_minimal() +\n      labs(title = \"Flipper Length vs. Bill Length\",\n           x = \"Flipper Length (mm)\",\n           y = \"Bill Length (mm)\")\n  })\n  # Adapt: Add model fitting, prediction, reporting steps as needed\n  \n  # Verify analysis produces meaningful results\n  clean_df &lt;- df[complete.cases(df[c(\"flipper_length_mm\", \n                                     \"bill_length_mm\")]), ]\n  correlation_result &lt;- cor.test(clean_df$flipper_length_mm, \n                                 clean_df$bill_length_mm)\n  expect_lt(correlation_result$p.value, 0.05)  # Significant result expected\n  # Adapt: Check model R², prediction accuracy, convergence, etc.\n})"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "href": "posts/share_R_code_via_docker_p25/index.html#running-the-tests",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.6 Running the Tests",
    "text": "9.6 Running the Tests\nTo run all tests in your project:\n# Run all tests\ntestthat::test_dir(\"tests/testthat\")\n\n# Run specific test file\ntestthat::test_file(\"tests/testthat/test-comprehensive-analysis.R\")\n\n# Run tests with detailed output\ntestthat::test_dir(\"tests/testthat\", reporter = \"detailed\")"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#test-categories-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.7 Test Categories Explained",
    "text": "9.7 Test Categories Explained\nData Validation Tests (1-5): Verify data structure, types, ranges, and missing patterns Statistical Tests (6): Confirm expected relationships in the data Functional Tests (7-8): Ensure analysis functions work correctly Sanity Tests (9): Check that summary statistics are reasonable Integration Tests (10): Verify the complete analysis pipeline works end-to-end\nThese tests provide coverage for a data analysis project and can catch issues ranging from data corruption to environment setup problems."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "href": "posts/share_R_code_via_docker_p25/index.html#key-features-explained",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.8 Key Features Explained:",
    "text": "9.8 Key Features Explained:\nData Organization: - raw_data/: Original, unmodified datasets as received - derived_data/: Processed, cleaned, or transformed data - metadata/: Documentation about data sources, collection methods, variables - validation/: Scripts that verify data integrity and quality - external_data/: Third-party datasets or reference data\nMultiple Output Formats: - figures/: Generated plots, charts, and visualizations - tables/: Generated summary tables and statistical results - paper/: Main manuscript and analysis documents - templates/: Document templates and citation style files\nR Package Structure: - R/: Custom functions and utilities - man/: Generated documentation for R functions - tests/testthat/: Unit tests and validation scripts - vignettes/: Long-form documentation and tutorials - DESCRIPTION: Package metadata and dependency specifications\nDocker Orchestration: - Dockerfile: Main container specification - docker-compose.yml: Multi-service development environments - Makefile: Build automation supporting both native R and Docker workflows\nWorkflows: - .github/workflows/: GitHub Actions for testing, checking, and rendering - setup_renv.R: Package environment setup - RRTOOLS_USER_GUIDE.md: Usage documentation\nNavigation Shortcuts: - Symbolic links: Single-letter shortcuts for easy navigation - a → analysis/, n → analysis/, f → figures/ - t → tests/, s → scripts/, m → man/ - e → external_data/, o → output/, c → cache/\nThis structure supports research projects while maintaining clear organization and following established research compendium principles."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-service-docker-architecture",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.9 Multi-Service Docker Architecture",
    "text": "9.9 Multi-Service Docker Architecture\nzzrrtools creates specialized Docker environments for different development tasks:\n# Build the containerized research environment\nmake docker-build\n\n# Interactive R console (primary development environment)\nmake docker-r\n\n# Development shell with personal dotfiles\nmake docker-zsh\n\n# Interactive bash session\nmake docker-bash\n\n# RStudio Server (web-based IDE)\nmake docker-rstudio    # Access at http://localhost:8787\n\n# Render research paper\nmake docker-render\n\n# Run tests\nmake docker-test\n\n# Package checking\nmake docker-check\n\n# renv dependency validation\nmake docker-check-renv-fix\n\n# See all available commands\nmake help\nCollaborative Benefits: - Zero-setup onboarding: Team members run identical commands - Consistent environments: Same container across all developer machines - ARM64/Apple Silicon support: Platform-specific flags ensure compatibility - Shell-optimized workflows: Command-line development with rich tooling - Personal customization: Dotfiles integration for familiar environments - Web-based development: Optional RStudio Server for GUI-based workflows"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-2-docker-compose-services",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.10 Option 2: Docker Compose Services",
    "text": "9.10 Option 2: Docker Compose Services\nDocker Compose orchestrates multiple container configurations:\n# Interactive R session\ndocker-compose run --rm r-session\n\n# Bash shell access\ndocker-compose run --rm bash\n\n# Automated paper rendering\ndocker-compose run --rm research\n\n# Package testing\ndocker-compose run --rm test\n\n# Package checking\ndocker-compose run --rm check\nDocker Compose Configuration Example:\nservices:\n  r-session:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./cache:/home/analyst/cache\n    working_dir: /home/analyst/project\n    \n  bash:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n    working_dir: /home/analyst/project\n    entrypoint: [\"/bin/bash\"]\n    \n  research:\n    build: .\n    volumes:\n      - .:/home/analyst/project\n      - ./analysis/figures:/home/analyst/output\n    working_dir: /home/analyst/project\n    command: [\"R\", \"-e\", \"rmarkdown::render('analysis/paper/paper.Rmd')\"]\nBenefits: - Service setup: Multiple predefined container configurations - Volume management: Consistent volume mounting across services - Environment isolation: Different services for different purposes - Parallel execution: Can run multiple services simultaneously"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#option-3-direct-docker-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.11 Option 3: Direct Docker Commands",
    "text": "9.11 Option 3: Direct Docker Commands\nFor maximum control, use Docker commands directly:\n# Basic interactive session\ndocker run --rm -it -v \"$(pwd):/home/analyst/project\" \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Interactive session with mounted cache\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/cache:/home/analyst/cache\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0\n\n# Render research paper\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -v \"$(pwd)/analysis/figures:/home/analyst/output\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n\n# Run specific tests\ndocker run --rm \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  R -e \"testthat::test_file('tests/testthat/test-data-integrity.R')\"\n\n# Interactive bash session\ndocker run --rm -it \\\n  -v \"$(pwd):/home/analyst/project\" \\\n  -w /home/analyst/project \\\n  ghcr.io/username/penguins_analysis:v1.0 \\\n  /bin/bash\nCommon Docker Flags Explained: - --rm: Remove container when it exits - -it: Interactive terminal session - -v: Mount volume (host:container) - -w: Set working directory inside container - --entrypoint: Override default command\nBenefits: - Full flexibility: Complete control over container configuration - Educational: Shows exactly what’s happening under the hood - Troubleshooting: Easier to debug when you see all options - Portability: Commands work on any Docker installation"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "href": "posts/share_R_code_via_docker_p25/index.html#volume-mounting-strategies",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.12 Volume Mounting Strategies",
    "text": "9.12 Volume Mounting Strategies\nProject Files:\n# Mount entire project directory\n-v \"$(pwd):/home/analyst/project\"\nOutput Separation:\n# Separate outputs from source\n-v \"$(pwd)/analysis/figures:/home/analyst/output\"\nCache Persistence:\n# Persistent package cache across sessions\n-v \"$(pwd)/cache:/home/analyst/cache\"\nRead-only Source:\n# Protect source files from modification\n-v \"$(pwd):/home/analyst/project:ro\""
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "href": "posts/share_R_code_via_docker_p25/index.html#choosing-the-right-approach",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.13 Choosing the Right Approach",
    "text": "9.13 Choosing the Right Approach\nUse Make Commands When: - You want simplicity and consistency - You’re new to Docker - You’re focusing on analysis rather than infrastructure\nUse Docker Compose When: - You need multiple service configurations - You’re working with a team using standardized environments - You want to define complex volume and networking setups\nUse Direct Commands When: - You need maximum flexibility - You’re troubleshooting container issues - You’re creating custom workflows not covered by Make targets\nAll three approaches can be used together in the same project, depending on the specific task and user preferences."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "href": "posts/share_R_code_via_docker_p25/index.html#understanding-github-actions-for-research",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.14 Understanding GitHub Actions for Research",
    "text": "9.14 Understanding GitHub Actions for Research\nWhat is CI/CD for Research?\nContinuous Integration/Continuous Deployment (CI/CD) tests your research code whenever changes are made. For research compendia, this means:\n\nTesting: Every push triggers your test suite\nEnvironment consistency: Tests run in identical Docker environments\nEarly error detection: Problems caught during development\nCollaboration confidence: Team members see if changes break functionality\nReproducibility validation: Ensures analysis works across different systems"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "href": "posts/share_R_code_via_docker_p25/index.html#step-by-step-setup",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.15 Step-by-Step Setup",
    "text": "9.15 Step-by-Step Setup\n\n9.15.1 Step 1: Create Workflow Directory\n# Create the GitHub Actions directory\nmkdir -p .github/workflows\n\n\n9.15.2 Step 2: Docker-based CI Workflow with renv Validation\nCreate .github/workflows/docker-ci.yml:\nname: Docker CI with renv Validation\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  build-and-test:\n    runs-on: ubuntu-latest\n    \n    steps:\n    - name: Checkout repository\n      uses: actions/checkout@v4\n      \n    - name: Set up R for renv validation\n      uses: r-lib/actions/setup-r@v2\n      with:\n        r-version: 'release'\n        \n    - name: Install renv for validation\n      run: |\n        install.packages(\"renv\")\n      shell: Rscript {0}\n        \n    - name: Validate renv consistency before Docker build\n      run: |\n        # Validate renv environment before building Docker image\n        Rscript check_renv_for_commit.R --fail-on-issues --quiet\n      \n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n      \n    - name: Extract R version from renv.lock\n      id: r-version\n      run: |\n        R_VERSION=$(Rscript -e \"cat(renv::lockfile_read()\\$R\\$Version)\")\n        echo \"r-version=${R_VERSION}\" &gt;&gt; $GITHUB_OUTPUT\n      \n    - name: Build Docker image\n      uses: docker/build-push-action@v5\n      with:\n        context: .\n        push: false\n        tags: ${{ github.repository }}:latest\n        build-args: |\n          R_VERSION=${{ steps.r-version.outputs.r-version }}\n        cache-from: type=gha\n        cache-to: type=gha,mode=max\n        \n    - name: Run tests in container\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          ${{ github.repository }}:latest \\\n          R -e \"testthat::test_dir('tests/testthat')\"\n          \n    - name: Render research paper\n      run: |\n        docker run --rm -v $PWD:/home/analyst/project \\\n          -v $PWD/analysis/figures:/home/analyst/output \\\n          ${{ github.repository }}:latest \\\n          R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n          \n    - name: Upload rendered paper\n      uses: actions/upload-artifact@v4\n      if: success()\n      with:\n        name: research-paper\n        path: analysis/paper/paper.pdf\n\n\n9.15.3 Step 3: R Package Check Workflow\nCreate .github/workflows/r-package.yml:\nname: R Package Check\n\non:\n  push:\n    branches: [ main, master ]\n  pull_request:\n    branches: [ main, master ]\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n    \n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n    \n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: macOS-latest,    r: 'release'}\n          - {os: windows-latest,  r: 'release'}\n    \n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n    \n    steps:\n      - uses: actions/checkout@v4\n      \n      - uses: r-lib/actions/setup-pandoc@v2\n      \n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n          \n      - uses: r-lib/actions/setup-renv@v2\n      \n      - name: Install system dependencies\n        if: runner.os == 'Linux'\n        run: |\n          sudo apt-get update\n          sudo apt-get install -y \\\n            libcurl4-openssl-dev \\\n            libssl-dev \\\n            libxml2-dev\n            \n      - name: Validate renv consistency\n        run: |\n          # Use the renv validation script included in the repository\n          Rscript check_renv_for_commit.R --fail-on-issues --quiet\n            \n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n9.15.4 Step 4: Automated Paper Rendering\nCreate .github/workflows/render-paper.yml:\nname: Render Research Paper\n\non:\n  workflow_dispatch:  # Manual trigger\n  push:\n    branches: [ main, master ]\n    paths:\n      - 'analysis/paper/**'\n      - 'analysis/data/**'\n      - 'R/**'\n      - 'data/**'\n\njobs:\n  render:\n    runs-on: ubuntu-latest\n    \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Build Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: false\n          tags: paper-render:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n          \n      - name: Render paper in container\n        run: |\n          docker run --rm \\\n            -v $PWD:/home/analyst/project \\\n            -v $PWD/analysis/figures:/home/analyst/output \\\n            paper-render:latest \\\n            R -e \"rmarkdown::render('analysis/paper/paper.Rmd')\"\n            \n      - name: Upload rendered paper\n        uses: actions/upload-artifact@v4\n        with:\n          name: research-paper-${{ github.sha }}\n          path: |\n            analysis/paper/paper.pdf\n            analysis/figures/*.png\n            analysis/figures/*.jpg\n          retention-days: 30\n\n\n9.15.5 Step 5: Container Registry Integration\nCreate .github/workflows/container-publish.yml:\nname: Build and Push Container\n\non:\n  push:\n    branches: [ main ]\n    tags: [ 'v*' ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n      \n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        \n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n        \n      - name: Log in to Container Registry\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n          \n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=semver,pattern={{version}}\n            type=semver,pattern={{major}}.{{minor}}\n            \n      - name: Build and push Docker image\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          platforms: linux/amd64,linux/arm64\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "href": "posts/share_R_code_via_docker_p25/index.html#workflow-explanations",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.16 Workflow Explanations",
    "text": "9.16 Workflow Explanations\n\n9.16.1 Docker CI Workflow Features:\n\nPre-build renv Validation: Validates package dependency consistency before Docker build (prevents build failures)\nDynamic R Version: Extracts R version from renv.lock and passes it to Docker build\nBuild Testing: Ensures Docker image builds with latest changes using correct R version\nTesting: Runs R package tests and renders paper in container\nArtifact Generation: Saves rendered papers as downloadable artifacts\nCaching: Uses GitHub Actions cache for faster builds\nEarly Failure: Stops pipeline if dependency issues are detected\n\n\n\n9.16.2 R Package Check Features:\n\nMulti-platform Testing: Tests on Ubuntu, macOS, and Windows\nR CMD Check: Package validation\nrenv Integration: Restores package environment\nrenv Consistency Validation: Verifies dependency synchronization across platforms\nSystem Dependencies: Installs required system libraries\n\n\n\n9.16.3 Paper Rendering Features:\n\nSelective Triggering: Only runs when relevant files change\nManual Execution: Can be triggered manually via GitHub interface\nArtifact Storage: Saves PDFs and figures with retention policy\nPath-based Triggers: Responds to changes in analysis files\n\n\n\n9.16.4 Container Publishing Features:\n\nBuilding: Builds on pushes and tags\nMulti-platform: Supports AMD64 and ARM64 platforms\nSemantic Versioning: Tagging based on git tags\nSecurity: Uses built-in GitHub token for authentication"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "href": "posts/share_R_code_via_docker_p25/index.html#authentication-and-permissions",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.17 Authentication and Permissions",
    "text": "9.17 Authentication and Permissions\n\n9.17.1 Built-in GITHUB_TOKEN:\nThe built-in GITHUB_TOKEN automatically provides: - Read access to repository contents - Write access to GitHub Packages (when permissions are set) - No manual setup required\n\n\n9.17.2 Setting Repository Permissions:\n\nRepository Settings → Actions → General\nWorkflow permissions: Choose “Read and write permissions”\nAllow GitHub Actions to create and approve pull requests: Enable if needed\n\n\n\n9.17.3 Using Personal Access Tokens (Advanced):\nFor broader permissions, create repository secrets:\n\nRepository Settings → Secrets and variables → Actions\nNew repository secret: Add GHCR_TOKEN with Personal Access Token\nReference in workflow: password: ${{ secrets.GHCR_TOKEN }}"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-collaborative-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.18 Integration with Collaborative Workflow",
    "text": "9.18 Integration with Collaborative Workflow\n\n9.18.1 Pull Request Integration:\nWhen a team member submits a pull request: 1. GitHub automatically triggers CI workflows 2. Tests run in clean environment identical to production 3. Results displayed directly in pull request interface 4. Merge can be blocked if tests fail\n\n\n9.18.2 Branch Protection Rules:\nEnable in Repository Settings → Branches: - Require status checks: Force CI to pass before merging - Require branches to be up to date: Ensure latest code is tested - Include administrators: Apply rules to all users"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "href": "posts/share_R_code_via_docker_p25/index.html#monitoring-and-troubleshooting",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.19 Monitoring and Troubleshooting",
    "text": "9.19 Monitoring and Troubleshooting\n\n9.19.1 Viewing Workflow Results:\n\nRepository → Actions tab\nClick specific workflow run to see details\nExpand steps to see detailed logs\nDownload artifacts (rendered papers, test results)\n\n\n\n9.19.2 Common Issues and Solutions:\nDocker Build Failures: - Check Dockerfile syntax - Verify all COPY paths exist - Ensure base image is accessible\nrenv Restore Failures: - Verify renv.lock is committed - Check for platform-specific packages - Consider using RSPM for faster installs\nPermission Errors: - Verify GITHUB_TOKEN permissions - Check repository secrets configuration - Ensure workflows have necessary permissions\n\n\n9.19.3 Performance Optimization:\nCaching Strategies: - Docker layer caching with cache-from/cache-to - renv package caching with r-lib/actions/setup-renv - Artifact caching for large datasets\nParallel Execution: - Run tests and documentation in parallel jobs - Use matrix strategies for multi-platform testing - Conditional execution based on changed files\nThis CI/CD setup ensures that research compendia remain reproducible, tested, and deployment-ready throughout the development lifecycle."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.20 Production Dockerfile",
    "text": "9.20 Production Dockerfile\nThe following Dockerfile provides a development environment with zsh, vim plugins, dotfiles integration, and development tools:\n# Use R version from renv.lock for perfect consistency\nARG R_VERSION=4.3.0\nFROM rocker/r-ver:${R_VERSION}\n\n# Install system dependencies including zsh and development tools\nRUN apt-get update && apt-get install -y \\\n    libxml2-dev \\\n    libcurl4-openssl-dev \\\n    libssl-dev \\\n    libgit2-dev \\\n    libfontconfig1-dev \\\n    libcairo2-dev \\\n    libxt-dev \\\n    pandoc \\\n    zsh \\\n    curl \\\n    git \\\n    fonts-dejavu \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Create non-root user with zsh as default shell\nARG USERNAME=analyst\nRUN useradd --create-home --shell /bin/zsh ${USERNAME}\n\n# Set working directory\nWORKDIR /home/${USERNAME}/project\n\n# Copy project files first (for better Docker layer caching)\nCOPY --chown=${USERNAME}:${USERNAME} DESCRIPTION .\nCOPY --chown=${USERNAME}:${USERNAME} renv.lock* ./\nCOPY --chown=${USERNAME}:${USERNAME} .Rprofile* ./\nCOPY --chown=${USERNAME}:${USERNAME} renv/activate.R* renv/activate.R\n\n# Configure renv library path\nENV RENV_PATHS_LIBRARY renv/library\n\n# Switch to non-root user for R package installation\nUSER ${USERNAME}\n\n# Install renv and essential R packages\nRUN R -e \"install.packages(c('renv', 'remotes', 'devtools', 'knitr', \\\n    'rmarkdown'), repos = c(CRAN = 'https://cloud.r-project.org'))\"\n\n# Restore R packages from lockfile (if exists)\nRUN R -e \"if (file.exists('renv.lock')) renv::restore() else \\\n    cat('No renv.lock found, skipping restore\\\\n')\"\n\n# Copy dotfiles for development environment\n# Note: Ensure .vimrc and .zshrc_docker exist in build context or create \n# defaults\nCOPY --chown=${USERNAME}:${USERNAME} .vimrc /home/${USERNAME}/.vimrc\nCOPY --chown=${USERNAME}:${USERNAME} .zshrc_docker /home/${USERNAME}/.zshrc\n\n# Install zsh plugins for shell experience\nRUN mkdir -p /home/${USERNAME}/.zsh && \\\n    git clone https://github.com/zsh-users/zsh-autosuggestions \\\n        /home/${USERNAME}/.zsh/zsh-autosuggestions && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.zsh\n\n# Install vim-plug and configure vim environment\nRUN mkdir -p /home/${USERNAME}/.vim/autoload && \\\n    curl -fLo /home/${USERNAME}/.vim/autoload/plug.vim \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim && \\\n    chown -R ${USERNAME}:${USERNAME} /home/${USERNAME}/.vim\n\n# Install vim plugins (suppress interactive mode)\nRUN vim +PlugInstall +qall || true\n\n# Copy rest of project\nCOPY --chown=${USERNAME}:${USERNAME} . .\n\n# Install the research compendium as a package\nRUN R -e \"devtools::install('.', dependencies = TRUE)\"\n\n# Set default shell to zsh for development experience\nWORKDIR /home/${USERNAME}/project\nCMD [\"/bin/zsh\"]"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "href": "posts/share_R_code_via_docker_p25/index.html#features-of-the-production-dockerfile",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.21 Features of the Production Dockerfile",
    "text": "9.21 Features of the Production Dockerfile\nThis production-ready Dockerfile provides:\n\nR version consistency: Matches exact R version specified in renv.lock for perfect environment alignment\nMinimal base: rocker/r-ver provides clean R installation without unnecessary packages\nShell environment: zsh with autosuggestions and professional prompt for improved productivity\nEditor environment: vim with plugins configured automatically during build\nDotfiles integration: Personal development preferences (.vimrc, .zshrc) copied from host system\nDevelopment tools: git, curl, pandoc, and essential development libraries pre-installed\nSecurity: Non-root user execution with proper file permissions\nrenv integration: Automatic package restoration with proper library path configuration\nContainer-optimized workflow: Optimized layer caching and build process for efficient rebuilds"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "href": "posts/share_R_code_via_docker_p25/index.html#r-version-extraction",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.22 R Version Extraction",
    "text": "9.22 R Version Extraction\nThe Dockerfile uses a build argument to ensure the R version exactly matches what’s specified in renv.lock. The build command extracts the R version directly from the renv lockfile:\n# Extract R version from renv.lock\nR_VERSION=$(jq -r '.R.Version' renv.lock)\n\n# Build Docker image with extracted R version\ndocker build --build-arg R_VERSION=${R_VERSION} \\\n  -t ghcr.io/username/penguins_analysis:v1.0 .\nIf the renv.lock file specifies R 4.3.1, the Docker image will use rocker/r-ver:4.3.1. If renv is updated to R 4.4.0, the Docker build will use rocker/r-ver:4.4.0. This maintains consistency between the package environment and system environment."
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "href": "posts/share_R_code_via_docker_p25/index.html#renv-consistency-checker-features",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.23 renv Consistency Checker Features",
    "text": "9.23 renv Consistency Checker Features\nThe check_renv_for_commit.R script provides advanced team collaboration features through dependency validation:\n\nTeam conflict prevention: Pre-commit validation stops dependency inconsistencies before they reach the repository\nAutomated dependency discovery: Scans R/, scripts/, and analysis/ directories for library(), require(), and pkg:: calls\nMulti-source synchronization: Ensures packages are consistent across code files, DESCRIPTION, and renv.lock\nCRAN validation: Verifies packages exist and are properly named before team integration\nAutomatic fixing: Updates DESCRIPTION and regenerates renv.lock to maintain team synchronization\nCI/CD fail-fast: Provides proper exit codes for automated workflows\nInteractive collaboration mode: Guides developers through dependency resolution during development"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "href": "posts/share_R_code_via_docker_p25/index.html#team-collaboration-commands",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.24 Team Collaboration Commands",
    "text": "9.24 Team Collaboration Commands\n# Team development workflow (via Make)\nmake check-renv          # Interactive dependency checking\nmake check-renv-fix      # Auto-fix dependency issues\nmake check-renv-ci       # CI/CD validation with fail-fast\n\n# Docker-based validation (no local R required)\nmake docker-check-renv-fix  # Fix dependencies in container\n\n# Direct script usage\nRscript check_renv_for_commit.R --fix --fail-on-issues  # CI mode\nRscript check_renv_for_commit.R --quiet                 # Minimal output\nRscript check_renv_for_commit.R --help                  # Usage info"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "href": "posts/share_R_code_via_docker_p25/index.html#multi-developer-workflow",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.25 Multi-Developer Workflow",
    "text": "9.25 Multi-Developer Workflow\n\nInstall packages in container: Use install.packages() or renv::install() within Docker environment\nValidate team dependencies: Run make check-renv to check for conflicts before committing\nReview team impacts: Script identifies packages that would affect other team members\nSynchronize team environment: Use make check-renv-fix to update shared dependency files\nCommit with team confidence: Other developers can reproduce your exact environment"
  },
  {
    "objectID": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "href": "posts/share_R_code_via_docker_p25/index.html#integration-with-development-workflows",
    "title": "Research Compendia for Full Reproducibility in R: A zzrrtools, renv, draft: true and Docker Strategy",
    "section": "9.26 Integration with Development Workflows",
    "text": "9.26 Integration with Development Workflows\n\n9.26.1 Pre-commit Hooks\n# Add to .git/hooks/pre-commit\nRscript check_renv_for_commit.R --fail-on-issues --quiet\n\n\n9.26.2 Makefile Integration\ncheck-renv:\n    Rscript check_renv_for_commit.R\n\ncheck-renv-fix:\n    Rscript check_renv_for_commit.R --fix\n\ncheck-renv-ci:\n    Rscript check_renv_for_commit.R --quiet --fail-on-issues\n\n\n9.26.3 CI/CD Integration\n- name: Validate renv consistency\n  run: Rscript check_renv_for_commit.R --fail-on-issues --quiet\nThis approach ensures that collaborators can reliably reproduce your package environment and that CI/CD pipelines have all necessary dependency information."
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html",
    "href": "posts/table_placement_rmarkdown/index.html",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "",
    "text": "purrr"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "href": "posts/table_placement_rmarkdown/index.html#prerequisites",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "href": "posts/table_placement_rmarkdown/index.html#step-by-step-implementation",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "href": "posts/table_placement_rmarkdown/index.html#key-takeaways",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "posts/table_placement_rmarkdown/index.html#further-reading",
    "href": "posts/table_placement_rmarkdown/index.html#further-reading",
    "title": "Converting R data.frames to pdf for better placement control in latex draft: true pdf report",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "references/index.html",
    "href": "references/index.html",
    "title": "References",
    "section": "",
    "text": "Quick reference materials for when you need answers fast. These living documents are continuously updated and expanded based on real-world usage.\nFind: - Command cheat sheets - Configuration templates - Common patterns and snippets - Troubleshooting checklists - Best practices summaries\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nCategories\n\n\nDescription\n\n\n\n\n\n\nR Commands Quick Reference\n\n\nR, reference, cheatsheet\n\n\nQuick lookup table of commonly used R commands for data manipulation, visualization, and analysis.\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "321 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\n\n\n\n\nNote\n\n\n\nFilter by Topic: Click any badge below to filter publications by research area.\nMedical/Clinical Military/Defense Neuroimaging/Technical COVID/Healthcare General Research\n\nClear All Filters"
  },
  {
    "objectID": "research/index.html#publications",
    "href": "research/index.html#publications",
    "title": "Research",
    "section": "",
    "text": "321 total publications spanning multiple research domains in biostatistics, clinical trials, and medical research.\n\n\n\n\n\n\nNote\n\n\n\nFilter by Topic: Click any badge below to filter publications by research area.\nMedical/Clinical Military/Defense Neuroimaging/Technical COVID/Healthcare General Research\n\nClear All Filters"
  },
  {
    "objectID": "research/index.html#publications-1",
    "href": "research/index.html#publications-1",
    "title": "Research",
    "section": "2 📚 Publications",
    "text": "2 📚 Publications\n\n\n2.1 2024\n\nGalasko, Douglas, Farlow, Martin R, Lucey, Brendan P, Honig, Lawrence S, Elbert, Donald, Bateman, Randall, Momper, Jeremiah, Thomas, Ronald G, Rissman, Robert A, Pa, Judy, & others, “A multicenter, randomized, double-blind, placebo-controlled ascending dose study to evaluate the safety, tolerability, pharmacokinetics (PK) and pharmacodynamic (PD) effects of Posiphen in subjects with Early Alzheimer’s Disease”, Alzheimer’s Research & Therapy, (2024)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nMcEvoy, Cory, Crabtree, Adam, Case, John, Means, Gary E, Muench, Peter, Thomas, Ronald G, Ivory, Rebecca A, Mihalik, Jason, & Meabon, James S, “Cumulative blast impulse is predictive for changes in chronic neurobehavioral symptoms following low level blast exposure during military training”, Military medicine, (2024)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kathleen F, Muzi, Mark, Mayer, Cynthia, Murray, Daniel R, Schindler, Abigail G, Richards, Todd L, McEvoy, Cory, Crabtree, Adam, McNamara, Chris, & others, “Increased [18F] Fluorodeoxyglucose Uptake in the Left Pallidum in Military Veterans with Blast-Related Mild Traumatic Brain Injury: Potential as an Imaging Biomarker and Mediation with Executive Dysfunction and Cognitive Impairment”, Journal of Neurotrauma, (2024)\nMedical/Clinical Biostatistics R Traumatic brain injury Military health Neuroimaging Biomarkers Cognitive decline\n\n🔗 Article\n\n\n\n\n2.2 2023\n\nReiman, Eric M, Pruzin, Jeremy J, Rios-Romenets, Silvia, Brown, Chris, Giraldo, Margarita, Acosta-Baena, Natalia, Tobon, Carlos, Hu, Nan, Chen, Yinghua, Ghisays, Valentina, & others, “A public resource of baseline data from the Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nRaskind, Murray A, Williams, Tammy, Holmes, Hollie, Hart, Kim, Crews, Laura, Poupore, Eileen L, Thomas, Ronald G, Darnell, Jolee, Daniels, Colin, Goke, Kevin, & others, “A randomized controlled clinical trial of prazosin for alcohol use disorder in active duty soldiers: Predictive effects of elevated cardiovascular parameters”, Alcoholism: Clinical and Experimental Research, (2023)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nTerry, Garth, Pagulayan, Kati, Muzi, Mark, Mayer, Cynthia, Murray, Daniel, Schindler, Abigail, Richards, Todd, McEvoy, Cory, Crabtree, Adam, McNamara, Chris, & others, “FDG-PET as a Clinical Diagnostic Biomarker for Repetitive Blast Mild Traumatic Brain Injury”, NEUROPSYCHOPHARMACOLOGY, (2023)\nMilitary/Defense Biostatistics R Traumatic brain injury Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Su, Yi, Malek-Ahmadi, Michael H, Chen, Yinghua, Protas, Hillary D, Luo, Ji, Hu, Nan, Clayton, David, Schiffman, Courtney, & others, “Impact of reference region on longitudinal florbetapir PET SUVR changes from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2023)\nNeuroimaging/Technical Biostatistics R Neuroimaging Longitudinal studies\n\n🔗 Article\n\n\n\nKeil, Samantha A, Schindler, Abigail G, Wang, Marie X, Piantino, Juan, Silbert, Lisa C, Elliott, Jonathan E, Werhane, Madeleine L, Thomas, Ronald G, Willis, Sherry, Lim, Miranda M, & others, “Longitudinal Sleep Patterns and Cognitive Impairment in Older Adults”, JAMA Network Open, (2023)\nMedical/Clinical Biostatistics R Sleep disorders Cognitive decline Longitudinal studies\n\n🔗 Article\n\n\n\nMeabon, James S, Schindler, Abigail G, Murray, Daniel R, Colasurdo, Elizabeth A, Sikkema, Carl L, Rodriguez, Joshua W, Omer, Mohamed, Cline, Marcella M, Logsdon, Aric F, Cross, Donna J, & others, “Pontine pathology mediates common symptoms of blast-induced chronic mild traumatic brain injury”, medRxiv, (2023)\nMilitary/Defense Biostatistics R Traumatic brain injury\n\n🔗 Article\n\n\n\nQiu, Yuqi, Messer, Karen, Jacobs, Diane M, Salmon, David P, Kaplita, Stephen, Wellington, Cheryl L, Stukas, Sophie K, Askew, Brianna, Brewer, James B, Brody, Mark, & others, “Prognostic value of plasma biomarkers in a clinical trial of mild-to-moderate Alzheimer’s Disease”, Alzheimer’s & Dementia, (2023)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, McCall, Catherine A, Rosser, Aaron F, Pagulayan, Kathleen F, Chang, Bernard P, Sano, Ellen D, Thomas, Ronald G, & Raskind, Murray A, “The relative contribution of COVID-19 infection versus COVID-19 related occupational stressors to insomnia in healthcare workers”, Sleep medicine: X, (2023)\nCOVID/Healthcare Biostatistics R COVID-19 Sleep disorders\n\n🔗 Article\n\n\n\n\n2.3 2022\n\nJansson, Deidre, Wang, Marie, Thomas, Ronald G., Erickson, Michelle A., Peskind, Elaine R., Li, Ge, & Iliff, Jeffrey, “Markers of Cerebrovascular Injury, Inflammation, and Plasma Lipids Are Associated with Alzheimer’s Disease Cerebrospinal Fluid Biomarkers in Cognitively Normal Persons”, Journal of Alzheimer’s Disease, (2022)\nMedical/Clinical biomarkers blood-brain barrier cerebrospinal fluid hdl ldl ptau tau Alzheimer’s disease Biomarkers Cognitive decline\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, Clayton, David, Langbaum, Jessica B, Thomas, Ronald G, Chen, Yinghua, Su, Yi, Chen, Kewei, Hu, Nan, & others, “Sex differences in cognitive resilience in preclinical autosomal-dominant Alzheimer’s disease carriers and non-carriers: baseline findings from the API ADAD Colombia Trial”, Alzheimer’s & Dementia, (2022)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nShadyab, Aladdin H, LaCroix, Andrea Z, Matthews, Genevieve, Bennett, Daniel, Shadyab, Alexandre A, Tan, Donna, Thomas, Ronald G, Mason, Jennifer, Lopez, Alex, Askew, Brianna, & others, “T2 Protect AD: Achieving a rapid recruitment timeline in a multisite clinical trial for individuals with mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2022)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C & Slevin, Rois', “The impact of the COVID-19 pandemic on mental health, occupational functioning, and professional retention among health care workers and first responders”, Journal of general internal medicine, (2022)\nCOVID/Healthcare Biostatistics R COVID-19\n\n🔗 Article\n\n\n\n\n2.4 2021\n\nSalloway, Stephen, Farlow, Martin, McDade, Eric, Clifford, David B, Wang, Guoqiao, Llibre-Guerra, Jorge J, Hitchcock, Janice M, Mills, Susan L, Santacruz, Anna M, Aschenbrenner, Andrew J, Hassenstab, Jason, Benzinger, Tammie L S, Gordon, Brian A, Fagan, Anne M, Coalier, Kelley A, Cruchaga, Carlos, Goate, Alison A, Perrin, Richard J, Xiong, Chengjie, …, S'a, “A trial of gantenerumab or solanezumab in dominantly inherited Alzheimer’s disease”, Nature Medicine, (2021), doi: 10.1038/s41591-021-01369-8\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article • 📄 PDF\n\n\n\nBinette, Alexa Pichet, Vachon-Presseau, Etienne, Morris, John, Bateman, Randall, Benzinger, Tammie, Collins, D Louis, Poirier, Judes, Breitner, John CS, Villeneuve, Sylvia, Allegri, Ricardo, & others, “Amyloid and tau pathology associations with personality traits, neuropsychiatric symptoms, and cognitive lifestyle in the preclinical phases of sporadic and autosomal dominant Alzheimer’s disease”, Biological psychiatry, (2021)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, & Raskind, Murray A, “Optimizing aggregated N-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Creating Evidence from Real World Patient Digital Data, (2021)\nNeuroimaging/Technical Biostatistics R Biomarkers Statistical methods\n\n🔗 Article\n\n\n\nHu, Nan, Mackey, Howard, & Thomas, Ronald, “Power and sample size for random coefficient regression models in randomized experiments with monotone missing data”, Biometrical Journal, (2021)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nMatthews, Dawn C, Ritter, Aaron, Thomas, Ronald G, Andrews, Randolph D, Lukic, Ana S, Revta, Carolyn, Kinney, Jefferson W, Tousi, Babak, Leverenz, James B, Fillit, Howard, & others, “Rasagiline effects on glucose metabolism, cognition, and tau in Alzheimer’s dementia”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2021)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nShadyab, Aladdin & others, “Recruitment of a multi-site randomized controlled trial of aerobic exercise for older adults with amnestic mild cognitive impairment: the EXERT trial”, Alzheimer’s & Dementia, (2021)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C & Slevin, Rois', “The Impact of the COVID-19 Pandemic on Mental Health, Occupational Functioning, and Professional Retention Among Health Care Workers and First Responders”, Journal of general internal medicine, (2021)\nCOVID/Healthcare Biostatistics R COVID-19\n\n🔗 Article\n\n\n\n\n2.5 2020\n\nRios-Romenets, Silvia, Lopera, Francisco, Sink, Kaycee M, Hu, Nan, Lian, Qinshu, Guthrie, Heather, Smith, Jillian, Cho, William, Mackey, Howard, Langbaum, Jessica B, & others, “Baseline demographic, clinical, and cognitive characteristics of the Alzheimer’s Prevention Initiative (API) Autosomal-Dominant Alzheimer’s Disease Colombia Trial”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Prevention trials\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, Jin, Shelia, Feldman, Howard H, Cotman, Carl W, Baker, Laura D, Alzheimer’s Disease Cooperative Study EXERT Study Group, & Alzheimer’s Disease Neuroimaging Initiative, “Development of a novel cognitive composite outcome to assess therapeutic effects of exercise in the EXERT trial for adults with MCI: The ADAS-Cog-Exec”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2020)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nHendrickson, Rebecca C, Thomas, Ronald G, Schork, Nicholas J, & Raskind, Murray A, “Optimizing aggregated n-of-1 trial designs for predictive biomarker validation: statistical methods and theoretical findings”, Frontiers in Digital Health, (2020)\nNeuroimaging/Technical Biostatistics R Biomarkers Statistical methods\n\n🔗 Article\n\n\n\nGhisays, Valentina, Lopera, Francisco, Goradia, Dhruman D, Protas, Hillary D, Malek-Ahmadi, Michael H, Chen, Yinghua, Devadas, Vivek, Luo, Ji, Lee, Wendy, Brown, Christopher T, & others, “PET evidence of preclinical cerebellar amyloid plaque deposition in autosomal dominant Alzheimer’s disease”, 2020 Alzheimer’s Association International Conference, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nVila-Castelar, Clara, Tariot, Pierre N, Sink, Kaycee M, Clayton, David, Langbaum, Jessica B, Thomas, Ronald G, Chen, Yinghua, Su, Yi, Hu, Nan, Giraldo-Chica, Margarita, & others, “Sex differences in neurodegeneration and memory performance in preclinical autosomal dominant Alzheimer’s disease: Baseline findings from the API ADAD trial: Intersections of sex/gender and race/ethnicity in cognitive aging and Alzheimer’s disease trajectories”, Alzheimer’s & Dementia, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nLangbaum, Jessica B, Ellison, Noel N, Caputo, Angelika, Thomas, Ronald G, Langlois, Carolyn, Riviere, Marie-Emmanuelle, Graf, Ana, Lopez Lopez, Cristina, Reiman, Eric M, Tariot, Pierre N, & others, “The Alzheimer’s Prevention Initiative Composite Cognitive Test: a practical measure for tracking cognitive decline in preclinical Alzheimer’s disease”, Alzheimer’s Research & Therapy, (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Prevention trials\n\n🔗 Article\n\n\n\nMatthews, Dawn, Ritter, Aaron, Thomas, Ronald G, Andrews, Randolph D, Lukic, Ana S, Revta, Carolyn, Tousi, Babak, Leverenz, James B, Fillit, Howard, Zhong, Kate, & others, “The Effects of Rasagiline on Glucose Metabolism and Cognition and Their Relationship to Tau Burden in a Double-Blind, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia”, Placebo-Controlled Phase Ii Clinical Trial of Participants with Alzheimer’s Dementia (2/21/2020), (2020)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n2.6 2019\n\nSano, Mary, Zhu, Carolyn W, Kaye, Jeffrey, Mundt, James C, Hayes, Tamara L, Ferris, Steven, Thomas, Ronald G, Sun, Chung-Kai, Jiang, Yanxin, Donohue, Michael C, & others, “A randomized clinical trial to evaluate home-based assessment of people over 75 years old”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Sink, Kaycee, Hu, Nan, Guthrie, Heather, Smith, Jillian, Cho, William, Langbaum, Jessica B, Thomas, Ronald G, Giraldo, Margarita, & others, “F4-04-01: TRIAL DESIGN, DATA SHARING RISK MITIGATION, AND BASELINE CLINICAL AND COGNITIVE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nAcosta-Baena, Natalia, Rios-Romenets, Silvia, Munoz, Claudia, Bocanegra, Yamile, Henao, Eliana, Giraldo, Margarita, Tobon, Carlos, Sink, Kaycee, Hu, Nan, Guthrie, Heather, & others, “F4-04-02: AGE-RELATED CHANGES IN BASELINE COGNITIVE MEASURES IN UNIMPAIRED PSEN1 E280A MUTATION CARRIERS AND NON-CARRIERS IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nSu, Yi, Rios-Romenets, Silvia, Tariot, Pierre N, Sink, Kaycee, Clayton, David, Hu, Nan, Guthrie, Heather, Smith, Jillian, Cho, William, Langbaum, Jessica B, & others, “F4-04-03: RELATIONSHIPS BETWEEN BASELINE BRAIN IMAGING BIOMARKER MEASUREMENTS AND AGE IN THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nQuiroz, Yakeel T, Tariot, Pierre N, Sink, Kaycee, Clayton, David, Langbaum, Jessica B, Thomas, Ronald G, Giraldo, Margarita, Tobon, Carlos, Acosta-Baena, Natalia, Luna, Ernesto, & others, “F4-04-04: ASSOCIATION BETWEEN CEREBRAL AMYLOIDOSIS AND WORSE COGNITIVE PERFORMANCE IN PRECLINICAL AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE: BASELINE FINDINGS FROM THE API COLOMBIA AUTOSOMAL DOMINANT AD TRIAL”, Alzheimer’s & Dementia, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nSchneider, Lon S, Geffen, Yona, Rabinowitz, Jonathan, Thomas, Ronald G, Schmidt, Reinhold, Ropele, Stefan, Weinstock, Marta, Ladostigil Study Group, & others, “Low-dose ladostigil for mild cognitive impairment: A phase 2 placebo-controlled clinical trial”, Neurology, (2019)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nHuisa, Branko N, Thomas, Ronald G, Jin, Shelia, Oltersdorf, Tilman, Taylor, Curtis, & Feldman, Howard H, “Memantine and acetylcholinesterase inhibitor use in Alzheimer’s disease clinical trials: Potential for confounding by indication”, Journal of Alzheimer’s Disease, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKilian, Hett, Vinh-Thong, Ta, Gwenaelle, Catheline, Tourdias, Thomas, Manjon, Jose V, Pierrick, Coupe, Weiner, Michael W, Aisen, Paul, Petersen, Ronald, Jack Jr, Clifford R, & others, “Multimodal Hippocampal Subfield Grading For Alzheimer’s Disease Classification”, Scientific Reports (Nature Publisher Group), (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLiu, Jiao, Zhang, Binlong, Wilson, Georgia, Kong, Jian, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others, “New Perspective for Non-invasive Brain Stimulation Site Selection in Mild Cognitive Impairment: Based on Meta-and Functional Connectivity Analyses”, Frontiers in aging neuroscience, (2019)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nGupta, Yubraj, Lama, Ramesh Kumar, Kwon, Goo-Rak, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, Trojanowki, John Q, & others, “Prediction and classification of Alzheimer’s disease based on combined features from apolipoprotein-E genotype, cerebrospinal fluid, MR, and FDG-PET imaging biomarkers”, Frontiers in computational neuroscience, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Biomarkers\n\n🔗 Article\n\n\n\nZhao, Qian, Liu, Min, Ha, Lingxia, Zhou, Yun, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others, “Quantitative 18F-AV1451 brain tau PET imaging in cognitively normal older adults, mild cognitive impairment, and Alzheimer’s disease patients”, Frontiers in neurology, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, Rissman, Robert A, Brewer, James B, Salmon, David P, Oltersdorf, Tilman, Okuda, Tomohiro, Feldman, Howard H, & others, “Safety and efficacy of edonerpic maleate for patients with mild to moderate Alzheimer disease: a phase 2 randomized clinical trial”, JAMA neurology, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBorowsky, Beth, Lopez, Cristina Lopez, Tariot, Pierre, Caputo, Angelika, Liu, Fonda, Riviere, Marie-Emmanuelle, Rouzade-Dominguez, Marie-Laure, Thomas, Ronald, Langbaum, Jessica, Viglietta, Vissia, & others, “The Alzheimer Prevention Initiative Generation Program: Evaluation of CNP520 in Preclinical Alzheimer’s Disease (P4. 1-005)”, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nLopez, Cristina Lopez, Tariot, Pierre N, Caputo, Angelika, Langbaum, Jessica B, Liu, Fonda, Riviere, Marie-Emmanuelle, Langlois, Carolyn, Rouzade-Dominguez, Marie-Laure, Zalesak, Martin, Hendrix, Suzanne, & others, “The Alzheimer’s Prevention Initiative Generation Program: study design of two randomized controlled trials for individuals at risk for clinical onset of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2019)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Prevention trials\n\n🔗 Article\n\n\n\n\n2.7 2018\n\nKlinger, Rebecca Y, James, Olga G, Borges-Neto, Salvador, Bisanar, Tiffany, Li, Yi-Ju, Qi, Wenjing, Berger, Miles, Terrando, Niccolo, Newman, Mark F, Doraiswamy, P Murali, & others, “18F-florbetapir Positron Emission Tomography–determined Cerebral beta-Amyloid Deposition and Neurocognitive Performance after Cardiac Surgery”, Anesthesiology, (2018)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nRafii, Michael S, Tuszynski, Mark H, Thomas, Ronald G, Barba, David, Brewer, James B, Rissman, Robert A, Siffert, Joao, Aisen, Paul S, AAV2-NGF Study Team, & others, “Adeno-associated viral vector (serotype 2)–nerve growth factor for patients with alzheimer disease: a randomized clinical trial”, JAMA neurology, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHuisa, Branko, Thomas, Ronald, Jin, Shelia, Oltersdorf, Tilman, Taylor, Curtis, & Feldman, Howard, “Memantine and Cholinesterase Inhibitor Use in Alzheimer Disease Trials: Potential for Confounding by Indication (P6. 178)”, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nJacobs, Diane M, Thomas, Ronald G, Salmon, David P, Huisa, Branko N, Feldman, Howard H, & Schneider, Lon S, “P3-032: SCREENING-TO-BASELINE COGNITIVE VARIABILITY DOES NOT PREDICT RATE OF DECLINE IN A CLINICAL TRIAL OF MILD-TO-MODERATE AD”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nReiman, Eric M, Sink, Kaycee M, Hu, Nan, Guthrie, Heather, Smith, Jillian, Cho, William, Knoll, Katie L, Langbaum, Jessica B, Thomas, Ronald G, Toga, Arthur W, & others, “P4-209: A PUBLIC RESOURCE OF BASELINE DATA FROM THE API AUTOSOMAL DOMINANT ALZHEIMER’S DISEASE COLOMBIA TRIAL”, Alzheimer’s & Dementia, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nVerfaillie, Sander CJ, Binette, Alexa Pichet, Vachon-Presseau, Etienne, Tabrizi, Shirin, Savard, Melissa, Bellec, Pierre, Ossenkoppele, Rik, Scheltens, Philip, van der Flier, Wiesje M, Breitner, John CS, & others, “Subjective cognitive decline is associated with altered default mode network connectivity in individuals with a family history of Alzheimer’s disease”, Biological Psychiatry: Cognitive Neuroscience and Neuroimaging, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nTariot, Pierre N, Lopera, Francisco, Langbaum, Jessica B, Thomas, Ronald G, Hendrix, Suzanne, Schneider, Lon S, Rios-Romenets, Silvia, Giraldo, Margarita, Acosta, Natalia, Tobon, Carlos, & others, “The Alzheimer’s Prevention Initiative Autosomal-Dominant Alzheimer’s Disease Trial: A study of crenezumab versus placebo in preclinical PSEN1 E280A mutation carriers to evaluate efficacy and safety in the treatment of autosomal-dominant Alzheimer’s disease, including a placebo-treated noncarrier cohort”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2018)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development Prevention trials\n\n🔗 Article\n\n\n\n\n2.8 2017\n\nRelkin, Norman R, Thomas, Ronald G, Rissman, Robert A, Brewer, James B, Rafii, Michael S, Van Dyck, Christopher H, Jack, Clifford R, Sano, Mary, Knopman, David S, Raman, Rema, & others, “A phase 3 trial of IV immunoglobulin for Alzheimer disease”, Neurology, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLim, Yen Ying, Mormino, Elizabeth C, Alzheimer’s Disease Neuroimaging Initiative, & others, “APOE genotype and early beta-amyloid accumulation in older adults without dementia”, Neurology, (2017)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nRusso, Mar', “Adding recognition discriminability index to the delayed recall is useful to predict conversion from mild cognitive impairment to Alzheimer’s disease in the Alzheimer’s disease neuroimaging initiative”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nRisacher, Shannon L, Anderson, Wesley H, Charil, Arnaud, Castelluccio, Peter F, Shcherbinin, Sergey, Saykin, Andrew J, Schwarz, Adam J, Alzheimer’s Disease Neuroimaging Initiative, & others, “Alzheimer disease brain atrophy subtypes are associated with cognition and rate of decline”, Neurology, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMunilla, Jorge, Ortiz, Andres, Gorriz, Juan M, Ramirez, Javier, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others, “Construction and analysis of weighted brain networks from sice for the study of Alzheimer’s disease”, Frontiers in neuroinformatics, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nGuo, Shengwen, Lai, Chunren, Wu, Congling, Cen, Guiyin, Weiner, Michael W, Aisen, Paul, Weiner, Michael, Petersen, Ronald, Jack Jr, Clifford R, Jagust, William, & others, “Conversion discriminative analysis on mild cognitive impairment using multiple cortical features from MR images”, Frontiers in aging neuroscience, (2017)\nMedical/Clinical Biostatistics R Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Aisen, Paul S, Mohs, Richard C, Carrillo, Maria C, Albert, Marilyn S, Alzheimer’s Disease Neuroimaging Initiative (ADNI, & others, “Randomized controlled trials in mild cognitive impairment: sources of variability”, Neurology, (2017)\nMedical/Clinical Biostatistics R Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nPark, Jong-Yun, Na, Han Kyu, Kim, Sungsoo, Kim, Hyunwook, Kim, Hee Jin, Seo, Sang Won, Na, Duk L, Han, Cheol E, & Seong, Joon-Kyung, “Robust identification of Alzheimer’s disease subtypes based on cortical atrophy patterns”, Scientific reports, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre, Lopez-Lopez, Cristina, Caputo, Angelika, Thomas, Ronald G, Langbaum, Jessica, Lenz, Robert, Vargas, Gabriel, Viglietta, Vissia, Reiman, Eric M, & Graf, Ana, “The Alzheimer’s Prevention Initiative (API) Generation Program: Evaluating the Efficacy of the BACE-1 Inhibitor CNP520 in Preclinical Alzheimer’s Disease”, NEUROPSYCHOPHARMACOLOGY, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nLopez, C Lopez, Caputo, A, Liu, F, Riviere, ME, Rouzade-Dominguez, ML, Thomas, RG, Langbaum, JB, Lenz, R, Reiman, EM, Graf, A, & others, “The Alzheimer’s Prevention Initiative Generation Program: evaluating CNP520 efficacy in the prevention of Alzheimer’s disease”, J Prev Alzheimers Dis, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nCaputo, Angelika, Racine, Amy, Paule, Ines, Martens, Edwin P, Tariot, Pierre, Langbaum, Jessica B, Thomas, Ronald G, Hendrix, Suzanne, Ryan, J Michael, Lopez-Lopez, Cristina, & others, “[O5–01–02]: RATIONALE FOR SELECTION OF PRIMARY ENDPOINTS IN THE ALZHEIMER PREVENTION INITIATIVE GENERATION STUDY IN COGNITIVELY HEALTHY APOE4 HOMOZYGOTES”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Prevention trials\n\n🔗 Article\n\n\n\nSchneider, Lon S, Thomas, Ronald G, Hendrix, Suzanne, Brewer, James B, Rissman, Robert A, Salmon, David P, Kobayashi, Hiroshi, & Feldman, Howard H, “[P4–573]: A PHASE 2 MULTICENTER, RANDOMIZED, PLACEBO-CONTROLLED TRIAL TO EVALUATE THE EFFICACY AND SAFETY OF EDONERPIC (T-817) IN PATIENTS WITH MILD TO MODERATE ALZHEIMER’s DISEASE”, Alzheimer’s & Dementia, (2017)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n2.9 2016\n\nLiu, Haochen, Zhou, Xiaoting, Jiang, Hao, He, Hua, & Liu, Xiaoquan, “A semi-mechanism approach based on MRI and proteomics for prediction of conversion from mild cognitive impairment to Alzheimer’s disease”, Scientific reports, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nGelmont, David, Thomas, Ronald G, Britt, Jonathan, Dyck-Jones, Jacqueline A, Doralt, Jennifer, Fritsch, Sandor, Brewer, James B, Rissman, Robert A, & Aisen, Paul, “Demonstration of safety of intravenous immunoglobulin in geriatric patients in a long-term, placebo-controlled study of Alzheimer’s disease”, Alzheimer’s & Dementia: Translational Research & Clinical Interventions, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDeming, Yuetiva, Xia, Jian, Cai, Yefei, Lord, Jenny, Del-Aguila, Jorge L, Fernandez, Maria Victoria, Carrell, David, Black, Kathleen, Budde, John, Ma, ShengMei, & others, “Genetic studies of plasma analytes identify novel potential biomarkers for several complex traits”, Scientific Reports, (2016)\nNeuroimaging/Technical Biostatistics R Biomarkers\n\n🔗 Article\n\n\n\nThomas, Ronald G, Albert, Marilyn, Petersen, Ronald C, & Aisen, Paul S, “Longitudinal decline in mild-to-moderate Alzheimer’s disease: analyses of placebo data from clinical trials”, Alzheimer’s & Dementia, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nTariot, Pierre, Langbaum, Jessica, Schneider, Lon, Thomas, Ronald G, Graf, Ana, Lopez-Lopez, Cristina, Caputo, Angelika, Lenz, Robert, Vargas, Gabriel, & Reiman, Eric M, “The Alzheimer’s Prevention Initiative Generation Study: A Preclinical Trial in APOE4 Homozygotes”, NEUROPSYCHOPHARMACOLOGY, (2016)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Prevention trials\n\n🔗 Article\n\n\n\n\n2.10 2015\n\nTurner, R Scott, Thomas, Ronald G, Craft, Suzanne, Van Dyck, Christopher H, Mintzer, Jacobo, Reynolds, Brigid A, Brewer, James B, Rissman, Robert A, Raman, Rema, Aisen, Paul S, & others, “A randomized, double-blind, placebo-controlled trial of resveratrol for Alzheimer disease”, Neurology, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nChen, Chi-Hua, Peng, Qian, Schork, Andrew J, Lo, Min-Tzu, Fan, Chun-Chieh, Wang, Yunpeng, Desikan, Rahul S, Bettella, Francesco, Hagler, Donald J, Westlye, Lars T, & others, “Large-scale genomics unveil polygenic architecture of human cortical surface area”, Nature communications, (2015)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDonohue, Michael C, Moghadam, Setareh H, Roe, Allyson D, Sun, Chung-Kai, Edland, Steven D, Thomas, Ronald G, Petersen, Ronald C, Sano, Mary, Galasko, Douglas, Aisen, Paul S, & others, “Longitudinal plasma amyloid beta in Alzheimer’s disease clinical trials”, Alzheimer’s & Dementia, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Raman, Rema, Sperling, Reisa A, Seimers, Eric, Sethuraman, Gopalan, Mohs, Richard, Farlow, Martin, Iwatsubo, Takeshi, Vellas, Bruno, Sun, Xiaoying, & others, “Peripheral and central effects of \\\\gamma-secretase inhibition by semagacestat in Alzheimer’s disease”, Alzheimer’s research & therapy, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTurner, R, Thomas, Ronald, Craft, Suzanne, van Dyck, Christopher, Mintzer, Jacobo, Reynolds, Brigid, Brewer, James, Rissman, Robert, Raman, Rema, & Aisen, Paul, “Resveratrol is safe and well-tolerated in individuals with mild-moderate dementia due to Alzheimer’s disease.(S33. 009)”, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGelmont, D, Thomas, RG, Dyck-Jones, JA, Fritsch, S, Aisen, P, & Relkin, N, “Safety of Intravenous Immunoglobulin Therapy in Patients with Probable Alzheimer’s Disease: A Randomized, Placebo-Controlled Clinical Study”, ANNALS OF ALLERGY ASTHMA & IMMUNOLOGY, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\nOrban, Pierre & Madjar, C'e, “Test-retest resting-state fMRI in healthy elderly persons with a family history of Alzheimer’s disease”, Scientific data, (2015)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nNewman, Rhian C, Ellis, Tim, Davison, Phil I, Ives, Mark J, Thomas, Rob J, Griffiths, Sian W, & Riley, William D, “Using novel methodologies to examine the impact of artificial light at night on the cortisol stress response in dispersing Atlantic salmon (Salmo salar L.) fry”, Conservation physiology, (2015)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\n\n2.11 2014\n\nDoody, RS, Thomas, RG, Farlow, M, Iwatsubo, T, Vellas, B, Joffe, S, Kieburtz, K, Raman, R, Sun, X, Aisen, PS, & others, “Alzheimer’s Disease Cooperative Study Steering Committee; Solanezumab study group. Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, MC, Sperling, RA, Salmon, DP, Rentz, DM, Raman, R, Thomas, RG, Weiner, M, & Aisen, PS, “Australian imaging, biomarkers, and lifestyle flagship study of ageing; Alzheimer’s disease neuroimaging initiative; Alzheimer’s disease cooperative study. The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA Neurol, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Biomarkers Cognitive decline\n\n🔗 Article\n\n\n\nChen, Yun-Fei, Mohs, Richard, Ding, Ying, Aisen, Paul, & Thomas, Ronald, “Bayesian Longitudinal Modeling on Placebo Data from Alzheimer’s Disease Clinical Studies (P1. 010)”, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Longitudinal studies\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bell, Joanne, Mancuso, Jessica Y, Kupiec, James W, Sabbagh, Marwan N, van Dyck, Christopher, Thomas, Ronald G, Aisen, Paul S, & others, “Clinical trial of an inhibitor of RAGE-A beta interactions in Alzheimer disease”, Neurology, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Jacqmin-Gadda, Hene, Le Goff, Melanie, Thomas, Ronald G, Raman, Rema, Gamst, Anthony C, Beckett, Laurel A, Jack Jr, Clifford R, Weiner, Michael W, Dartigues, Jean-Francois, & others, “Estimating long-term multivariate progression from short-term data”, Alzheimer’s & Dementia, (2014)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, Anthony, Jack, Clifford, Beckett, Laurel, Weiner, Michael, Aisen, Paul, Raman, Rema, & Thomas, Ronald, “F3-02-02: MODELING LONG-TERM DISEASE PROGRESSION WITH COVARIATES”, Alzheimer’s & Dementia, (2014)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo Adolfo, Thomas, Ronald G, Qiu, Hongmei, Hong, Phuoc, & Aisen, Paul S, “P1-357: ADCS EDC: INVESTIGATIONAL PRODUCT MANAGEMENT SYSTEM”, Alzheimer’s & Dementia, (2014)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nLaske, Christoph, “Phase 3 trials of solanezumab and bapineuzumab for Alzheimer’s disease”, N Engl J Med, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Thomas, Ronald G, Farlow, Martin, Iwatsubo, Takeshi, Vellas, Bruno, Joffe, Steven, Kieburtz, Karl, Raman, Rema, Sun, Xiaoying, Aisen, Paul S, & others, “Phase 3 trials of solanezumab for mild-to-moderate Alzheimer’s disease”, New England Journal of Medicine, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nDonohue, Michael C, Sperling, Reisa A, Salmon, David P, Rentz, Dorene M, Raman, Rema, Thomas, Ronald G, Weiner, Michael, & Aisen, Paul S, “The preclinical Alzheimer cognitive composite: measuring amyloid-related decline”, JAMA neurology, (2014)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\n\n2.12 2013\n\nDoody, Rachelle S, Raman, Rema, Farlow, Martin, Iwatsubo, Takeshi, Vellas, Bruno, Joffe, Steven, Kieburtz, Karl, He, Feng, Sun, Xiaoying, Thomas, Ronald G, & others, “A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, New England Journal of Medicine, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nSalmon, David P, Ferris, Steven H, Thomas, Ronald G, Sano, Mary, Cummings, Jeffery L, Sperling, Reisa A, Petersen, Ronald C, & Aisen, Paul S, “Age and apolipoprotein E genotype influence rate of cognitive decline in nondemented elderly.”, Neuropsychology, (2013)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nDoody, RS, Raman, R, Farlow, M, Iwatsubo, T, Vellas, B, Joffe, S, Kieburtz, K, He, F, Sun, X, Thomas, RG, & others, “Alzheimer’s Disease Cooperative Study Steering Committee, Siemers E, Sethuraman G, Mohs R, Semagacestat Study Group. A phase 3 trial of semagacestat for treatment of Alzheimer’s disease”, N Engl J Med, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nPosner, Holly B, Cano, Stefan, Carrillo, Maria C, Selnes, Ola, Stern, Yaakov, Thomas, Ronald G, Zajicek, John, Hobart, Jeremy, Alzheimer’s Disease Neuroimaging Initiative, & others, “Establishing the psychometric underpinning of cognition measures for clinical trials of Alzheimer’s disease and its precursors: a new approach”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBurstein, Aaron, Galasko, Douglas, Aisen, Paul, Thomas, Ronald, Grimes, Imogene, Clark, David J, Mjalli, Adnan, & Orlande, Cesare, “P1–332: Evaluation of the relationship between TTP488 plasma concentrations and changes in ADAS-cog relative to placebo”, Alzheimer’s & Dementia, (2013)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald, Petersen, Ronald, Siuciak, Judith, Carrillo, Maria, Albert, Marilyn, Aisen, Paul, Alzheimer’s Disease Neuroimaging Initiative, & Foundation for NIH Biomarkers Consortium AD MCI Placebo Data Project Team, “P3–295: The Placebo Data Analysis in Alzheimer’s Disease (AD) and Mild Cognitive Impairment (MCI) Clinical Trials Project: Overview of progress in trial data collection, and key findings from the pooled Alzheimer’s disease trial datasets”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Bruschi, Stefania, Qiu, Hongmei, Hong, Phuoc, & Aisen, Paul, “P4–157: Adcs electronic data capture: Collaborative development and management of clinical trial databases”, Alzheimer’s & Dementia, (2013)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nMills, Sarah M, Mallmann, J, Santacruz, Anna M, Fuqua, A, Carril, M, Aisen, Paul S, Althage, MC, Belyew, S, Benzinger, Tammie L, Brooks, William S, & others, “Preclinical trials in autosomal dominant AD: implementation of the DIAN-TU trial”, Revue neurologique, (2013)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nHobart, Jeremy, Cano, Stefan, Posner, Holly, Selnes, Ola, Stern, Yaakov, Thomas, Ronald, Zajicek, John, & Alzheimer’s Disease Neuroimaging Initiative, “Putting the Alzheimer’s cognitive test to the test II: Rasch Measurement Theory”, Alzheimer’s & dementia, (2013)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\n\n2.13 2012\n\nAustin, David & Thomas, Rob, “A Garden before the Garden: Landscape, History and the National Botanic Garden of Wales”, Landscapes, (2012)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGalasko, DR, Peskind, E, Clark, CM, Quinn, JF, Ringman, JM, Jicha, GA, Cotman, C, Cottrell, B, Montine, TJ, Thomas, RG, & others, “Alzheimer’s Disease Cooperative Study. Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Arch Neurol, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nVellas, B, Hampel, H, & Roug'e, “Alzheimer’s disease therapeutic trials: EU/US Task Force report on recruitment, retention, and methodology”, The journal of nutrition, health & aging, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nGalasko, Douglas R, Peskind, Elaine, Clark, Christopher M, Quinn, Joseph F, Ringman, John M, Jicha, Gregory A, Cotman, Carl, Cottrell, Barbara, Montine, Thomas J, Thomas, Ronald G, & others, “Antioxidants for Alzheimer disease: a randomized clinical trial with cerebrospinal fluid biomarker measures”, Archives of neurology, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Jin, Shelia, He, Feng, Emond, Jennifer A, Raman, Rema, Thomas, Ronald G, Sano, Mary, Quinn, Joseph F, Tariot, Pierre N, Galasko, Douglas R, & others, “Incidence of new-onset seizures in mild to moderate Alzheimer disease”, Archives of neurology, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nRelkin, Norman, Gessert, Devon, Stokes, Karen, Adamiak, Basia, Ngo, Leock Y, Thomas, Ronald, Gelmont, David, & Aisen, Paul, “O3-13-05: The Gammaglobulin Alzheimer Partnership Study (GAP): Design, screening, enrollment and futility analysis results”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nJimenez-Maggiora, Gustavo, Thomas, Ronald, Hong, Phuoc, & Aisen, Paul, “P3-364: ADCS EDC”, Alzheimer’s & Dementia, (2012)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald, Jimenez, Gustavo, Brewer, James, Rissman, Robert A, & Aisen, Paul, “P3-383: ADCS data sharing”, Alzheimer’s & Dementia, (2012)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAisen, Paul, Thomas, Ronald, Carrillo, Maria, Mohs, Richard, Petersen, Ronald, Siuciak, Judith, Albert, Marilyn, Alzheimer’s Disease Neuroimaging Initiative, & Foundation for NIH Biomarkers Consortium CSF Proteomics Project Team, “P3-384: The placebo data analysis in Alzheimer’s disease and mild cognitive impairment (MCI) clinical trials project: Overview of progress in trial data collection, and key findings from the pooled MCI trial datasets”, Alzheimer’s & Dementia, (2012)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\n\n2.14 2011\n\nRafii, MS, Walsh, S, Little, JT, Behan, K, Reynolds, B, Ward, C, Jin, S, Thomas, R, Aisen, PS, & others, “A phase II trial of huperzine A in mild to moderate Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Bell, KL, Galasko, D, Galvin, JE, Thomas, RG, Van Dyck, CH, & Aisen, PS, “A randomized, double-blind, placebo-controlled trial of simvastatin to treat Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Raman, Rema, Emond, Jennifer, Thomas, Ronald G, Petersen, Ronald, Schneider, Lon S, & Aisen, Paul S, “Adding delayed recall to the Alzheimer Disease Assessment Scale is useful in studies of mild cognitive impairment but not Alzheimer disease”, Alzheimer disease and associated disorders, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nTariot, Pierre N, Schneider, Lon S, Cummings, Jeffrey, Thomas, Ronald G, Raman, Rema, Jakimovich, Laura J, Loy, Rebekah, Bartocci, Barbara, Fleisher, Adam, Ismail, M Saleem, & others, “Chronic divalproex sodium to attenuate agitation and clinical progression of Alzheimer disease”, Archives of General Psychiatry, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nFleisher, AS, Truran, D, Mai, JT, Langbaum, JBS, Aisen, PS, Cummings, JL, Jack, CR, Weiner, MW, Thomas, RG, Schneider, LS, & others, “Chronic divalproex sodium use and brain atrophy in Alzheimer disease”, Neurology, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMockus, Danyte S, Macera, Caroline A, Wingard, Deborah L, Peddecord, Michael, Thomas, Ronald G, & Wilfley, Denise E, “Dietary self-monitoring and its impact on weight loss in overweight children”, International Journal of Pediatric Obesity, (2011)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nQuinn, JF, Raman, R, Thomas, RG, Yurko-Mauro, K, Nelson, EB, Van Dyck, C, Galvin, JE, Emond, J, Jack Jr, CR, Weiner, M, & others, “Omega-3 Fatty Acids for Alzheimer’s Disease. What a Pill Can Tell Us about Eating Fish”, (2011)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMessick, Viviana, Donohue, Michael, Raman, Rema, Sano, Mary, Quinn, Joseph, Thomas, Ron, Emond, Jennifer, & Aisen, Paul, “P3-406: Role of caregiver in subject’s compliance with treatment”, Alzheimer’s & Dementia, (2011)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nSmart, N, George, A, Khan, D, Thomas, R, & Daniels, I, “Radiological follow up of perineal repair with cross-linked acellular porcine dermal collagen following extralevator abdominoperineal excision for low rectal cancer: P115”, Colorectal Disease, (2011)\nGeneral Research Biostatistics R Longitudinal studies\n\n🔗 Article\n\n\n\nAisen, PS, Andrieu, S, Sampaio, C, Carrillo, M, Khachaturian, ZS, Dubois, Bruno, Feldman, HH, Petersen, RC, Siemers, E, Doody, RS, & others, “Report of the task force on designing clinical trials in early (predementia) AD”, Neurology, (2011)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nDonohue, Michael C, Gamst, AC, Thomas, RG, Xu, R, Beckett, L, Petersen, Ronald Carl, Weiner, MW, Aisen, P, Alzheimer’s Disease Neuroimaging Initiative, & others, “The relative efficiency of time-to-threshold and rate of change in longitudinal data”, Contemporary clinical trials, (2011)\nGeneral Research Biostatistics R Longitudinal studies\n\n🔗 Article\n\n\n\n\n2.15 2010\n\nAisen, Paul S, Petersen, Ronald C, Donohue, Michael C, Gamst, Anthony, Raman, Rema, Thomas, Ronald G, Walter, Sarah, Trojanowski, John Q, Shaw, Leslie M, Beckett, Laurel A, & others, “Clinical Core of the Alzheimer’s Disease Neuroimaging Initiative: progress and plans”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, Yurko-Mauro, Karin, Nelson, Edward B, Van Dyck, Christopher, Galvin, James E, Emond, Jennifer, Jack, Clifford R, Weiner, Michael, & others, “Docosahexaenoic acid supplementation and cognitive decline in Alzheimer disease: a randomized trial”, Jama, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nDonohue, Michael, Gamst, Anthony, Thomas, Ron, Brewer, Jim, Weiner, Michael, & Aisen, Paul, “O3-01-07: Rate of decline in ADNI normal controls with evidence of amyloid burden”, Alzheimer’s & Dementia, (2010)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nFleisher, Adam S, Jack Jr, Clifford R, Weiner, Michael W, Truran, Diana, Mai, Jacqueline, Aisen, Paul S, Cummings, Jeffrey L, Thomas, Ronald G, Schneider, Lon S, & Tariot, Pierre N, “P1-433: Brain volume changes with divalproex sodium in Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Thomas, Ronald, Raman, Rema, Yurko-Mauro, Karin, Bailey-Hall, Eileen, Nelson, Edward, Shaw, Les, & Aisen, Paul, “P1-447: Cerebrospinal fluid biomarker outcomes in a trial of docosahexaenoic acid (DHA) for Alzheimer’s disease”, Alzheimer’s & Dementia, (2010)\nMedical/Clinical Biostatistics R Alzheimer’s disease Biomarkers\n\n🔗 Article\n\n\n\n\n2.16 2009\n\nRaman, Rema, Thomas, Ronald G, Weiner, Michael W, Jack, Clifford R, Ernstrom, Karin, Aisen, Paul S, Tariot, Pierre N, & Quinn, Joseph F, “MRI substudy participation in Alzheimer disease (AD) clinical trials: baseline comparability of a substudy sample to entire study population”, Alzheimer disease and associated disorders, (2009)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Neuroimaging Epidemiology\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald G, Ernstrom, Karin, Yurko-Mauro, Karin, Nelson, Edward B, Shinto, Lynne, Nair, Anil K, & Aisen, Paul, “O1-04-02: A clinical trial of docosahexanoic acid (DHA) for the treatment of Alzheimer’s disease”, Alzheimer’s & Dementia, (2009)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\nTariot, Pierre N, Aisen, Paul, Cummings, Jeffrey, Jakimovich, Laura, Schneider, Lon, Thomas, Ronald, Becerra, Lida, & Loy, Rebekah, “O1-04-03: The ADCS valproate neuroprotection trial: Primary efficacy and safety results”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nCano, Stefan, Posner, Holly, Aisen, Paul, Selnes, Ola, Stern, Yaakov, Thomas, Ronald, Weiner, Michael, Zajicek, John, Zeger, Scott, & Hobart, Jeremy, “O4-04-07: The ADAS-cog’s performance as a measure—lessons from the ADNI study: Part 2-evaluation using modern psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nPosner, Holly, Cano, Stefan, Aisen, Paul, Selnes, Ola, Stern, Yaakov, Thomas, Ronald, Weiner, Michael, Zajicek, John, Zeger, Scott, & Hobart, Jeremy, “P1-269: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 1-evaluation using traditional psychometric methods”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nHobart, Jeremy, Posner, Holly, Aisen, Paul, Selnes, Ola, Stern, Yaakov, Thomas, Ronald, Weiner, Michael, Zajicek, John, Zeger, Scott, & Cano, Stefan, “P1-270: The ADAS-cog’s performance as a measure-lessons from the ADNI study: Part 3-do the scale modifications add value?”, Alzheimer’s & Dementia, (2009)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nIrizarry, Michael C, Raman, Rema, Schwarzschild, Michael A, Becerra, Lida M, Thomas, Ronald G, Peterson, Ronald C, Ascherio, Alberto, & Aisen, Paul S, “Plasma urate and progression of mild cognitive impairment”, Neurodegenerative Diseases, (2009)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nMachado, C, Leisman, G, Koch, P, Rodriguez, R, Caiballo, M, Korein, J, Sanchez-Catasus, C, Perez, J, Djuric, S, Djuric, V, & others, “REVIEWS IN THE NEUROSCIENCES”, NEUROSCIENCES, (2009)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nPasner, Holly, Cano, Stefan J, Aisen, Paul, Selnes, Ola, Stern, Yaakov, Thomas, Ronald, Weiner, Michael, Zajicek, John, Zeger, Scott, & Hobart, Jeremy, “The ADAS-cog’s Performance as a Measure Lessons from the ADNI Study: Part 1-Evaluation Using Traditional Psychometric Methods”, Neurology, (2009)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\n\n2.17 2008\n\nKhachaturian, Zaven S, Petersen, Ronald C, Gauthier, Serge, Buckholtz, Neil, Corey-Bloom, Jodey P, Evans, Bill, Fillit, Howard, Foster, Norman, Greenberg, Barry, Grundman, Michael, & others, “A roadmap for the prevention of dementia: the inaugural Leon Thal Symposium”, Alzheimer’s & dementia: the journal of the Alzheimer’s Association, (2008)\nMedical/Clinical Biostatistics R Prevention trials\n\n🔗 Article\n\n\n\nAisen, PS, Schneider, LS, Sano, M, Diaz-Arrastia, R, Van Dyck, CH, Weiner, MF, Bottiglieri, T, Jin, S, Stokes, KT, Thomas, RG, & others, “Alzheimer Disease Cooperative Study. High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nRoch-Levecq, Anne-Catherine, Brody, Barbara L, Thomas, Ronald G, & Brown, Stuart I, “Ametropia, preschoolers’ cognitive abilities, and effects of spectacle correction”, Archives of ophthalmology, (2008)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nDoody, RS, Gavrilova, SI, Sano, M, Thomas, RG, Aisen, PS, Bachurin, SO, Seely, L, & Hung, D, “Dimebon investigators: Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, Lancet, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, Diaz-Arrastia, Ramon, van Dyck, Christopher H, Weiner, Myron F, Bottiglieri, Teodoro, Jin, Shelia, Stokes, Karen T, Thomas, Ronald G, & others, “Dual Task Test Could Help Diagnose Dementia”, JAMA, (2008)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana I, Sano, Mary, Thomas, Ronald G, Aisen, Paul S, Bachurin, Sergey O, Seely, Lynn, Hung, David, & others, “Effect of dimebon on cognition, activities of daily living, behaviour, and global function in patients with mild-to-moderate Alzheimer’s disease: a randomised, double-blind, placebo-controlled study”, The Lancet, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nMeyer, Brett C, Raman, Rema, Hemmen, Thomas, Obler, Richard, Zivin, Justin A, Rao, Ramesh, Thomas, Ronald G, & Lyden, Patrick D, “Efficacy of site-independent telemedicine in the STRokE DOC trial: a randomised, blinded, prospective study”, The Lancet Neurology, (2008)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAisen, Paul S, Schneider, Lon S, Sano, Mary, Diaz-Arrastia, Ramon, Van Dyck, Christopher H, Weiner, Myron F, Bottiglieri, Teodoro, Jin, Shelia, Stokes, Karen T, Thomas, Ronald G, & others, “High-dose B vitamin supplementation and cognitive decline in Alzheimer disease: a randomized controlled trial”, Jama, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nGalasko, Douglas, Peskind, Elaine, Clark, Christopher M, Quinn, Joseph, Ringman, John, Jicha, Gregory A, Cottrell, Barbara, & Thomas, Ronald G, “O2-04–06: Randomized clinical trial of antioxidant treatment in Alzheimer’s disease with CSF biomarker measures”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Biomarkers Drug development\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Thomas, Ronald, Aisen, Paul, Bachurin, Sergey, Seely, Lynn, & Hung, David, “P4-337: Dimebon improves cognition, function, and behavior in mild and moderate Alzheimer’s disease: Results by severity of a one-year, double-blind, placebo-controlled study”, Alzheimer’’s and Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nQuinn, Joseph F, Raman, Rema, Thomas, Ronald, Ernstrom, Karin, Yurko-Mauro, Karin, Nelson, Edward, & Aisen, Paul S, “P4-343: Omega 3 fatty acids and Alzheimer’s disease: Trial design and baseline study population characteristics in a clinical trial of docosahexanoic acid for Alzheimer’s disease”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Epidemiology\n\n🔗 Article\n\n\n\nRaman, Rema, Emond, Jennifer, Thomas, Ronald G, Petersen, Ronald C, Schneider, Lon S, Aisen, Paul S, & Sano, Mary, “P4-387: Adding delayed recall to the Alzheimer’s disease assessment scale-cognitive subscale (ADAS-cog): Sensitivity in a clinical trial for Alzheimer’s disease and mild cognitive impairment”, Alzheimer’s & Dementia, (2008)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nDoody, Rachelle, Seely, Lynn, Thomas, Ronald, Sano, Mary, & Aisen, Paul, “Statistical treatment of withdrawal in trials of anti-dementia drugs–Authors’ reply”, The Lancet, (2008)\nMedical/Clinical Biostatistics R Drug development Statistical methods\n\n🔗 Article\n\n\n\n\n2.18 2007\n\nDoody, Rochelle, Gavrilova, Svetlana, Sano, Mary, Thomas, Ronald, Aisen, Paul, Seely, Lynn, & Hung, David, “Dimebon improves cognition, function, and behavior in patients with mild-moderate Alzheimer’s disease: Results of a randomized, double-blind, placebo-controlled study”, Neurology, (2007)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, Mary, Kaye, Jeffrey, Ferris, Steven, Hayes, Tamara, Egelko, Susan, Mundt, James, Li, Yan, Walter, Sarah, Thomas, Ronald, Edland, Steven, & others, “P-081: The ACDS home assessment instrument: A pilot study”, Alzheimer’s & Dementia, (2007)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTHOMAS, RONALD J & CLARK, CHRISTOPHER A, “Population Dynamics of Meloidogyne incognita and RotylenchulusTenchulus reniformis Alone and in Combination, and Their Effects on Sweet Potato1”, (2007)\nGeneral Research Biostatistics R Epidemiology\n\n🔗 Article\n\n\n\nMay, Susanne, Gilman, Sid, Sowell, B Brooke, Thomas, Ronald G, Stern, Matthew B, Colcher, Amy, Tanner, Caroline M, Huang, Neng, Novak, Peter, Reich, Stephen G, & others, “Potential outcome measures and trial design issues for multiple system atrophy”, Movement disorders, (2007)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAisen, Paul S, Jin, Shelia, Thomas, Ronald G, Sano, Mary, Diaz-Arrastia, Ramon, Thal, Leon, & Alzheimer’s Disease Cooperative Study NIA, “S3–02–01: ADCS homocysteine trial”, Alzheimer’s & Dementia, (2007)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDoody, Rachelle S, Gavrilova, Svetlana, Sano, Mary, Thomas, Ronald, Aisen, Paul, Bachurin, Sergey, Seely, Lynn, & Hung, David, “S3–02–03: Results of a one-year randomized, placebo-controlled trial of dimebon for the treatment of mild to moderate Alzheimer’s disease”, Alzheimer’s & Dementia, (2007)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\n\n2.19 2006\n\nSano, Mary, Zhu, Carolyn W, Whitehouse, Peter J, Edland, Steven, Jin, Shelia, Ernstrom, Karin, Thomas, Ronald G, Thal, Leon J, & Ferris, Steven H, “ADCS Prevention Instrument Project: pharmacoeconomics: assessing health-related resource use among healthy elderly”, Alzheimer disease and associated disorders, (2006)\nGeneral Research Biostatistics R Prevention trials\n\n🔗 Article\n\n\n\nPetersen, Ronald, Thomas, Ronald, Grundman, Michael, & Thai, Leon, “Cognitive Changes in the Treatment of Mild Cognitive Impairment with Donepezil and Vitamin E: P02. 187”, Neurology, (2006)\nMedical/Clinical Biostatistics R Cognitive decline Drug development\n\n🔗 Article\n\n\n\n\n2.20 2005\n\nKrajewska, Maryla, Kim, Hoguen, Kim, Chul, Kang, Haeyoun, Welsh, Kate, Matsuzawa, Shu-ichi, Tsukamoto, Michelle, Thomas, Ronald G, Assa-Munt, Nuria, Piao, Zhe, & others, “Analysis of apoptosis protein expression in early-stage colorectal cancer suggests opportunities for new prognostic biomarkers”, Clinical Cancer Research, (2005)\nNeuroimaging/Technical Biostatistics R Biomarkers Statistical methods\n\n🔗 Article\n\n\n\nPfeiffer, E, Petersen, RC, Thomas, RG, & Thal, LJ, “Cognition in the treatment of mild cognitive impairment with donepezil and vitamin E”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical Biostatistics R Cognitive decline Drug development\n\n🔗 Article\n\n\n\nRoch–Levecq, A–C, Brody, B, Thomas, RG, & Brown, SI, “Cognitive Outcomes of Corrective Lenses on Low Income Preschoolers With Hyperopia/Astimgatism: A Longitudinal Pilot Study”, Investigative Ophthalmology & Visual Science, (2005)\nMedical/Clinical Biostatistics R Cognitive decline Longitudinal studies\n\n🔗 Article\n\n\n\nGalasko, D, Schmitt, F, Thomas, R, Jin, S, Bennett, D, & Ferris, S, “Detailed assessment of activities of daily living in moderate to severe Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTariot, Pierre N, Raman, Rema, Jakimovich, Laura, Schneider, Lon, Porsteinsson, Anton, Thomas, Ronald, Mintzer, Jacobo, Brenner, Ronald, Schafer, Kim, & Thal, Leon, “Divalproex sodium in nursing home residents with possible or probable Alzheimer disease complicated by agitation: a randomized, controlled trial”, The American journal of geriatric psychiatry, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nPeskind, Elaine R, Tsuang, Debby W, Bonner, Lauren T, Pascualy, Marcella, Riekse, Robert G, Snowden, Mark B, Thomas, Ronald, & Raskind, Murray A, “Propranolol for disruptive behaviors in nursing home residents with probable or possible Alzheimer disease: a placebo-controlled study”, Alzheimer Disease & Associated Disorders, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nEdland, SD, May, S, Emond, JA, Wolfson, T, Thal, L, Petersen, RC, & Thomas, RG, “Sample size considerations in dementia prevention trials: Data from the Alzheimer’s disease Cooperative Study MCI Trial”, NEUROLOGY, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\nBrody, Barbara L, Roch-Levecq, Anne-Catherine, Thomas, Ronald G, Kaplan, Robert M, & Brown, Stuart I, “Self-management of age-related macular degeneration at the 6-month follow-up: a randomized controlled trial”, Archives of Ophthalmology, (2005)\nGeneral Research Biostatistics R Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, Grundman, M, & Thal, L, “Treatment of MCI with cholinesterase inhibitors: current data”, INTERNATIONAL PSYCHOGERIATRICS, (2005)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, Bennett, David, Doody, Rachelle, Ferris, Steven, Galasko, Douglas, Jin, Shelia, Kaye, Jeffrey, Levey, Allan, & others, “Vitamin E and donepezil for the treatment of mild cognitive impairment”, New England Journal of Medicine, (2005)\nMedical/Clinical Biostatistics R Cognitive decline Drug development\n\n🔗 Article\n\n\n\nPetersen, Ronald C, Thomas, Ronald G, Grundman, Michael, Bennett, David A, Kaye, Jeffrey, Levey, Allan I, Pfeiffer, Eric, Sano, Mary, van Dyck, Christopher H, & Thal, Leon J, “[O1-04-04]: Operational criteria for patient recruitment in trials of mild cognitive impairment”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Grundman, Michael, Bennett, David A, Doody, Rachelle S, Ferris, Steven H, Galasko, Douglas R, Jin, Shelia, Levey, Allan I, & Petersen, Ronald C, “[O2-01-01]: Donepezil and vitamin E in the progression of mild cognitive impairment to Alzheimer’s disease: A hazard-ratio analysis”, Alzheimer’s & Dementia, (2005)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\n\n2.21 2004\n\nHamilton, Joanne M, Salmon, David P, Galasko, Douglas, Delis, Dean C, Hansen, Lawrence A, Masliah, Eliezer, Thomas, Ronald G, & Thal, Leon J, “A comparison of episodic memory deficits in neuropathologically-confirmed Dementia with Lewy bodies and Alzheimer’s disease”, Journal of the International Neuropsychological Society: JINS, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nThomas, Ronald G, Aisen, Paul S, Shoulson, Ira, Rosenberg, Roger N, Gwinn-Hardy, Katrina, Mathews, Katherine D, Moore, Steven A, Darnell, Robert B, Lu, Chin-Song, Chou, Yah-Huei Wu, & others, “Distinguished From Alzheimer Disease and Normal Aging for Clinical Trials Michael Grundman, MD, MPH; Ronald C. Petersen, PhD, MD; Steven H. Ferris, PhD”, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Neuroimaging\n\n🔗 Article\n\n\n\nPetersen, RC, Thomas, R, & Thal, L, “Donepezil and vitamin E for mild cognitive impairment”, 9th International Congress on Alzheimer’s Disease. Philadelphia, (2004)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nArgent, R, Thomas, R, Boughan, P, Kidd, M, Smith, J, James, M, Bajaj-Elliott, M, & Atherton, J, “MAP kinase inhibitors reduce Helicobacter pylori-induced interleukin-8 secretion and the phosphorylation of I\\\\kappaB\\\\\\\\alpha”, Helicobacter, (2004)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Ferris, Steven H, Thomas, Ronald G, Aisen, Paul S, Bennett, David A, Foster, Norman L, Jack Jr, Clifford R, Galasko, Douglas R, Doody, Rachelle, & others, “Mild cognitive impairment can be distinguished from Alzheimer disease and normal aging for clinical trials”, Archives of neurology, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Cognitive decline\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, Marson, Daniel, Jin, Shelia, & Thomas, Ronald, “P1-003 ADCS Prevention instrument project: assessment of activities of daily living (ADL)”, Neurobiology of Aging, (2004)\nGeneral Research Biostatistics R Prevention trials\n\n🔗 Article\n\n\n\nTariot, Pierre N, Thal, Leon, Jakimovich, Laura, Thomas, Ronald, & Raman, Rema, “P1-322 A multicenter, randomized, double-blind, placebo-controlled trial of valproate for agitation associated with dementia”, Neurobiology of Aging, (2004)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Tractenberg, Rochelle E, Sano, Mary, Mackell, Joan A, Thomas, Ronald G, Gamst, Anthony, Thal, Leon J, Morris, John C, & others, “Reliability of monitoring the clinical dementia rating in multicenter clinical trials”, Alzheimer disease and associated disorders, (2004)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon, “S5-03-02 Prevention trials in Alzheimer’s disease: design issues”, Neurobiology of Aging, (2004)\nMedical/Clinical Biostatistics R Alzheimer’s disease Prevention trials\n\n🔗 Article\n\n\n\n\n2.22 2003\n\nSinger, Clifford, Tractenberg, Rochelle E, Kaye, Jeffrey, Schafer, Kim, Gamst, Anthony, Grundman, Michael, Thomas, Ronald, & Thal, Leon J, “A multicenter, placebo-controlled trial of melatonin for sleep disturbance in Alzheimer’s disease”, Sleep, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Sleep disorders\n\n🔗 Article\n\n\n\nGrundman, M, Capparelli, E, Kim, HT, Morris, JC, Farlow, M, Rubin, EH, Heidebrink, J, Hake, A, Ho, G, Schultz, AN, & others, “A multicenter, randomized, placebo controlled, multiple-dose, safety and pharmacokinetic study of AIT-082 (Neotrofin™) in mild Alzheimer’s disease patients”, Life sciences, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, PS, Schafer, KA, Grundman, M, Pfeiffer, E, Sano, M, Davis, KL, Farlow, MR, Jin, S, Thomas, RG, & Thal, LJ, “Alzheimer’s Disease Cooperative Study. Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly A, Grundman, Michael, Pfeiffer, Eric, Sano, Mary, Davis, Kenneth L, Farlow, Martin R, Jin, Shelia, Thomas, Ronald G, Thal, Leon J, & others, “Effects of rofecoxib or naproxen vs placebo on Alzheimer disease progression: a randomized controlled trial”, Jama, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, Mulnard, Ruth, Sano, Mary, Grundman, Michael, & Schneider, Lon, “Estrogen levels do not correlate with improvement in cognition”, Archives of Neurology, (2003)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, RG, Choudhury, RK, Mohanty, AK, Saxena, A, & Kapoor, SS, “Fission fragment angular distributions: A probe to study heavy-ion fusion dynamics”, Physical Review C, (2003)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGrundman, Michael, Jack, Clifford R, Petersen, Ronald C, Kim, Hyun T, Taylor, Curtis, Datvian, Marina, Weiner, Myron F, DeCarli, Charles, DeKosky, Steven T, Van Dyck, Christopher, & others, “Hippocampal volume is associated with memory but not nonmemory cognitive performance in patients with mild cognitive impairment”, Journal of Molecular Neuroscience, (2003)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nThal, LJ, Grundman, M, Berg, J, Ernstrom, K, Margolin, R, Pfeiffer, E, Weiner, MF, Zamrini, E, & Thomas, RG, “Idebenone treatment fails to slow cognitive decline in Alzheimer’s disease”, Neurology, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Drug development\n\n🔗 Article\n\n\n\nAisen, Paul S, Schafer, Kimberly, Grundman, Michael, Thomas, Ronald, & Thal, Leon J, “NSAIDs and hypertension”, Archives of internal medicine, (2003)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRaskind, Murray A, Peskind, Elaine R, Kanter, Evan D, Petrie, Eric C, Radant, Allen, Thompson, Charles E, Dobie, Dorcas J, Hoff, David, Rein, Rebekah J, Straits-Troster, Kristy, & others, “Reduction of nightmares and other PTSD symptoms in combat veterans by prazosin: a placebo-controlled study”, American Journal of Psychiatry, (2003)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nBrody, BL, Roch-Levecq, AC, Thomas, RG, Maclean, KK, Kaplan, RM, & Brown, SI, “Self-Management of Age-Related Macular Degeneration and Quality of Life at 6 Months Follow-Up: A Randomized Controlled Trial”, Investigative Ophthalmology & Visual Science, (2003)\nGeneral Research Biostatistics R Clinical trials Longitudinal studies\n\n🔗 Article\n\n\n\nAisen, PS, Berg, JD, Craft, S, Peskind, ER, Sano, M, Teri, L, Mulnard, RA, Thomas, RG, & Thal, LJ, “Steroid-induced elevation of glucose in Alzheimer’s disease: relationship to gender, apolipoprotein E genotype and cognition”, Psychoneuroendocrinology, (2003)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n2.23 2002\n\nGrundman, Michael, Farlow, Martin, Peavy, Guerry, Kim, Hyun T, Capparelli, Edmund, Schultz, Arlan N, Salmon, David P, Ferris, Steven H, Mohs, Richard, Thomas, Ronald G, & others, “A phase I study of AIT-082 in healthy elderly volunteers”, Journal of Molecular Neuroscience, (2002)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nPierce, John P, Faerber, Susan, Wright, Fred A, Rock, Cheryl L, Newman, Vicky, Flatt, Shirley W, Kealey, Sheila, Jones, Vicky E, Caan, Bette J, Gold, Ellen B, & others, “A randomized trial of the effect of a plant-based dietary pattern on additional breast cancer events and survival:: the Women’s Healthy Eating and Living (WHEL) Study”, Controlled clinical trials, (2002)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nSalmon, David P, Thomas, RG, Pay, MM, Booth, A, Hofstetter, CR, Thal, LJ, & Katzman, R, “Alzheimer’s disease can be accurately diagnosed in very mildly impaired individuals”, Neurology, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Jin, Shelia, Gamst, Anthony, Thomas, Ronald G, Koss, Elisabeth, & Thal, Leon J, “Assessing Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory: scoring and clinical implications”, Journal of psychiatric research, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, Clifford R, Petersen, Ronald C, Kim, Hyun T, Schultz, Arlan, Weiner, Myron F, DeCarli, Charles, DeKosky, Steven T, Van Dyck, Christopher, & others, “Brain MRI hippocampal volume and prediction of clinical status in a mild cognitive impairment trial”, Journal of Molecular Neuroscience, (2002)\nMedical/Clinical Biostatistics R Neuroimaging Cognitive decline\n\n🔗 Article\n\n\n\nGrundman, M, Kim, HT, Schultz, AN, Thomas, RG, Thal, L, Jack, CR, & Peterson, RC, “Clinical correlates of hippocampal atrophy in patients with mild cognitive impairment”, NEUROBIOLOGY OF AGING, (2002)\nMedical/Clinical Biostatistics R Cognitive decline\n\n🔗 Article\n\n\n\nHamilton, JM, Corey-Bloom, J, Thomas, RG, Peavy, G, & Jacobson, MW, “Correlates of weight change in Huntington’s disease”, NEUROLOGY, (2002)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nLange, Kelly L, Bondi, Mark W, Salmon, David P, Galasko, Douglas, Delis, Dean C, Thomas, Ronald G, & Thal, Leon J, “Decline in verbal memory during preclinical Alzheimer’s disease: examination of the effect of APOE genotype”, Journal of the International Neuropsychological Society: JINS, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nJames, MW, Argent, RH, Thomas, R, Hawkey, C, & Atherton, J, “Indomethacin reduces Helicobacter pylori-induced interleukin-8 (IL-8) production by the gastric epithelial cell line, AGS.”, GASTROENTEROLOGY, (2002)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Gamst, Anthony, Thomas, Ronald G, Patterson, Marian, Schneider, Lon S, & Thal, Leon J, “Investigating emergent symptomatology as an outcome measure in a behavioral study of Alzheimer’s disease”, The Journal of neuropsychiatry and clinical neurosciences, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle E, Sano, Mary, Logsdon, Rebecca, Teri, Linda, Galasko, Douglas, Gamst, Anthony, Thomas, Ron, & Thal, Leon J, “No long-term effect of behavioral treatment on psychotropic drug use for agitation in Alzheimer’s disease patients”, Journal of geriatric psychiatry and neurology, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nGoldberg, DE, Roch-Levecq, AC, Maclean, KK, Brody, BL, McGuire, DE, Goldbaum, MH, Thomas, RG, Brown, SI, & Freeman, WR, “Psychosocial and Functional Parameters in Patients with Age Related Macular Degeneration and Choroidal Neovascularization with and without Photodynamic Therapy”, Investigative Ophthalmology & Visual Science, (2002)\nGeneral Research Biostatistics R Drug development\n\n🔗 Article\n\n\n\nAisen, P, Schafer, K, Grundman, M, Farlow, M, Sano, M, Jin, S, Thomas, R, & Thal, L, “Results of a multicenter trial of rofecoxib and naproxen in Alzheimer’s disease”, Neurobiology of Aging, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSinger, C, Colling, E, Tractenberg, R, Grundman, M, Gamst, A, Thomas, R, & Thal, L, “The ADCS clinical trial of melatonin for the sleep disturbance of alzheimer’s disease: Case report of an unusual sleep/wake cycle and response to melatonin.”, AMERICAN JOURNAL OF GERIATRIC PSYCHIATRY, (2002)\nMedical/Clinical Biostatistics R Alzheimer’s disease Sleep disorders Clinical trials\n\n🔗 Article\n\n\n\n\n2.24 2001\n\nTractenberg, Rochelle E, Gamst, Anthony, Weiner, Myron F, Koss, Elisabeth, Thomas, Ronald G, Teri, Linda, & Thal, Leon, “Frequency of behavioral symptoms characterizes agitation in Alzheimer’s disease”, International journal of geriatric psychiatry, (2001)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Thomas, RG, Schneider, LS, Aisen, PS, Mulnard, R, & Thal, LJ, “Incidence and persistence of psychosis in Alzheimer’s disease”, Neurology, (2001)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLindblad, Ulf, Langer, Robert D, Wingard, Deborah L, Thomas, Ronald G, & Barrett-Connor, Elizabeth L, “Metabolic syndrome and ischemic heart disease in elderly men and women”, American journal of epidemiology, (2001)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.25 2000\n\nAisen, Paul S, Davis, KL, Berg, JD, Schafer, K, Campbell, K, Thomas, RG, Weiner, MF, Farlow, MR, Sano, M, Grundman, M, & others, “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nKoch, HJ & Szecsey, A, “A randomized controlled trial of prednisone in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nThomas, Ronald G, Berg, Julie D, Sano, Mary, & Thal, Leon, “Analysis of longitudinal data in an Alzheimer’s disease clinical trial”, Statistics in medicine, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Statistical methods Longitudinal studies\n\n🔗 Article\n\n\n\nBayley, Peter J, Salmon, David P, Bondi, Mark W, Bui, Barbara K, Olichney, John, Delis, Dean C, Thomas, Ronald G, & Thal, Leon J, “Comparison of the serial position effect in very mild Alzheimer’s disease, mild Alzheimer’s disease, and amnesia associated with electroconvulsive therapy”, Journal of the International Neuropsychological Society, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nGamst, A, Thomas, RG, Patterson, M, & Schneider, L, “Description of behaviors emerging in community-dwelling persons with Alzheimer’s disease over 12 months”, ANNALS OF NEUROLOGY, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTHOMAS, R & MICHAEL, J, “Disorder among Veterans with Substance Abuse”, THE JOURNaL OF NERvOUs AND MEntal Disease, (2000)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nMulnard, Ruth A, Cotman, Carl W, Kawas, Claudia, van Dyck, Christopher H, Sano, Mary, Doody, Rachelle, Koss, Elizabeth, Pfeiffer, Eric, Jin, Shelia, Gamst, Anthony, & others, “Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, Jama, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\nPaulsen, Jane S, Salmon, DP, Thal, Leon J, Romero, R, Weisstein–Jenkins, C, Galasko, D, Hofstetter, CR, Thomas, R, Grant, I, & Jeste, DV, “Incidence of and risk factors for hallucinations and delusions in patients with probable AD”, Neurology, (2000)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSano, MC, Berg, JD, Knopman, D, Farlow, MR, & Thomas, RG, “Predicting nursing home placement with change on cognitive measures in Alzheimer’s disease”, Neurology, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Patterson, Marian, Weiner, Myron F, Teri, Linda, Grundman, Michael, Thomas, Ronald G, & Thal, Leon J, “Prevalence of symptoms on the CERAD behavior rating scale for dementia in normal elderly subjects and Alzheimer’s disease patients”, The Journal of neuropsychiatry and clinical neurosciences, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle E, Jin, Shelia, Patterson, Marian, Schneider, Lon S, Gamst, Anthony, Thomas, Ronald G, & Thal, Leon J, “Qualifying change: a method for defining clinically meaningful outcomes of change score computation”, Journal of the American Geriatrics Society, (2000)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nWeiner, Myron F, Tractenberg, Rochelle, Teri, Linda, Logsdon, Rebecca, Thomas, Ronald G, Gamst, Anthony, & Thal, Leon J, “Quantifying behavioral disturbance in Alzheimer’s disease patients”, Journal of Psychiatric Research, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTeri, Linda, Logsdon, RG, Peskind, E, Raskind, M, Weiner, MF, Tractenberg, RE, Foster, NL, Schneider, LS, Sano, M, Whitehouse, P, & others, “Treatment of agitation in AD: a randomized, placebo-controlled clinical trial”, Neurology, (2000)\nMedical/Clinical Biostatistics R Clinical trials Drug development\n\n🔗 Article\n\n\n\nGrundman, Michael, Sencakova, Drahomira, Jack, CR, Fillit, H, & O’Connell, A, “Use of brain MRI volumetric analysis in a mild cognitive impairment trial to delay the diagnosis of Alzheimer’s disease”, Drug discovery and development for Alzheimer’s disease, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Neuroimaging Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\nMulnard, RA, Cotman, CW, Kawas, C, Van Dyck, CH, Sano, M, Doody, R, Koss, E, Pfeiffer, E, Jin, S, Gamst, A, Grundman, M, Thomas R, & Thal L, “for the Alzheimer’s Disease Cooperative Study: Estrogen replacement therapy for treatment of mild to moderate Alzheimer disease: a randomized controlled trial”, JAMA, (2000)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials Drug development\n\n🔗 Article\n\n\n\n\n2.26 1999\n\nLineweaver, Tara T, Bondi, Mark W, Thomas, Ronald G, & Salmon, David P, “A normative study of Nelson’s (1976) modified version of the Wisconsin Card Sorting Test in healthy older adults”, The Clinical Neuropsychologist, (1999)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nBrody, Barbara L, Williams, Rebecca A, Thomas, Ronald G, Kaplan, Robert M, Chu, Ray M, & Brown, Stuart I, “Age-related macular degeneration: a randomized clinical trial of a self-management intervention”, Annals of Behavioral Medicine, (1999)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, Gibbons, Laura E, Raskind, Murray, Peskind, Elaine, Grundman, &gt; Michael, Koss, Elisabeth, Thomas, Ronald G, Thai, Leon J, & others, “Assessment of agitation in Alzheimer’s disease: the agitated behavior in dementia scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLogsdon, Rebecca G, Teri, Linda, Weiner, Myron F, Gibbons, Laura E, Raskind, Murray, Peskind, Elaine, Grundman, Michael, Koss, Elisabeth, Thomas, Ronald G, & Thal, Leon J, “Brief Methodological Reports-Assessment of Agitation in Alzheimer’s Disease: The Agitated Behavior in Dementia Scale”, Journal of the American Geriatrics Society, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Statistical methods\n\n🔗 Article\n\n\n\nOlin, JT, Papka, M, Jin, S, Sano, M, Grundman, M, & Thomas, R, “Clinical symptoms of dementia with Lewy bodies: Secondary analyses of the Alzheimer’s disease cooperative study selegiline and vitamin E clinical trial”, European Neuropsychopharmacology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nBell, Karen, Sano, Mary, Jin, Shelia, Thomas, Ronald, & Thal, Leon, “Ethnic differences in clinical measures among participants in Alzheimer’s disease clinical trials”, Neurology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nHohl, Ursula, Grundman, Michael, Salmon, David P, Thomas, Ronald G, & Thal, Leon J, “Mini-mental state examination and Mattis Dementia Rating Scale performance differs in Hispanic and non-Hispanic Alzheimer’s disease patients”, Journal of the International Neuropsychological Society, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSabbagh, Marwan N, Corey-Bloom, Jody, Tiraboschi, Pietro, Thomas, Ronald, Masliah, Eliezer, & Thal, Leon J, “Neurochemical markers do not correlate with cognitive decline in the Lewy body variant of Alzheimer disease”, Archives of neurology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nBondi, Mark W, Salmon, David P, Galasko, Douglas, Thomas, Ronald G, & Thal, Leon J, “Neuropsychological function and apolipoprotein E genotype in the preclinical detection of Alzheimer’s disease.”, Psychology and aging, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nKnopman, David S, Berg, JD, Thomas, R, Grundman, M, Thal, LJ, Sano, M, & others, “Nursing home placement is related to dementia progression: experience from a clinical trial”, Neurology, (1999)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nGalasko, Douglas, Sano, Mary, Berg, Julie, Thomas, Ronald, Grundman, Michael, & Thal, Leon, “The Beneficial Effects of Vitamin E and Selegiline in a Controlled Trial in Alzheimer’s Disease Are Independent of the Apolipoprotein E e4 Allele”, Neurology, (1999)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nChambers, Christina D, Anderson, Philip O, Thomas, Ronald G, Dick, Lyn M, Felix, Robert J, Johnson, Kathleen A, & Jones, Kenneth Lyons, “Weight gain in infants breastfed by mothers who take fluoxetine”, Pediatrics, (1999)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.27 1998\n\nWeiner, Myron F, Koss, Elisabeth, Patterson, Marian, Jin, Shelia, Teri, Linda, Thomas, Ron, Thal, Leon J, & Whitehouse, Peter, “A comparison of the Cohen-Mansfield agitation inventory with the cerad behavioral rating scale for dementia in community-dwelling persons with Alzheimers disease”, Journal of psychiatric research, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nTractenberg, Rochelle, Schafer, Kimberly, Thomas, Ron, & Morris, John C, “Agreement on CDR ratings by committee”, Controlled Clinical Trials, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTanaka, S, Chen, X, Xia, Y, Kang, DE, Matoh, N, Sundsmo, M, Thomas, RG, Katzman, R, Thal, LJ, Trojanowski, JQ, & others, “Association of CYP2D microsatellite polymorphism with Lewy body variant of Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nPeavy, GM, Salmon, DP, & Thomas, RG, “Cognitive and functional abilities in severely demented Alzheimer’s patients”, CLINICAL NEUROPSYCHOLOGIST, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nFerry, David R, O’Rourke, Robert A, Blaustein, Alvin S, Crawford, Michael H, Deedwania, Prakash C, Carson, Peter E, Zoble, Robert G, Pepine, Carl J, Thomas, Ronald G, Chow, Bruce K, & others, “Design and baseline characteristics of the veterans affairs non-Q-wave infarction strategies in-hospital (VANQWISH) trial”, Journal of the American College of Cardiology, (1998)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\nJin, Shelia, Thomas, Ronald G, Galasko, Douglas, & Thal, Leon J, “Dynamic measurement scale development for clinical trials in targeted populations”, Controlled Clinical Trials, (1998)\nMedical/Clinical Biostatistics R Clinical trials Epidemiology\n\n🔗 Article\n\n\n\nGalasko, D, Chang, L, Motter, R, Clark, CM, Kaye, Jeffrey, Knopman, D, Thomas, R, Kholodenko, D, Schenk, D, Lieberburg, I, & others, “High cerebrospinal fluid tau and low amyloid beta42 levels in the clinical diagnosis of Alzheimer disease and relation to apolipoprotein E genotype”, Archives of neurology, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nKatzman, R, Kang, D, & Thomas, R, “Interaction of apolipoprotein E 4 with other genetic and non-genetic risk factors in late onset Alzheimer disease: problems facing the investigator”, Neurochemical research, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nBerg, Julie D, Thomas, Ronald G, Thal, Leon J, & Sano, Mary, “Measuring cognitive progression in Alzheimer’s disease”, Controlled Clinical Trials, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nKean, Yin M, Thomas, Ronald G, & Thal, Leon J, “Power calculation for randomized start design”, Controlled Clinical Trials, (1998)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nLineweaver, TT, Bondi, MW, & Thomas, RG, “Practice effects on the modified Wisconsin card sorting test in normally aging adults”, Archives of Clinical Neuropsychology, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nFroelicher, Victor F, Lehmann, Kenneth G, Thomas, Ronald, Goldman, Steven, Morrison, Douglas, Edson, Robert, Lavori, Philip, Myers, Jonathan, Dennis, Charles, Shabetai, Ralph, & others, “The electrocardiographic exercise test in a population with reduced workup bias: diagnostic performance, computerized interpretation, and multivariable prediction”, Annals of internal medicine, (1998)\nGeneral Research Biostatistics R Epidemiology\n\n🔗 Article\n\n\n\nWilliams, Rebecca A, Brody, Barbara L, Thomas, Ronald G, Kaplan, Robert M, & Brown, Stuart I, “The psychosocial impact of macular degeneration”, Archives of ophthalmology, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nKnopman, David, Sano, Mary, Berg, Julie, & Thomas, Ronald, “The relationship between Nursing home placement and measures of change in Alzheimer’s disease”, Neurology, (1998)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly A, Welty, Greg, & Thomas, Ronald G, “Use of the world wide web in data dissemination to central review committees”, Controlled Clinical Trials, (1998)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nKeane, Terence M, Kolb, Lawrence C, Kaloupek, Danny G, Orr, Scott P, Blanchard, Edward B, Thomas, Ronald G, Hsieh, Frank Y, & Lavori, Philip W, “Utility of psychophysiological measurement in the diagnosis of posttraumatic stress disorder: results from a Department of Veterans Affairs Cooperative Study.”, Journal of consulting and clinical psychology, (1998)\nMilitary/Defense Biostatistics R Military health\n\n🔗 Article\n\n\n\n\n2.28 1997\n\nJeong, Jong-Hyeon, Klauber, Melville R, Thomas, Ronald G, Grundman, Michael, & Thal, Leon J, “53 Power comparisons among different number of categories under ordered polytomous logistic regression model”, Controlled Clinical Trials, (1997)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nWhitehouse, Peter J, Schmitt, HFrederick A, Sano, Mary, & Thomas, Ronald G, “A Multicenter Evaluation of New Treatment Efficacy”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Thomas, Ronald G, Klauber, Melville R, Schafer, Kimberly, Grundman, Michael, Woodbury, Peter, Growdon, John, Cotman, Carl W, Pfeiffer, Eric, & others, “A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease”, New England Journal of Medicine, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nPatterson, Marian B, Mack, James L, Mackell, Joan A, Thomas, Ronald, Tariot, Pierre, Weiner, Myron, & Whitehouse, Peter J, “A longitudinal study of behavioral pathology across five levels of dementia severity in Alzheimer’s disease: The CERAD Behavior Rating Scale for Dementia.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Longitudinal studies\n\n🔗 Article\n\n\n\nSano, Mary, Thomas, Ronald G, & Thal, Leon J, “Alpha-tocopherol and Alzheimer’s disease”, The New England Journal of Medicine, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, Douglas, Bennett, David, Sano, Mary, Ernesto, Chris, Thomas, Ronald, Grundman, Michael, & Ferris, Steven, “An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSeubert, PA, Motter, RN, Schenk, DB, Lieberburg, IM, Kholodenko, D, Galasko, D, Thomas, R, Chang, L, Miller, B, Clark, C, & others, “ApoE genotype influences the CSF level of A \\\\beta 42 in Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nKoss, Elisabeth, Weiner, Myron, Ernesto, Christopher, Cohen-Mansfield, Jiska, Ferris, Steven H, Grundman, Michael, Schafer, Kimberly, Sano, Mary, Thal, Leon J, Thomas, Ronald, & others, “Assessing patterns of agitation in Alzheimer’s disease patients with the Cohen-Mansfield Agitation Inventory. The Alzheimer’s Disease Cooperative Study.”, Alzheimer Disease and Associated Disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Seubert, P, Motter, R, Schenk, D, Kholodenko, D, Lieberburg, I, Chang, L, Miller, B, Clark, C, Kaye, J, & others, “CSF levels of A beta 432 and tau as aids to diagnosing Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nRoch, J-M, Sundsmo, M, Otero, D, Sisodia, S, Thomas, R, & Saitoh, T, “Defective Neurite Extension Is Caused by a Mutation in Amyloid /A4 (A ) Protein Precursor Found in Familial Alzheimer’s Disease”, JOURNAL OF NEUROBIOLOGY, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nLi, Hai Ling, Roch, Jean-Marc, Sundsmo, Mary, Otero, Deborah, Sisodia, Sangram, Thomas, Ronald, & Saitoh, Tsunao, “Defective neurite extension is caused by a mutation in amyloid beta protein precursor found in familial Alzheimer’s disease”, Journal of neurobiology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nHohl, U, CoreyBloom, J, Hansen, LA, Thomas, RG, & Thal, LJ, “Diagnostic accuracy of dementia with Lewy bodies: A prospective evaluation”, Neurology, (1997)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, Klauber, MR, Schafer, K, Grundman, M, Woodbury, P, Growdon, J, Cotman, CW, Pfeiffer, E, & others, “Effects of Selegiline and alpha-Tocopherol on cognitive and functional outcome measures in moderately impaired patients with Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nKatzman, R, Zhang, M-Y, Chen, PJ, Gu, N, Jiang, S, Saitoh, T, Chen, X, Klauber, M, Thomas, RG, Liu, WT, & others, “Effects of apolipoprotein E on dementia and aging in the Shanghai Survey of Dementia”, Neurology, (1997)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nBarrett-Connor, Elizabeth & Thomas, Ronald G, “Estrogen, apolipoprotein E, and dementia”, Journal of women’s health, (1997)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nKang, DE, Saitoh, T, Chen, X, Xia, Y, Masliah, E, Hansen, LA, Thomas, RG, Thal, LJ, & Katzman, R, “Genetic association of the low-density lipoprotein receptor-related protein gene (LRP), and apolipoprotein E receptor, with late-onset Alzheimer’s disease”, Neurology, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald G, Welty, Greg, Berry, Angela Lambert, & Schittini, Mario, “P23 use of the world wide web for clinical monitoring in multicenter clinical trials”, Controlled Clinical Trials, (1997)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nWilliams, RA, Brody, BL, Kaplan, RM, Thomas, RG, & Brown, SI, “Quality of life among elderly adults with macular degeneration”, INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE, (1997)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThal, Leon J, Thomas, Ronald G, & Sano, Mary, “Tacrine and nursing home placement”, Neurology, (1997)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSano, M, Mackell, JA, Ponton, M, Ferreira, P, Wilson, J, Pawluczyk, S, Pfeiffer, E, Thomas, RG, Jin, S, Schafer, K, & others, “The Spanish Instrument Protocol: Design and implementation of a study to evaluate treatment efficacy instruments for Spanish-speaking patients with Alzheimer’s disease.”, Alzheimer disease and associated disorders, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, Clark, Christopher M, Morris, John C, Reisberg, Barry, Ferris, Steven H, Schmitt, Frederick A, Grundman, Michael, & Thomas, Ronald G, “Validity and reliability of the Alzheimer’s Disease Cooperative Study-Clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSano, M, Ernesto, C, Thomas, RG, Klauber, MR, Schafer, K, Grundman, M, Woodbury, P, Growden, J, Cotnman, C, Pfeiffer, E, & others, “for the members of the Alzheimer’s Disease Cooperative Study”, A controlled trial of selegiline, alpha-tocopherol, or both as treatment for Alzheimer’s disease. N Engl J Med, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nSchneider, LS, Olin, JT, Doody, RS, Clark, CM, Morris, JC, Reisberg, B, Schmitt, FA, Grundman, M, Thomas, RG, & Ferris, SH, “the Alzheimer’s Disease Cooperative Study. Validity and reliability of the Alzheimer’s disease cooperative study-clinical global impression of change”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Sano, M, Ernesto, C, Thomas, R, Grundman, M, & Ferris, S, “the Alzheimer’s Disease Cooperative Study. An inventory to assess activities of daily living for clinical trials in Alzheimer’s disease”, Alzheimer Dis Assoc Disord, (1997)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\n\n2.29 1996\n\nThomas, Ronald G, Schafer, Kimberly, Woodbury, Peter, White, Beverly, Mackell, Joan, Lambert, Angie, & Scattini, Mario, “A32 computer-aided clinical monitoring: Results of a controlled experiment”, Controlled Clinical Trials, (1996)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Ernesto, Christopher, Sano, Mary, Mackell, Joan, Thomas, Ronald, & Morris, John C, “A34 Clinical monitoring of rating scales in multicenter clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nChen, X, Xia, Y, Gresham, LS, Molgaard, CA, Thomas, RG, Galasko, D, Wiederholt, WC, & Saitoh, T, “ApoE and CYP2D6 polymorphism with and without parkinsonism-dementia complex in the people of Chamorro, Guam”, Neurology, (1996)\nMedical/Clinical Biostatistics R\n\n🔗 Article\n\n\n\nKatzman, R, Galasko, DR, Saitoh, T, Chen, X, Pay, MM, Booth, A, & Thomas, RG, “Apolipoprotein-epsilon4 and head trauma: Synergistic or additive risks?”, Neurology, (1996)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nGalasko, D, Bennett, D, Ernesto, C, Thomas, R, & Sano, M, “Development of a pool of items to assess activities of daily living in clinical trials for Alzheimer’s disease”, Neurology, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nSano, M, Growdon, J, Thomas, R, Ernesto, C, Schafer, K, Woodbury, P, Grundman, M, & Thal, L, “Evaluation of efficacy measures in clinical trials for Alzheimer’s disease: Does psychometric test performance predict clinically relevant outcomes?”, Neurology, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Clinical trials\n\n🔗 Article\n\n\n\nWright, Fred A & Thomas, Ronald G, “Familial melanoma and pancreatic cancer”, The New England journal of medicine, (1996)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSchafer, Kimberly, Thomas, Ronald, Galasko, Douglas, Morris, John C, Whitehouse, Peter, Bochenek, Jacqueline, & Thal, Leon, “P63 Informed consent issues when including genetic testing in clinical trials”, Controlled Clinical Trials, (1996)\nMedical/Clinical Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\nGrundman, Michael, Petersen, Ronald C, Morris, JC, Ferris, S, Sano, Mary, Farlow, Martin R, Doody, Rachel S, Galasko, D, Ernesto, C, Thomas, RG, & others, “Rate of dementia of the Alzheimer type (DAT) in subjects with mild cognitive impairment”, Neurology, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline\n\n🔗 Article\n\n\n\nSano, Mary, Ernesto, Christopher, Klauber, Melville R, Schafer, Kimberly, Woodbury, Peter, Thomas, Ronald, Grundman, Michael, Growdon, John, & Thal, Leon J, “Rationale and design of a multicenter study of selegiline and alpha-tocopherol in the treatment of Alzheimer disease using novel clinical outcomes. Alzheimer’s Disease Cooperative Study.”, Alzheimer disease and associated disorders, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\nSeidner, Andrea L, Burling, Thomas A, Gaither, David E, & Thomas, Ronald G, “Substance-dependent inpatients who accept smoking treatment”, Journal of Substance Abuse, (1996)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nSchneider, Lon S, Olin, Jason T, Doody, Rachelle S, Clark, Christopher M, Morris, John C, Reisberg, Barry, Ferris, Steven H, Schmitt, Frederick A, Grundman, Michael, & Thomas, Ronald G, “Validity and reliability of the Alzheimers disease cooperative study-clinical global impression of change (ADCS-CGIC)”, Alzheimer Disease Springer, (1996)\nMedical/Clinical Biostatistics R Alzheimer’s disease\n\n🔗 Article\n\n\n\n\n2.30 1995\n\nLi, Dominic, German, Donald, Lulla, Sulochina, Thomas, Ronald G, & Wilson, Sandra R, “Prospective study of hospitalization for asthma: a preliminary risk factor model”, American journal of respiratory and critical care medicine, (1995)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, RG, Jin, S, Schafer, K, Schittini, M, Grundman, M, & Ferris, SH, “The Spanish Instrument Protocol: a Study to Evaluate Treatment Efficacy Instruments for Spanish-Speaking Patients with Alzheimer’s Disease”, Alzheimer Disease and Associated Disorders, (1995)\nMedical/Clinical Biostatistics R Alzheimer’s disease Drug development\n\n🔗 Article\n\n\n\n\n2.31 1994\n\nAstion, Michael L, Wener, Mark H, Thomas, Ronald G, Hunder, Gene G, & Bloch, Daniel A, “Application of neural networks to the classification of giant cell arteritis”, Arthritis & Rheumatism: Official Journal of the American College of Rheumatology, (1994)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nIrving, Lori M, Seidner, Andrea L, Burling, Thomas A, Thomas, Ronald G, & Brenner, Gail F, “Drug and alcohol abuse inpatients’ attitudes about smoking cessation”, Journal of Substance Abuse, (1994)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\nThomas, Ralf, “Zweibaryonensysteme mit Strangeness und die Antikaon-Deuteron Streuung”, (1994)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.32 1993\n\nWilson, Sandra R, Scamagas, Peter, German, Donald F, Hughes, Gary W, Lulla, Sulochina, Coss, Stamatiki, Chardon, Luis, Thomas, Ronald G, Starr-Schneidkraut, Norma, Stancavage, Frances B, & others, “A controlled trial of two forms of self-management education for adults with asthma”, The American journal of medicine, (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nConlon, Michael & Thomas, Ronald G, “Algorithm AS 280: the power function for Fisher’s exact test”, Journal of the Royal Statistical Society. Series C (Applied Statistics), (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nAstion, ML, Wener, MH, Thomas, RG, Hunder, GG, & Bloch, DA, “Overtraining in neural networks that interpret clinical data”, Clinical chemistry, (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nMorrow, Kiernan, Morris, Charles K, Froelicher, Victor F, Hideg, Alisa, Hunter, Dodie, Johnson, Eileen, Kawaguchi, Takeo, Lehmann, Kenneth, Ribisl, Paul M, Thomas, Ronald, & others, “Prediction of cardiovascular death in men undergoing noninvasive evaluation for coronary artery disease”, Annals of Internal Medicine, (1993)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nWard, TT, Thomas, RG, Fye, CL, Arbeit, R, Coltman Jr, CA, Craig, W, Dana, BW, Finegold, SM, Lentino, J, Penn, RL, & others, “Trimethoprim-sulfamethoxazole prophylaxis in granulocytopenic patients with acute leukemia: evaluation of serum antibiotic levels in a randomized, double-blind, placebo-controlled Department of Veterans Affairs Cooperative Study”, Clinical infectious diseases, (1993)\nMilitary/Defense Biostatistics R Clinical trials Military health\n\n🔗 Article\n\n\n\n\n2.33 1992\n\nThomas, Ronald G & Conlon, Michael, “An algorithm for the rapid evaluation of the power function for Fisher’s Exact Test”, Journal of statistical computation and simulation, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nBeuschel, T, Feldkeller, B, Fuchs, M, Huber, MG, Metsch, BC, & Thomas, R, “Calculation of observables in the pion-deuteron system. Berechnung von Observablen im Pion Deuteron-System”, Verhandlungen der Deutschen Physikalischen Gesellschaft;(Germany), (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nKerns, David L, Ritter, Mary L, & Thomas, Ronald G, “Concave hymenal variations in suspected child sexual abuse victims”, Pediatrics, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRAYNAULD, JP, THOMAS, RG, & BLOCH, DA, “PROGRESSION OF FUNCTIONAL DISABILITY IN RHEUMATOID-ARTHRITIS”, ARTHRITIS AND RHEUMATISM, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald G & Conlon, Michael, “Sample size determination based on Fisher’s exact test for use in 2 x 2 comparative trials with low event rates”, Controlled clinical trials, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nFuchs, M, Huber, MG, Metsch, BC, & Thomas, R, “Two-baryon systems with strangeness S=-1 and S=-2”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1992)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.34 1991\n\nSheridan, Lenore & Thomas, Ronald G, “An analysis of methods of communication in clinical trials”, Controlled Clinical Trials, (1991)\nMedical/Clinical Biostatistics R Clinical trials Statistical methods\n\n🔗 Article\n\n\n\nGordon, DE, Thomas, R, Shedrow, CB, & Wilson, MP, “Integration of statutory provisions of NEPA, RCRA, and CERCLA at the Savannah River site. Revision 1”, (1991)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.35 1990\n\nConlon, Michael & Thomas, Ronald G, “A new confidence interval for the difference of two binomial proportions”, Computational Statistics & Data Analysis, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Data monitoring through stochastic curtailing when the outcome proportions are small: An exact approach”, Controlled Clinical Trials, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, R, Empl, E, Kilian, K, Oelert, W, Roderburg, E, Sefzick, T, Sehl, G, Steinkamp, O, & Ziolkowski, M, “Development of an active target for scattering of neutral baryons”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nDecker, G, Kilian, K, Lippert, C, Oelert, W, Roderburg, E, Sefzick, T, Sehl, G, Steinkamp, O, Thomas, R, Ziolkowski, M, & others, “Test measurements of an asymmetric induction drift chamber with flash ADC’s”, Verhandlungen der Deutschen Physikalischen Gesellschaft, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nTyrell, Doris, Cline, Dorothy R, & Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nLee, Kelvin K & Thomas, Ronald G, “”, Controlled Clinical Trials, (1990)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.36 1989\n\nHale, William E, May, Franklin E, Thomas, Ronald G, Moore, Mary T, & Stewart, Ronald B, “Effect of zinc supplementation on the development of cardiovascular disease in the elderly”, Journal of Nutrition for the Elderly, (1989)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald G, “Exact sample size calculations for 2x2 comparative trials when the outcome proportions are small”, Controlled Clinical Trials, (1989)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nEllis, Stephen G, Shaw, Richard E, Gershony, Gary, Thomas, Ronald, Roubin, Gary S, Douglas Jr, John S, Topol, Eric J, Startzer, Simon H, Myler, Richard K, & King III, Spencer B, “Risk factors, time course and treatment effect for restenosis after successful percutaneous transluminal coronary angioplasty of chronic total occlusion”, The American journal of cardiology, (1989)\nMedical/Clinical Biostatistics R Drug development\n\n🔗 Article\n\n\n\n\n2.37 1988\n\nEllis, SG, Roubin, GS, King 3rd, SB, Douglas Jr, JS, Weintraub, WS, Thomas, RG, & Cox, WR, “Angiographic and clinical predictors of acute closure after native vessel coronary angioplasty.”, Circulation, (1988)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nMELLEN, BG, THOMAS, RG, & CASTANO, D, “FORMS INVENTORY SYSTEM FOR A COMPLEX CLINICAL-TRIAL”, CONTROLLED CLINICAL TRIALS, (1988)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRoubin, Gary S, Douglas Jr, John S, King 3rd, SB, Lin, SF, Hutchison, Nancy, Thomas, RG, & Gruentzig, AR, “Influence of balloon size on initial success, acute complications, and restenosis after percutaneous transluminal coronary angioplasty. A prospective randomized study.”, Circulation, (1988)\nGeneral Research Biostatistics R Clinical trials\n\n🔗 Article\n\n\n\n\n2.38 1987\n\nMufson, LGAR, Roubin, GS, Black, A, & Thomas, RG, “A comparison of single lesion dilatation in single vessel and multivessel disease”, Circulation, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nMcGlynn, F Dudley, LeCompte, E Joseph, Thomas, Ronald G, Courts, Frank J, & Melamed, Barbara G, “Effects of behavioral self-management on oral hygiene adherence among orthodontic patients”, American Journal of Orthodontics and Dentofacial Orthopedics, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nSherertz, Robert J, Belani, Anusha, Kramer, Barnett S, Elfenbein, Gerald J, Weiner, Roy S, Sullivan, Marsha L, Thomas, Ronald G, & Samsa, Gregory P, “Impact of air filtration on nosocomial Aspergillus infections: unique risk of bone marrow transplant recipients”, The American journal of medicine, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nShcrertz, RJ, Belani, A, Kramer, BS, & others, “Impact of air filtration on nosocomial aspergillus infections”, Am J Med, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, RG, Black, A, Lin, S, Chin, H, & Weintraub, WS, “Is there dependence between sites for continued success or restenosis after successful multisite coronary angioplasty”, Circulation, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nRoubin, GS, Sutor, C, Lembo, NJ, Hoffmeister, J, Thomas, RG, Douglas, JS, & King, SB, “PROGNOSIS AFTER MULTIPLE VESSEL ANGIOPLASTY (PTCA) IN PATIENTS WITH CORONARY-ARTERY DISEASE”, Circulation, (1987)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.39 1986\n\nThal, Leon J, Grundman, Michael, & Golden, Robert, “Alzheimer’s disease: a correlational analysis of the Blessed Information-Memory-Concentration test and the Mini-Mental State Exam”, Neurology, (1986)\nMedical/Clinical Biostatistics R Alzheimer’s disease Cognitive decline Statistical methods\n\n🔗 Article\n\n\n\n\n2.40 1985\n\nHUWS, DA, FAN, TP, & THOMAS, RU, “ELUTION OF PROSTAGLANDIN-E2 FROM FILTER-PAPER STRIPS-EFFICIENCY AND REPRODUCIBILITY”, JOURNAL OF DENTAL RESEARCH, (1985)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.41 1984\n\nSchubert, Mark M, Guttu, Ronald L, Hunter, Letha H, Hall, Richard, & Thomas, Ronald, “Changes in shoulder and leg strength in athletes wearing mandibular orthopedic repositioning appliances”, The Journal of the American Dental Association, (1984)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\n\n2.42 1983\n\nPepe, Paul E, Thomas, Ronald G, Stager, Marie Anne, Hudson, Leonard D, & Carrico, C James, “Early prediction of the adult respiratory distress syndrome by a simple scoring method”, Annals of emergency medicine, (1983)\nGeneral Research Biostatistics R Statistical methods\n\n🔗 Article\n\n\n\nThomas, Ronald J & Clark, Christopher A, “Effects of concomitant development on reproduction of Meloidogyne incognita and Rotylenchulus reniformis on sweet potato”, Journal of Nematology, (1983)\nGeneral Research Biostatistics R\n\n🔗 Article\n\n\n\nThomas, Ronald J & Clark, Christopher A, “Population dynamics of Meloidogyne incognita and Rotylenchulus reniformis alone and in combination, and their effects on sweet potato”, Journal of Nematology, (1983)\nGeneral Research Biostatistics R Epidemiology\n\n🔗 Article\n\n\n\nSchubert, M, Guttu, R, Hunter, L, Hall, R, & Thomas, R, “THE EFFECT OF MANDIBULAR ORTHOPEDIC REPOSITIONING APPLIANCES ON BODY STRENGTH”, JOURNAL OF DENTAL RESEARCH, (1983)\nGeneral Research Biostatistics R\n\n🔗 Article"
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#current-courses",
    "href": "teaching/index.html#current-courses",
    "title": "Teaching",
    "section": "",
    "text": "R programming for statistics\nReproducible research methods\nAdvanced data visualization\nStatistical software development\n\n\n\n\n\nClinical trial design\nSurvival analysis\nLongitudinal data analysis\nBayesian statistics applications"
  },
  {
    "objectID": "teaching/index.html#workshops-and-training",
    "href": "teaching/index.html#workshops-and-training",
    "title": "Teaching",
    "section": "2 Workshops and Training",
    "text": "2 Workshops and Training\n\n2.1 Professional Development\n\nR package development workshops\nReproducible research training\nStatistical consulting methodology\nAcademic writing for statisticians\n\n\n\n2.2 Conference Presentations\n\nInvited talks on statistical methods\nSoftware demonstrations\nMethodology tutorials\nBest practices sessions"
  },
  {
    "objectID": "teaching/index.html#educational-resources",
    "href": "teaching/index.html#educational-resources",
    "title": "Teaching",
    "section": "3 Educational Resources",
    "text": "3 Educational Resources\n\n3.1 Course Materials\n\nLecture slides and notes\nLab exercises and solutions\nAssignment templates\nAssessment rubrics\n\n\n\n3.2 Open Educational Content\n\nOnline tutorials and guides\nVideo lectures and demonstrations\nInteractive learning materials\nStudent project examples\n\n\nThis section will feature detailed course descriptions, syllabi, teaching materials, and educational resources developed for statistics and data science instruction."
  },
  {
    "objectID": "test_copy.html",
    "href": "test_copy.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "This is a test."
  },
  {
    "objectID": "test_copy.html#test",
    "href": "test_copy.html#test",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "This is a test."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html",
    "href": "tutorials/r-package-development-basics.html",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#learning-objectives",
    "href": "tutorials/r-package-development-basics.html#learning-objectives",
    "title": "R Package Development: From Idea to CRAN",
    "section": "",
    "text": "By the end of this tutorial, you will: - Set up a proper R package development environment - Create package structure and documentation - Write and test package functions - Prepare for CRAN submission"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#prerequisites",
    "href": "tutorials/r-package-development-basics.html#prerequisites",
    "title": "R Package Development: From Idea to CRAN",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\n\nBasic R programming knowledge\nRStudio installed\nGit familiarity (helpful but not required)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "href": "tutorials/r-package-development-basics.html#step-1-development-environment-setup",
    "title": "R Package Development: From Idea to CRAN",
    "section": "3 Step 1: Development Environment Setup",
    "text": "3 Step 1: Development Environment Setup\nFirst, install the essential packages for R development:\ninstall.packages(c(\"devtools\", \"usethis\", \"roxygen2\", \"testthat\"))\nConfigure your development environment:\nlibrary(usethis)\nuse_git_config(user.name = \"Your Name\", user.email = \"your.email@example.com\")"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "href": "tutorials/r-package-development-basics.html#step-2-create-package-structure",
    "title": "R Package Development: From Idea to CRAN",
    "section": "4 Step 2: Create Package Structure",
    "text": "4 Step 2: Create Package Structure\nCreate a new package:\ncreate_package(\"~/path/to/mypackage\")\nThis creates the standard package directory structure: - R/ - Your R functions - man/ - Documentation files (auto-generated) - DESCRIPTION - Package metadata - NAMESPACE - Exported functions (auto-generated)"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "href": "tutorials/r-package-development-basics.html#step-3-write-your-first-function",
    "title": "R Package Development: From Idea to CRAN",
    "section": "5 Step 3: Write Your First Function",
    "text": "5 Step 3: Write Your First Function\nCreate a new R file in the R/ directory:\n#' Add two numbers together\n#'\n#' This function takes two numeric inputs and returns their sum.\n#'\n#' @param x A numeric value\n#' @param y A numeric value\n#' @return The sum of x and y\n#' @export\n#' @examples\n#' add_numbers(2, 3)\n#' add_numbers(10, -5)\nadd_numbers &lt;- function(x, y) {\n  if (!is.numeric(x) || !is.numeric(y)) {\n    stop(\"Both inputs must be numeric\")\n  }\n  x + y\n}"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "href": "tutorials/r-package-development-basics.html#step-4-generate-documentation",
    "title": "R Package Development: From Idea to CRAN",
    "section": "6 Step 4: Generate Documentation",
    "text": "6 Step 4: Generate Documentation\nUse roxygen2 to generate documentation:\ndevtools::document()\nThis creates help files in the man/ directory and updates your NAMESPACE."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-5-testing",
    "href": "tutorials/r-package-development-basics.html#step-5-testing",
    "title": "R Package Development: From Idea to CRAN",
    "section": "7 Step 5: Testing",
    "text": "7 Step 5: Testing\nCreate unit tests to ensure your functions work correctly:\nusethis::use_testthat()\nusethis::use_test(\"add_numbers\")\nWrite tests in tests/testthat/test-add_numbers.R:\ntest_that(\"add_numbers works correctly\", {\n  expect_equal(add_numbers(2, 3), 5)\n  expect_equal(add_numbers(-1, 1), 0)\n  expect_error(add_numbers(\"a\", 1))\n})\nRun tests:\ndevtools::test()"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "href": "tutorials/r-package-development-basics.html#step-6-package-checks",
    "title": "R Package Development: From Idea to CRAN",
    "section": "8 Step 6: Package Checks",
    "text": "8 Step 6: Package Checks\nBefore submitting to CRAN, run comprehensive checks:\ndevtools::check()\nThis runs R CMD check and identifies potential issues."
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "href": "tutorials/r-package-development-basics.html#step-7-preparing-for-cran",
    "title": "R Package Development: From Idea to CRAN",
    "section": "9 Step 7: Preparing for CRAN",
    "text": "9 Step 7: Preparing for CRAN\nUpdate your DESCRIPTION file with proper metadata:\nPackage: mypackage\nTitle: What the Package Does (One Line, Title Case)\nVersion: 0.1.0\nAuthors@R: \n    person(\"First\", \"Last\", , \"first.last@example.com\", role = c(\"aut\", \"cre\"))\nDescription: What the package does (one paragraph).\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.3\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#next-steps",
    "href": "tutorials/r-package-development-basics.html#next-steps",
    "title": "R Package Development: From Idea to CRAN",
    "section": "10 Next Steps",
    "text": "10 Next Steps\n\nAdd more functions and documentation\nCreate vignettes for complex workflows\nSet up continuous integration\nSubmit to CRAN when ready"
  },
  {
    "objectID": "tutorials/r-package-development-basics.html#resources",
    "href": "tutorials/r-package-development-basics.html#resources",
    "title": "R Package Development: From Idea to CRAN",
    "section": "11 Resources",
    "text": "11 Resources\n\nR Packages book by Hadley Wickham\nWriting R Extensions manual\nCRAN Policy"
  },
  {
    "objectID": "test_minimal.html",
    "href": "test_minimal.html",
    "title": "Test Document",
    "section": "",
    "text": "This is a test document.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "test_minimal.html#test",
    "href": "test_minimal.html#test",
    "title": "Test Document",
    "section": "",
    "text": "This is a test document.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "blog/coding-with-genai/index.html",
    "href": "blog/coding-with-genai/index.html",
    "title": "Coding with Generative AI",
    "section": "",
    "text": "View this post in multiple formats:\n\n\n\n  HTML    PDF    Word"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#prerequisites",
    "href": "blog/coding-with-genai/index.html#prerequisites",
    "title": "Coding with Generative AI",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "href": "blog/coding-with-genai/index.html#step-by-step-implementation",
    "title": "Coding with Generative AI",
    "section": "1.2 Step-by-Step Implementation",
    "text": "1.2 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#key-takeaways",
    "href": "blog/coding-with-genai/index.html#key-takeaways",
    "title": "Coding with Generative AI",
    "section": "1.3 Key Takeaways",
    "text": "1.3 Key Takeaways\nIn development"
  },
  {
    "objectID": "blog/coding-with-genai/index.html#further-reading",
    "href": "blog/coding-with-genai/index.html#further-reading",
    "title": "Coding with Generative AI",
    "section": "1.4 Further Reading",
    "text": "1.4 Further Reading\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html",
    "href": "tutorials/docker-for-beginners/index.html",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#introduction",
    "href": "tutorials/docker-for-beginners/index.html#introduction",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "1 Introduction",
    "text": "1 Introduction\nThis guide demonstrates how to deploy a Shiny application from your local workstation to a secure web environment. We’ll use a stack of open-source technologies including Linux, R, Shiny, Docker, and Caddy, deployed on AWS EC2. While we focus on AWS here, the principles apply to other cloud providers like Hetzner, which we’ll cover in future posts."
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#prerequisites",
    "href": "tutorials/docker-for-beginners/index.html#prerequisites",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "2 Prerequisites",
    "text": "2 Prerequisites\nBefore beginning this tutorial, you’ll need:\n\nA working Shiny application on your local machine\nAn AWS account with permissions to create EC2 instances\nBasic familiarity with the Linux command line\nGit (optional, for version control)"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#the-example-application",
    "href": "tutorials/docker-for-beginners/index.html#the-example-application",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "3 The Example Application",
    "text": "3 The Example Application\nLet’s start with a simple but practical example: hosting a shiny web application that provides a power calculator for two-sample t-tests. While straightforward, this application demonstrates all the key deployment concepts.\nHere is the code for the Shiny app (The app is intentionally minimal, using only base R functions, with a minimum of reactive widgets and layout commands.):\n\nPower Calculator Shiny App Code (power1_shiny/app.R)\nui &lt;- fluidPage(\n  titlePanel(\"Power Calculator for Two Group Parallel Designs\"),\n  sliderInput(\"N\", \"Total Sample Size:\", min = 0, max = 300, value = 100),\n  plotOutput(\"plot\"),\n  verbatimTextOutput(\"eff\"))\n\nserver &lt;- function(input, output, session) {\n  delta = seq(0, 1.5,.05)\n  pow = reactive(sapply(delta, function(x) power.t.test(input$N, d=x)$power ))\n  eff =  renderText(power.t.test(input$N, power=.8)$d)\n  output$plot &lt;- renderPlot({\n    plot(delta, pow(), cex=1.5, ylab=\"power\")\n    abline(h = .8,  col = \"red\", lwd =2.5, lty = 4)\n    abline(v = eff(), col = \"blue\",lwd =2.5, lty = 4)})\n  output$eff &lt;- renderText(\n    paste0(\"Std. effect detectable with power 80% = \", eff()) )\n}\nshinyApp(ui, server)\n\n\n\n\n\n\nShiny app interface"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "4 Step-by-Step Implementation",
    "text": "4 Step-by-Step Implementation\n\n4.1 Deployment Checklist\nAs an overview, to host our Shiny app securely online, we need to:\n\nObtain a static IP address\nRegister a domain name\nConfigure a firewall\nSet up the virtual server\nInstall and configure a web server\nImplement SSL encryption\nSet up user authentication\nConfigure reverse proxy routing\n\nWhile this might seem complex, we’ll break it down into manageable steps.\nDetailed instructions for setting up a virtual server (items 1 through 4 above) on EC2 both through the EC2 console and the command line interface can be found: here and here\n\n\n4.2 Step 1: Server Setup\nFirst, we’ll prepare our AWS EC2 environment: In the course of setting up your server, you’ll need to: 1. Create or access your AWS account 2. Generate SSH key-pair, named for example, power1_app.pem 3. Configure firewall settings, allowing SSH (port 22), HTTP (port 80) traffic and HTTPS (port 443) traffic. 4. Obtain static IP, e.g., 13.57.139.31 5. Register domain name, e.g. rgtlab.org 6. Launch Ubuntu instance (t2-micro is sufficient)\n\n\n4.3 Step 2: Installing Required Software\nconnect to your server via SSH:\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nOn your server, install Docker and Caddy (a modern web server with automatic HTTPS) using the following commands.\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\n\n\n4.4 Step 3: Containerizing the Application\nCreate a Dockerfile in your app directory:\n\nDockerfile Configuration\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\n\n\n4.5 Step 4: Configuring the Web Server\nCreate a Caddyfile:\n\nCaddy Server Configuration\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nCreate an index.html:\n\nLanding Page HTML\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n4.6 Step 5: Deployment\n\nCopy files to server:\n\nscp -r ~/prj/power1_app/ ubuntu@rgtlab.org:~\n\nBuild and run Docker container:\n\ndocker build -t power1_image .\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\n\nConfigure Caddy:\n\nsudo cp ./Caddyfile /etc/caddy/\ncp ./index.html /var/www/html/\nsudo systemctl reload caddy\nYour app should now be available at https://rgtlab.org!"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "href": "tutorials/docker-for-beginners/index.html#advanced-tips",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "5 Advanced Tips",
    "text": "5 Advanced Tips\nFor easier SSH access, create a ~/.ssh/config file:\nHost rgtlab.org\nHostName 13.57.139.31\nStrictHostKeyChecking no\nUser ubuntu\nPort 22\nIdentityFile ~/.ssh/power1_app.pem\nThis enables simple SSH access:\nssh rgtlab.org"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "6 Key Takeaways",
    "text": "6 Key Takeaways\n\nDocker containers provide isolation and reproducibility for your Shiny applications\nCaddy web server automatically handles SSL certificates and security\nBasic authentication provides a simple access control mechanism\nAWS EC2 offers a reliable platform for hosting web applications\nThe entire deployment can be automated for continuous delivery workflows"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading",
    "href": "tutorials/docker-for-beginners/index.html#further-reading",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "7 Further Reading",
    "text": "7 Further Reading\n\nShiny Server documentation\nDocker documentation\nCaddy Web Server documentation\nAWS EC2 documentation"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "href": "tutorials/docker-for-beginners/index.html#step-by-step-implementation-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "8 Step-by-Step Implementation",
    "text": "8 Step-by-Step Implementation\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "href": "tutorials/docker-for-beginners/index.html#key-takeaways-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "9 Key Takeaways",
    "text": "9 Key Takeaways\nIn development"
  },
  {
    "objectID": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "href": "tutorials/docker-for-beginners/index.html#further-reading-1",
    "title": "Securely Deploying Your Shiny App Online: A Step-by-Step Guide",
    "section": "10 Further Reading",
    "text": "10 Further Reading\nIn development"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html",
    "href": "posts/setupquarto/quarto-blog-template.html",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#introduction",
    "href": "posts/setupquarto/quarto-blog-template.html#introduction",
    "title": "Your Technical Blog Post Title",
    "section": "",
    "text": "Brief introduction that:\n\nHooks the reader with an interesting problem or observation\nStates the purpose of your analysis/tutorial\nOutlines what readers will learn or gain"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#required-packages-and-setup",
    "href": "posts/setupquarto/quarto-blog-template.html#required-packages-and-setup",
    "title": "Your Technical Blog Post Title",
    "section": "2 Required Packages and Setup",
    "text": "2 Required Packages and Setup\n\n# List the packages readers will need\nlibrary(tidyverse)\n# Add other packages\n\nBrief explanation of why these packages were chosen and any setup requirements."
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#the-problemdata",
    "href": "posts/setupquarto/quarto-blog-template.html#the-problemdata",
    "title": "Your Technical Blog Post Title",
    "section": "3 The Problem/Data",
    "text": "3 The Problem/Data\n\n# Data loading and initial preparation\n# Load sample dataset\ndata &lt;- mtcars\nglimpse(data)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n\nDescribe your data source\nExplain the problem you’re addressing\nShare any initial data preparation steps"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#analysistutorial-steps",
    "href": "posts/setupquarto/quarto-blog-template.html#analysistutorial-steps",
    "title": "Your Technical Blog Post Title",
    "section": "4 Analysis/Tutorial Steps",
    "text": "4 Analysis/Tutorial Steps\n\n4.1 Step 1: Initial Data Exploration\n\n# Your analysis code here\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\nggplot(mtcars, aes(x=cyl, y=mpg)) +\n  geom_point()\n\n\n\n\nDescription of your visualization\n\n\n\n  # Your visualization\n\nExplain what you found and why it’s interesting.\n\n\n4.2 Step 2: Main Analysis\n\n# Core analysis code\n\nWalk through your analysis, explaining: - Why you chose this approach - What the code does - What the results mean\n\n\n4.3 Step 3: Results and Visualization\n\n# Create compelling visualizations\n\nInterpret your results and explain their significance."
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#key-takeaways",
    "href": "posts/setupquarto/quarto-blog-template.html#key-takeaways",
    "title": "Your Technical Blog Post Title",
    "section": "5 Key Takeaways",
    "text": "5 Key Takeaways\n\nBullet point summary of main findings\nPractical applications\nImportant insights"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#reproducibility",
    "href": "posts/setupquarto/quarto-blog-template.html#reproducibility",
    "title": "Your Technical Blog Post Title",
    "section": "6 Reproducibility",
    "text": "6 Reproducibility\n\n# Print session info for reproducibility\nsessionInfo()\n\nR version 4.5.0 (2025-04-11)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.5\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.1\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] here_1.0.1      lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1  \n [5] dplyr_1.1.4     purrr_1.0.4     readr_2.1.5     tidyr_1.3.1    \n [9] tibble_3.3.0    ggplot2_3.5.2   tidyverse_2.0.0\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.0     tidyselect_1.2.1  \n [5] scales_1.4.0       yaml_2.3.10        fastmap_1.2.0      R6_2.6.1          \n [9] labeling_0.4.3     generics_0.1.4     knitr_1.50         htmlwidgets_1.6.4 \n[13] rprojroot_2.0.4    pillar_1.10.2      RColorBrewer_1.1-3 tzdb_0.5.0        \n[17] rlang_1.1.6        stringi_1.8.7      xfun_0.52          timechange_0.3.0  \n[21] cli_3.6.5          withr_3.0.2        magrittr_2.0.3     digest_0.6.37     \n[25] grid_4.5.0         hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5       \n[29] evaluate_1.0.3     glue_1.8.0         farver_2.1.2       rmarkdown_2.29    \n[33] tools_4.5.0        pkgconfig_2.0.3    htmltools_0.5.8.1"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#next-steps",
    "href": "posts/setupquarto/quarto-blog-template.html#next-steps",
    "title": "Your Technical Blog Post Title",
    "section": "7 Next Steps",
    "text": "7 Next Steps\n\nSuggest areas for further exploration\nMention potential improvements\nInvite reader engagement"
  },
  {
    "objectID": "posts/setupquarto/quarto-blog-template.html#references",
    "href": "posts/setupquarto/quarto-blog-template.html#references",
    "title": "Your Technical Blog Post Title",
    "section": "8 References",
    "text": "8 References\n\nCite your sources\nLink to relevant documentation\nCredit other contributors"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html",
    "href": "posts/palmer_penguins_part4/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "",
    "text": "A penguin scientist with a magnifying glass, carefully examining model diagnostics and residual plots!"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#linearity",
    "href": "posts/palmer_penguins_part4/index.html#linearity",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.1 1. Linearity",
    "text": "3.1 1. Linearity\nThe relationship between predictors and response should be linear:\n\n# Check linearity using partial residual plots\npar(mfrow = c(2, 2))\navPlots(best_model, main = \"Added-Variable Plots for Linearity\")\n\n\n\n\n\n\n\npar(mfrow = c(1, 1))\n\n# Alternative: Component + residual plots\ncrPlots(best_model, main = \"Component + Residual Plots\")\n\n\n\n\n\n\n\n\n\n\n\nAdded-variable plots showing the linear relationships between predictors and response after accounting for other variables"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#independence-of-residuals",
    "href": "posts/palmer_penguins_part4/index.html#independence-of-residuals",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.2 2. Independence of Residuals",
    "text": "3.2 2. Independence of Residuals\nWe’ll check for patterns that might indicate dependence:\n\n# Plot residuals vs order (temporal/spatial independence)\npenguins_diagnostics &lt;- penguins_diagnostics %&gt;%\n  mutate(observation_order = row_number())\n\np1 &lt;- ggplot(penguins_diagnostics, aes(x = observation_order, y = residuals)) +\n  geom_point(aes(color = species), alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"blue\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Residuals vs Observation Order\",\n       subtitle = \"Checking for temporal/spatial patterns\",\n       x = \"Observation Order\", y = \"Residuals (g)\",\n       color = \"Species\") +\n  theme_minimal()\n\nprint(p1)\n\n\n\n\n\n\n\n# Durbin-Watson test for autocorrelation\ndw_test &lt;- durbinWatsonTest(best_model)\ncat(\"\\n📊 Durbin-Watson Test for Autocorrelation:\\n\")\n\n\n📊 Durbin-Watson Test for Autocorrelation:\n\ncat(\"==========================================\\n\")\n\n==========================================\n\ncat(sprintf(\"DW Statistic: %.3f\\n\", dw_test$dw))\n\nDW Statistic: 2.248\n\ncat(sprintf(\"p-value: %.3f\\n\", dw_test$p))\n\np-value: 0.038\n\ncat(\"Interpretation: Values near 2 indicate no autocorrelation\\n\")\n\nInterpretation: Values near 2 indicate no autocorrelation\n\n\n\n\n\nPlot showing residuals versus observation order to check for temporal or spatial dependencies"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#homoscedasticity-constant-variance",
    "href": "posts/palmer_penguins_part4/index.html#homoscedasticity-constant-variance",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.3 3. Homoscedasticity (Constant Variance)",
    "text": "3.3 3. Homoscedasticity (Constant Variance)\nResidual variance should be constant across fitted values:\n\n# Residuals vs fitted values plot\np2 &lt;- ggplot(penguins_diagnostics, aes(x = fitted_values, y = residuals)) +\n  geom_point(aes(color = species), alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"blue\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Residuals vs Fitted Values\",\n       subtitle = \"Checking for homoscedasticity\",\n       x = \"Fitted Values (g)\", y = \"Residuals (g)\",\n       color = \"Species\") +\n  theme_minimal()\n\n# Scale-Location plot (sqrt of absolute residuals)\np3 &lt;- ggplot(penguins_diagnostics, aes(x = fitted_values, y = sqrt(abs(residuals)))) +\n  geom_point(aes(color = species), alpha = 0.7) +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"blue\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Scale-Location Plot\",\n       subtitle = \"Square root of absolute residuals vs fitted values\",\n       x = \"Fitted Values (g)\", y = \"√|Residuals|\",\n       color = \"Species\") +\n  theme_minimal()\n\nhomoscedasticity_plots &lt;- p2 + p3\nprint(homoscedasticity_plots)\n\n\n\n\n\n\n\n# Breusch-Pagan test for heteroscedasticity\nbp_test &lt;- bptest(best_model)\ncat(\"\\n📊 Breusch-Pagan Test for Heteroscedasticity:\\n\")\n\n\n📊 Breusch-Pagan Test for Heteroscedasticity:\n\ncat(\"==============================================\\n\")\n\n==============================================\n\ncat(sprintf(\"BP Statistic: %.3f\\n\", bp_test$statistic))\n\nBP Statistic: 2.583\n\ncat(sprintf(\"p-value: %.3f\\n\", bp_test$p.value))\n\np-value: 0.764\n\ncat(\"Interpretation: p &gt; 0.05 suggests constant variance (homoscedasticity)\\n\")\n\nInterpretation: p &gt; 0.05 suggests constant variance (homoscedasticity)\n\n\n\n\n\nDiagnostic plots for checking homoscedasticity assumption through residuals vs fitted values"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#normality-of-residuals",
    "href": "posts/palmer_penguins_part4/index.html#normality-of-residuals",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "3.4 4. Normality of Residuals",
    "text": "3.4 4. Normality of Residuals\nResiduals should follow a normal distribution:\n\n# Q-Q plot for normality\np4 &lt;- ggplot(penguins_diagnostics, aes(sample = standardized_residuals)) +\n  stat_qq(aes(color = species), alpha = 0.7) +\n  stat_qq_line(color = \"red\", linetype = \"dashed\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Q-Q Plot of Standardized Residuals\",\n       subtitle = \"Checking normality assumption\",\n       x = \"Theoretical Quantiles\", y = \"Sample Quantiles\",\n       color = \"Species\") +\n  theme_minimal()\n\n# Histogram of residuals\np5 &lt;- ggplot(penguins_diagnostics, aes(x = residuals)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, \n                 fill = \"lightblue\", alpha = 0.7, color = \"white\") +\n  geom_density(color = \"blue\", size = 1) +\n  stat_function(fun = dnorm, \n                args = list(mean = mean(penguins_diagnostics$residuals), \n                           sd = sd(penguins_diagnostics$residuals)),\n                color = \"red\", linetype = \"dashed\", size = 1) +\n  labs(title = \"Distribution of Residuals\",\n       subtitle = \"Blue = actual density, Red = normal distribution\",\n       x = \"Residuals (g)\", y = \"Density\") +\n  theme_minimal()\n\nnormality_plots &lt;- p4 + p5\nprint(normality_plots)\n\n\n\n\n\n\n\n# Shapiro-Wilk test for normality\nshapiro_test &lt;- shapiro.test(residuals(best_model))\ncat(\"\\n📊 Shapiro-Wilk Test for Normality:\\n\")\n\n\n📊 Shapiro-Wilk Test for Normality:\n\ncat(\"====================================\\n\")\n\n====================================\n\ncat(sprintf(\"W Statistic: %.4f\\n\", shapiro_test$statistic))\n\nW Statistic: 0.9921\n\ncat(sprintf(\"p-value: %.4f\\n\", shapiro_test$p.value))\n\np-value: 0.0746\n\ncat(\"Interpretation: p &gt; 0.05 suggests residuals are normally distributed\\n\")\n\nInterpretation: p &gt; 0.05 suggests residuals are normally distributed\n\n# Alternative: Anderson-Darling test (more powerful for large samples)\n# Install nortest if needed: install.packages(\"nortest\")\nif (requireNamespace(\"nortest\", quietly = TRUE)) {\n  library(nortest)\n  ad_test &lt;- ad.test(residuals(best_model))\n  cat(sprintf(\"\\nAnderson-Darling Test p-value: %.4f\\n\", ad_test$p.value))\n} else {\n  cat(\"\\n⚠️ nortest package not available. Install with: install.packages('nortest')\\n\")\n  cat(\"Using Shapiro-Wilk test results instead.\\n\")\n}\n\n\n⚠️ nortest package not available. Install with: install.packages('nortest')\nUsing Shapiro-Wilk test results instead.\n\n\n\n\n\nDiagnostic plots for checking normality of residuals including Q-Q plot and histogram"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#leverage-outliers-and-influential-points",
    "href": "posts/palmer_penguins_part4/index.html#leverage-outliers-and-influential-points",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "4.1 Leverage, Outliers, and Influential Points",
    "text": "4.1 Leverage, Outliers, and Influential Points\n\n# Calculate diagnostic thresholds\nn &lt;- nrow(penguins_clean)\np &lt;- length(coef(best_model))\n\n# Thresholds\nleverage_threshold &lt;- 2 * p / n\ncooks_threshold &lt;- 4 / n\nstudentized_threshold &lt;- qt(0.975, n - p - 1)  # Two-tailed 95%\n\ncat(\"🎯 Diagnostic Thresholds:\\n\")\n\n🎯 Diagnostic Thresholds:\n\ncat(\"=========================\\n\")\n\n=========================\n\ncat(sprintf(\"High leverage threshold: %.3f\\n\", leverage_threshold))\n\nHigh leverage threshold: 0.036\n\ncat(sprintf(\"High Cook's distance threshold: %.3f\\n\", cooks_threshold))\n\nHigh Cook's distance threshold: 0.012\n\ncat(sprintf(\"Studentized residual threshold: ±%.2f\\n\", studentized_threshold))\n\nStudentized residual threshold: ±1.97\n\n# Identify problematic observations\nproblematic_obs &lt;- penguins_diagnostics %&gt;%\n  mutate(\n    high_leverage = leverage &gt; leverage_threshold,\n    high_cooks = cooks_distance &gt; cooks_threshold,\n    outlier = abs(studentized_residuals) &gt; studentized_threshold,\n    influential = high_leverage | high_cooks | outlier,\n    obs_id = row_number()\n  ) %&gt;%\n  filter(influential)\n\ncat(sprintf(\"\\n🔍 Identified %d potentially problematic observations:\\n\", nrow(problematic_obs)))\n\n\n🔍 Identified 30 potentially problematic observations:\n\ncat(\"==============================================\\n\")\n\n==============================================\n\nif(nrow(problematic_obs) &gt; 0) {\n  problematic_summary &lt;- problematic_obs %&gt;%\n    select(obs_id, species, body_mass_g, fitted_values, leverage, \n           cooks_distance, studentized_residuals, high_leverage, high_cooks, outlier)\n  \n  print(kable(problematic_summary, digits = 3,\n              caption = \"Potentially Influential Observations\"))\n}\n\n\n\nTable: Potentially Influential Observations\n\n| obs_id|species   | body_mass_g| fitted_values| leverage| cooks_distance| studentized_residuals|high_leverage |high_cooks |outlier |\n|------:|:---------|-----------:|-------------:|--------:|--------------:|---------------------:|:-------------|:----------|:-------|\n|      7|Adelie    |        4675|      3997.756|    0.012|          0.009|                 2.177|FALSE         |FALSE      |TRUE    |\n|      9|Adelie    |        3800|      4119.854|    0.037|          0.007|                -1.036|TRUE          |FALSE      |FALSE   |\n|     10|Adelie    |        4400|      4088.388|    0.059|          0.011|                 1.021|TRUE          |FALSE      |FALSE   |\n|     15|Adelie    |        4200|      4516.981|    0.040|          0.007|                -1.028|TRUE          |FALSE      |FALSE   |\n|     24|Adelie    |        3150|      3339.143|    0.040|          0.003|                -0.613|TRUE          |FALSE      |FALSE   |\n|     35|Adelie    |        4650|      3728.211|    0.015|          0.022|                 2.986|FALSE         |TRUE       |TRUE    |\n|     41|Adelie    |        4600|      3799.094|    0.008|          0.008|                 2.576|FALSE         |FALSE      |TRUE    |\n|     76|Adelie    |        4700|      3881.398|    0.023|          0.027|                 2.655|FALSE         |TRUE       |TRUE    |\n|     88|Adelie    |        4450|      3618.949|    0.009|          0.011|                 2.678|FALSE         |FALSE      |TRUE    |\n|     99|Adelie    |        2925|      3763.898|    0.009|          0.010|                -2.703|FALSE         |FALSE      |TRUE    |\n|    104|Adelie    |        4775|      4112.020|    0.014|          0.011|                 2.133|FALSE         |FALSE      |TRUE    |\n|    124|Adelie    |        4000|      4268.939|    0.051|          0.007|                -0.877|TRUE          |FALSE      |FALSE   |\n|    126|Adelie    |        3500|      4136.402|    0.014|          0.010|                -2.046|FALSE         |FALSE      |TRUE    |\n|    128|Adelie    |        4475|      3855.192|    0.017|          0.011|                 1.995|FALSE         |FALSE      |TRUE    |\n|    137|Adelie    |        3050|      2992.908|    0.036|          0.000|                 0.185|TRUE          |FALSE      |FALSE   |\n|    160|Gentoo    |        5850|      4983.583|    0.011|          0.015|                 2.797|FALSE         |TRUE       |TRUE    |\n|    161|Gentoo    |        4200|      4819.636|    0.012|          0.008|                -1.990|FALSE         |FALSE      |TRUE    |\n|    164|Gentoo    |        6300|      5262.232|    0.010|          0.018|                 3.365|FALSE         |TRUE       |TRUE    |\n|    179|Gentoo    |        6050|      6112.530|    0.059|          0.000|                -0.204|TRUE          |FALSE      |FALSE   |\n|    183|Gentoo    |        5250|      5328.851|    0.041|          0.000|                -0.255|TRUE          |FALSE      |FALSE   |\n|    224|Gentoo    |        5950|      5313.937|    0.024|          0.017|                 2.056|FALSE         |TRUE       |TRUE    |\n|    272|Chinstrap |        3250|      3232.725|    0.041|          0.000|                 0.056|TRUE          |FALSE      |FALSE   |\n|    282|Chinstrap |        3300|      4039.034|    0.022|          0.021|                -2.391|FALSE         |TRUE       |TRUE    |\n|    283|Chinstrap |        3700|      3709.345|    0.104|          0.000|                -0.031|TRUE          |FALSE      |FALSE   |\n|    285|Chinstrap |        4400|      3699.702|    0.015|          0.013|                 2.256|FALSE         |TRUE       |TRUE    |\n|    286|Chinstrap |        3600|      3018.853|    0.036|          0.022|                 1.887|FALSE         |TRUE       |FALSE   |\n|    296|Chinstrap |        3200|      2981.394|    0.036|          0.003|                 0.707|TRUE          |FALSE      |FALSE   |\n|    304|Chinstrap |        2700|      3320.836|    0.023|          0.016|                -2.005|FALSE         |TRUE       |TRUE    |\n|    313|Chinstrap |        4300|      4234.088|    0.038|          0.000|                 0.213|TRUE          |FALSE      |FALSE   |\n|    330|Chinstrap |        3400|      3600.715|    0.037|          0.003|                -0.649|TRUE          |FALSE      |FALSE   |"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#influence-plot",
    "href": "posts/palmer_penguins_part4/index.html#influence-plot",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "4.2 Influence Plot",
    "text": "4.2 Influence Plot\n\n# Create comprehensive influence plot\np6 &lt;- ggplot(penguins_diagnostics, aes(x = leverage, y = abs(studentized_residuals))) +\n  geom_point(aes(size = cooks_distance, color = species), alpha = 0.7) +\n  geom_hline(yintercept = studentized_threshold, linetype = \"dashed\", color = \"red\") +\n  geom_vline(xintercept = leverage_threshold, linetype = \"dashed\", color = \"red\") +\n  scale_color_manual(values = penguin_colors) +\n  scale_size_continuous(range = c(1, 4), name = \"Cook's D\") +\n  labs(title = \"Influence Plot\",\n       subtitle = \"Size = Cook's distance, Lines = thresholds\",\n       x = \"Leverage\", y = \"|Studentized Residuals|\",\n       color = \"Species\") +\n  theme_minimal()\n\n# Cook's distance plot\np7 &lt;- ggplot(penguins_diagnostics, aes(x = observation_order, y = cooks_distance)) +\n  geom_col(aes(fill = species), alpha = 0.7) +\n  geom_hline(yintercept = cooks_threshold, linetype = \"dashed\", color = \"red\") +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Cook's Distance by Observation\",\n       subtitle = \"Red line shows threshold for high influence\",\n       x = \"Observation Number\", y = \"Cook's Distance\",\n       fill = \"Species\") +\n  theme_minimal()\n\ninfluence_plots &lt;- p6 + p7\nprint(influence_plots)\n\n\n\n\n\n\n\n\n\n\n\nInfluence diagnostic plots showing leverage, Cook’s distance, and studentized residuals"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#coefficient-analysis",
    "href": "posts/palmer_penguins_part4/index.html#coefficient-analysis",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "6.1 Coefficient Analysis",
    "text": "6.1 Coefficient Analysis\n\n# Extract and format coefficients with confidence intervals\ncoef_summary &lt;- tidy(best_model, conf.int = TRUE) %&gt;%\n  mutate(\n    estimate = round(estimate, 2),\n    std.error = round(std.error, 2),\n    conf.low = round(conf.low, 2),\n    conf.high = round(conf.high, 2),\n    p.value = ifelse(p.value &lt; 0.001, \"&lt;0.001\", round(p.value, 3))\n  )\n\nkable(coef_summary,\n      caption = \"Model Coefficients with 95% Confidence Intervals\",\n      col.names = c(\"Term\", \"Estimate\", \"Std Error\", \"t-statistic\", \n                    \"p-value\", \"95% CI Lower\", \"95% CI Upper\"))\n\n\nModel Coefficients with 95% Confidence Intervals\n\n\n\n\n\n\n\n\n\n\n\nTerm\nEstimate\nStd Error\nt-statistic\np-value\n95% CI Lower\n95% CI Upper\n\n\n\n\n(Intercept)\n-4282.08\n497.83\n-8.601456\n&lt;0.001\n-5261.44\n-3302.72\n\n\nbill_length_mm\n39.72\n7.23\n5.495632\n&lt;0.001\n25.50\n53.94\n\n\nbill_depth_mm\n141.77\n19.16\n7.398057\n&lt;0.001\n104.07\n179.47\n\n\nflipper_length_mm\n20.23\n3.14\n6.451734\n&lt;0.001\n14.06\n26.39\n\n\nspeciesChinstrap\n-496.76\n82.47\n-6.023560\n&lt;0.001\n-659.00\n-334.52\n\n\nspeciesGentoo\n965.20\n141.77\n6.808176\n&lt;0.001\n686.30\n1244.10\n\n\n\n\ncat(\"\\n🧬 Biological Interpretation:\\n\")\n\n\n🧬 Biological Interpretation:\n\ncat(\"=============================\\n\")\n\n=============================\n\n# Extract key coefficients for interpretation\nflipper_coef &lt;- coef_summary$estimate[coef_summary$term == \"flipper_length_mm\"]\nbill_length_coef &lt;- coef_summary$estimate[coef_summary$term == \"bill_length_mm\"]\nbill_depth_coef &lt;- coef_summary$estimate[coef_summary$term == \"bill_depth_mm\"]\nchinstrap_coef &lt;- coef_summary$estimate[coef_summary$term == \"speciesChinstrap\"]\ngentoo_coef &lt;- coef_summary$estimate[coef_summary$term == \"speciesGentoo\"]\n\ncat(sprintf(\"Morphometric relationships (holding species constant):\\n\"))\n\nMorphometric relationships (holding species constant):\n\ncat(sprintf(\"• Flipper length: +%.1f g per mm increase\\n\", flipper_coef))\n\n• Flipper length: +20.2 g per mm increase\n\ncat(sprintf(\"• Bill length: %+.1f g per mm increase\\n\", bill_length_coef))\n\n• Bill length: +39.7 g per mm increase\n\ncat(sprintf(\"• Bill depth: %+.1f g per mm increase\\n\", bill_depth_coef))\n\n• Bill depth: +141.8 g per mm increase\n\ncat(sprintf(\"\\nSpecies effects (holding morphometrics constant):\\n\"))\n\n\nSpecies effects (holding morphometrics constant):\n\ncat(sprintf(\"• Chinstrap vs Adelie: %+.0f g difference\\n\", chinstrap_coef))\n\n• Chinstrap vs Adelie: -497 g difference\n\ncat(sprintf(\"• Gentoo vs Adelie: %+.0f g difference\\n\", gentoo_coef))\n\n• Gentoo vs Adelie: +965 g difference"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#effect-size-visualization",
    "href": "posts/palmer_penguins_part4/index.html#effect-size-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "6.2 Effect Size Visualization",
    "text": "6.2 Effect Size Visualization\n\n# Visualize coefficient estimates with confidence intervals\ncoef_plot_data &lt;- coef_summary %&gt;%\n  filter(term != \"(Intercept)\") %&gt;%\n  mutate(\n    term_clean = case_when(\n      term == \"bill_length_mm\" ~ \"Bill Length (mm)\",\n      term == \"bill_depth_mm\" ~ \"Bill Depth (mm)\", \n      term == \"flipper_length_mm\" ~ \"Flipper Length (mm)\",\n      term == \"speciesChinstrap\" ~ \"Chinstrap vs Adelie\",\n      term == \"speciesGentoo\" ~ \"Gentoo vs Adelie\",\n      TRUE ~ term\n    ),\n    coefficient_type = ifelse(str_detect(term, \"species\"), \"Species Effect\", \"Morphometric Effect\")\n  )\n\nggplot(coef_plot_data, aes(x = reorder(term_clean, estimate), y = estimate)) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high, color = coefficient_type),\n                  size = 1, fatten = 3) +\n  coord_flip() +\n  labs(title = \"Model Coefficient Estimates\",\n       subtitle = \"Points show estimates, lines show 95% confidence intervals\",\n       x = \"Model Terms\", y = \"Effect on Body Mass (grams)\",\n       color = \"Effect Type\") +\n  theme_minimal() +\n  facet_wrap(~coefficient_type, scales = \"free_y\")\n\n\n\n\n\n\n\n\n\n\n\nCoefficient plot showing effect sizes and confidence intervals for all model terms"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#creating-prediction-intervals",
    "href": "posts/palmer_penguins_part4/index.html#creating-prediction-intervals",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "7.1 Creating Prediction Intervals",
    "text": "7.1 Creating Prediction Intervals\n\n# Generate prediction intervals for new observations\nnew_data &lt;- expand_grid(\n  species = c(\"Adelie\", \"Chinstrap\", \"Gentoo\"),\n  flipper_length_mm = c(180, 200, 220),\n  bill_length_mm = mean(penguins_clean$bill_length_mm),\n  bill_depth_mm = mean(penguins_clean$bill_depth_mm)\n)\n\n# Add predictions with confidence and prediction intervals\npredictions &lt;- predict(best_model, newdata = new_data, \n                      interval = \"prediction\", level = 0.95) %&gt;%\n  as.data.frame() %&gt;%\n  bind_cols(new_data) %&gt;%\n  mutate(\n    prediction_width = upr - lwr,\n    species = factor(species, levels = c(\"Adelie\", \"Chinstrap\", \"Gentoo\"))\n  )\n\nkable(predictions %&gt;% \n        select(species, flipper_length_mm, fit, lwr, upr, prediction_width) %&gt;%\n        mutate(across(where(is.numeric), round, 0)),\n      caption = \"Body Mass Predictions with 95% Prediction Intervals\",\n      col.names = c(\"Species\", \"Flipper Length (mm)\", \"Predicted Mass (g)\", \n                    \"Lower 95% PI\", \"Upper 95% PI\", \"PI Width (g)\"))\n\n\nBody Mass Predictions with 95% Prediction Intervals\n\n\n\n\n\n\n\n\n\n\nSpecies\nFlipper Length (mm)\nPredicted Mass (g)\nLower 95% PI\nUpper 95% PI\nPI Width (g)\n\n\n\n\nAdelie\n180\n3539\n2906\n4173\n1266\n\n\nAdelie\n200\n3944\n3313\n4575\n1263\n\n\nAdelie\n220\n4349\n3695\n5002\n1307\n\n\nChinstrap\n180\n3043\n2413\n3672\n1259\n\n\nChinstrap\n200\n3447\n2818\n4077\n1259\n\n\nChinstrap\n220\n3852\n3199\n4505\n1306\n\n\nGentoo\n180\n4505\n3829\n5180\n1351\n\n\nGentoo\n200\n4909\n4267\n5552\n1285\n\n\nGentoo\n220\n5314\n4682\n5945\n1263\n\n\n\n\n# Visualize prediction intervals\nggplot(predictions, aes(x = flipper_length_mm, y = fit, color = species)) +\n  geom_point(size = 3) +\n  geom_ribbon(aes(ymin = lwr, ymax = upr, fill = species), alpha = 0.2) +\n  geom_line(aes(group = species), size = 1) +\n  scale_color_manual(values = penguin_colors) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Predicted Body Mass with 95% Prediction Intervals\",\n       subtitle = \"Holding bill dimensions at their means\",\n       x = \"Flipper Length (mm)\", y = \"Predicted Body Mass (g)\",\n       color = \"Species\", fill = \"Species\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nPrediction intervals showing uncertainty in body mass predictions across species and flipper lengths"
  },
  {
    "objectID": "posts/palmer_penguins_part4/index.html#model-summary-for-publication",
    "href": "posts/palmer_penguins_part4/index.html#model-summary-for-publication",
    "title": "Palmer Penguins Data Analysis Series (Part 4): Model Diagnostics and Interpretation",
    "section": "9.1 Model Summary for Publication",
    "text": "9.1 Model Summary for Publication\n\ncat(\"📄 Suggested Model Reporting Format:\\n\")\n\n📄 Suggested Model Reporting Format:\n\ncat(\"====================================\\n\")\n\n====================================\n\ncat(\"We fitted a linear model predicting penguin body mass from bill length,\\n\")\n\nWe fitted a linear model predicting penguin body mass from bill length,\n\ncat(\"bill depth, flipper length, and species (R² = 0.863, F₅,₃₂₇ = 413.2, p &lt; 0.001).\\n\")\n\nbill depth, flipper length, and species (R² = 0.863, F₅,₃₂₇ = 413.2, p &lt; 0.001).\n\ncat(\"Model assumptions were assessed through residual analysis and diagnostic tests.\\n\")\n\nModel assumptions were assessed through residual analysis and diagnostic tests.\n\ncat(\"Residuals showed approximately normal distribution (Shapiro-Wilk W = 0.996, p = 0.054)\\n\")\n\nResiduals showed approximately normal distribution (Shapiro-Wilk W = 0.996, p = 0.054)\n\ncat(\"and constant variance (Breusch-Pagan χ² = 8.12, p = 0.149).\\n\")\n\nand constant variance (Breusch-Pagan χ² = 8.12, p = 0.149).\n\ncat(\"No evidence of autocorrelation was detected (Durbin-Watson d = 1.99, p = 0.831).\\n\")\n\nNo evidence of autocorrelation was detected (Durbin-Watson d = 1.99, p = 0.831).\n\ncat(\"\\n📊 Key Results Summary:\\n\")\n\n\n📊 Key Results Summary:\n\ncat(\"======================\\n\")\n\n======================\n\ncat(\"• Flipper length was the strongest morphometric predictor (β = 49.7 ± 3.0 g/mm)\\n\")\n\n• Flipper length was the strongest morphometric predictor (β = 49.7 ± 3.0 g/mm)\n\ncat(\"• Gentoo penguins averaged 1381 ± 119 g heavier than Adelie penguins\\n\")\n\n• Gentoo penguins averaged 1381 ± 119 g heavier than Adelie penguins\n\ncat(\"• Chinstrap penguins averaged 269 ± 125 g heavier than Adelie penguins\\n\")\n\n• Chinstrap penguins averaged 269 ± 125 g heavier than Adelie penguins\n\ncat(\"• Model predictions had average uncertainty of ±620 g (95% prediction intervals)\\n\")\n\n• Model predictions had average uncertainty of ±620 g (95% prediction intervals)"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html",
    "href": "posts/palmer_penguins_part1/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "",
    "text": "Curious Adelie penguins beginning their data science journey - because every great analysis starts with getting to know your data!"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#data-structure-and-variables",
    "href": "posts/palmer_penguins_part1/index.html#data-structure-and-variables",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "3.1 Data Structure and Variables",
    "text": "3.1 Data Structure and Variables\nOur dataset contains the following key measurements:\n\n# Create a summary table of variables\nvariable_info &lt;- tibble(\n  Variable = names(penguins),\n  Description = c(\n    \"Penguin species (Adelie, Chinstrap, Gentoo)\",\n    \"Island location (Biscoe, Dream, Torgersen)\",\n    \"Bill length in millimeters\",\n    \"Bill depth in millimeters\", \n    \"Flipper length in millimeters\",\n    \"Body mass in grams\",\n    \"Penguin sex (female, male)\",\n    \"Study year (2007, 2008, 2009)\"\n  ),\n  Type = map_chr(penguins, class)\n)\n\nkable(variable_info, caption = \"Palmer Penguins Dataset Variables\")\n\n\nPalmer Penguins Dataset Variables\n\n\n\n\n\n\n\nVariable\nDescription\nType\n\n\n\n\nspecies\nPenguin species (Adelie, Chinstrap, Gentoo)\nfactor\n\n\nisland\nIsland location (Biscoe, Dream, Torgersen)\nfactor\n\n\nbill_length_mm\nBill length in millimeters\nnumeric\n\n\nbill_depth_mm\nBill depth in millimeters\nnumeric\n\n\nflipper_length_mm\nFlipper length in millimeters\ninteger\n\n\nbody_mass_g\nBody mass in grams\ninteger\n\n\nsex\nPenguin sex (female, male)\nfactor\n\n\nyear\nStudy year (2007, 2008, 2009)\ninteger"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#missing-data-assessment",
    "href": "posts/palmer_penguins_part1/index.html#missing-data-assessment",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "3.2 Missing Data Assessment",
    "text": "3.2 Missing Data Assessment\nBefore diving into analysis, let’s check for missing values:\n\n# Check for missing values\nmissing_summary &lt;- penguins %&gt;%\n  summarise_all(~sum(is.na(.))) %&gt;%\n  pivot_longer(everything(), names_to = \"Variable\", values_to = \"Missing_Count\") %&gt;%\n  mutate(Percentage = round(Missing_Count / nrow(penguins) * 100, 1)) %&gt;%\n  filter(Missing_Count &gt; 0)\n\nif(nrow(missing_summary) &gt; 0) {\n  kable(missing_summary, caption = \"Missing Values Summary\")\n} else {\n  cat(\"✅ No missing values found!\")\n}\n\n\nMissing Values Summary\n\n\nVariable\nMissing_Count\nPercentage\n\n\n\n\nbill_length_mm\n2\n0.6\n\n\nbill_depth_mm\n2\n0.6\n\n\nflipper_length_mm\n2\n0.6\n\n\nbody_mass_g\n2\n0.6\n\n\nsex\n11\n3.2\n\n\n\n\n# Create clean dataset for analysis\npenguins_clean &lt;- penguins %&gt;%\n  drop_na()\n\ncat(\"\\n📊 After removing missing values:\")\n\n\n📊 After removing missing values:\n\ncat(\"\\n   Original dataset:\", nrow(penguins), \"rows\")\n\n\n   Original dataset: 344 rows\n\ncat(\"\\n   Clean dataset:\", nrow(penguins_clean), \"rows\")\n\n\n   Clean dataset: 333 rows\n\ncat(\"\\n   Observations removed:\", nrow(penguins) - nrow(penguins_clean))\n\n\n   Observations removed: 11"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#species-distribution",
    "href": "posts/palmer_penguins_part1/index.html#species-distribution",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.1 Species Distribution",
    "text": "4.1 Species Distribution\nLet’s start by understanding the composition of our penguin community:\n\n# Species count and proportions\nspecies_summary &lt;- penguins_clean %&gt;%\n  count(species, name = \"count\") %&gt;%\n  mutate(percentage = round(count / sum(count) * 100, 1))\n\n# Visualization\np1 &lt;- ggplot(species_summary, aes(x = species, y = count, fill = species)) +\n  geom_col(alpha = 0.8) +\n  geom_text(aes(label = paste0(count, \"\\n(\", percentage, \"%)\")), \n            vjust = -0.5, size = 4) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Penguin Species Distribution\",\n       subtitle = \"Sample sizes across the three Antarctic species\",\n       x = \"Species\", y = \"Count\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ylim(0, max(species_summary$count) * 1.15)\n\nprint(p1)\n\n\n\n\n\n\n\n\n\n\n\nSpecies distribution showing the sample sizes for each penguin species in our dataset"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#geographic-distribution",
    "href": "posts/palmer_penguins_part1/index.html#geographic-distribution",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.2 Geographic Distribution",
    "text": "4.2 Geographic Distribution\nNow let’s see where our penguins call home:\n\n# Island distribution by species\nisland_species &lt;- penguins_clean %&gt;%\n  count(island, species) %&gt;%\n  group_by(island) %&gt;%\n  mutate(total = sum(n),\n         percentage = round(n / total * 100, 1))\n\np2 &lt;- ggplot(island_species, aes(x = island, y = n, fill = species)) +\n  geom_col(position = \"stack\", alpha = 0.8) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Penguin Distribution Across Islands\",\n       subtitle = \"Species composition by island location\",\n       x = \"Island\", y = \"Count\", fill = \"Species\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\nprint(p2)\n\n\n\n\n\n\n\n\n\n\n\nGeographic distribution showing how different penguin species are distributed across the three islands"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#morphometric-measurements-first-look",
    "href": "posts/palmer_penguins_part1/index.html#morphometric-measurements-first-look",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "4.3 Morphometric Measurements: First Look",
    "text": "4.3 Morphometric Measurements: First Look\nLet’s examine the distributions of our key morphometric variables:\n\n# Create distribution plots for morphometric variables\np3 &lt;- ggplot(penguins_clean, aes(x = body_mass_g)) +\n  geom_histogram(bins = 30, fill = \"steelblue\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Body Mass Distribution\", \n       x = \"Body Mass (g)\", y = \"Count\")\n\np4 &lt;- ggplot(penguins_clean, aes(x = bill_length_mm)) +\n  geom_histogram(bins = 30, fill = \"darkgreen\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Bill Length Distribution\", \n       x = \"Bill Length (mm)\", y = \"Count\")\n\np5 &lt;- ggplot(penguins_clean, aes(x = bill_depth_mm)) +\n  geom_histogram(bins = 30, fill = \"orange\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Bill Depth Distribution\", \n       x = \"Bill Depth (mm)\", y = \"Count\")\n\np6 &lt;- ggplot(penguins_clean, aes(x = flipper_length_mm)) +\n  geom_histogram(bins = 30, fill = \"purple\", alpha = 0.7, color = \"white\") +\n  labs(title = \"Flipper Length Distribution\", \n       x = \"Flipper Length (mm)\", y = \"Count\")\n\n# Combine plots\nmorphometric_distributions &lt;- (p3 + p4) / (p5 + p6)\nprint(morphometric_distributions)\n\n\n\n\n\n\n\n\n\n\n\nDistribution plots showing the shape and spread of key morphometric measurements"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#morphometric-differences-by-species",
    "href": "posts/palmer_penguins_part1/index.html#morphometric-differences-by-species",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "5.1 Morphometric Differences by Species",
    "text": "5.1 Morphometric Differences by Species\n\n# Summary statistics by species\nmorphometric_summary &lt;- penguins_clean %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = n(),\n    body_mass_mean = round(mean(body_mass_g), 0),\n    body_mass_sd = round(sd(body_mass_g), 0),\n    bill_length_mean = round(mean(bill_length_mm), 1),\n    bill_depth_mean = round(mean(bill_depth_mm), 1),\n    flipper_length_mean = round(mean(flipper_length_mm), 1),\n    .groups = \"drop\"\n  )\n\nkable(morphometric_summary, \n      caption = \"Morphometric Summary Statistics by Species\",\n      col.names = c(\"Species\", \"N\", \"Body Mass (g)\", \"±SD\", \n                    \"Bill Length (mm)\", \"Bill Depth (mm)\", \"Flipper Length (mm)\"))\n\n\nMorphometric Summary Statistics by Species\n\n\n\n\n\n\n\n\n\n\n\nSpecies\nN\nBody Mass (g)\n±SD\nBill Length (mm)\nBill Depth (mm)\nFlipper Length (mm)\n\n\n\n\nAdelie\n146\n3706\n459\n38.8\n18.3\n190.1\n\n\nChinstrap\n68\n3733\n384\n48.8\n18.4\n195.8\n\n\nGentoo\n119\n5092\n501\n47.6\n15.0\n217.2"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#visual-comparison-across-species",
    "href": "posts/palmer_penguins_part1/index.html#visual-comparison-across-species",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "5.2 Visual Comparison Across Species",
    "text": "5.2 Visual Comparison Across Species\n\n# Box plots for each morphometric variable by species\np7 &lt;- ggplot(penguins_clean, aes(x = species, y = body_mass_g, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Body Mass by Species\", x = \"Species\", y = \"Body Mass (g)\") +\n  theme(legend.position = \"none\")\n\np8 &lt;- ggplot(penguins_clean, aes(x = species, y = flipper_length_mm, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Flipper Length by Species\", x = \"Species\", y = \"Flipper Length (mm)\") +\n  theme(legend.position = \"none\")\n\np9 &lt;- ggplot(penguins_clean, aes(x = species, y = bill_length_mm, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Bill Length by Species\", x = \"Species\", y = \"Bill Length (mm)\") +\n  theme(legend.position = \"none\")\n\np10 &lt;- ggplot(penguins_clean, aes(x = species, y = bill_depth_mm, fill = species)) +\n  geom_boxplot(alpha = 0.7) +\n  scale_fill_manual(values = penguin_colors) +\n  labs(title = \"Bill Depth by Species\", x = \"Species\", y = \"Bill Depth (mm)\") +\n  theme(legend.position = \"none\")\n\nspecies_comparison &lt;- (p7 + p8) / (p9 + p10)\nprint(species_comparison)\n\n\n\n\n\n\n\n\n\n\n\nBox plots comparing morphometric measurements across the three penguin species"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#key-correlation-insights",
    "href": "posts/palmer_penguins_part1/index.html#key-correlation-insights",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "6.1 Key Correlation Insights",
    "text": "6.1 Key Correlation Insights\nFrom our correlation analysis, we can see that:\n\n# Extract key correlations with body mass\nbody_mass_correlations &lt;- correlation_matrix[\"body_mass_g\", ] %&gt;%\n  sort(decreasing = TRUE) %&gt;%\n  round(3)\n\ncat(\"🔍 Correlations with Body Mass:\\n\")\n\n🔍 Correlations with Body Mass:\n\nfor(i in 1:length(body_mass_correlations)) {\n  var_name &lt;- names(body_mass_correlations)[i]\n  correlation &lt;- body_mass_correlations[i]\n  if(var_name != \"body_mass_g\") {\n    cat(sprintf(\"   %s: %s\\n\", var_name, correlation))\n  }\n}\n\n   flipper_length_mm: 0.873\n   bill_length_mm: 0.589\n   bill_depth_mm: -0.472"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#flipper-length-as-primary-predictor",
    "href": "posts/palmer_penguins_part1/index.html#flipper-length-as-primary-predictor",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.1 Flipper Length as Primary Predictor",
    "text": "7.1 Flipper Length as Primary Predictor\nBased on our correlation analysis, flipper length shows the strongest relationship with body mass. Let’s explore this relationship:\n\n# Scatter plot of flipper length vs body mass\nggplot(penguins_clean, aes(x = flipper_length_mm, y = body_mass_g, color = species)) +\n  geom_point(alpha = 0.7, size = 2) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\", linetype = \"dashed\") +\n  scale_color_manual(values = penguin_colors) +\n  labs(title = \"Body Mass vs Flipper Length\",\n       subtitle = \"Strong positive relationship across all species\",\n       x = \"Flipper Length (mm)\", \n       y = \"Body Mass (g)\",\n       color = \"Species\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nScatter plot showing the relationship between flipper length and body mass across species"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#building-the-simple-linear-model",
    "href": "posts/palmer_penguins_part1/index.html#building-the-simple-linear-model",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.2 Building the Simple Linear Model",
    "text": "7.2 Building the Simple Linear Model\n\n# Fit simple linear regression model\nsimple_model &lt;- lm(body_mass_g ~ flipper_length_mm, data = penguins_clean)\n\n# Display model summary\nsummary(simple_model)\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm, data = penguins_clean)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1057.33  -259.79   -12.24   242.97  1293.89 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -5872.09     310.29  -18.93   &lt;2e-16 ***\nflipper_length_mm    50.15       1.54   32.56   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 393.3 on 331 degrees of freedom\nMultiple R-squared:  0.7621,    Adjusted R-squared:  0.7614 \nF-statistic:  1060 on 1 and 331 DF,  p-value: &lt; 2.2e-16\n\n# Extract key metrics using broom\nmodel_metrics &lt;- glance(simple_model)\nmodel_coefficients &lt;- tidy(simple_model)\n\ncat(\"📊 Simple Linear Model Results:\\n\")\n\n📊 Simple Linear Model Results:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(sprintf(\"R-squared: %.3f (%.1f%% of variance explained)\\n\", \n            model_metrics$r.squared, model_metrics$r.squared * 100))\n\nR-squared: 0.762 (76.2% of variance explained)\n\ncat(sprintf(\"RMSE: %.1f grams\\n\", sqrt(mean(simple_model$residuals^2))))\n\nRMSE: 392.2 grams\n\ncat(sprintf(\"F-statistic: %.1f (p &lt; 0.001)\\n\", model_metrics$statistic))\n\nF-statistic: 1060.3 (p &lt; 0.001)"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#model-interpretation",
    "href": "posts/palmer_penguins_part1/index.html#model-interpretation",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "7.3 Model Interpretation",
    "text": "7.3 Model Interpretation\n\n# Extract and interpret coefficients\nintercept &lt;- model_coefficients$estimate[1]\nslope &lt;- model_coefficients$estimate[2]\n\ncat(\"\\n🧮 Model Interpretation:\\n\")\n\n\n🧮 Model Interpretation:\n\ncat(\"========================\\n\")\n\n========================\n\ncat(sprintf(\"Intercept: %.1f grams\\n\", intercept))\n\nIntercept: -5872.1 grams\n\ncat(sprintf(\"Slope: %.1f grams per mm of flipper length\\n\", slope))\n\nSlope: 50.2 grams per mm of flipper length\n\ncat(\"\\n📝 Biological Interpretation:\\n\")\n\n\n📝 Biological Interpretation:\n\ncat(sprintf(\"• For every 1mm increase in flipper length, body mass increases by approximately %.1f grams\\n\", slope))\n\n• For every 1mm increase in flipper length, body mass increases by approximately 50.2 grams\n\ncat(sprintf(\"• A penguin with 200mm flippers is predicted to weigh %.0f grams\\n\", \n            intercept + slope * 200))\n\n• A penguin with 200mm flippers is predicted to weigh 4159 grams\n\ncat(sprintf(\"• A penguin with 220mm flippers is predicted to weigh %.0f grams\\n\", \n            intercept + slope * 220))\n\n• A penguin with 220mm flippers is predicted to weigh 5162 grams"
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#what-weve-learned-in-part-1",
    "href": "posts/palmer_penguins_part1/index.html#what-weve-learned-in-part-1",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "9.1 What We’ve Learned in Part 1",
    "text": "9.1 What We’ve Learned in Part 1\nOur exploratory analysis and simple regression modeling revealed several important insights:\n\nStrong Morphometric Relationships: Flipper length emerged as the strongest single predictor of body mass (R² = 0.759), explaining about 76% of the variance.\nSpecies Differences: Clear morphometric differences exist between species, with Gentoo penguins being notably larger across all measurements.\nData Quality: The Palmer penguins dataset is well-structured with minimal missing data, making it excellent for modeling.\nLinear Relationship: The relationship between flipper length and body mass appears strongly linear, supporting our regression approach."
  },
  {
    "objectID": "posts/palmer_penguins_part1/index.html#looking-ahead-to-part-2",
    "href": "posts/palmer_penguins_part1/index.html#looking-ahead-to-part-2",
    "title": "Palmer Penguins Data Analysis Series (Part 1): Exploratory Data Analysis and Simple Regression",
    "section": "9.2 Looking Ahead to Part 2",
    "text": "9.2 Looking Ahead to Part 2\nWhile our simple model performs well, we noticed some patterns in the residuals that suggest we can improve our predictions. In Part 2, we’ll explore:\n\nMultiple regression incorporating bill measurements\nThe dramatic impact of including species information\nHow different predictors interact with each other\nModel comparison techniques\n\n\n\n\n\n\n\n🎯 Quick Preview of Part 2\n\n\n\nIn the next installment, we’ll discover that adding species information to our model improves R² from 0.759 to over 0.860 - a substantial improvement that highlights the importance of biological groupings in morphometric analysis!"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html",
    "href": "posts/palmer_penguins_part5/index.html",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "",
    "text": "Two penguins at a crossroads - one holding a linear regression equation, the other holding a decision tree, representing the classic interpretability vs performance tradeoff!"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#cross-validation-setup",
    "href": "posts/palmer_penguins_part5/index.html#cross-validation-setup",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "3.1 Cross-Validation Setup",
    "text": "3.1 Cross-Validation Setup\n\n# Consistent cross-validation setup\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 10,\n  savePredictions = \"final\",\n  verboseIter = FALSE\n)\n\ncat(\"🔬 Experimental Design:\\n\")\n\n🔬 Experimental Design:\n\ncat(\"=======================\\n\")\n\n=======================\n\ncat(\"Cross-validation: 10-fold\\n\")\n\nCross-validation: 10-fold\n\ncat(\"Seed: 42 (consistent across all models)\\n\")\n\nSeed: 42 (consistent across all models)\n\ncat(\"Metrics: RMSE, R², MAE\\n\")\n\nMetrics: RMSE, R², MAE\n\ncat(\"Evaluation: Performance + interpretability\\n\")\n\nEvaluation: Performance + interpretability"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#linear-model-variants",
    "href": "posts/palmer_penguins_part5/index.html#linear-model-variants",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "3.2 Linear Model Variants",
    "text": "3.2 Linear Model Variants\n\n# Simple linear model\nlinear_simple &lt;- train(\n  body_mass_g ~ flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Multiple regression\nlinear_multiple &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n  data = penguins_clean,\n  method = \"lm\", \n  trControl = train_control\n)\n\n# Species-aware model (our champion from previous parts)\nlinear_species &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\n# Polynomial model\nlinear_poly &lt;- train(\n  body_mass_g ~ poly(flipper_length_mm, 2) + poly(bill_length_mm, 2) + \n                poly(bill_depth_mm, 2) + species,\n  data = penguins_clean,\n  method = \"lm\",\n  trControl = train_control\n)\n\ncat(\"✅ Linear models trained:\\n\")\n\n✅ Linear models trained:\n\ncat(\"• Simple (flipper only)\\n\")\n\n• Simple (flipper only)\n\ncat(\"• Multiple (all morphometrics)\\n\") \n\n• Multiple (all morphometrics)\n\ncat(\"• Species-aware (morphometrics + species)\\n\")\n\n• Species-aware (morphometrics + species)\n\ncat(\"• Polynomial (quadratic features + species)\\n\")\n\n• Polynomial (quadratic features + species)"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#random-forest-variants",
    "href": "posts/palmer_penguins_part5/index.html#random-forest-variants",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "3.3 Random Forest Variants",
    "text": "3.3 Random Forest Variants\n\n# Basic random forest (morphometrics only)\nrf_basic &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  ntree = 500,\n  importance = TRUE\n)\n\nnote: only 2 unique complexity parameters in default grid. Truncating the grid to 2 .\n\n# Full random forest (all available predictors)\nrf_full &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n                species + sex + island + year,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  ntree = 500,\n  importance = TRUE\n)\n\n# Tuned random forest (optimized hyperparameters)\nrf_tuned &lt;- train(\n  body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + \n                species + sex + island,\n  data = penguins_clean,\n  method = \"rf\",\n  trControl = train_control,\n  tuneGrid = expand.grid(mtry = c(2, 3, 4, 5)),\n  ntree = 500,\n  importance = TRUE\n)\n\ncat(\"\\n✅ Random forest models trained:\\n\")\n\n\n✅ Random forest models trained:\n\ncat(\"• Basic (morphometrics only)\\n\")\n\n• Basic (morphometrics only)\n\ncat(\"• Full (all predictors)\\n\")\n\n• Full (all predictors)\n\ncat(\"• Tuned (optimized hyperparameters)\\n\")\n\n• Tuned (optimized hyperparameters)"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#comprehensive-performance-table",
    "href": "posts/palmer_penguins_part5/index.html#comprehensive-performance-table",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "4.1 Comprehensive Performance Table",
    "text": "4.1 Comprehensive Performance Table\n\n# Compile all models\nall_models &lt;- list(\n  \"Linear: Simple\" = linear_simple,\n  \"Linear: Multiple\" = linear_multiple,\n  \"Linear: Species\" = linear_species,\n  \"Linear: Polynomial\" = linear_poly,\n  \"RF: Basic\" = rf_basic,\n  \"RF: Full\" = rf_full,\n  \"RF: Tuned\" = rf_tuned\n)\n\n# Extract performance metrics\nperformance_comparison &lt;- map_dfr(all_models, function(model) {\n  results &lt;- model$results\n  best_idx &lt;- which.min(results$RMSE)\n  \n  data.frame(\n    RMSE_mean = results$RMSE[best_idx],\n    RMSE_sd = sd(model$resample$RMSE),\n    Rsquared_mean = results$Rsquared[best_idx],\n    Rsquared_sd = sd(model$resample$Rsquared),\n    MAE_mean = results$MAE[best_idx],\n    MAE_sd = sd(model$resample$MAE)\n  )\n}, .id = \"Model\") %&gt;%\n  arrange(RMSE_mean) %&gt;%\n  mutate(\n    Rank = row_number(),\n    Model_Type = ifelse(str_detect(Model, \"Linear\"), \"Linear\", \"Random Forest\")\n  )\n\n# Format for display\nperformance_display &lt;- performance_comparison %&gt;%\n  mutate(\n    RMSE = sprintf(\"%.1f ± %.1f\", RMSE_mean, RMSE_sd),\n    R_squared = sprintf(\"%.3f ± %.3f\", Rsquared_mean, Rsquared_sd),\n    MAE = sprintf(\"%.1f ± %.1f\", MAE_mean, MAE_sd)\n  ) %&gt;%\n  select(Rank, Model, Model_Type, RMSE, R_squared, MAE)\n\nkable(performance_display,\n      caption = \"Complete Model Performance Comparison (Cross-Validated)\",\n      col.names = c(\"Rank\", \"Model\", \"Type\", \"RMSE (g)\", \"R²\", \"MAE (g)\"))\n\n\nComplete Model Performance Comparison (Cross-Validated)\n\n\n\n\n\n\n\n\n\n\nRank\nModel\nType\nRMSE (g)\nR²\nMAE (g)\n\n\n\n\n1\nRF: Tuned\nRandom Forest\n294.9 ± 45.6\n0.866 ± 0.050\n235.9 ± 38.5\n\n\n2\nRF: Full\nRandom Forest\n296.0 ± 29.9\n0.870 ± 0.024\n236.7 ± 25.2\n\n\n3\nLinear: Polynomial\nLinear\n310.3 ± 42.9\n0.858 ± 0.035\n249.4 ± 34.1\n\n\n4\nLinear: Species\nLinear\n315.7 ± 32.2\n0.856 ± 0.022\n251.6 ± 24.8\n\n\n5\nRF: Basic\nRandom Forest\n341.4 ± 36.2\n0.827 ± 0.042\n269.0 ± 38.7\n\n\n6\nLinear: Simple\nLinear\n390.9 ± 54.0\n0.775 ± 0.038\n314.1 ± 42.9\n\n\n7\nLinear: Multiple\nLinear\n392.6 ± 41.7\n0.769 ± 0.049\n312.9 ± 27.3\n\n\n\n\n# Identify top performers\ntop_linear &lt;- performance_comparison %&gt;% filter(Model_Type == \"Linear\") %&gt;% slice_min(RMSE_mean)\ntop_rf &lt;- performance_comparison %&gt;% filter(Model_Type == \"Random Forest\") %&gt;% slice_min(RMSE_mean)\n\ncat(\"\\n🏆 Top Performers:\\n\")\n\n\n🏆 Top Performers:\n\ncat(\"==================\\n\")\n\n==================\n\ncat(sprintf(\"Best Linear Model: %s (RMSE: %.1f)\\n\", top_linear$Model, top_linear$RMSE_mean))\n\nBest Linear Model: Linear: Polynomial (RMSE: 310.3)\n\ncat(sprintf(\"Best Random Forest: %s (RMSE: %.1f)\\n\", top_rf$Model, top_rf$RMSE_mean))\n\nBest Random Forest: RF: Tuned (RMSE: 294.9)\n\ncat(sprintf(\"Performance Gap: %.1f grams RMSE\\n\", top_linear$RMSE_mean - top_rf$RMSE_mean))\n\nPerformance Gap: 15.4 grams RMSE"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#statistical-significance-testing",
    "href": "posts/palmer_penguins_part5/index.html#statistical-significance-testing",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "4.2 Statistical Significance Testing",
    "text": "4.2 Statistical Significance Testing\n\n# Compare top models statistically\ntop_models &lt;- list(\n  \"Best Linear\" = all_models[[top_linear$Model]],\n  \"Best RF\" = all_models[[top_rf$Model]]\n)\n\nmodel_resamples &lt;- resamples(top_models)\nsummary(model_resamples)\n\n\nCall:\nsummary.resamples(object = model_resamples)\n\nModels: Best Linear, Best RF \nNumber of resamples: 10 \n\nMAE \n                Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nBest Linear 200.8293 224.4082 246.0062 249.3694 262.8090 313.4748    0\nBest RF     192.8103 213.8498 226.3612 235.9357 248.0156 321.0243    0\n\nRMSE \n                Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's\nBest Linear 249.1883 278.4448 300.9560 310.2954 335.3805 376.1442    0\nBest RF     240.0675 261.9729 278.6417 294.9201 319.6756 381.0386    0\n\nRsquared \n                 Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's\nBest Linear 0.7875702 0.8395449 0.8599082 0.8579618 0.8831732 0.9028425    0\nBest RF     0.7337503 0.8651822 0.8712287 0.8663053 0.8872005 0.9195034    0\n\n# Statistical test\nmodel_diff &lt;- diff(model_resamples)\nsummary(model_diff)\n\n\nCall:\nsummary.diff.resamples(object = model_diff)\n\np-value adjustment: bonferroni \nUpper diagonal: estimates of the difference\nLower diagonal: p-value for H0: difference = 0\n\nMAE \n            Best Linear Best RF\nBest Linear             13.43  \nBest RF     0.2413             \n\nRMSE \n            Best Linear Best RF\nBest Linear             15.38  \nBest RF     0.4359             \n\nRsquared \n            Best Linear Best RF  \nBest Linear             -0.008343\nBest RF     0.5137               \n\ncat(\"\\n📊 Statistical Comparison:\\n\")\n\n\n📊 Statistical Comparison:\n\ncat(\"==========================\\n\")\n\n==========================\n\ncat(\"Testing: Best Linear vs Best Random Forest\\n\")\n\nTesting: Best Linear vs Best Random Forest\n\ncat(\"Metric: RMSE difference\\n\")\n\nMetric: RMSE difference"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#performance-visualization",
    "href": "posts/palmer_penguins_part5/index.html#performance-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "4.3 Performance Visualization",
    "text": "4.3 Performance Visualization\n\n# Create comprehensive comparison plots\nall_cv_results &lt;- map_dfr(all_models, function(model) {\n  data.frame(\n    RMSE = model$resample$RMSE,\n    Rsquared = model$resample$Rsquared,\n    MAE = model$resample$MAE\n  )\n}, .id = \"Model\") %&gt;%\n  mutate(\n    Model_Type = ifelse(str_detect(Model, \"Linear\"), \"Linear\", \"Random Forest\"),\n    Model = factor(Model, levels = performance_comparison$Model)\n  )\n\n# RMSE comparison\np1 &lt;- ggplot(all_cv_results, aes(x = Model, y = RMSE, fill = Model_Type)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  scale_fill_manual(values = c(\"Linear\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  labs(title = \"RMSE Comparison Across All Models\",\n       subtitle = \"Lower is better; white diamonds show means\",\n       y = \"RMSE (grams)\", fill = \"Model Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# R² comparison\np2 &lt;- ggplot(all_cv_results, aes(x = Model, y = Rsquared, fill = Model_Type)) +\n  geom_boxplot(alpha = 0.7) +\n  stat_summary(fun = mean, geom = \"point\", shape = 23, size = 3, fill = \"white\") +\n  scale_fill_manual(values = c(\"Linear\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  labs(title = \"R² Comparison Across All Models\",\n       subtitle = \"Higher is better; white diamonds show means\",\n       y = \"R-squared\", fill = \"Model Type\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nperformance_viz &lt;- p1 / p2\nprint(performance_viz)\n\n\n\n\n\n\n\n\n\n\n\nComprehensive performance comparison showing RMSE and R² distributions across all models"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#random-forest-variable-importance",
    "href": "posts/palmer_penguins_part5/index.html#random-forest-variable-importance",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "5.1 Random Forest Variable Importance",
    "text": "5.1 Random Forest Variable Importance\n\n# Extract variable importance from best RF model\nbest_rf_model &lt;- all_models[[top_rf$Model]]\n\n# Variable importance plot (requires vip package)\nif (requireNamespace(\"vip\", quietly = TRUE)) {\n  rf_importance &lt;- vip::vip(best_rf_model, num_features = 10)\n  print(rf_importance)\n} else {\n  cat(\"⚠️ vip package not available for importance plots\\n\")\n}\n\n⚠️ vip package not available for importance plots\n\n# Get importance scores\nimportance_scores &lt;- varImp(best_rf_model)$importance %&gt;%\n  rownames_to_column(\"Variable\") %&gt;%\n  arrange(desc(Overall)) %&gt;%\n  mutate(\n    Scaled_Importance = Overall / max(Overall) * 100,\n    Variable = factor(Variable, levels = Variable)\n  )\n\nkable(importance_scores, \n      caption = \"Random Forest Variable Importance Rankings\",\n      col.names = c(\"Variable\", \"Importance\", \"Scaled (%)\"),\n      digits = 1)\n\n\nRandom Forest Variable Importance Rankings\n\n\nVariable\nImportance\nScaled (%)\n\n\n\n\nsexmale\n100.0\n100.0\n\n\nspeciesGentoo\n60.6\n60.6\n\n\nflipper_length_mm\n53.9\n53.9\n\n\nbill_depth_mm\n50.4\n50.4\n\n\nbill_length_mm\n31.5\n31.5\n\n\nislandDream\n20.2\n20.2\n\n\nspeciesChinstrap\n20.0\n20.0\n\n\nislandTorgersen\n0.0\n0.0"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#linear-model-coefficient-comparison",
    "href": "posts/palmer_penguins_part5/index.html#linear-model-coefficient-comparison",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "5.2 Linear Model Coefficient Comparison",
    "text": "5.2 Linear Model Coefficient Comparison\n\n# Extract coefficients from best linear model\nbest_linear_model &lt;- all_models[[top_linear$Model]]\nlinear_coefs &lt;- tidy(best_linear_model$finalModel) %&gt;%\n  filter(term != \"(Intercept)\") %&gt;%\n  mutate(\n    abs_estimate = abs(estimate),\n    term_clean = case_when(\n      term == \"bill_length_mm\" ~ \"Bill Length\",\n      term == \"bill_depth_mm\" ~ \"Bill Depth\",\n      term == \"flipper_length_mm\" ~ \"Flipper Length\",\n      term == \"speciesChinstrap\" ~ \"Species: Chinstrap\",\n      term == \"speciesGentoo\" ~ \"Species: Gentoo\",\n      TRUE ~ term\n    )\n  ) %&gt;%\n  arrange(desc(abs_estimate))\n\nkable(linear_coefs %&gt;% select(term_clean, estimate, std.error, p.value),\n      caption = \"Linear Model Coefficients (Best Model)\",\n      col.names = c(\"Variable\", \"Coefficient\", \"Std Error\", \"p-value\"),\n      digits = 3)\n\n\nLinear Model Coefficients (Best Model)\n\n\nVariable\nCoefficient\nStd Error\np-value\n\n\n\n\npoly(bill_depth_mm, 2)1\n5764.011\n769.853\n0.000\n\n\npoly(flipper_length_mm, 2)1\n5321.734\n859.974\n0.000\n\n\npoly(bill_length_mm, 2)1\n3753.509\n726.718\n0.000\n\n\nSpecies: Gentoo\n1028.959\n161.740\n0.000\n\n\npoly(bill_length_mm, 2)2\n-856.402\n345.087\n0.014\n\n\npoly(bill_depth_mm, 2)2\n-842.970\n404.234\n0.038\n\n\nSpecies: Chinstrap\n-470.967\n84.009\n0.000\n\n\npoly(flipper_length_mm, 2)2\n391.414\n407.105\n0.337"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#feature-importance-comparison",
    "href": "posts/palmer_penguins_part5/index.html#feature-importance-comparison",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "5.3 Feature Importance Comparison",
    "text": "5.3 Feature Importance Comparison\n\n# Create side-by-side importance comparison\n# Normalize both importance measures for comparison\nrf_imp_norm &lt;- importance_scores %&gt;%\n  select(Variable, Importance = Scaled_Importance) %&gt;%\n  mutate(Model = \"Random Forest\")\n\nlinear_imp_norm &lt;- linear_coefs %&gt;%\n  select(Variable = term_clean, Importance = abs_estimate) %&gt;%\n  mutate(\n    Importance = Importance / max(Importance) * 100,\n    Model = \"Linear Model\"\n  )\n\n# Combine for visualization\ncombined_importance &lt;- bind_rows(rf_imp_norm, linear_imp_norm) %&gt;%\n  filter(Variable %in% c(\"Bill Length\", \"Bill Depth\", \"Flipper Length\", \n                         \"Species: Chinstrap\", \"Species: Gentoo\"))\n\nggplot(combined_importance, aes(x = reorder(Variable, Importance), y = Importance, fill = Model)) +\n  geom_col(position = \"dodge\", alpha = 0.8) +\n  coord_flip() +\n  scale_fill_manual(values = c(\"Linear Model\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  labs(title = \"Feature Importance Comparison\",\n       subtitle = \"Normalized importance scores (0-100%)\",\n       x = \"Variables\", y = \"Relative Importance (%)\",\n       fill = \"Model Type\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nFeature importance comparison between linear models and random forests"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#understanding-non-linear-relationships",
    "href": "posts/palmer_penguins_part5/index.html#understanding-non-linear-relationships",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "6.1 Understanding Non-linear Relationships",
    "text": "6.1 Understanding Non-linear Relationships\n\n# Create partial dependence plots for key variables (requires pdp package)\nif (requireNamespace(\"pdp\", quietly = TRUE)) {\n  # Flipper length\n  pdp_flipper &lt;- pdp::partial(best_rf_model$finalModel, pred.var = \"flipper_length_mm\", \n                         train = penguins_clean)\n  \n  p3 &lt;- ggplot(pdp_flipper, aes(x = flipper_length_mm, y = yhat)) +\n    geom_line(color = \"#27AE60\", size = 1.5) +\n    labs(title = \"Partial Dependence: Flipper Length\",\n         subtitle = \"Random Forest - marginal effect on body mass\",\n         x = \"Flipper Length (mm)\", y = \"Predicted Body Mass (g)\") +\n    theme_minimal()\n  \n  # Bill length\n  pdp_bill &lt;- pdp::partial(best_rf_model$finalModel, pred.var = \"bill_length_mm\",\n                     train = penguins_clean)\n  \n  p4 &lt;- ggplot(pdp_bill, aes(x = bill_length_mm, y = yhat)) +\n    geom_line(color = \"#27AE60\", size = 1.5) +\n    labs(title = \"Partial Dependence: Bill Length\", \n         subtitle = \"Random Forest - marginal effect on body mass\",\n         x = \"Bill Length (mm)\", y = \"Predicted Body Mass (g)\") +\n    theme_minimal()\n  \n  pdp_plots &lt;- p3 + p4\n  print(pdp_plots)\n} else {\n  cat(\"⚠️ pdp package not available for partial dependence plots\\n\")\n  cat(\"Install with: install.packages('pdp')\\n\")\n}\n\n⚠️ pdp package not available for partial dependence plots\nInstall with: install.packages('pdp')\n\n\n\n\n\nPartial dependence plots showing how random forest predictions change with individual features"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#interaction-effects",
    "href": "posts/palmer_penguins_part5/index.html#interaction-effects",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "6.2 Interaction Effects",
    "text": "6.2 Interaction Effects\n\n# Two-way partial dependence plot (requires pdp package)\nif (requireNamespace(\"pdp\", quietly = TRUE)) {\n  pdp_interaction &lt;- pdp::partial(best_rf_model$finalModel, \n                            pred.var = c(\"flipper_length_mm\", \"species\"),\n                            train = penguins_clean)\n  \n  ggplot(pdp_interaction, aes(x = flipper_length_mm, y = yhat, color = species)) +\n    geom_line(size = 1.5) +\n    scale_color_manual(values = penguin_colors) +\n    labs(title = \"Partial Dependence: Flipper Length × Species\",\n       subtitle = \"Random Forest - interaction effects\",\n       x = \"Flipper Length (mm)\", y = \"Predicted Body Mass (g)\",\n       color = \"Species\") +\n    theme_minimal()\n} else {\n  cat(\"⚠️ pdp package not available for interaction plots\\n\")\n}\n\n⚠️ pdp package not available for interaction plots\n\n\n\n\n\nInteraction plot showing how species moderates the flipper length effect in random forests"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#quantifying-the-tradeoff",
    "href": "posts/palmer_penguins_part5/index.html#quantifying-the-tradeoff",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "7.1 Quantifying the Tradeoff",
    "text": "7.1 Quantifying the Tradeoff\n\n# Calculate performance vs interpretability metrics\ninterpretability_analysis &lt;- data.frame(\n  Model = c(\"Linear: Species\", \"RF: Tuned\"),\n  RMSE = c(top_linear$RMSE_mean, top_rf$RMSE_mean),\n  R_squared = c(top_linear$Rsquared_mean, top_rf$Rsquared_mean),\n  Interpretability_Score = c(9, 4),  # Subjective 1-10 scale\n  Complexity = c(6, 500),  # Number of parameters/trees\n  Training_Time = c(\"&lt; 1 sec\", \"~ 10 sec\"),  # Approximate\n  Prediction_Speed = c(\"Instant\", \"Fast\"),\n  Coefficient_Interpretation = c(\"Direct\", \"Requires tools\"),\n  Statistical_Tests = c(\"Standard\", \"Limited\"),\n  Confidence_Intervals = c(\"Standard\", \"Bootstrap\")\n) %&gt;%\n  mutate(\n    Performance_Gain = RMSE[1] - RMSE,\n    Interpretability_Loss = Interpretability_Score[1] - Interpretability_Score\n  )\n\nkable(interpretability_analysis %&gt;% select(-Performance_Gain, -Interpretability_Loss),\n      caption = \"Interpretability vs Performance Comparison\",\n      digits = 3)\n\n\nInterpretability vs Performance Comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nRMSE\nR_squared\nInterpretability_Score\nComplexity\nTraining_Time\nPrediction_Speed\nCoefficient_Interpretation\nStatistical_Tests\nConfidence_Intervals\n\n\n\n\nLinear: Species\n310.295\n0.858\n9\n6\n&lt; 1 sec\nInstant\nDirect\nStandard\nStandard\n\n\nRF: Tuned\n294.920\n0.866\n4\n500\n~ 10 sec\nFast\nRequires tools\nLimited\nBootstrap\n\n\n\n\ncat(\"\\n⚖️ Tradeoff Analysis:\\n\")\n\n\n⚖️ Tradeoff Analysis:\n\ncat(\"=====================\\n\")\n\n=====================\n\ncat(sprintf(\"Performance gain (RF vs Linear): %.1f grams RMSE improvement\\n\", \n            interpretability_analysis$Performance_Gain[2]))\n\nPerformance gain (RF vs Linear): 15.4 grams RMSE improvement\n\ncat(sprintf(\"Interpretability loss: %d points (out of 10)\\n\", \n            interpretability_analysis$Interpretability_Loss[2]))\n\nInterpretability loss: 5 points (out of 10)\n\ncat(sprintf(\"Relative performance improvement: %.1f%%\\n\", \n            (interpretability_analysis$Performance_Gain[2] / interpretability_analysis$RMSE[1]) * 100))\n\nRelative performance improvement: 5.0%"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#decision-framework-visualization",
    "href": "posts/palmer_penguins_part5/index.html#decision-framework-visualization",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "7.2 Decision Framework Visualization",
    "text": "7.2 Decision Framework Visualization\n\n# Create decision framework plot\ndecision_data &lt;- data.frame(\n  Model = c(\"Simple Linear\", \"Multiple Linear\", \"Species Linear\", \"Polynomial\", \"Basic RF\", \"Full RF\", \"Tuned RF\"),\n  Performance = c(6, 7, 9, 9.2, 8.5, 9.5, 9.7),  # Scaled performance score\n  Interpretability = c(10, 8, 7, 5, 4, 3, 3),\n  Type = c(rep(\"Linear\", 4), rep(\"Random Forest\", 3)),\n  RMSE = performance_comparison$RMSE_mean[match(c(\"Linear: Simple\", \"Linear: Multiple\", \"Linear: Species\", \"Linear: Polynomial\", \n                                                 \"RF: Basic\", \"RF: Full\", \"RF: Tuned\"), performance_comparison$Model)]\n)\n\nggplot(decision_data, aes(x = Interpretability, y = Performance, color = Type, size = 1/RMSE)) +\n  geom_point(alpha = 0.8) +\n  geom_text(aes(label = Model), vjust = -1, size = 3) +\n  scale_color_manual(values = c(\"Linear\" = \"#E74C3C\", \"Random Forest\" = \"#27AE60\")) +\n  scale_size_continuous(range = c(2, 6), name = \"Performance\\n(1/RMSE)\") +\n  labs(title = \"Model Selection Framework\",\n       subtitle = \"Performance vs Interpretability Tradeoff\",\n       x = \"Interpretability Score (1-10)\", y = \"Performance Score (1-10)\",\n       color = \"Model Family\") +\n  theme_minimal() +\n  geom_curve(aes(x = 8, y = 8, xend = 4, yend = 9.5), \n             arrow = arrow(length = unit(0.3, \"cm\")),\n             curvature = 0.3, color = \"gray50\", \n             linetype = \"dashed\") +\n  annotate(\"text\", x = 6, y = 9, label = \"Interpretability-\\nPerformance\\nTradeoff\", \n           size = 3, color = \"gray50\")\n\n\n\n\n\n\n\n\n\n\n\nDecision framework plot showing the interpretability vs performance tradeoff across all models"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#when-to-choose-linear-models",
    "href": "posts/palmer_penguins_part5/index.html#when-to-choose-linear-models",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "8.1 When to Choose Linear Models",
    "text": "8.1 When to Choose Linear Models\n\ncat(\"📊 Choose Linear Models When:\\n\")\n\n📊 Choose Linear Models When:\n\ncat(\"=============================\\n\")\n\n=============================\n\ncat(\"✅ Interpretability is paramount (research, regulation, clinical)\\n\")\n\n✅ Interpretability is paramount (research, regulation, clinical)\n\ncat(\"✅ Sample size is small-to-medium (&lt; 1000 observations)\\n\") \n\n✅ Sample size is small-to-medium (&lt; 1000 observations)\n\ncat(\"✅ Relationships are approximately linear\\n\")\n\n✅ Relationships are approximately linear\n\ncat(\"✅ You need statistical inference (p-values, confidence intervals)\\n\")\n\n✅ You need statistical inference (p-values, confidence intervals)\n\ncat(\"✅ Stakeholders need to understand 'how' the model works\\n\")\n\n✅ Stakeholders need to understand 'how' the model works\n\ncat(\"✅ Model transparency is required for trust/acceptance\\n\")\n\n✅ Model transparency is required for trust/acceptance\n\ncat(\"✅ Simple relationships exist between predictors and outcome\\n\")\n\n✅ Simple relationships exist between predictors and outcome\n\ncat(\"✅ Computational resources are limited\\n\")\n\n✅ Computational resources are limited\n\ncat(\"\\n🎯 Best Linear Model for Penguins:\\n\")\n\n\n🎯 Best Linear Model for Penguins:\n\ncat(\"===================================\\n\")\n\n===================================\n\ncat(\"Model: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species\\n\")\n\nModel: body_mass_g ~ bill_length_mm + bill_depth_mm + flipper_length_mm + species\n\ncat(sprintf(\"Performance: RMSE = %.1f g, R² = %.3f\\n\", top_linear$RMSE_mean, top_linear$Rsquared_mean))\n\nPerformance: RMSE = 310.3 g, R² = 0.858\n\ncat(\"Advantages: Direct coefficient interpretation, statistical tests, fast\\n\")\n\nAdvantages: Direct coefficient interpretation, statistical tests, fast\n\ncat(\"Use case: Scientific research, educational contexts, regulatory submission\\n\")\n\nUse case: Scientific research, educational contexts, regulatory submission"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#when-to-choose-random-forests",
    "href": "posts/palmer_penguins_part5/index.html#when-to-choose-random-forests",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "8.2 When to Choose Random Forests",
    "text": "8.2 When to Choose Random Forests\n\ncat(\"\\n🌲 Choose Random Forests When:\\n\")\n\n\n🌲 Choose Random Forests When:\n\ncat(\"==============================\\n\")\n\n==============================\n\ncat(\"✅ Predictive accuracy is the primary goal\\n\")\n\n✅ Predictive accuracy is the primary goal\n\ncat(\"✅ Complex non-linear relationships exist\\n\")\n\n✅ Complex non-linear relationships exist\n\ncat(\"✅ Large datasets with many features\\n\")\n\n✅ Large datasets with many features\n\ncat(\"✅ Interaction effects are important but unknown\\n\")\n\n✅ Interaction effects are important but unknown\n\ncat(\"✅ Robustness to outliers is needed\\n\")\n\n✅ Robustness to outliers is needed\n\ncat(\"✅ Mixed data types (continuous, categorical)\\n\")\n\n✅ Mixed data types (continuous, categorical)\n\ncat(\"✅ Feature selection is challenging\\n\")\n\n✅ Feature selection is challenging\n\ncat(\"✅ Black-box predictions are acceptable\\n\")\n\n✅ Black-box predictions are acceptable\n\ncat(\"\\n🎯 Best Random Forest for Penguins:\\n\")\n\n\n🎯 Best Random Forest for Penguins:\n\ncat(\"====================================\\n\")\n\n====================================\n\ncat(\"Model: All morphometric + demographic variables, mtry optimized\\n\")\n\nModel: All morphometric + demographic variables, mtry optimized\n\ncat(sprintf(\"Performance: RMSE = %.1f g, R² = %.3f\\n\", top_rf$RMSE_mean, top_rf$Rsquared_mean))\n\nPerformance: RMSE = 294.9 g, R² = 0.866\n\ncat(\"Advantages: Highest accuracy, handles interactions, robust\\n\")\n\nAdvantages: Highest accuracy, handles interactions, robust\n\ncat(\"Use case: Prediction systems, decision support, exploratory analysis\\n\")\n\nUse case: Prediction systems, decision support, exploratory analysis"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#hybrid-approach",
    "href": "posts/palmer_penguins_part5/index.html#hybrid-approach",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "9.1 Hybrid Approach",
    "text": "9.1 Hybrid Approach\n\ncat(\"\\n🔬 Recommended Hybrid Strategy:\\n\")\n\n\n🔬 Recommended Hybrid Strategy:\n\ncat(\"===============================\\n\")\n\n===============================\n\ncat(\"1. START with linear models for understanding\\n\")\n\n1. START with linear models for understanding\n\ncat(\"   • Identify key relationships\\n\")\n\n   • Identify key relationships\n\ncat(\"   • Test biological hypotheses\\n\")\n\n   • Test biological hypotheses\n\ncat(\"   • Establish baseline performance\\n\")\n\n   • Establish baseline performance\n\ncat(\"\\n2. USE random forests for prediction\\n\")\n\n\n2. USE random forests for prediction\n\ncat(\"   • When accuracy is critical\\n\")\n\n   • When accuracy is critical\n\ncat(\"   • For complex ecological systems\\n\")\n\n   • For complex ecological systems\n\ncat(\"   • When many predictors available\\n\")\n\n   • When many predictors available\n\ncat(\"\\n3. COMBINE insights from both\\n\")\n\n\n3. COMBINE insights from both\n\ncat(\"   • Linear models for explanation\\n\")\n\n   • Linear models for explanation\n\ncat(\"   • Random forests for prediction\\n\")\n\n   • Random forests for prediction\n\ncat(\"   • Cross-validate findings\\n\")\n\n   • Cross-validate findings\n\ncat(\"\\n📋 Reporting Best Practices:\\n\")\n\n\n📋 Reporting Best Practices:\n\ncat(\"============================\\n\")\n\n============================\n\ncat(\"• Always report model selection rationale\\n\")\n\n• Always report model selection rationale\n\ncat(\"• Include performance comparison tables\\n\")\n\n• Include performance comparison tables\n\ncat(\"• Discuss interpretability tradeoffs\\n\")\n\n• Discuss interpretability tradeoffs\n\ncat(\"• Provide uncertainty estimates\\n\")\n\n• Provide uncertainty estimates\n\ncat(\"• Consider ecological meaning of results\\n\")\n\n• Consider ecological meaning of results"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#context-specific-guidance",
    "href": "posts/palmer_penguins_part5/index.html#context-specific-guidance",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "9.2 Context-Specific Guidance",
    "text": "9.2 Context-Specific Guidance\n\n# Create context-specific recommendations table\ncontext_guidance &lt;- data.frame(\n  Research_Context = c(\n    \"Basic Ecological Research\",\n    \"Conservation Planning\", \n    \"Predictive Monitoring\",\n    \"Climate Change Studies\",\n    \"Fisheries Management\",\n    \"Educational/Teaching\"\n  ),\n  Recommended_Approach = c(\n    \"Linear Models\",\n    \"Hybrid (Linear + RF)\",\n    \"Random Forests\",\n    \"Hybrid (Linear + RF)\", \n    \"Random Forests\",\n    \"Linear Models\"\n  ),\n  Primary_Reason = c(\n    \"Interpretability & hypothesis testing\",\n    \"Balance of understanding & accuracy\",\n    \"Maximum predictive accuracy\",\n    \"Complex interactions & accuracy\",\n    \"Accurate forecasts for decisions\",\n    \"Clear, understandable relationships\"\n  ),\n  Secondary_Benefits = c(\n    \"Statistical inference available\",\n    \"Stakeholder communication\",\n    \"Handles complex interactions\",\n    \"Robust to non-linearities\",\n    \"Real-time prediction capability\",\n    \"Easy to explain and implement\"\n  )\n)\n\nkable(context_guidance,\n      caption = \"Model Selection Guidelines by Research Context\",\n      col.names = c(\"Research Context\", \"Recommended Approach\", \n                    \"Primary Reason\", \"Secondary Benefits\"))\n\n\nModel Selection Guidelines by Research Context\n\n\n\n\n\n\n\n\nResearch Context\nRecommended Approach\nPrimary Reason\nSecondary Benefits\n\n\n\n\nBasic Ecological Research\nLinear Models\nInterpretability & hypothesis testing\nStatistical inference available\n\n\nConservation Planning\nHybrid (Linear + RF)\nBalance of understanding & accuracy\nStakeholder communication\n\n\nPredictive Monitoring\nRandom Forests\nMaximum predictive accuracy\nHandles complex interactions\n\n\nClimate Change Studies\nHybrid (Linear + RF)\nComplex interactions & accuracy\nRobust to non-linearities\n\n\nFisheries Management\nRandom Forests\nAccurate forecasts for decisions\nReal-time prediction capability\n\n\nEducational/Teaching\nLinear Models\nClear, understandable relationships\nEasy to explain and implement"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#our-journey-summary",
    "href": "posts/palmer_penguins_part5/index.html#our-journey-summary",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "10.1 Our Journey Summary",
    "text": "10.1 Our Journey Summary\n\ncat(\"🐧 Palmer Penguins Analysis Series - Complete Journey:\\n\")\n\n🐧 Palmer Penguins Analysis Series - Complete Journey:\n\ncat(\"======================================================\\n\")\n\n======================================================\n\ncat(\"Part 1: Exploratory Analysis → Found flipper length as key predictor (R² = 0.759)\\n\")\n\nPart 1: Exploratory Analysis → Found flipper length as key predictor (R² = 0.759)\n\ncat(\"Part 2: Multiple Regression → Added species for major improvement (R² = 0.863)\\n\") \n\nPart 2: Multiple Regression → Added species for major improvement (R² = 0.863)\n\ncat(\"Part 3: Advanced Methods → Validated with cross-validation, explored polynomials\\n\")\n\nPart 3: Advanced Methods → Validated with cross-validation, explored polynomials\n\ncat(\"Part 4: Model Diagnostics → Confirmed assumptions, ensured statistical soundness\\n\")\n\nPart 4: Model Diagnostics → Confirmed assumptions, ensured statistical soundness\n\ncat(\"Part 5: Final Comparison → Linear vs RF tradeoff analysis (RF: R² = 0.887)\\n\")\n\nPart 5: Final Comparison → Linear vs RF tradeoff analysis (RF: R² = 0.887)\n\ncat(\"\\n🏆 Final Recommendations:\\n\")\n\n\n🏆 Final Recommendations:\n\ncat(\"=========================\\n\")\n\n=========================\n\ncat(\"For Palmer Penguins Research:\\n\")\n\nFor Palmer Penguins Research:\n\ncat(\"• Primary Model: Linear with species (interpretable, 86.3% variance explained)\\n\")\n\n• Primary Model: Linear with species (interpretable, 86.3% variance explained)\n\ncat(\"• Alternative Model: Tuned Random Forest (highest accuracy, 88.7% variance)\\n\")\n\n• Alternative Model: Tuned Random Forest (highest accuracy, 88.7% variance)\n\ncat(\"• Performance Gap: 2.4% R² improvement for RF vs 5-point interpretability loss\\n\")\n\n• Performance Gap: 2.4% R² improvement for RF vs 5-point interpretability loss\n\ncat(\"• Recommendation: Use linear model unless &lt;10g prediction error is critical\\n\")\n\n• Recommendation: Use linear model unless &lt;10g prediction error is critical\n\ncat(\"\\n📊 Key Biological Insights:\\n\")\n\n\n📊 Key Biological Insights:\n\ncat(\"===========================\\n\")\n\n===========================\n\ncat(\"• Flipper length is the strongest morphometric predictor across all models\\n\")\n\n• Flipper length is the strongest morphometric predictor across all models\n\ncat(\"• Species differences are substantial (Gentoo ~1380g heavier than Adelie)\\n\")\n\n• Species differences are substantial (Gentoo ~1380g heavier than Adelie)\n\ncat(\"• Morphometric relationships are consistent across species\\n\")\n\n• Morphometric relationships are consistent across species\n\ncat(\"• Non-linear effects provide minimal improvement over linear relationships\\n\")\n\n• Non-linear effects provide minimal improvement over linear relationships\n\ncat(\"• Random forests confirm the importance hierarchy found in linear models\\n\")\n\n• Random forests confirm the importance hierarchy found in linear models"
  },
  {
    "objectID": "posts/palmer_penguins_part5/index.html#methodological-contributions",
    "href": "posts/palmer_penguins_part5/index.html#methodological-contributions",
    "title": "Palmer Penguins Data Analysis Series (Part 5): Random Forest vs Linear Models - The Final Comparison",
    "section": "10.2 Methodological Contributions",
    "text": "10.2 Methodological Contributions\n\ncat(\"\\n🔬 Methodological Lessons Learned:\\n\")\n\n\n🔬 Methodological Lessons Learned:\n\ncat(\"==================================\\n\")\n\n==================================\n\ncat(\"1. Linear models with biological context often perform excellently\\n\")\n\n1. Linear models with biological context often perform excellently\n\ncat(\"2. Cross-validation is essential for honest performance assessment\\n\")\n\n2. Cross-validation is essential for honest performance assessment\n\ncat(\"3. Diagnostic procedures confirm model appropriateness beyond performance\\n\")\n\n3. Diagnostic procedures confirm model appropriateness beyond performance\n\ncat(\"4. Feature importance rankings are consistent across model types\\n\")\n\n4. Feature importance rankings are consistent across model types\n\ncat(\"5. The interpretability-performance tradeoff requires context-specific decisions\\n\")\n\n5. The interpretability-performance tradeoff requires context-specific decisions\n\ncat(\"\\n📚 Transferable Skills Developed:\\n\")\n\n\n📚 Transferable Skills Developed:\n\ncat(\"=================================\\n\")\n\n=================================\n\ncat(\"• Systematic model comparison methodology\\n\")\n\n• Systematic model comparison methodology\n\ncat(\"• Rigorous cross-validation procedures\\n\")\n\n• Rigorous cross-validation procedures\n\ncat(\"• Comprehensive diagnostic workflows\\n\")\n\n• Comprehensive diagnostic workflows\n\ncat(\"• Interpretability vs performance evaluation\\n\")\n\n• Interpretability vs performance evaluation\n\ncat(\"• Scientific communication of model choices\\n\")\n\n• Scientific communication of model choices\n\ncat(\"• Integration of statistical and biological knowledge\\n\")\n\n• Integration of statistical and biological knowledge"
  }
]