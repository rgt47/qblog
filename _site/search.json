[
  {
    "objectID": "posts/dockerize_compose/index.html",
    "href": "posts/dockerize_compose/index.html",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "",
    "text": "Photo by Nathan Waters"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#hosting",
    "href": "posts/dockerize_compose/index.html#hosting",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.1 Hosting",
    "text": "2.1 Hosting\nHow to set up the hosting server? There are many ways to accomplish the hosting. Here we’ll describe a straightforward and efficient approach using mainstream cloud services and open source tools. In other words, we’ll describe how to ‘spin’ up a virtual server on Amazon Web Service EC2, and use Docker, R, Shiny, and Caddy to put in place a secure web app to share with our colleagues.\n\n\n\nData flow\n\n\nFigure 2 illustrates the tools we’ll use and the flow of program and configuration files. In order to host power1_app online we’ll need to complete the following tasks:\nHosting List\n\nGenerate a virtual server with a firewall on EC2.\nObtain a static IPv4 address (to identify the server online)\nObtain a custom domain name (a name to associate with static IP address) from a domain registration provider.\nInstall and configure a webserver ( a tool to interact with https protocol requests )\nObtain and install a TLS (transport layer security) security certificate (to allow encrypted communication between the server and other machines on the network).\nConfigure user authentication for the web site.\nconfigure a reverse proxy method (to translate https, port 443, requests to Shiny, port 3838 requests).\n\n\n\n“What Is An SSL/TLS Certificate?\nAn SSL/TLS certificate is a digital object that allows systems to verify the identity & subsequently establish an encrypted network connection to another system using the Secure Sockets Layer/Transport Layer Security (SSL/TLS) protocol. Certificates are used within a cryptographic system known as a public key infrastructure (PKI). PKI provides a way for one party to establish the identity of another party using certificates if they both trust a third-party - known as a certificate authority. SSL/TLS certificates thus act as digital identity cards to secure network communications, establish the identity of websites over the Internet as well as resources on private networks.”\n reference"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "href": "posts/dockerize_compose/index.html#select-a-hosting-service",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "2.2 Select a hosting service",
    "text": "2.2 Select a hosting service\nThere are a number of cloud based server options we can choose from: Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll describe the process using AWS EC2. Detailed instructions for setting up a server on EC2, both via the console and the command line interface are covered in earlier posts ( here ) and ( here ).\nStep 0. Create an account or sign in to the AWS EC2 dashboard.\nStep 1. Set up an working environment with AWS server. This entails:\n\ndefine an ssh key-pair.\nconfigure a firewall.\nobtain a static IP.\nobtain a domain name.\nselect an instance (AMI, type and disk size), generate and launch server.\n\nOnce the server is available, connect via ssh, and login,\nThe only software necessary to install is docker (assuming it wasn’t installed in the server setup process). Install docker with the following commands:\nsudo snap install docker.io\nOnce the host is set up and docker installed, we’ll have accomplished items 1, 2, and 3 from our hosting list above. i.e. a customized virtual server wtih a static IP address, with a unique domain name and firewall are in place."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker",
    "href": "posts/dockerize_compose/index.html#docker",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.1 Docker",
    "text": "3.1 Docker\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access Shiny, and docker-compose to access Caddy, our webserver. The first file is the dockerfile. Here is our minimal dockerfile:\n\nshow the Dockerfile code\nFROM rocker/shiny:4.2.0\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis configuration file instructs Docker to build a container based on a Rocker/Shiny image (constructed as a ubuntu image with R and Shiny installed), then copy the power1_shiny/app.R code into the container and finally launch Shiny on (default) port 3838. We placed the power1_app/app.R code in the default location /srv/shiny-server we only need to start the server and it will find the shiny program.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nStart by building and pushing the image to the gitlab container registry.\n# login to gitlab\n\ncat gitlab_access_token | docker login \\\nregistry.gitlab.com -u rgt47 --password-stdin\n\ndocker build -t \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0 \\\n        --platform linux/x86_64 .\ndocker push \\\nregistry.gitlab.com/rgt47/power1_app/power1_image:v1.0"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#caddy",
    "href": "posts/dockerize_compose/index.html#caddy",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.2 Caddy",
    "text": "3.2 Caddy\nA Caddy web server configuration file (default name Caddyfile)\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquisition and installing of an SSL certificate. An SSL cert is required by most browsers to use the encrypted communication protocol https.\nWe use the caddy configuration file to specify three critical things.\n\nthe site domain name.\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) to port 3838 (Shiny port).\nadd login credentials for all users (e.g. bob/vanilla47):\n\nOur barebones Caddyfile looks like this:\n\nShow the Caddyfile code\n# use caddy auth tool to generate a password via the `bcrypt` algorithm.\n# &gt; caddy hash-password --plaintext hiccup\n\nrgtlab.org {\nbasicauth /power1/* {\n    Bob $2a$14$Zkx19XLiW6VYouLHR5NmfOFU0z2GTNmpkT/5qqR7hx4IjWJPDhjvG\n}\n    root * /srv\n    handle_path /power1/* {\n        reverse_proxy power1:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nhandle_path maps all https requests to port 3838 where Shiny is listening.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generates an SSL certificate."
  },
  {
    "objectID": "posts/dockerize_compose/index.html#docker-compose",
    "href": "posts/dockerize_compose/index.html#docker-compose",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.3 Docker Compose",
    "text": "3.3 Docker Compose\nAnd a third file is a config file for Docker Compose. Docker Compose is a Docker module that provides a framework for running multi-container applications. This docker compose YAML file instructs Docker to containerize our Shiny app, pull a caddy webserver image from Docker Hub and create a local network for the two containers to communicate in.\nA Docker-compose configuration file (default name docker-compose.yml).\nThe docker-compose.yml file:\n\ndocker-compose.yml. Show the code\nversion: \"3.7\"\n\nservices:\n  power1:\n    image: registry.gitlab.com/rgt47/power1_app/power1_image:v1.0\n    restart: unless-stopped\n    expose:\n      - \"3838\"\n  caddy:\n    image: caddy:2.6.4-alpine\n    restart: always\n    ports:\n      - \"443:443\"\n    volumes:\n      - $PWD/Caddyfile:/etc/caddy/Caddyfile\n      - $PWD/site:/srv\n      - caddy_data:/data\n      - caddy_config:/config\n    depends_on:\n      - power1\n    environment:\n      - HOST=\"rgtlab.org\"\n      - EMAIL=\"rgthomas@ucsd.edu\"\nvolumes:\n  caddy_data:\n  caddy_config:"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#landing-page",
    "href": "posts/dockerize_compose/index.html#landing-page",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "3.4 Landing Page",
    "text": "3.4 Landing Page\nLastly, we need an html file, index.html in a subdirectory named site that provides the landing page for our server.\n\nindex.html. Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n    &lt;title&gt;Power Calculators&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"https://unpkg.com/bulma@0.9.0/css/bulma.min.css\" /&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"app\"&gt;\n      &lt;section class=\"hero is-small\"&gt;\n        &lt;div class=\"hero-body\"&gt;\n          &lt;div class=\"container has-text-centered\"&gt;\n            &lt;h1 class=\"title\"&gt;RGT Lab Power Calculators&lt;/h1&gt;\n          &lt;/div&gt;\n        &lt;/div&gt;\n      &lt;/section&gt;\n            &lt;hr&gt;\n\n            &lt;div class=\"columns\"&gt;\n              &lt;div class=\"column is-4 is-offset-1\"&gt;\n      &lt;img src=\"https://github.com/rgt47/power0/blob/master/power1.png?raw=true\"\n        width=\"200\" height=\"250\"  ”float: left; padding: 3px 3px 0px 3px;” &gt;\n              &lt;/div&gt;\n              &lt;div class=\"column is-6\"&gt;\n                &lt;h1 class=\"title\"&gt; Power1 App &lt;/h1&gt;\n                &lt;p&gt; Power for two-sample t-test &lt;/p&gt;\n                &lt;br&gt;\n                &lt;a href=\"./rebecca/\" class=\"button is-info\"&gt;Go to app&lt;/a&gt;\n              &lt;/div&gt;\n            &lt;/div&gt;\n\n    &lt;/div&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nAt this point our power1_app repo looks like this:\n.\n├── Caddyfile\n├── Dockerfile\n├── docker-compose.yml\n└── site\n    └── index.html"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "href": "posts/dockerize_compose/index.html#tip-1.-docker-on-m1-macbook.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.1 Tip 1. Docker on M1 macbook.",
    "text": "5.1 Tip 1. Docker on M1 macbook.\nTo get docker functioning properly with rocker images on M1 Mac desktop use --platform option.\ndocker build -t power1_shiny --platform linux/x86_64 .\ndocker run -d -p 80:3838 --platform linux/x86_64 power1_shiny"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "href": "posts/dockerize_compose/index.html#tip-2-add-user-to-docker-group-on-server.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.2 Tip 2 add user to docker group on server.",
    "text": "5.2 Tip 2 add user to docker group on server.\nAdd ubuntu to the docker group to allow docker to run without sudo.\nsudo usermod -aG docker ${USER}"
  },
  {
    "objectID": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "href": "posts/dockerize_compose/index.html#tip-3-ssh-config-file.",
    "title": "A Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.",
    "section": "5.3 Tip 3 ssh config file.",
    "text": "5.3 Tip 3 ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\n\n\n\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/setupquarto/index.html",
    "href": "posts/setupquarto/index.html",
    "title": "Setting up a minimal Quarto blog",
    "section": "",
    "text": "quarto\n\n\n\n1 Introduction\nReview this post:\n2024-06-12 Adding a blog to your existing Quarto website https://samanthacsik.github.io/posts/2022-10-24-quarto-blogs/\nQuarto is an extension of the Rmarkdown ecosystem. It leverages the power of knitr and pandoc, providing a number of useful additional tools for literate programming, report generation and blogging.\nI’m using quarto for my lab’s home page with an embedded blog. (focusonR.org).\nThis post will describe some of the core components We’ll start with a minimal setup to provide some orientation.\nThe recommended method from the Quarto documentation initiate a blog, say qblog, is to run the command quarto create-project in your ~/shr blog development directory. Note: Quarto types include blogs, websites, manuscripts, books, etc.\n❯ quarto create-project qblog --type website:blog\nThis command generates a project folder ~/shr/qblog with the following structure:\nqblog/\n|-- _quarto.yml\n|-- about.qmd\n|-- index.qmd\n|-- posts/\n|   |-- _metadata.yml\n|   |-- post-with-code/\n|   |   |-- image.jpg\n|   |   `-- index.qmd\n|   `-- welcome/\n|       |-- index.qmd\n|       `-- thumbnail.jpg\n|-- profile.jpg\n`-- styles.css\nNote: A quarto blog can be much more elaborate than this template, but it can also be further minimized\nTo start blogging the next steps are:\n\ncd to ~/shr/qblog/posts/\nfor the post, create a new directory, say sample_post\ncd to ~/shr/qblog/posts/sample_post\ncreate and edit a index.qmd file adding content, e.g. using vim. vim   index.qmd\n\nBefore we go any further let’s examine the basic elements of the site. The framework for a quarto blog can be quite minimal. For example the following subset of files is sufficient for a useful blog:\n\nminimal_qblog\n|-- _quarto.yml\n|-- index.qmd\n`-- posts\n    |-- index.qmd\n    `-- sample_post.qmd\nwith file contents:\n\n\n\n_quarto.yml\n\nproject:\n  type: website\nwebsite:\n  title: \"Thomas Lab home page\"\n  navbar:\n    left:\n      - href: posts/index.qmd\n        text: Blog\nformat:\n  html:\n    theme: cosmo\n\n\n\n\n\nindex.qmd\n\n---\ntitle: \"Thomas lab\"\n---\n\n**Director: Professor Ronald G. Thomas**&lt;br&gt;\nSchool of Public Health&lt;br&gt;\nUC, San Diego&lt;br&gt;\nLa Jolla, California\n\nFocused on new and useful data science technologies.\n\n\n\n\n\nposts/index.qmd\n\n---\ntitle: \"Blog\"\nlisting: default\n---\n\n\n\n\n\nposts/post1.qmd\n\n---\ntitle: \"First post\"\n---\n\n# Introduction\n\n    Minimal text for first post. \n\n\n\n\n2 Results\nMinimal blog presents as the following:\n\nWhen run the first time the quarto engine generates a web site in the directory _site. This site contains CSS code as defined by the theme command in the _quarto.yml file.\n\n\n3 Appendix\nmcanouil/awesome-quarto: A curated list of Quarto talks, tools, examples & articles\nConsider some ideas from\n\nRob Hyndman - Template of quarto website\nEric Ekholm - Modifying the Default Quarto Blog Structure\nAllison Hill - We don’t talk about Quarto\nNick Tierney - Notes on Changing from Rmarkdown/Bookdown to Quarto\nSamantha Csik * Creating your personal website using Quarto\n2024-06-12 [ Adding a blog to your existing Quarto website ] ( https://samanthacsik.github.io/posts/2022-10-24-quarto-blogs/ )\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up a Minimal {Quarto} Blog},\n  date = {2024-08-19},\n  url = {https://focusonr.org/posts/setupquarto},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up a Minimal Quarto\nBlog.” August 19, 2024. https://focusonr.org/posts/setupquarto."
  },
  {
    "objectID": "posts/simpleS3/index.html",
    "href": "posts/simpleS3/index.html",
    "title": "Writing a simple R package in S3.",
    "section": "",
    "text": "S3 OOP in R\n\n\n\n1 Introduction\nIf you, like me, feel its time to expand your R programming armamentarium to include S3 methods. This blog may help.\nWhere to start?\nIn this post we’ll walk through an example of a simple “table 1” function using S3 methods.\nWe’ll start with the ‘raw’ data from a sample of the Penguins data set and return a dataframe with summary measures.\nS3 methods allow coders to write functions that perform differently for different classes of objects.\nIn our project we want to build a function that creates a row in the ‘Table 1’ table for each variable in the formula regardless of the class of the variable.\nNow reading Nick Tierney R journal paper.\n\nlibrary(pacman)\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(knitr)\nsource(\"~/shr/zz.tools.R\")\nknitr::opts_chunk$set(collapse = T)\nset.seed(101)\ndat &lt;- palmerpenguins::penguins %&gt;%\n  fil(!is.na(sex))\n\n\n\n2 References\nAlso useful other references:\nIntroduction to Scientific Programming and Simulation using R. Jomes. Maillardet, Robinson.\n[1608.07161] A Simple Guide to S3 Methods https://arxiv.org/abs/1608.07161\nWhy your S3 method isn’t working | R-bloggers\nDealing with S3 methods in R with a simple example | R-bloggers\nVideo on S3 Classes in R by Dr Andrew Robinson | R-bloggers\nUnexported S3 Methods and R Packages | R-bloggers\nSimple Guide to S3 Methods | R-bloggers\nThe S3 OOP system | R-bloggers\nNick Tierney R journal paper.\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {{Writing} a Simple {R} Package in {S3.}},\n  date = {2024-07-17},\n  url = {https://focusonr.org/posts/simpleS3},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024.“Writing a Simple R Package in\nS3. .” July 17, 2024. https://focusonr.org/posts/simpleS3."
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#title-add-the-normal-mode-mapping-zy-for-quarto-files.",
    "href": "posts/simple_vim_plugin/index.html#title-add-the-normal-mode-mapping-zy-for-quarto-files.",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "2.1 Title: Add the normal mode mapping ZY for quarto files.",
    "text": "2.1 Title: Add the normal mode mapping ZY for quarto files."
  },
  {
    "objectID": "posts/simple_vim_plugin/index.html#introduction-1",
    "href": "posts/simple_vim_plugin/index.html#introduction-1",
    "title": "A simple vim package for interfacing with a REPL",
    "section": "2.2 Introduction:",
    "text": "2.2 Introduction:\nThe goal is to allow quarto filetypes to render to pdf using a mapping called from the qmd file.\n\nstart by constructing a mapping in .vimrc: (easier to develop there) map ZY to a shell escape and call to quarto_render. ( use ZT map in rgt-R.vim as a template).\ntest using any index.qmd file in posts. e.g. ~/config_ultisnips/index.qmd.\nonce the mapping works then move it to the plugin and add a autocommand that only adds the mapping for quarto filetype files.\nopen ~/prj/qblog/posts/vim_plugin_zz.tools.vim-R/rgt-R/plugin/rgt-R.vim\ncopy ZT mapping to ZY\nmodify ZY to render quarto files with render_quarto command."
  },
  {
    "objectID": "posts/share_rmd_code_via_docker/index.html",
    "href": "posts/share_rmd_code_via_docker/index.html",
    "title": "Simple process for sharing Rmarkdown code via Docker",
    "section": "",
    "text": "1 Introduction\nLets assume you have an rmarkdown Rmd file, say peng.Rmd, that you’re written to analyze some data. You now want to share the code with a colleague, we’ll call him Joe. How to proceed?\nThe simplest option is simply to send Joe the “rmd” file containing the code via the most convenient method (e.g. email/text/slack/discord/github/USB drive etc.)\nThe next step will be for the Joe to ( attempt to ) load and run the code. Typically he would do this with either using Rstudio.app to open the file and knit it, render it from the command line with the command:\n&gt; R -e \"render('peng.Rmd')\"\nSometimes this approach works, and all is well. Joe can add comments or expand the code and reply to you. Frequently, however, this naive process will fail for any number of reasons. Ideally to facilitate reproducibility Joe will have as similar a computing environment as you, the original developer. This can be difficult to achieve, especially given the dynamic nature of open source software. For example Joe may have an outdated version of R installed on his workstation, or his R environment may be missing a necessary package. Additiional potential problems include: the required package may be present but its the wrong version, the program may need to source an additional file thats missing, or the program load some data that it can’t find on Joe’s machine.\nAll of these problems go away if instead of sending the program as a standalone text file you send it as a docker image. In this post we’ll walk through the process of dockerizing the R code.\nAssume a simple Rmd file like this:\n\n---\ntitle: \"Penguins analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r format(Sys.time(), '%B %d, %Y')`\"\nfontsize: 11pt\ngeometry: \"left=3cm,right=5cm,top=2cm,bottom=2cm\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\n      in_header: \"preamble.tex\"\n---\n\n```{r include=F, echo=F}\nlibrary(pacman)\np_load(palmerpenguins, tidyverse, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, results = \"asis\", dev = \"pdf\"\n)\n```\n\n# Introduction\n\nWe can work with the dataset `penguins` included in the package `palmerpenguins`.\n```{r }\nlibrary(palmerpenguins)\n```\nOne naive approach is to split the dataset and do three separate\nanalyses:\n\n```{r }\ndf1 &lt;- split(penguins, penguins$species)\n\nfoo &lt;- function(df, z) {\n  df |&gt; ggplot(aes(x = bill_length_mm, y = flipper_length_mm)) +\n    geom_point(aes(color = island), alpha = .5) +\n    geom_smooth() +\n    scale_color_manual(values = c(\"purple\", \"green\", \"red\")) +\n    theme_bw() +\n    labs(\n      title = paste(z, \" Penguin Anatomy Comparison\"), x = \"Flipper length\",\n      y = \"Bill length\", color = \"Island\"\n    )\n  plotfile_name &lt;- paste0(z, \".pdf\")\n  ggsave(plotfile_name)\n  cat(paste0(\"\\\\includegraphics[height=3cm]{\", plotfile_name, \"}\"), \"\\n\")\n  cat(\"\\\\vspace{1cm}\", \"\\n\")\n}\n\nbar &lt;- df1 |&gt; map2(names(df1), foo)\n```\nThe Rmd file runs cleanly on our machine and generates the the report on the following page. However, we note that the third plot needs additional examination and want to relay the program to our colleague Joe for further analyis.\n\n\n\nrendered page\n\n\n\n\n2 Share program code with Joe. Two approaches, Naive and Docker based.\nWhats the best way to accomplish this?\nWe start by simply emailing the file to him (rgthomas4747@gmail.com) and asking him to collaborate.\nJoe downloads the attachment. Opens a working directory and attempts to run the Rmd file\nwith the command\n&gt; R -e \"render('peng.Rmd')\"\nJoe has a linux mint desktop\n&gt; mkdir peng_collaboration\n&gt; cd peng_collaboration\n&gt; R -e \"render('peng.Rmd')\"\nLinux can’f find R\nJoe can fix this by installing R\n&gt; sudo apt install r-base-core\nNext R can not find the function render.\nJoe determines that render is a function in the package rmarkdown\nHe endeavors to installs rmarkdown with\n\nR -e \"install.packages('rmarkdown')\"\nThis fails due to inadequate permission on the directory /usr/lib/R/library\n\nsudo apt install libssl-dev libcurl4-openssl-dev unixodbc-dev libxml2-dev\\\nlibmariadb-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev\\\nlibfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\nAlso latex is not available\nOne more try… and the latex engine notes the absence of the file\n~/shr/preamble.tex\nSo, I need to relay the missing .tex file.\nAlso the .png (sudoku.png) logo file.\nFinally! success.\n\n\n3 Docker approach\nAlternatively, consider the “Docker” approach.\nBefore sending peng.Rmd to Joe we’ll dockerize it.\n\nPrepare a work directory: penguins. We want to send Joe a container that has R and all the preliminaries taken care of so that all he has to do is\n\nHere is the docker file\n\nFROM rocker/verse:4\nRUN apt update\nRUN apt install vim -y\nRUN R -e \"install.packages('pacman')\"\nRUN R -e \"install.packages('palmerpenguins')\"\nRUN R -e \"install.packages('tidyverse')\"\nRUN R -e \"install.packages('knitr')\"\nRUN R -e \"install.packages('rmarkdown')\"\nRUN tlmgr init-usertree\nRUN tlmgr update --self --all\nRUN  tlmgr install  fancyhdr adjustbox geometry titling\n\nRUN addgroup --system joe && adduser --system --ingroup joe joe\nRUN chmod -R 0777 '/usr/local/lib/R/site-library'\nRUN chown joe:joe -R /home/joe\nUSER joe\nWORKDIR /home/joe\nRUN mkdir -p /home/joe/shr\nRUN mkdir -p /home/joe/output\nCOPY /preamble.tex /home/joe/shr\n# COPY /.Rprofile /home/joe/shr\nCOPY sudoku.png /home/joe/shr\nCOPY peng.Rmd /home/joe/shr\nCMD [\"/bin/bash\"]\nrun docker\ndocker build -t rgt47/penguin_review --platform=linux/amd64 .\ndocker push rgt47/peng_review\nrelay image to Joe\ndocker push rgt47/peng_review\nor\ndocker save rgt47/peng_review | gzip &gt; peng_review_trans.tgz\ndocker load -i peng_review_trans.tgz\n&gt; docker pull rgt47/penguin_review\n\n&gt; droot=\"$PWD\"/output docker run -it --rm --platform linux/x86_64 \\\n-v $droot:/home/joe/output peng_review\n&gt; cd output\n&gt; library(rmarkdown); render('../shr/peng.Rmd')\nImportant to include the association between the /home/joe/output directory in the container with the output directory on the local workstation. Thats where the results of the analysis will be saved.\n&gt; R -e \"library(rmarkdown); render('peng.Rmd')\"\nand if he wants to edit peng.Rmd\n&gt; vim peng.Rmd\n\n\\usepackage[export]{adjustbox}\n\\usepackage{fancyhdr}\n\\usepackage{titling}\n\n\\pagestyle{fancy}\n\n\\pretitle{\n\\begin{flushright}\n\\includegraphics[width=3cm,valign=c]{sudoku.png}\\\\\n\\end{flushright}\n\\begin{flushleft} \\LARGE }\n\\posttitle{\\par\\end{flushleft}\\vskip 0.5em}\n\\predate{\\begin{flushleft}\\large}\n    \\postdate{\\par\\end{flushleft}}\n    \\preauthor{\\begin{flushleft}\\large}\n    \\postauthor{\\par\\end{flushleft}}\n\\fancyfoot[L]{\\currfilename} %put date in header\n\\fancyfoot[R]{\\includegraphics[width=.8cm]{sudoku.png}}\n\\fancyhead[L]{\\today} %put current file in footer\n\n\n4 REFERENCES\nRunning your R script in Docker\n\n\n5 Practice\nNotes.\nSituation: Mint is loaded and peng1.Rmd is transferred from researcher 1 to /home/z directory.\nTry to run the program with command from colleague:\n\nR -e “render(‘peng1.Rmd’)”\n\nResult: error message:\nCommand R not found.\nSo install R…. to fix\n\nsudo apt install r-base-core Try again…\n\n\nR -e “render(‘peng1.Rmd’)” Result: R loads but gives error: could not find function “render”\n\nSearch google “R render”\nResult: https://pkgs.rstudio.com/rmarkdown/reference/render.html\nLooks like render is a function inside rmarkdown package. so install package R&gt; install.packages(“rmarkdown”)\nTry again.\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)”\n\nResult: error. pandoc version 1.12.3 or higher required.\nNow try to install pandoc Try again. &gt; R -e “library(rmarkdown); render(‘peng1.Rmd’)” Result: error. there is no called pacman\nso install pacman R&gt; install.packages(“pacman”) Try again…\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)” result: failed pandoc could not find /Users/zenn/shr/preamble.tex\n\nThis makes sense we forgot to send the preamble.tex file to researcher 2. Lets send it now. Also we need to adjust its location from a macos style file name to a linux based one.\nTo edit peng1.Rmd we need vim &gt; sudo apt install vim\nTry again Result: pandoc error “pdflatex not found” Lets install tinytex. First in R and then in mint R&gt; install.packages(“tinytex”) R&gt; tinytex::install_tinytex() # to uninstall TinyTeX, run # tinytex::uninstall_tinytex()\nTry again:\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)” result: pandoc error: file sudoku_apple.pdf not found.\n\nThis makes sense we forgot to send the logo file. Lets send the file and try again.\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)” Result: error no bibliography file found.\n\nThis makes sense we forgot to send the bib file. Lets send the file and try again. Also need to edit the location of bib file.\nTry again:\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)”\n\nresults: minor error. Some packages weren’t loading via pacman.\nTry removing janitor, kableExtra, tidyverse, readxl and add ggplot2.\nTry again:\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)”\n\nSuccess!\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Simple Process for Sharing {Rmarkdown} Code via {Docker}},\n  date = {2024-08-22},\n  url = {https://focusonr.org/posts/share_rmd_code_via_docker},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Simple Process for Sharing\nRmarkdown Code via Docker.” August 22, 2024. https://focusonr.org/posts/share_rmd_code_via_docker."
  },
  {
    "objectID": "posts/setupneovim/index.html",
    "href": "posts/setupneovim/index.html",
    "title": "Setting up a minimal neovim environment for data science code development",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash \n\n1 Introduction\nNeovim (a fork of Vim) is a text editor that has several advantages for data science code development. One of its main attractions (besides being open source) is that it has a number of useful plugins to facilitate working on R, python, and julia code. Also, its modal, keyboard-centric system allows text and code manipulation at potentially far greater speed than conventional, mouse-centric, systems.\nIn this post we describe a minimal, yet functional setup to allow a quick start with neovim. We also describe a more extensive setup utilizing several of the neovim-only plugins that together allow neovim to provide IDE style code editing and REPL interaction for the three primary data science coding tools: R, Python, and Julia.\nOur presentation here is for a Macos environment. Appendix one contains required adjustments for a ubuntu linux environment.\n\n\n2 Install the latest stable version of neovim.\nWith minimal effort we can install both the terminal and GUI versions of neovim. The simplist approach is to use homebrew:\n&gt; brew install neovim neovim-qt\nSuggest set up convenience aliases in zsh.\n&gt; alias ng = \"nvim-qt\"\n&gt; alias nt = \"nvim\"\n(mnemonic: the t in nt is for terminal, the g in ng is for GUI)\n\n\n3 Configure neovim\nThe standard location for neovim configuration files on “unix-like” systems is ~/.config/nvim. The main config file is either init.vim (VimL) or init.lua (Lua). In this post we’ll focus on lua based configuration.\nHere is the file hierarchy we’ll construct. In fact all the code in the lua subdirectory could be bundled into the init.lua file, but this approach is clearer and cleaner.\n.\n|-- ginit.vim\n|-- init.lua\n|-- lazy-lock.json\n|-- lua\n|   |-- basics.lua\n|   |-- leap-config.lua\n|   |-- nvim-R-config.lua\n|   |-- nvim-cmp-config.lua\n|   |-- nvim-telescope-config.lua\n|   |-- nvim-tree-config.lua\n|   `-- treesitter-config.lua\n|-- my_snippets\n|   |-- all.snippets\n|   |-- tex\n|   |-- R\n|   |-- python\n|   |-- julia\n|   |-- giles.tex.snipppets\n|   |-- mail.snippets\n|   |-- r.snippets\n|   |-- rmd.snippets\n|   |-- snippets.snippets\n|   |-- tex.snippets\n|   |-- text.snippets\n|   `-- txt.snippets\n|-- spell\n|   |-- en.utf-8.add\n|   `-- en.utf-8.add.spl\nNeovim on its own is limited. We can add the functionality we need using plugins. To install one or more plugins we’ll need a plugin manager. There are several to choose from. We’ll use the Lazy plugin manager for this post. To install the Lazy plugin manager issue the following command at the shell prompt:\n&gt; git clone https://github.com/folke/lazy.nvim.git \\\n   ~/.local/share/nvim/lazy/lazy.nvim\nAdd the following code to init.lua list the plugins needed to be installed from github and “feed” them to Lazy for installation.\nNvim-R, Leap, UltiSnips, and vimtex need additional configuration. The required code is contained in bespoke files under the lua directory.\n\nvim.g.mapleader = \",\"\nvim.g.maplocalleader = \" \"\nvim.opt.rtp:prepend(\"~/.local/share/nvim/lazy/lazy.nvim\")\nrequire('plugins')\nrequire('basics')\nrequire('nvim-tree-config')\nrequire('nvim-R-config')\nrequire('nvim-telescope-config')\nrequire('leap').add_default_mappings()\nrequire('leap-config')\nrequire('lualine').setup()\nList of plugins\n\n\n\n\n\n\nrequire('lazy').setup({\n--\n--minimal data science setup\n--\n'jalvesaq/Nvim-R',\n'lervag/vimtex',\n'SirVer/ultisnips',\n'jalvesaq/vimcmdline',\n--\n--optional utilities\n--\n\"nvim-lualine/lualine.nvim\",\n\"bluz71/vim-moonfly-colors\",\n'junegunn/vim-peekaboo',\n'tpope/vim-commentary',\n'francoiscabrol/ranger.vim',\n'machakann/vim-highlightedyank',\n'tpope/vim-surround',\n'ggandor/leap.nvim',\n--\n--neovim specific\n'nvim-lua/plenary.nvim',\n'nvim-tree/nvim-web-devicons',\n'nvim-tree/nvim-tree.lua',\n'nvim-telescope/telescope.nvim',\n'nvim-treesitter/nvim-treesitter',\n'neovim/nvim-lspconfig',\n})\n\n\n\n4 plugin discussions\n\n\n# basics\n```sh\n\n\n\n\n\n\nlocal map = vim.keymap.set\nlocal opts = {noremap = true}\nvim.cmd([[\n\"    paste registers into terminal\ntnoremap &lt;expr&gt; &lt;C-R&gt; '&lt;C-\\&gt;&lt;C-N&gt;\"'.nr2char(getchar()).'pi'\nset background=dark\ncolorscheme moonfly\nlet $FZF_DEFAULT_COMMAND = 'rg --files --hidden'\nset completeopt=menu,menuone,noinsert,noselect\nset number relativenumber\nset textwidth=80\nset cursorline\nset clipboard=unnamed\nset iskeyword-=_\nset hlsearch\nset splitright\nset hidden\nset incsearch\nset noswapfile\nset showmatch\nset ignorecase\nset smartcase\nset gdefault\nfiletype plugin on\nset encoding=utf-8\nset nobackup\nset nowritebackup\nset updatetime=300\nset signcolumn=yes\nset colorcolumn=80\nset timeoutlen=1000 ttimeoutlen=10\nlet g:UltiSnipsSnippetDirectories = ['~/.config/nvim/my_snippets']\nlet g:UltiSnipsExpandTrigger=\"&lt;tab&gt;\"\nlet g:UltiSnipsJumpForwardTrigger=\"&lt;c-j&gt;\"\nlet g:UltiSnipsJumpBackwardTrigger=\"&lt;c-k&gt;\"\nnnoremap &lt;leader&gt;U &lt;Cmd&gt;call UltiSnips#RefreshSnippets()&lt;CR&gt;\n\nautocmd BufWinEnter,WinEnter term://* startinsert\n\"autocmd TermOpen * exec \"normal! i\"\n]])\nmap('n', ':', ';', opts)\nmap('n', ';', ':', opts)\nmap('n', '&lt;leader&gt;u',':UltiSnipsEdit&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;U','&lt;Cmd&gt;call UltiSnips#RefreshSnippets()&lt;cr&gt;', opts)\nmap('n', '&lt;localleader&gt;&lt;localleader&gt;','&lt;C-d&gt;', opts)\nmap('n', '-','$', opts)\nmap('n', '&lt;leader&gt;w','vipgq', opts)\nmap('n', '&lt;leader&gt;v',':edit ~/.config/nvim/init.lua&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;n',':edit ~/.config/nvim/lua/basics.lua&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;a','ggVG', opts)\nmap('n', '&lt;leader&gt;t',':tab split&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;y',':vert sb3&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;0',':ls!&lt;CR&gt;:b&lt;Space&gt;', opts)\nmap('n', '&lt;leader&gt;&lt;leader&gt;','&lt;C-w&gt;w', opts)\nmap('n', '&lt;leader&gt;1','&lt;C-w&gt;:b1&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;2','&lt;C-w&gt;:b2&lt;cr&gt;', opts)\nmap('n', '&lt;leader&gt;3','&lt;C-w&gt;:b3&lt;cr&gt;', opts)\nmap('t',  'ZZ', \"q('yes')&lt;CR&gt;\", opts)\nmap('t',  'ZQ', \"q('no')&lt;CR&gt;\", opts)\nmap('v',  '-', '$', opts)\nmap('t',  '&lt;leader&gt;0','&lt;C-\\\\&gt;&lt;C-n&gt;&lt;C-w&gt;:ls!&lt;cr&gt;:b&lt;Space&gt;', opts)\nmap('t',  '&lt;Escape&gt;','&lt;C-\\\\&gt;&lt;C-n&gt;', opts)\nmap('t',  ',,','&lt;C-\\\\&gt;&lt;C-n&gt;&lt;C-w&gt;w', opts)\nmap('i',  '&lt;Esc&gt;', '&lt;Esc&gt;`^', opts)\n\n\n\n5 Set up R\n\n\n\n\n\n\nvim.cmd([[\niabb &lt;buffer&gt; x %&gt;%\niabb &lt;buffer&gt; z %in%\nlet R_auto_start = 2\nlet R_enable_comment = 1\nlet R_hl_term = 0\nlet R_clear_line = 1\nlet R_pdfviewer = \"zathura\"\nlet R_assign = 2\nlet R_latexcmd = ['xelatex']\naugroup rmarkdown\nautocmd!\nautocmd FileType rmd,r nnoremap &lt;buffer&gt; &lt;CR&gt;  :call SendLineToR(\"down\")&lt;CR&gt;\nautocmd FileType rmd,r nnoremap &lt;buffer&gt; &lt;space&gt;' :call RMakeRmd(\"default\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;i :call RAction(\"dim\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;h :call RAction(\"head\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;p :call RAction(\"print\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;q :call RAction(\"length\")&lt;cr&gt;\nautocmd FileType rmd,r noremap &lt;space&gt;n :call RAction(\"nvim.names\")&lt;cr&gt;\nautocmd FileType rmd,r vmap &lt;buffer&gt; &lt;CR&gt; &lt;localleader&gt;sd\nautocmd FileType rmd,r nmap &lt;buffer&gt; &lt;space&gt;j &lt;localleader&gt;gn\nautocmd FileType rmd,r nmap &lt;buffer&gt; &lt;space&gt;k &lt;localleader&gt;gN\nautocmd FileType rmd,r nmap &lt;buffer&gt; &lt;space&gt;l &lt;localleader&gt;cd\naugroup END\n]])\n\n\n\n\n\n\n\n\n6 Appendix Ubuntu tweaks\n\n\n7 Appendix Isolate configuration files\ngit clone https://github.com/LazyVim/starter ~/.config/LazyVim\nNVIM_APPNAME=LazyVim nvim\n\n\n8 Appendix\nConsider using multiple config to evaluate:\nSwitching Configs in Neovim • Michael Uloth\n\n\n9 NB: study this init.vim with ALE for completion\nstudy this init.vim with ALE for completion\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up a Minimal Neovim Environment for Data Science Code\n    Development},\n  date = {2024-07-17},\n  url = {https://focusonr.org/posts/setupneovim},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up a Minimal Neovim\nEnvironment for Data Science Code Development.” July 17, 2024. https://focusonr.org/posts/setupneovim."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html",
    "href": "posts/server_setup_aws_console/index.html",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#select-a-hosting-service",
    "href": "posts/server_setup_aws_console/index.html#select-a-hosting-service",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "2.1 Select a hosting service",
    "text": "2.1 Select a hosting service\nThere are a number of cloud based server hosting options to choose from: for example Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean or Hetzner to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nIn this post we’ll provide a step-by-step description of a process using Amazon Web Services Elastic Compute Cloud (AWS EC2) infrastructure.\nAWS is, in our view, a reasonable choice for setting up a small custom server. Its not the cheapest option, but the system is well documented and, in our experience, reliable.\nThe first step is to get set up with AWS. To start, open the EC2 console by visiting the URL:\n   https://aws.amazon.com/console\n(see margin figure)\nIn the console window choose regional service. For us its “N. California”.\n\n\n\n\n\nAWS console\n\n\nNext create an account, or sign in. Once you’re logged in navigate to the EC2 dashboard. Its through this dashboard (aka console) that we’ll define the parameters for the type of server to launch and the mechanisms for communicating with it. We’ll refer to these as “Pre-Launch” tasks."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#overview",
    "href": "posts/server_setup_aws_console/index.html#overview",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nAlong with selecting a server we need to set up a working environment. We recommend setting up the working environment before launching the server, as it saves some back and forth with the console, but doing so is not required. The working environment consists of four main components:\n\nA security credential (RSA key-pair) to allow remote and secure login to the virtual server once its launched.\nA firewall, or security model, which restricts incoming server access. The purpose of the firewall is to close ofe all incoming packet traffic except through those ports specifically named.\nA static IP address, say 111.222.333.444. A static IP is required for maintaining the link between the domain name and the server when rebooting. (The default is for the instance/server to be assigned a new IP address each time its rebooted).\nA domain name, say rgtlab.org. A domain name is not required but will facilitate collaborator access by not requiring the use of the IP address directly.\n\nThese working environment components are not directly tied to any specific server. In fact, you can define multiple instances of each component. The only requirement is that you pick one of each to associate with each server."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#work-environment-details.",
    "href": "posts/server_setup_aws_console/index.html#work-environment-details.",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "3.2 Work Environment Details.",
    "text": "3.2 Work Environment Details.\n\n3.2.1 Ssh key pair\nIn order to securely communicate with the server we need to exchange an RSA key pair with AWS. The pair consists of a private key and a public key. We can define a key pair in one of two ways in EC2. Either, generate the pair locally, on our workstation and upload the public key to EC2, or have EC2 generate the key pair and download the private key. The EC2 based generation process will place the public key in the ~/.ssh/authorized_keys file on the server.\nFor the first option (local generation) we create a directory on our workstation to hold the keys and navigate to it, e.g. ~/.ssh. In the ~/.ssh directory generate the keys with the command\n&gt; ssh-keygen -m PEM\nPEM defines the key format. More information on public key authentication can be found (here). Also detailed instructions are available on AWS (here)\nIn the interactive dialog that follows name the key prefix something like power1_app.pem. The dialog will ask for a passphrase. You can enter a phrase for an additional level of security, but its not required. The ssh-keygen program will generate two files: power1_app.pem and power1_app.pem.pub\nTo complete the process return to the EC2 dashboard and select Network & Security/Keypair/Actions and then Import key pair in the left panel. Enter the name power1_app and select the Browse button. Navigate to the ~/.ssh/power1_app.pem.pub file and and select the Import key pair button at the bottom of the page.\nFor the second approach (EC2 generated) select Create key pair button in the upper right of the console page. A form will appears and ask for a name. Enter something like power1_app. Select RSA for key pair type and .pem for key file format. The keys will be created and the private key power1_app.pem will be offered for download to the local machine. We suggest placing it in the ~/.ssh directory. Lastly, change the permissions for the private key, so only you can access with the following command:\n&gt; sudo chmod 400 power1_app.pem\n\n\n3.2.2 Firewall\nTo create a firewall, click on Security groups under Network & Security settings in the left hand panel. Choose Create security group, and name the security group something like power1_app.\nUnder Inbound Rules select SSH and HTTPS from the Type dropdown menu. Select Anywhere IPv4 0.0.0.0/0 for both (??).\nThis will create a firewall that leaves open only ports 22 and 443, for ssh and https incoming traffic, respectively.\n\n\n3.2.3 Static IP address\nYou can use the EC2 elastic IP service to get a static IP. Navigate to Network and Security again and select Allocate Elastic IP. An IP will be assigned from the EC2 pool of available IPv4 IP addresses e.g. 13.57.139.31.\n\n\n3.2.4 Domain Name\nTo obtain a dedicated domain name, leave the EC2 dashboard and go to Amazon route 53 dashboard to select a domain name and associate it with our static IP (select Service at the top of the dashboard and search for Route 53).\nOnce a domain name is acquired, e.g. rgtlab.org, you can associate it with any IP address, static or dynamic. This can be done via the Route 53 service. For example, to associate domain name rgtlab.org with the elastic IP 111.2222.333.444 do the following in Route 53:\n\nclick on hosted zones in the side panel\nclick on rgtlab.org in center panel\nclick on checkbox for rgtlab.org type=A line\nthen click on edit record in right panel\nchange IP address to the assigned static 111.222.333.444 in “value”."
  },
  {
    "objectID": "posts/server_setup_aws_console/index.html#access-server",
    "href": "posts/server_setup_aws_console/index.html#access-server",
    "title": "Set up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)",
    "section": "4.1 Access server",
    "text": "4.1 Access server\nOn your laptop log into server with\nssh -i \"~/.ssh/power1_app\" ubuntu@rgtlab.org"
  },
  {
    "objectID": "posts/minimalist_edc_app/index.html#polish-the-interface",
    "href": "posts/minimalist_edc_app/index.html#polish-the-interface",
    "title": "Minimal EDC in Shiny",
    "section": "2.1 Polish the interface",
    "text": "2.1 Polish the interface\nStart with the online/CRC book “Outstanding User interfaces with Shiny” Granjon (2022)"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html",
    "href": "posts/extend_shiny_app/index.html",
    "title": "Extend Shiny power app to five tabs",
    "section": "",
    "text": "Shiny"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#modules",
    "href": "posts/extend_shiny_app/index.html#modules",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.1 Modules",
    "text": "2.1 Modules"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#golem",
    "href": "posts/extend_shiny_app/index.html#golem",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.2 Golem",
    "text": "2.2 Golem"
  },
  {
    "objectID": "posts/extend_shiny_app/index.html#package",
    "href": "posts/extend_shiny_app/index.html#package",
    "title": "Extend Shiny power app to five tabs",
    "section": "2.3 Package",
    "text": "2.3 Package"
  },
  {
    "objectID": "posts/setupobs/index.html",
    "href": "posts/setupobs/index.html",
    "title": "Setting up OBS for webcasting",
    "section": "",
    "text": "1 Introduction\nWebcasting for biostatistics is the challenge.\nLets take it one step at a time.\nStart with the open source project OBS.\nWelcome | OBS\nSteps to get started. Work with youtube video.\nHow to Use OBS Studio\ngoal is to be able to create short, 5 minute, videos demonstrating “real time” data analysis.\nfirst project:\n\nwork through first 10 minutes of Dave Robinson “water” tidytuesday analysis.\ncreate a 5 minute version of the analysis in vim using rgt-R tools and ultisnips.\ncreate a simple OBS framework for the screencast.\nSections TBD\nYoutube channel\nBackground blur\nKeycastr\nHigh contrast colorscheme\nhotkeys\naudio setup\nvideo setup\nformat ?\nscenes\ntwitter\nblog\nstack\npodcast\nvimcasts\ntwitch\ntidytuesday\nimovie for editing\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up {OBS} for Webcasting},\n  date = {2024-06-17},\n  url = {https://focusonr.org/posts/setupobs},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up OBS for\nWebcasting.” June 17, 2024. https://focusonr.org/posts/setupobs."
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html",
    "href": "posts/setup_R_vimtex/index.html",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "",
    "text": "vim setup"
  },
  {
    "objectID": "posts/setup_R_vimtex/index.html#yaml-header",
    "href": "posts/setup_R_vimtex/index.html#yaml-header",
    "title": "Setting up R, vimtex and Ultisnips in vim on a Mac",
    "section": "8.1 YAML header",
    "text": "8.1 YAML header\nThe RMD file contains a YAML metadata header delineated with the lines “—” above and below. For this example we want to generate a pdf formatted output file.\nThe YAML can be as simple as one line specifying the output as pdf.\n---\noutput: pdf_document\n---\nWhich results in a simple output file as follows:\nNB. to invoke file completion in vim for the rmd (or quarto) change the vim filetype using the command:\n:set filetype=tex\nthen enter, e.g., \\includegraphics{ or \\input{ followed by C-x C-o. and a pop-up menu with possible completions with appear.\n\n---\ntitle: \"Penguins data analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r Sys.Date()`\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\nheader-includes:\n    - \\usepackage{lipsum, fancyhdr, titling, currfile}\n    - \\usepackage[export]{adjustbox}\n    - \\pagestyle{fancy}\n    - \\pretitle{\n    - \\begin{flushright} \\includegraphics[width=3cm,valign=c]{sudoku.pdf}\n    - \\end{flushright}\n    - \\noindent\\rule{\\linewidth}{2pt}\\begin{flushleft}\\LARGE}\n    - \\posttitle{\\end{flushleft}\\noindent\\rule{\\linewidth}{2pt}}\n---"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#user-interface",
    "href": "posts/power_analysis_shiny_app/index.html#user-interface",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.1 User interface",
    "text": "2.1 User interface"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#parameters",
    "href": "posts/power_analysis_shiny_app/index.html#parameters",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.2 Parameters",
    "text": "2.2 Parameters"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#visualization",
    "href": "posts/power_analysis_shiny_app/index.html#visualization",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.3 Visualization",
    "text": "2.3 Visualization"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#reporting-formats",
    "href": "posts/power_analysis_shiny_app/index.html#reporting-formats",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.4 Reporting formats",
    "text": "2.4 Reporting formats"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#specifying-effect-size",
    "href": "posts/power_analysis_shiny_app/index.html#specifying-effect-size",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.5 Specifying effect size",
    "text": "2.5 Specifying effect size"
  },
  {
    "objectID": "posts/power_analysis_shiny_app/index.html#itt-and-completers",
    "href": "posts/power_analysis_shiny_app/index.html#itt-and-completers",
    "title": "Constructing a medium complexity shiny app for power analysis",
    "section": "2.6 Itt and completers",
    "text": "2.6 Itt and completers"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nBest practices for parsing a formula in R programming\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSimple process for sharing R code via Docker\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSimple process for sharing Rmarkdown code via Docker\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSimple process for sharing R code via Docker\n\n\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nInstall Arch Linux on a Macbook Air\n\n\nA set of tips for installation and post install\n\n\n\nMint\n\n\nlinux\n\n\nR\n\n\nPython\n\n\nJulia\n\n\n\nstep by step description of howto install and customize an Arch instance for data science workflow\n\n\n\n\n\nAug 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nA Concise Strategy to get your Shiny App Online, Securely and Continuously Updated.\n\n\ngitlab, Docker-compose, EC2 version\n\n\n\nAWS\n\n\nDocker\n\n\nShiny\n\n\ndocker-compose\n\n\n\nThis is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online.” \n\n\n\n\n\nAug 21, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nUsing the AWS command line interface to launch an EC2 server\n\n\n\n\n\n\nAWS\n\n\n\nBatch programs to setup a virtual server to host a Shiny app\n\n\n\n\n\nAug 21, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up git for (solo) data science workflow\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a minimal Quarto blog\n\n\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nInstall Linux Mint on a Macbook Air\n\n\nA set of tips for installation and post install\n\n\n\nMint\n\n\nlinux\n\n\nR\n\n\nPython\n\n\nJulia\n\n\n\nstep by step description of howto install and customize a Mint instance for data science workflow\n\n\n\n\n\nAug 5, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nA simple process to get your Shiny app online (securely).\n\n\n\n\n\n\nDocker\n\n\nShiny\n\n\n\nThis is the first in a series of posts offering suggested strategies for leveraging open source technologies to effectively host data science analysis apps and reports online.\n\n\n\n\n\nJul 17, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nWriting a simple R package in S3.\n\n\n\n\n\n\nR\n\n\noop\n\n\nS3\n\n\ncoding\n\n\n\nGetting started with S3 OO programming in R\n\n\n\n\n\nJul 17, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a minimal neovim environment for data science code development\n\n\nA neovim IDE for R, Python, and Julia\n\n\n\nNeovim\n\n\nVim\n\n\n\nThis is the first in a series of posts offering suggested strategies for setting up key tools for data science code development\n\n\n\n\n\nJul 17, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up R, vimtex and Ultisnips in vim on a Mac\n\n\n\n\n\n\nvim\n\n\nR\n\n\nTex\n\n\nUltisnips\n\n\n\nDetailed configuration for optimal interaction and efficiency\n\n\n\n\n\nJul 2, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConfigure ultisnips to streamline R and Rmd coding\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nA simple vim package for interfacing with a REPL\n\n\n\n\n\n\nR\n\n\nvim\n\n\n\nAn alternative to Nvim-R and vim-slime\n\n\n\n\n\nJun 28, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up OBS for webcasting\n\n\n\n\n\n\n\n\n\n\n\nJun 17, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nMinimal EDC in Shiny\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConstructing a medium complexity shiny app for power analysis\n\n\n\n\n\n\n\n\n\n\n\nFeb 25, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nWorking example for generating multiple plots inside a map2 call\n\n\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConfigure the command line for data science development\n\n\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nRCT validation language\n\n\n\n\n\n\n\n\n\n\n\nFeb 11, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nConfigure the tiling window manager yabai for macos\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nExtend Shiny power app to five tabs\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nSet up a virtual server on AWS EC2 Console (in anticipation of hosting Shiny apps)\n\n\n\n\n\n\nAWS\n\n\n\nDetailed steps for setting up a lightweight server on AWS. \n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\n\n\n\n\n\n\nMimicing the softmood reddit post\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2024\n\n\nRonald (Ryy) Glenn Thomas\n\n\n\n\n\n\nNo matching items\n\n\n  \n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Blog},\n  url = {https://focusonr.org/posts},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. n.d. “Blog.” https://focusonr.org/posts."
  },
  {
    "objectID": "posts/config_term_zsh/index.html",
    "href": "posts/config_term_zsh/index.html",
    "title": "Configure the command line for data science development",
    "section": "",
    "text": "iterm2"
  },
  {
    "objectID": "posts/config_term_zsh/index.html#configzsh.zsh_aliases",
    "href": "posts/config_term_zsh/index.html#configzsh.zsh_aliases",
    "title": "Configure the command line for data science development",
    "section": "3.1 ~/.config/zsh/.zsh_aliases",
    "text": "3.1 ~/.config/zsh/.zsh_aliases\n\nalias mm='mutt'\nalias sk='open -a Skim'\nalias vc='vim ~/.vimrc'\nalias vz='vim ~/.zshrc'\nalias sz='source ~/.zshrc'\nalias p2='enscript -C -2 -r -j --media=Letter'\nalias p1='enscript  -j --media=Letter'\nalias yr=\"yabai --restart-service\"\nalias lt='eza -lrFha -sold'\nalias mvim=\"/Applications/MacVim.app/Contents/bin/mvim\"\nalias tp='trash-put -v'\nalias rm='echo \"This is not the command you are looking for.\"; false'\nalias s='scd'\nalias ZZ='exit'\nalias r=\"radian\"\nalias nt=\"nvim\"\nalias -g ...='../..'\nalias -g ....='../../..'\nalias -g .....='../../../..'\nalias -g ......='../../../../..'\n\nalias -- -='cd -'\nalias 1='cd -1'\nalias 2='cd -2'\nalias 3='cd -3'\nalias 4='cd -4'\nalias 5='cd -5'\nalias 6='cd -6'\nalias 7='cd -7'\nalias 8='cd -8'\nalias 9='cd -9'\n\nalias md='mkdir -p'\nalias rd=rmdir\n\n# List directory contents\nalias lsa='ls -lah'\nalias l='ls -lah'\nalias ll='ls -lh'\nalias la='ls -lAh'\n\n# search for directory and cd to it\nalias sd=\"cd ~ && cd \\$(find * -type d -not -path '*/Library/*' | fzf)\""
  },
  {
    "objectID": "posts/config_term_zsh/index.html#configzsh.zsh_exports",
    "href": "posts/config_term_zsh/index.html#configzsh.zsh_exports",
    "title": "Configure the command line for data science development",
    "section": "3.2 ~/.config/zsh/.zsh_exports",
    "text": "3.2 ~/.config/zsh/.zsh_exports\n\nexport EDITOR=\"vim\"\nexport TEXINPUTS='.:/Users/zenn/shr/images:/Users/zenn/shr:'\nexport PATH=\".:.local/bin:/opt/homebrew/sbin:/opt/homebrew/bin:$PATH:$HOME/bin\"\nexport vpc_id=\"vpc-14814b73\"\nexport subnet_id=\"subnet-f02c90ab\"\nexport ami_id=\"ami-014d05e6b24240371\"\nexport keypair_name=\"rebecca_app\"\nexport proj_name=\"rebecca_app\"\nexport instance_type=\"t2.micro\"\nexport storage_size=\"30\"\nexport ami_id=\"ami-014d05e6b24240371\"\nexport security_grp=\"sg-008cace70d32f6267\"\nexport static_ip='13.56.101.209'\n\nif type rg &&gt; /dev/null; then\n  export FZF_DEFAULT_COMMAND='rg --files --hidden --no-ignore-vcs'\n  export FZF_DEFAULT_OPTS='-m --height 50% --border'\nfi\n\nexport ZSH_AUTOSUGGEST_HIGHLIGHT_STYLE=\"fg=011,bg=black,bold,underline\"\nLS_COLORS+='pi=01;33:so=01;33:do=01;33:bd=01;33:cd=01;33:su=01;35:sg=01;35:ca=01;35:ex=01;32'\nexport LSCOLORS='ExGxDxDxCxDxDxFxFxexEx'"
  },
  {
    "objectID": "posts/config_term_zsh/index.html#configzsh.zsh_functions",
    "href": "posts/config_term_zsh/index.html#configzsh.zsh_functions",
    "title": "Configure the command line for data science development",
    "section": "3.3 ~/.config/zsh/.zsh_functions",
    "text": "3.3 ~/.config/zsh/.zsh_functions\n\nfunction d () {\n  if [[ -n $1 ]]; then\n    dirs \"$@\"\n  else\n    dirs -v | head -n 10\n  fi\n}\n\nmma () { /Applications/Mathematica.app/Contents/MacOS/WolframKernel -script $1 }\nfunction gz() {\n    git add .\n    git commit -a -m \"$1\"\n    git push\n}"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Thomas Lab",
    "section": "",
    "text": "twitter\n  \n  \n    \n     Github\n  \n\n      \nThe Thomas Lab in the the Herbert Wertheim School of Public Health and Human Longevity Science at UC San Diego focuses on developing data science methodology and educational materials."
  },
  {
    "objectID": "posts/formula_parsing/index.html#references",
    "href": "posts/formula_parsing/index.html#references",
    "title": "Best practices for parsing a formula in R programming",
    "section": "2.1 References:",
    "text": "2.1 References:\n“the formula is used to specify the symbolic model as well as generating the intended design matrix” The R Formula Method: The Good Parts · R Views\n” You’re probably familiar with formulas from linear models (e.g. lm(mpg ~ displ, data = mtcars)) but formulas are more than just a tool for modelling: they are a general way of capturing an unevaluated expression”\n“because a formula captures two things:\nAn unevaluated expression.\nThe context (environment) in which the expression was created.\n~ is a single character that allows you to say: “I want to capture the meaning of this code, without evaluating it right away”. For that reason, the formula can be thought of as a “quoting” operator.”\nNon-standard evaluation\nAdvanced Programming and Non-Standard Evaluation with dplyr | by Ryan Boyer | Shipt Tech"
  },
  {
    "objectID": "posts/mimicsoftmood/index.html",
    "href": "posts/mimicsoftmood/index.html",
    "title": "Mimicing the softmood reddit post",
    "section": "",
    "text": "1 Introduction\n\n\n\n\n\nunder construction\n\n\nVery impressed with the reddit post of ykonstant\n[Cinnamon] Soft mood and latex workflow\nThis project is an attempt to mimic the various elements of the post, particularly the ultisnips portion.\nThe key elements to get started:\nThe list from the post:\n\nDE: Cinnamon\n\nTerminal emulator: iterm2 brew install iterm2\n\nWallpaper: Abstract geometry lofi coffee\n\n\n\n\n\n\nunder construction\n\n\n\nMusic mix credits: Loosen up your mind by Homework Radio\n\nRoot system animation: The Beauty of E8 by David Madore\n\nEye candy: cli-visualiser, cmatrix, neofetch, pipes.sh\n\nReference Management System: Zotero\n\nBrowser: qutebrowser with zotero connector\n\nVim Colorscheme: habiLight modified\n\nStatus Bar: airline with custom theme, adapted from gruvbox code.\n\nVim plugins: vimtex, ultisnips, vim-surround.\n\nbrew install neofetch\n\n\n\n\n\nunder construction\n\n\n\n\n2 Using qutebrowser\n\n\n3 Using Zotero\nstarts at 2:50 on video\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Mimicing the Softmood Reddit Post},\n  date = {2024-01-23},\n  url = {https://focusonr.org/posts/mimicsoftmood},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Mimicing the Softmood Reddit\nPost.” January 23, 2024. https://focusonr.org/posts/mimicsoftmood."
  },
  {
    "objectID": "posts/rct_validation_lang/index.html",
    "href": "posts/rct_validation_lang/index.html",
    "title": "RCT validation language",
    "section": "",
    "text": "1 Introduction\nConsider a simple programming language to capture the essence of clinical trial data base validation logic.\nSimilar in concept to Coffeescript (compiles to Lua) or Moonscript (compiles to Javascript).\nIdea is for trial design and initiation team to collaborate (say on gppgle docs) to develop the quality control validation logic and then translate that language into a series of snippets in Lua (using Lpeg)\nhttps://www.inf.puc-rio.br/~roberto/lpeg/\n\n1.0.1 consider matlab to R converter\nCRAN - Package matconv\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {RCT Validation Language},\n  date = {2024-02-11},\n  url = {https://focusonr.org/posts/rct_validation_lang},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “RCT Validation\nLanguage.” February 11, 2024. https://focusonr.org/posts/rct_validation_lang."
  },
  {
    "objectID": "posts/setup_yabai/index.html",
    "href": "posts/setup_yabai/index.html",
    "title": "Configure the tiling window manager yabai for macos",
    "section": "",
    "text": "quarto\n\n\n\n1 Introduction\nYabai is a tiling window manager for macOS.\nFrom the wiki Home · koekeishiya/yabai Wiki · GitHub\n“It automatically modifies your window layout using a binary space partitioning algorithm … . interface allows you to control and query windows, spaces and displays to enable powerful integration with tools like skhd to allow you to work more efficiently with macOS.”\nRequirements: (from the WIKI)\n\nIn the Desktop & Dock tab, inside the Mission Control pane, the setting “Displays have separate Spaces” must be enabled.\nSystem Settings (macOS 13.x, 14.x) In the Desktop & Dock tab, inside the Mission Control pane, the setting “Automatically rearrange Spaces based on most recent use” should be disabled for commands that rely on the ordering of spaces to work reliably.\nSystem Settings (macOS 14.x) In the Desktop & Dock tab, inside the Desktop & Stage Manager pane, the setting “Show Items On Desktop” should be enabled for display and space focus commands to work reliably in multi-display configurations.\nSystem Settings (macOS 14.x) In the Desktop & Dock tab, inside the Desktop & Stage Manager pane, the setting “Click wallpaper to reveal Desktop” should be set to “Only in Stage Manager” for display and space focus commands to work reliably.\n\nbrew install koekeishiya/formulae/yabai\n# start yabai\nyabai --start-service\nSample configuration files can be found in the ↗ examples directory. Refer to the ↗ documentation or the wiki for further information.\nKeyboard shortcuts can be defined with ↗ skhd or any other suitable software you may prefer. ## yabairc\n\n#!/usr/bin/env bash\nsudo yabai --load-sa\nyabai -m signal --add event=dock_did_restart action=\"sudo yabai --load-sa\"\nset -x\n\n# ====== Variables =============================\n\ndeclare -A gaps\ndeclare -A color\n\ngaps[\"top\"]=\"12\"\ngaps[\"bottom\"]=\"12\"\ngaps[\"left\"]=\"12\"\ngaps[\"right\"]=\"12\"\ngaps[\"inner\"]=\"12\"\n\ncolor[\"focused\"]=\"0xE0808080\"\ncolor[\"normal\"]=\"0x00010101\"\ncolor[\"preselect\"]=\"0xE02d74da\"\n\n\n# ===== Loading Scripting Additions ============\n\n# See: https://github.com/koekeishiya/yabai/wiki/Installing-yabai-(latest-release)#macos-big-sur---automatically-load-scripting-addition-on-startup\n# sudo yabai --load-sa\n# yabai -m signal --add event=dock_did_restart action=\"sudo yabai --load-sa\"\n\n# ===== Tiling setting =========================\n\nyabai -m config layout                      bsp\n\nyabai -m config top_padding                 \"${gaps[\"top\"]}\"\nyabai -m config bottom_padding              \"${gaps[\"bottom\"]}\"\nyabai -m config left_padding                \"${gaps[\"left\"]}\"\nyabai -m config right_padding               \"${gaps[\"right\"]}\"\nyabai -m config window_gap                  \"${gaps[\"inner\"]}\"\n\nyabai -m config mouse_follows_focus         on\nyabai -m config focus_follows_mouse         on\n\nyabai -m config window_topmost              off\nyabai -m config window_opacity              off\nyabai -m config window_shadow               float\n\nyabai -m config window_border               on\nyabai -m config window_border_width         2\nyabai -m config active_window_border_color  \"${color[\"focused\"]}\"\nyabai -m config normal_window_border_color  \"${color[\"normal\"]}\"\nyabai -m config insert_feedback_color       \"${color[\"preselect\"]}\"\n\nyabai -m config active_window_opacity       1.0\nyabai -m config normal_window_opacity       0.90\nyabai -m config split_ratio                 0.50\n\nyabai -m config auto_balance                on\n\nyabai -m config mouse_modifier              fn\nyabai -m config mouse_action1               move\nyabai -m config mouse_action2               resize\n\n\n\nset +x\nprintf \"yabai: configuration loaded...\\\\n\"\n\n\n2 skhd\n\n# experimental \n# # move window to display left and right\nshift + alt - s : yabai -m window --display west; yabai -m display --focus west;\nshift + alt - g : yabai -m window --display east; yabai -m display --focus east;\n# opens iTerm2\nalt - return : \"${HOME}\"/bin/open_iterm.sh\n\n\n# Navigation\nalt - h : yabai -m window --focus west\nalt - j : yabai -m window --focus south\nalt - k : yabai -m window --focus north\nalt - l : yabai -m window --focus east\n\n# Moving windows\nshift + alt - h : yabai -m window --warp west\nshift + alt - j : yabai -m window --warp south\nshift + alt - k : yabai -m window --warp north\nshift + alt - l : yabai -m window --warp east\n\n# Move focus container to workspace\nshift + alt - m : yabai -m window --space last; yabai -m space --focus last\nshift + alt - p : yabai -m window --space prev; yabai -m space --focus prev\nshift + alt - n : yabai -m window --space next; yabai -m space --focus next\nshift + alt - 1 : yabai -m window --space 1; yabai -m space --focus 1\nshift + alt - 2 : yabai -m window --space 2; yabai -m space --focus 2\nshift + alt - 3 : yabai -m window --space 3; yabai -m space --focus 3\nshift + alt - 4 : yabai -m window --space 4; yabai -m space --focus 4\n\n# Resize windows\nlctrl + alt - h : yabai -m window --resize left:-50:0; \\\n                  yabai -m window --resize right:-50:0\nlctrl + alt - j : yabai -m window --resize bottom:0:50; \\\n                  yabai -m window --resize top:0:50\nlctrl + alt - k : yabai -m window --resize top:0:-50; \\\n                  yabai -m window --resize bottom:0:-50\nlctrl + alt - l : yabai -m window --resize right:50:0; \\\n                  yabai -m window --resize left:50:0\n\n# Equalize size of windows\nlctrl + alt - e : yabai -m space --balance\n\n# Enable / Disable gaps in current workspace\nlctrl + alt - g : yabai -m space --toggle padding; yabai -m space --toggle gap\n\n# Rotate windows clockwise and anticlockwise\nalt - r         : yabai -m space --rotate 270\nshift + alt - r : yabai -m space --rotate 90\n\n# Rotate on X and Y Axis\nshift + alt - x : yabai -m space --mirror x-axis\nshift + alt - y : yabai -m space --mirror y-axis\n\n\n# Float / Unfloat window\nshift + alt - space : \\\n    yabai -m window --toggle float; \\\n    yabai -m window --toggle border\n\n# Restart Yabai\nshift + lctrl + alt - r : \\\n    /usr/bin/env osascript &lt;&lt;&lt; \\\n        \"display notification \\\"Restarting Yabai\\\" with title \\\"Yabai\\\"\"; \\\n    launchctl kickstart -k \"gui/${UID}/homebrew.mxcl.yabai\"\n\n# Make window native fullscreen\nalt - f         : yabai -m window --toggle zoom-fullscreen\nshift + alt - f : yabai -m window --toggle native-fullscreen\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Configure the Tiling Window Manager Yabai for Macos},\n  date = {2024-02-09},\n  url = {https://focusonr.org/posts/setup_yabai},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Configure the Tiling Window\nManager Yabai for Macos.” February 9, 2024. https://focusonr.org/posts/setup_yabai."
  },
  {
    "objectID": "posts/config_ultisnips/index.html",
    "href": "posts/config_ultisnips/index.html",
    "title": "Configure ultisnips to streamline R and Rmd coding",
    "section": "",
    "text": "iterm2\n\n\n\n1 Introduction\nSnippets are a useful mechanism to streamline coding in R, Rmarkdown, and Quarto and really any other programming language. They are code templates that can be inserted as replacements for trigger strings the progammer enters. They can be set up to be automatic or on-demand or contingent on ??.\n\n\n\n2 References\n\nThe ultisnips help page on github\nUltiSnips Plugin Guide for LaTeX | Vim and LaTeX Series Part 2 | ejmastnak\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Configure Ultisnips to Streamline {R} and {Rmd} Coding},\n  date = {2024-07-02},\n  url = {https://focusonr.org/posts/config_ultisnips},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Configure Ultisnips to\nStreamline R and Rmd Coding.” July 2, 2024. https://focusonr.org/posts/config_ultisnips."
  },
  {
    "objectID": "posts/install_mint_on_macbook/index.html#install-mint-on-a-macbook-air",
    "href": "posts/install_mint_on_macbook/index.html#install-mint-on-a-macbook-air",
    "title": "Install Linux Mint on a Macbook Air",
    "section": "1.1 Install Mint on a macbook air",
    "text": "1.1 Install Mint on a macbook air\nThe target machine is a 2016 13-inch MacBook Air with four Thunderbolt 3 Ports.\nTo start the process download an iso file from the Mint website. The current “Virginia” version of Mint iso file is 3.07 GB in size. The “Cinnamon” edition is recommended.\nSpecifically, download the torrent file for Linux Mint 22 Wilma Cinnamon edition. linuxmint-22-cinnamon-64bit.iso.torrent Install the mac app Transmission and add the torrent file.\nAlso download the associated sha256sum.txt file.\nTo check the integrity of your local ISO file, generate its SHA256 checksum and compare it to the content of the sha256sum.txt file:\n&gt; sha256sum -b linuxmint-22-cinnamon-64bit.iso\nWe can transfer the iso file to a USB flash drive using one of several methods. On macos we suggest using the app balanaEtcher. You can download balanaEtcher\nInsert the bootable USB flash drive into the target macbook and reboot. Hold the ALT key while the machine reboots and you’ll be presented with a screen offering boot drive options. Select the icon for the USB drive. A grub menu will appear.1\n1  GNU GRand Unified Bootloader (GRUB). “When your Linux operating system starts up, GRUB is the first program that runs. It loads the kernel of the operating system, and then the kernel loads the rest of the operating system, including the shell, the desktop environment, and other operating system features.”  codecademy.com  From the Grub menu choose Start Linux Mint 22 Cinnamon 64-bit. and the Mint install program will start.\nA linux mint desktop will appear allowing you to “test drive” Mint or to continue the install by double clicking the icon labeled install Linux Mint.\nA setup dialog will start. Select, in sequence\n\nLanguage (English for us),\nNetwork (If ethernet is available startup program will autmatically connect. If wifi only, not needed at this point, suggest skip),\ncodexes (check box “install multimedia codecs”),\noptions for installation type (choose “erase disk and install linux mint”).\nLocation (Los Angeles for us),\nname a user who will have administrator privileges, assign a password, and a hostname.\n\nAfter these screens the install process will proceed without additional user input.\nWhen complete connect the target machine to the Internet. As mentioned above, if you have ethernet connectivity plug the cable directly into the target macbook and Mint should connect automatically to the internet. For wireless wifi access Mint may or may not recognize hardware modem. If not use a supported external modem e.g. Panda Wireless modem. Panda is supported since Mint 22 has Ralink RT5372 drivers installed.\nThe final hardware related step is to add a second monitor, if available, via HDMI or “USB-C”.\nThats it. The base system is ready to go. Reboot and login with the admin username and password you provided earlier."
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#create-security-group-script",
    "href": "posts/server_setup_aws_cli/index.html#create-security-group-script",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.1 Create security group script",
    "text": "2.1 Create security group script\nGenerate security group: `\nExample:\n&gt; aws_create_security_group.sh -s $proj_name -g -k\nThis version of the script creates a security group with options to open ports: 22, 80, 3838, 443, 9000, and 9001 with flags -g, -i, -j, -k, -l, -m respectively.\nThe default, i.e. no flags set, is to open 22 and 443 only. the security group name is set as the base directory name.\n\n#!/usr/bin/env bash\nHelp()\n{\necho  The script generates a new security group\necho  the group name is given with the -n flag.\necho  ports are specificed with the -p flag. Any number of ports can be listed\necho  Anticipated incoming ports are 22 ssh, 80 http, 3838 shiny and 443 https.\necho  Script will fail if group name is already in use on EC2.\necho  reads vpc_id from the environment variables set in .zshrc\necho  example usage for ports 22, 80 and 443:\necho  aws_create_security_group.sh -n power1_app  -p 22 -p 80 -p 443\n}\nsg_grp_name=`basename $PWD`\nwhile getopts \":hp:n:\" opt; do\n    case $opt in\n        p ) ports+=(\"$OPTARG\") ;; # use the split+glob operator\n        n ) sg_grp_name=$OPTARG ;;\n        h ) Help\n            exit ;;\n        * ) echo 'error in command line parsing. Expect options n and p' &gt;&2\n            exit 1\n    esac\ndone\necho \"sg group name = $sg_grp_name\"\n\naws ec2 create-security-group \\\n    --group-name $sg_grp_name \\\n    --description \"security group\" \\\n    --tag-specifications \\\n    \"ResourceType=security-group,Tags=[{Key=Name,Value=$sg_grp_name}]\" \\\n    --vpc-id $vpc_id  &gt; temp.txt\nwait\nsecurity_grp=`jq -r .GroupId temp.txt`\nwait\necho \"security group ID = $security_grp\"\n\n for i in \"${ports[@]}\"\n do\n   aws ec2 authorize-security-group-ingress \\\n    --group-id $security_grp \\\n    --protocol tcp \\\n    --port ${i} \\\n    --cidr \"0.0.0.0/0\" &gt; /dev/null\n done"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#create-new-key-pair-with-a-project-name-flag",
    "href": "posts/server_setup_aws_cli/index.html#create-new-key-pair-with-a-project-name-flag",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.2 Create new key pair with a project name flag",
    "text": "2.2 Create new key pair with a project name flag\nExample usage: Note run with one parameter for optional keypair name.\n&gt; aws_create_keypair.sh -k $keypair_name\n\n#!/usr/bin/env bash\nHelp()\n{\necho  The script generates a new keypair\necho  the keypair name is given with the -k flag.\necho  Script will fail if pair name is already in use on EC2.\necho  aws_create_keypair.sh -k power1_app\n}\nwhile getopts 'hk:' flag; do\n  case \"${flag}\" in\n    h) Help\n      exit;;\n    k) key_pair_name=${OPTARG};;\n  esac\ndone\nbase=`basename $PWD`\nif [ -z \"$key_pair_name\" ]\nthen\n  key_pair_name=$base\nfi\necho \"key_pair_name is $key_pair_name\"\n\ncd ~/.ssh\nrm -f  ~/.ssh/$key_pair_name.pem\naws ec2 create-key-pair  --key-name  $key_pair_name \\\n   --query 'KeyMaterial' --output text &gt; ~/.ssh/$key_pair_name.pem\n\nwait\nchmod 400 ~/.ssh/$key_pair_name.pem"
  },
  {
    "objectID": "posts/server_setup_aws_cli/index.html#generate-instance",
    "href": "posts/server_setup_aws_cli/index.html#generate-instance",
    "title": "Using the AWS command line interface to launch an EC2 server",
    "section": "2.3 Generate instance",
    "text": "2.3 Generate instance\nstart up script. &gt; aws_create_instance.sh -p power1_app\n\n\n#!/usr/bin/env bash\nHelp()\n{\necho \"Notes on currect parameters:\"\necho \"security group should be in place already. check on EC2.  If not,\nrun ./awscli_create_security.sh.  \"\necho \"Key pair should be in place. check on EC2 and in ~/.ssh.\nIf not run ./create_keypair.sh. \"\necho \"ami id is for ubuntu linux 22.04 LTS.\nIf not what is desired check EC2 list of instances.\"\necho \"Check static IP: nslookup IPaddress.\nShould point to the domain name e.g.  rgtlab.org \"\necho  Usage: &gt;aws_create_instance.sh -p power1_app\necho \"\"\necho \"Review parameters: \"\necho \"---\"\necho \"proj_name is $proj_name\"\necho \"keypair_name is $keypair_name\"\necho \"vpc_id: $vpc_id\";\necho \"subnet_id: $subnet_id\";\necho \"ami_id: $ami_id\";\necho \"security_grp: $security_grp\";\necho \"static_ip: $static_ip\";\necho \"type: $type\";\necho \"size: $size\";\n}\nwhile getopts 'hp:' flag; do\n  case \"${flag}\" in\n    h) Help\n      exit;;\n    p) proj_name=${OPTARG};;\n  esac\ndone\nbase=`basename $PWD`\nif [ -z \"$proj_name\" ]\nthen\n  proj_name=$base\nfi\n\naws ec2 run-instances \\\n--image-id $ami_id \\\n--count 1 \\\n--instance-type $instance_type \\\n--key-name $keypair_name \\\n--security-group-ids $security_grp \\\n--subnet-id $subnet_id \\\n--block-device-mappings \"[{\\\"DeviceName\\\":\\\"/dev/sda1\\\",\\\"Ebs\\\":{\\\"VolumeSize\\\":$storage_size}}]\" \\\n--tag-specifications \"ResourceType=instance,Tags=[{Key=Name,Value=$proj_name}]\"  \\\n--user-data file://~/Dropbox/prj/c060/aws_startup_code.sh\n iid0=`aws ec2 describe-instances --filters \"Name=tag:Name,Values=$proj_name\" | \\\n    jq -r '.Reservations[].Instances[].InstanceId'`\necho $iid0\nread -p \"enter instance id:\" iid\necho \"instance id: $iid\"\naws ec2 associate-address --public-ip $static_ip --instance-id $iid\naws_startup.sh\n\n#!/bin/bash\napt update\n# Add Docker and Docker Compose support to the Ubuntu's packages list\napt-get install curl -y\napt-get install gnupg -y\napt-get install ca-certificates -y\napt-get install lsb-release -y\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | \\\n  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\necho \"deb [arch=\"$(dpkg --print-architecture)\" \\\nsigned-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n\"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\nsudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\napt-get update\napt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y\nsu ubuntu -\nusermod -aG docker ubuntu\n\n\n\n\n\n\nTip 1.\n\n\n\nFor convenience, construct a config file in ~/.ssh as:\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen we can ssh into the new server with\nsh&gt; ssh rgtlab.org\n\n\nChange the access permissions: sudo chmod 600 power1ssh.pem to be more restrictive."
  },
  {
    "objectID": "posts/setupgit/index.html",
    "href": "posts/setupgit/index.html",
    "title": "Setting up git for (solo) data science workflow",
    "section": "",
    "text": "purrr\n\n\n\n1 Introduction\nVersion Control for biostatistics/data-science data analysis is the challenge. There are multiple systems to choose from. We’ll discuss how to get started with git in this post.\nLets take it one step at a time.\nScenario 1: We have a git user @rgt47 has been working on a data analysis for some data from the public alzheimers disease data repository, ADNI. Its moderately complex and uses lots of packages. He’s ready to ask his team to join the analysis process. What are the first steps he should take to do that?\nStep 1. Start by adding the first team member with a github username @rgt4748 to the project.\nStep 2. User rgt47 should log into Github and navigating to the repository to be shared, say x24. Select settings (in top row of tabs) and then the collaborators tab (in the left panel)\nSelect green “add people” button on the right side of the page, then “invite collaborator”, then use the search box in the center of the page to locate user rgt4748. Lastly select “Add rgt4748”.\n\n#...............................................................................\n#                                                                              .\n#  got this far. All edits made. 8/20/24                                       .\n#                                                                              .\n#...............................................................................\n\nStep 3. rgt4748 should login and accept invitation:\nclick “message” icon in upper right corner.\nSelect “Invitation to join rgt47/x23 from rgt47”, then “Accept Invitation” green button in center of page.\nThey’ll be taken to the rgt47/x24 repo.\nNow on their workstation they can clone repository with the following code:\n&gt; git clone https://github.com/rgt4748/x24.git\n&gt; cd x24\n&gt; git branch myedits\n&gt; git checkout myedits\n&gt; vim x24.Rmd\nmodify title: \"R2\" to title: \"changed R2\" and save edits.\n&gt; git add .\n&gt; git commit -m \"sample edit\"\n&gt; git push origin myedits #(?)\n&gt; git checkout master\n&gt; git merge myedits\n&gt; git branch -d myedits #(delete branch)\nClick contribute button, then open pull request, create pull request, enter title and description.\nlogin as rgt47. you’ll see one notification. check files changed\n\n\n2 Appendix. GIT for nitwits\ngit init\ngit add fname\ngit status #see what happens on commit git commit -am “commit message”\ngit push\ngit branch work\ngit checkout work\n… make changes … git add * git commit -m “something”\ngit checkout master\ngit merge work\ngit branch -d work\ngit log #see all commits\ngit checkout HASH #Restore old branch\nConsider editing ./.git/config\nView file in master branch. git show master:a101.Rmd | mvim -\nCopy file from other branch (master) git checkout master uw.png\n\n\n3 Appendix: Tips\nTroubleshooting git pull –allow-unrelated-histories\nRule 6: Use the Imperative mood\nA valuable practice involves crafting commit messages with the underlying understanding that the commit, when implemented, will achieve a precise action. Construct your commit message in a manner that logically completes the sentence “If applied, this commit will…”. For instance, rather than,git commit -m “Fixed the bug on the layout page” . use this git commit -m “Fix the bug on the layout page” ✔\nIn other words, if this commit were to be applied, it would indeed fix the bug on the layout page.\nRule 7: Explain “What” and “Why”, but not “How”.\nLimiting commit messages to “what” and “why” creates concise yet informative explanations of each change. Developers seeking “How” the code was implemented can refer directly to the codebase. Instead, highlight what was altered and the rationale for the change, including which component or area was affected.\nCase Study: Angular’s Commit Message Practices\nAngular stands as a prominent illustration of effective commit messaging practices. The Angular team advocates for the use of specific prefixes when crafting commit messages. These prefixes include “chore: ,” “docs: ,” “style: ,” “feat: ,” “fix: ,” “refactor: ,” and “test: .” By incorporating these prefixes, the commit history becomes a valuable resource for understanding the nature of each commit. Tips\nRemember to prioritize clear and meaningful communication through your commit messages. A well-crafted commit message serves as a story that explains ‘what,’ ‘why,’ but not ‘how’ a change was made. Remember, your commit history is a collaborative resource that future you and your team will rely on. Make it a habit to create commit messages that stand as informative, concise, and consistent narratives.\nInterested in deepening your understanding of Git and evolving into a proficient “version controller”? Explore these exceptional resources:\n\nhttps://git-scm.com/doc\nhttps://git-scm.com/book/en/v2\nhttps://lab.github.com/\nhttps://www.atlassian.com/git/tutorials\nhttps://learngitbranching.js.org/\nhttps://www.gitkraken.com/git-cheat-sheet\nhttps://www.git-tower.com/learn/\n\n\n\n4 References:\nBest way to manage your dotfiles.\nGit Basics — All You Need To Know as a New Developer. | by Gabriel Bonfim | Sep, 2023 | Medium\nBryan, J. (2018). Excuse Me, Do You Have a Moment to Talk About Version Control? The American Statistician, 72(1), 20–27.\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Setting up Git for (Solo) Data Science Workflow},\n  date = {2024-08-21},\n  url = {https://focusonr.org/posts/setupgit},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Setting up Git for (Solo) Data\nScience Workflow.” August 21, 2024. https://focusonr.org/posts/setupgit."
  },
  {
    "objectID": "posts/share_R_code_via_docker/index.html",
    "href": "posts/share_R_code_via_docker/index.html",
    "title": "Simple process for sharing R code via Docker",
    "section": "",
    "text": "1 Motivation\nWe have code we want to send to a colleague to run and/or edit. In doing this we need to avoid the problem of potentially different R and R-package versions. We also need to avoid needing to install pandoc and latex as well as supplemental files, e.g. bibtex, latex preamble, logo graphics files.\nIn sum, we want out colleague to simply have to download a github repository and pull a docker image from dockerhub and then run the command:\ndocker run  -v \"$(pwd):/home/joe\" -v \"$(pwd)/output:/home/joe/output\" rgt47/penguins1\ninside the repo to get access to the identical R environment. And\n\nvim peng1.Rmd \nto edit\nand\nR -e \"library(rmarkdown); render('peng1.Rmd')\" \nto process code through R, pandoc, and latex.\n\n\n2 Introduction\nIts often the case that two research collaborators want to work on the same R codebase. Unfortunately, to accomplish this, its often not as simple as one researcher sending a text file containing the code to the other colleague.\nFor example, a number of elements of the computing environment can differ between collaborators, such as: the version of R, the operating system(macos vs. windows vs Linus vs Other), R packages installed, the versions of the packages, startup files (e.g. .Rprofile) and environment variables. Any of these can cause code working for one reseracher to break when run by a second.\n\n\n3 Methods\nLets assume you have some R program code in a file, say peng.R, that you’re written to analyze some “Palmer Penguin” data. You want to share the code with a colleague, we’ll call him Joe. How to proceed?\nThe simplest option is simply to send Joe the R file containing the code via the most convenient method (e.g. email)\nThe next step is for for Joe to (attempt to) run the code with the idea of expanding the analysis. Typically he would do this either using an IDE, such as Rstudio, or run the code from the command line in the terminal with the command:\n&gt; R -e \"source('peng1.Rmd')\"\nSometimes this approach works. When it does, Joe can add comments or expand the code and relay it back to you, “rince and repeat” and all is well. Frequently, however, this simple approach will fail for any of several reasons. Even when it runs, unless care is taken, its not guaranteed that Joe will get the same results you do.\nIdeally to facilitate reproducibility your colleague Joe will have a computing environment as similar to yours as possible. This can be difficult to achieve, especially given the dynamic nature of open source software. For example, Joe may have an older version of R installed on his workstation, or his R environment may be missing a necessary package to run the code or it may be the wrong version. Additiional potential problems include: the program may need to source an additional file or load data that’s missing.\nAll of these problems go away if instead of sending the program as a standalone text file you send it as a docker image. In this post we’ll walk through the process of dockerizing the R code.\n\n\n4 Methods\nAssume we have a simple R file that we want to share with Joe such as the following:\n---\ntitle: \"\\\\includegraphics[width=2cm, right]{sudoku_apple.pdf}\\\\newline \n  New Penguin plot\"\nauthor: \"R.G. Thomas\"\ndate: \"`r format(Sys.time(), '%B %d, %Y')`\"\nfontsize: 11pt\ngeometry: \"left=3cm,right=5cm,top=2cm,bottom=2cm\"\noutput:\n  pdf_document:\n    keep_tex: true \n    includes:\nheader-includes:\n   - \\usepackage{lipsum}\n   - \\usepackage[export]{adjustbox}\n   - \\usepackage{currfile}\n   - \\usepackage{fancyhdr}\n   - \\pagestyle{fancy}\n   - \\setlength{\\headheight}{14pt}\n   - \\fancyfoot[L]{\\currfilename} %put date in header\n   - \\fancyfoot[R]{\\includegraphics[width=.8cm]{sudoku_apple.pdf}}\n   - \\fancyhead[L]{\\today} %put current file in footer\n   - \\fancyhead[R]{Penguins RGT Lab report}\nlatex_engine: xelatex\n---\n\n```{r  echo=F}\n# clear env: objects and packages\nlibrary(pacman)\np_load(palmerpenguins, rmarkdown, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, fig.width = 5.2,\n  fig.height = 3, results = \"asis\", dev = \"pdf\"\n)\n```\n\n# Introduction\n\n\\lipsum[1-5]\n\nDraft report examining Penguin characteristics. Data from Alison Horst article\nin the `R journal` \n@m.horstPalmerArchipelagoPenguins2022\n\n```{r }\nattach(penguins)\nplot(flipper_length_mm, bill_length_mm, col = sex)\nlegend(\"topleft\", legend = levels(sex), pch = 16, col = unique(sex))\n```\n\n\\lipsum[1-5]\n\\bibliography{penguins.bib}\n\\bibliographystyle{plain}\n\\nocite{*}\n\n\n5 Share program code with Joe.\nJoe downloads the attachment. Opens a working directory and attempts to run the Rmd file\nwith the command\n&gt; R -e \"source('peng1.Rmd')\"\nJoe has a linux mint desktop\n&gt; mkdir peng1\n&gt; cd peng1\n&gt; R -e \"render('peng1.Rmd')\"\nLinux can’t find R\nJoe can fix this by installing R\n&gt; sudo apt install r-base-core\nSo install R…. to fix\n\nsudo apt install r-base-core Try again…\n\n\nR -e “render(‘peng1.Rmd’)” Result: R loads but gives error: could not find function “render”\n\nSearch google “R render”\nResult: https://pkgs.rstudio.com/rmarkdown/reference/render.html\nLooks like render is a function inside rmarkdown package. so install package\n\nR&gt; install.packages(\"rmarkdown\")\nTry again.\n\n&gt; R -e \"library(rmarkdown); render('peng1.Rmd')\"\nResult: error. pandoc version 1.12.3 or higher required.\nNow try to install pandoc Try again. &gt; R -e “library(rmarkdown); render(‘peng1.Rmd’)” Result: error. there is no called pacman\nso install pacman R&gt; install.packages(“pacman”) Try again…\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)” result: failed pandoc could not find /Users/zenn/shr/preamble.tex\n\nThis makes sense we forgot to send the preamble.tex file to researcher 2. Lets send it now. Also we need to adjust its location from a macos style file name to a linux based one.\nTo edit peng1.Rmd we need vim &gt; sudo apt install vim\nTry again Result: pandoc error “pdflatex not found” Lets install tinytex. First in R and then in mint R&gt; install.packages(“tinytex”) R&gt; tinytex::install_tinytex() # to uninstall TinyTeX, run # tinytex::uninstall_tinytex()\nTry again:\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)” result: pandoc error: file sudoku_apple.pdf not found.\n\nThis makes sense we forgot to send the logo file. Lets send the file and try again.\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)” Result: error no bibliography file found.\n\nThis makes sense we forgot to send the bib file. Lets send the file and try again. Also need to edit the location of bib file.\nTry again:\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)”\n\nresults: minor error. Some packages weren’t loading via pacman.\nTry removing janitor, kableExtra, tidyverse, readxl and add ggplot2.\nTry again:\n\nR -e “library(rmarkdown); render(‘peng1.Rmd’)”\n\nSuccess!\nLesson learned: The program peng1.Rmd needs access to three external files: 1. preamble.tex 2. penguins.bib 3. sudoku_apple.pdf\n\n\n6 Docker approach\nAlternatively, consider the “Docker” approach.\nBefore sending peng.Rmd to Joe we’ll dockerize it.\n\nPrepare a work directory: peng1. We want to prepare a repo and a docker image that has a standardized computing environment set up including R, the R packages and all the preliminaries taken care of, so that all Joe has to do is clone the repo and run the image from dockerhub.\n\nSteps for Joe:\n\ninstall docker on his machine.\ndownload docker image from dockerhub\nrun image\n\nHere is the docker file\n\nFROM rocker/r-devel\nRUN apt-get update -qq && apt-get -y --no-install-recommends install \\\n    libxml2 \\\n    libxml2-dev \\\n    libcairo2-dev \\\n    libsqlite3-dev \\\n    libpq-dev \\\n    libssh2-1-dev \\\n    unixodbc-dev \\\n    r-cran-v8 \\\n    libv8-dev \\\n    net-tools \\\n    libprotobuf-dev \\\n    protobuf-compiler \\\n    libjq-dev \\\n    libudunits2-0 \\\n    libudunits2-dev \\\n    libgdal-dev \\\n    libssl-dev\n## update system libraries\nRUN apt-get update && \\\n    apt-get upgrade -y && \\\n    apt-get clean\nRUN apt-get install pandoc -y\nRUN groupadd --system joe\nRUN useradd --system --gid joe -m joe\nRUN chown joe:joe -R /home/joe\nUSER joe\nWORKDIR /home/joe\nCOPY renv.lock renv.lock\nRUN R -e \"install.packages('renv', repos = c(CRAN = 'https://cloud.r-project.org'))\"\nCOPY renv/settings.json renv/settings.json\nRUN R -e \"renv::restore()\"\nCMD [\"/bin/bash\"]\nrun docker\ndocker build -t rgt47/penguins1 --platform=linux/amd64 .\nrelay image to Joe via dockerhub.\ndocker push rgt47/penguins1\nor\ndocker save rgt47/penguins1 | gzip &gt; penguins1_transfer.tgz\ndocker load -i penguins1_transfer.tgz\n&gt; docker pull rgt47/penguins1\n\ndocker run -it --rm \\\n-v \"$(pwd):/home/joe\" -v \"$(pwd)/output:/home/joe/output\" rgt47/penguins1\n\n\n&gt; cd output\n&gt; library(rmarkdown); render('peng1.Rmd')\nImportant to include the association between the /home/joe/output directory in the container with the output directory on the local workstation. Thats where the results of the analysis will be saved.\n&gt; R -e \"library(rmarkdown); render('peng1.Rmd')\"\nand if he wants to edit peng.Rmd\n&gt; vim peng1.Rmd\n\n\n7 REFERENCES\nRunning your R script in Docker\ndocker run --rm -p 8787:8787 -e PASSWORD=z rocker/rstudio\n\nj share\ncd peng1\n\ndocker build -t rgt47/penguin1 .\ndocker run --rm -it rgt47/penguin1\n\ndroot=\"${PWD}\"\n\ndocker run -it --rm -v $droot:/home/joe/output rgt47/penguin1 \n\nProblem\n☔ docker run -it --rm -v $droot:/home/joe rgt47/penguins1\n\nUnable to find image 'rgt47/penguins1:latest' locally\ndocker: Error response from daemon: manifest for rgt47/penguins1:latest not found: manifest unknown: manifest unknown.\nSee 'docker run --help'.\nshare_R_code_via_docker/peng1 ☔ echo $droot\n/Users/zenn/prj/qblog/posts/share_R_code_via_docker/peng1\nshare_R_code_via_docker/peng1 ☕ mkdir output\nshare_R_code_via_docker/peng1 ☕ f\n\nNeed a base R that includes dev tools\n\nTry rocker/r-devel\n\ndocker build -t rgt47/penguin2 . --platform linux/amd64\n\n\ndocker run --rm \\\n  -e DISABLE_AUTH=true -e ROOT=true \\\n  -v \"$(pwd):/home/rstudio/project:rw\" \\\n  -p 8787:8787 \\\n  --name rstudio rocker/verse:3.6.3\n\ndocker run -it --rm -v “$(pwd):/home/joe” rgt47/penguins1\nDockerfile with R code\n\nFROM rocker/r-devel\nRUN apt-get update && \\\n    apt-get upgrade -y && \\\n    apt-get clean\nRUN apt-get install terminator tree eza ssh zsh git fzf ripgrep vim curl \\\nautojump  zsh-autosuggestions sudo pandoc -y\nRUN Rscript -e 'install.packages(\"renv\")'\nCOPY renv.lock renv.lock\nRUN  Rscript -e 'renv::restore()'\nRUN groupadd --system joe\nRUN useradd --system --gid joe -m joe\nRUN usermod -aG sudo joe\nRUN echo joe:z | chpasswd\nRUN chown joe:joe -R /home/joe\nRUN chown joe:joe -R /usr/local/lib/R/site-library\nRUN chsh -s $(which zsh) joe\nWORKDIR /home/joe/\nCOPY .vimrc .vimrc\nCOPY .zshrc .zshrc\nRUN chown joe:joe -R /home/joe\nRUN mkdir -p  /home/joe/output\nUSER joe\nRUN curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\\n    https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\nCMD [\"/bin/zsh\"]\ndocker build -t rgt47/penguins1 . --platform linux/amd64\ndocker pull rgt47/penguins \ndocker run -it --rm -v \"$(pwd):/home/joe/peng2\" -v \"$(pwd)/out:/home/joe/output\" rgt47/penguins1\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Simple Process for Sharing {R} Code via {Docker}},\n  date = {2024-08-22},\n  url = {https://focusonr.org/posts/share_R_code_via_docker},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Simple Process for Sharing R\nCode via Docker.” August 22, 2024. https://focusonr.org/posts/share_R_code_via_docker."
  },
  {
    "objectID": "posts/share_shiny_code_via_docker/index.html",
    "href": "posts/share_shiny_code_via_docker/index.html",
    "title": "Simple process for sharing R code via Docker",
    "section": "",
    "text": "1 Introduction\nLets assume you have an rmarkdown Rmd file, say peng.Rmd, that you’re written to analyze some data. You now want to share the code with a colleague, we’ll call him Joe. How to proceed?\nThe simplest option is simply to send Joe the “rmd” file containing the code via the most convenient method (e.g. email/text/slack/discord/github/USB drive etc.)\nThe next step will be for the Joe to ( attempt to ) load and run the code. Typically he would do this with either using Rstudio.app to open the file and knit it, render it from the command line with the command:\n&gt; R -e \"render('peng.Rmd')\"\nSometimes this approach works, and all is well. Joe can add comments or expand the code and reply to you. Frequently, however, this naive process will fail for any number of reasons. Ideally to facilitate reproducibility Joe will have as similar a computing environment as you, the original developer. This can be difficult to achieve, especially given the dynamic nature of open source software. For example Joe may have an outdated version of R installed on his workstation, or his R environment may be missing a necessary package. Additiional potential problems include: the required package may be present but its the wrong version, the program may need to source an additional file thats missing, or the program load some data that it can’t find on Joe’s machine.\nAll of these problems go away if instead of sending the program as a standalone text file you send it as a docker image. In this post we’ll walk through the process of dockerizing the R code.\nAssume a simple Rmd file like this:\n\n---\ntitle: \"Penguins analysis\"\nauthor: \"R.G. Thomas\"\ndate: \"`r format(Sys.time(), '%B %d, %Y')`\"\nfontsize: 11pt\ngeometry: \"left=3cm,right=5cm,top=2cm,bottom=2cm\"\noutput:\n  pdf_document:\n    keep_tex: true\n    includes:\n      in_header: \"preamble.tex\"\n---\n\n```{r include=F, echo=F}\nlibrary(pacman)\np_load(palmerpenguins, tidyverse, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, results = \"asis\", dev = \"pdf\"\n)\n```\n\n# Introduction\n\nWe can work with the dataset `penguins` included in the package `palmerpenguins`.\n```{r }\nlibrary(palmerpenguins)\n```\nOne naive approach is to split the dataset and do three separate\nanalyses:\n\n```{r }\ndf1 &lt;- split(penguins, penguins$species)\n\nfoo &lt;- function(df, z) {\n  df |&gt; ggplot(aes(x = bill_length_mm, y = flipper_length_mm)) +\n    geom_point(aes(color = island), alpha = .5) +\n    geom_smooth() +\n    scale_color_manual(values = c(\"purple\", \"green\", \"red\")) +\n    theme_bw() +\n    labs(\n      title = paste(z, \" Penguin Anatomy Comparison\"), x = \"Flipper length\",\n      y = \"Bill length\", color = \"Island\"\n    )\n  plotfile_name &lt;- paste0(z, \".pdf\")\n  ggsave(plotfile_name)\n  cat(paste0(\"\\\\includegraphics[height=3cm]{\", plotfile_name, \"}\"), \"\\n\")\n  cat(\"\\\\vspace{1cm}\", \"\\n\")\n}\n\nbar &lt;- df1 |&gt; map2(names(df1), foo)\n```\nThe Rmd file runs cleanly on our machine and generates the the report on the following page. However, we note that the third plot needs additional examination and want to relay the program to our colleague Joe for further analyis.\n\n\n\nrendered page\n\n\n\n\n2 Share program code with Joe. Two approaches, Naive and Docker based.\nWhats the best way to accomplish this?\nWe start by simply emailing the file to him (rgthomas4747@gmail.com) and asking him to collaborate.\nJoe downloads the attachment. Opens a working directory and attempts to run the Rmd file\nwith the command\n&gt; R -e \"render('peng.Rmd')\"\nJoe has a linux mint desktop\n&gt; mkdir peng_collaboration\n&gt; cd peng_collaboration\n&gt; R -e \"render('peng.Rmd')\"\nLinux can’f find R\nJoe can fix this by installing R\n&gt; sudo apt install r-base-core\nNext R can not find the function render.\nJoe determines that render is a function in the package rmarkdown\nHe endeavors to installs rmarkdown with\n\nR -e \"install.packages('rmarkdown')\"\nThis fails due to inadequate permission on the directory /usr/lib/R/library\n\nsudo apt install libssl-dev libcurl4-openssl-dev unixodbc-dev libxml2-dev\\\nlibmariadb-dev libfontconfig1-dev libharfbuzz-dev libfribidi-dev\\\nlibfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev\nAlso latex is not available\nOne more try… and the latex engine notes the absence of the file\n~/shr/preamble.tex\nSo, I need to relay the missing .tex file.\nAlso the .png (sudoku.png) logo file.\nFinally! success.\n\n\n3 Docker approach\nAlternatively, consider the “Docker” approach.\nBefore sending peng.Rmd to Joe we’ll dockerize it.\n\nPrepare a work directory: penguins. We want to send Joe a container that has R and all the preliminaries taken care of so that all he has to do is\n\nHere is the docker file\n\nFROM rocker/verse:4\nRUN apt update\nRUN apt install vim -y\nRUN R -e \"install.packages('pacman')\"\nRUN R -e \"install.packages('palmerpenguins')\"\nRUN R -e \"install.packages('tidyverse')\"\nRUN R -e \"install.packages('knitr')\"\nRUN R -e \"install.packages('rmarkdown')\"\nRUN tlmgr init-usertree\nRUN tlmgr update --self --all\nRUN  tlmgr install  fancyhdr adjustbox geometry titling\n\nRUN addgroup --system joe && adduser --system --ingroup joe joe\nRUN chmod -R 0777 '/usr/local/lib/R/site-library'\nRUN chown joe:joe -R /home/joe\nUSER joe\nWORKDIR /home/joe\nRUN mkdir -p /home/joe/shr\nRUN mkdir -p /home/joe/output\nCOPY /preamble.tex /home/joe/shr\n# COPY /.Rprofile /home/joe/shr\nCOPY sudoku.png /home/joe/shr\nCOPY peng.Rmd /home/joe/shr\nCMD [\"/bin/bash\"]\nrun docker\ndocker build -t rgt47/penguin_review --platform=linux/amd64 .\ndocker push rgt47/peng_review\nrelay image to Joe\ndocker push rgt47/peng_review\nor\ndocker save rgt47/peng_review | gzip &gt; peng_review_trans.tgz\ndocker load -i peng_review_trans.tgz\n&gt; docker pull rgt47/penguin_review\n\n&gt; droot=\"$PWD\"/output docker run -it --rm --platform linux/x86_64 \\\n-v $droot:/home/joe/output peng_review\n&gt; cd output\n&gt; library(rmarkdown); render('../shr/peng.Rmd')\nImportant to include the association between the /home/joe/output directory in the container with the output directory on the local workstation. Thats where the results of the analysis will be saved.\n&gt; R -e \"library(rmarkdown); render('peng.Rmd')\"\nand if he wants to edit peng.Rmd\n&gt; vim peng.Rmd\n\n\\usepackage[export]{adjustbox}\n\\usepackage{fancyhdr}\n\\usepackage{titling}\n\n\\pagestyle{fancy}\n\n\\pretitle{\n\\begin{flushright}\n\\includegraphics[width=3cm,valign=c]{sudoku.png}\\\\\n\\end{flushright}\n\\begin{flushleft} \\LARGE }\n\\posttitle{\\par\\end{flushleft}\\vskip 0.5em}\n\\predate{\\begin{flushleft}\\large}\n    \\postdate{\\par\\end{flushleft}}\n    \\preauthor{\\begin{flushleft}\\large}\n    \\postauthor{\\par\\end{flushleft}}\n\\fancyfoot[L]{\\currfilename} %put date in header\n\\fancyfoot[R]{\\includegraphics[width=.8cm]{sudoku.png}}\n\\fancyhead[L]{\\today} %put current file in footer\n\n\n4 REFERENCES\nRunning your R script in Docker\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Simple Process for Sharing {R} Code via {Docker}},\n  date = {2024-08-22},\n  url = {https://focusonr.org/posts/share_shiny_code_via_docker},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Simple Process for Sharing R\nCode via Docker.” August 22, 2024. https://focusonr.org/posts/share_shiny_code_via_docker."
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#connect-to-target-machine-with-ssh",
    "href": "posts/install_arch_on_macbook/index.html#connect-to-target-machine-with-ssh",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "4.1 Connect to target machine with ssh",
    "text": "4.1 Connect to target machine with ssh\nconfigure WIFI\n\nbash&gt; iwctl\n\nidw&gt; device list (optional) (assume device is wlan0)\nidw&gt; station wlan0 scan (optional)\nidw&gt; station wlan0 connect rgtnet2\npassphrase for rgtnet2\nidw&gt; exit\n(assume the local IP address is 10.0.1.176)\nSet a password for root user. You’ll need it to log in.\nbash&gt; passwd\n  (enter `z` password)\nNew password: z\nRetype new password: z\n\nNow switch over to the mac.\n ssh  root@10.0.1.176"
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#begin-install-process",
    "href": "posts/install_arch_on_macbook/index.html#begin-install-process",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "4.2 Begin install process",
    "text": "4.2 Begin install process\nFirst step:\n\npartition harddisk:\n\nbash&gt; cfdisk /dev/nvme0n1\nUse interface to create two partitions:\n\nEFI type of size 1gb\nroot of size entire rest of disk.\nwrite partition to disk\n\ncheck the partition:\n\nFormat the partitions.\n\nEFI disk is fat32\nRoot is ext4\n\n\n# run in three parts\n# part 1\nmkfs.fat -F32 /dev/nvme0n1p1\nmkfs.ext4 /dev/nvme0n1p2\nloadkeys mac-us\ntimedatectl set-ntp true\nmount /dev/nvme0n1p2 /mnt\nreflector -p https  --save /etc/pacman.d/mirrorlist --country US --latest 15\\\n    --sort rate \npacman -Sy\npacstrap /mnt base  linux linux-firmware sudo\ngenfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n\n# part 2\narch-chroot /mnt\n\n# part 3\nln -sf /usr/share/zoneinfo/America/Los\\_Angeles /etc/localtime\nsed -i.bak 's/#en_US\\.UTF-8 UTF-8/en_US.UTF-8 UTF-8/' /etc/locale.gen\nlocale-gen\necho zz &gt;&gt; /etc/hostname\necho LANG=en_US.UTF-8  &gt;&gt; locale.conf\npacman -S  --noconfirm networkmanager intel-ucode grub efibootmgr \\\n  docker xorg-server xf86-video-intel gnome cinnamon vim sudo openssh \\\n  zsh base-devel  pandoc r firefox git fzf ripgrep zathura\n\nsystemctl enable NetworkManager gdm sshd docker\nmkdir /boot/efi\nmount /dev/nvme0n1p1 /boot/efi\ngrub-install --target=x86_64-efi --bootloader-id=GRUB --efi-directory=/boot/efi\ngrub-mkconfig -o /boot/grub/grub.cfg\n\n# next items are interactive\n#### in sudoers uncomment # %wheel ALL=(ALL) ALL\n#### add new user z with password z\nvim /etc/sudoers\n# password for root\npasswd\n\n# create account and assign password, say 'z', for user, say 'z'\nuseradd -m -G wheel z\npasswd z\nexit\numount -l /mnt\nThats it. The base system is ready to go. Reboot and login with the admin username and password you provided earlier. To choose the Cinnamon desktop environment, select z as the user and then click on the selection wheel. The default desktop is Gnome, but an option to switch to Cinnamon is offered."
  },
  {
    "objectID": "posts/install_arch_on_macbook/index.html#setup-yay",
    "href": "posts/install_arch_on_macbook/index.html#setup-yay",
    "title": "Install Arch Linux on a Macbook Air",
    "section": "6.1 setup YAY",
    "text": "6.1 setup YAY\n sudo git clone https://aur.archlinux.org/yay-git.git  \n sudo chown -R z:z ./yay-git\n cd yay-git\n makepkg -si\n yay -Syu \n yay -S autojump\n yay -S zsh-autosuggestions-git\n yay -S zotero\nMake zsh the default shell.\n&gt; chsh -s $(which zsh)\nStart Dropbox to transfer working environment\nyay -S dropbox\ndropbox \n# builtin autostart from preferences 8/12/24\nDropbox startup process will launch a “Sign in” web page. Login with Dropbox credentials through web page.\nNext\nRun bash shell script ~/Dropbox/dotfiles/set_up_links.sh to set up symbolic links (e.g. ln -s ~/Dropbox/prj ~/prj). See Appendix 1 below for details.\nSet up the shell (zsh) per the post [link to set up terminal post]\nInstall zotero using software manager and set up syncing (login: rgthomas)\nadd vimium extension to firefox"
  },
  {
    "objectID": "posts/plots_from_purrr/index.html",
    "href": "posts/plots_from_purrr/index.html",
    "title": "Working example for generating multiple plots inside a map2 call",
    "section": "",
    "text": "purrr\n\n\n\n1 Introduction\nConsider the problem of running a data analysis requiring a separate analysis for each of n strata. For example consider an effort to model the relationship between Bill length and Flipper length across three different species of penguins.\nWe can work with the dataset penguins included in the package palmerpenguins\nlibrary(palmerpenguins)\nOne naive approach is to split the dataset and do three separate analyses:\nThe R package purrr provides a straightforward method to conduct the analyses with a single command. Assume the set of data tables are contained in a list of dataframes. Also assume the analysis is a simple visualization of a potential linear association between two features,\n\n\n\n2 Plots for every variable and each species map inside map see ref 2 below\n\n\n3 combine plots in a upper triangular grid with correlation coefs\n\n\n4 Code\nlibrary(pacman)\np_load(grid, patchwork, rlang, purrr, palmerpenguins, tidyverse, knitr)\n\nopts_chunk$set(\n  warning = FALSE, message = FALSE, echo = FALSE, fig.width = 8,\n  fig.height = 9, results = \"asis\", dev = \"pdf\"\n)\ndf0 &lt;- sample_n(penguins, 50) |&gt; na.omit()\n# nn = 50 ; df1 = sample_n(penguins, 50)\ndf1 &lt;- split(df0, df0$species)\n# df2 = penguins |&gt; group_by(species)\n\n\nct &lt;- names(df0)[3:6]\n# mm = expand.grid(names(df1[3:6]), names(df1[3:6]))\nnn &lt;- t(combn(ct, 2))\ncolnames(nn) &lt;- letters[1:2]\nnn2 &lt;- data.frame(nn) |&gt; cbind(g = \"sex\")\n\nzz.scatter &lt;- function(data, formula, ...) {\n  # function to take a dataframe, and a formula with potentially a '|' group\n  #     option and return scatterplot matrix with optional R^2, loess smooth,\n  #     or least squares line.\n}\n\nplt1 &lt;- function(a, b, g, spc, df_split) {\n  out_plot &lt;- df_split |&gt; ggplot(aes(x = .data[[a]], y = .data[[b]])) +\n    geom_point(aes(color = .data[[g]]), alpha = .5) +\n    geom_smooth() +\n    scale_color_manual(values = c(\"purple\", \"green\", \"red\")) +\n    theme_bw()\n  assign(paste0(spc, \"_\", a, \"_\", b), value = out_plot, envir = .GlobalEnv)\n  return(out_plot)\n}\n\n\ntemp &lt;- df1 |&gt; map2(names(df1), function(df_split, spc) {\n  nn2 |&gt; pmap(function(a, b, g) {\n    plt1(b, a, g, spc, df_split)\n  })\n})\n\ntemp2 = list_flatten(temp)\nX &lt;- grid::textGrob(\"Species 1\")\ntemp2[[2]] = plot_spacer()\ntemp2[[4]] = X\nwrap_plots(temp2, ncol=3, nrow=6) +\n  plot_layout(\n    guides = \"collect\",\n    axis_titles = \"collect\"\n  ) \nA &lt;- temp[[1]][[1]]\np2 &lt;- temp[[1]][[2]]\np3 &lt;- temp[[1]][[3]]\np4 &lt;- temp[[1]][[4]]\np5 &lt;- temp[[1]][[5]]\np6 &lt;- temp[[1]][[6]]\np7 &lt;- temp[[2]][[1]]\np8 &lt;- temp[[2]][[2]]\np9 &lt;- temp[[2]][[3]]\np10 &lt;- temp[[2]][[4]]\np11 &lt;- temp[[2]][[5]]\np12 &lt;- temp[[2]][[6]]\np13 &lt;- temp[[3]][[1]]\np14 &lt;- temp[[3]][[2]]\np15 &lt;- temp[[3]][[3]]\np16 &lt;- temp[[3]][[4]]\np17 &lt;- temp[[3]][[5]]\np18 &lt;- temp[[3]][[6]]\n# names(temp)\n\nlayout &lt;- \"\nX##\nABC\n#DE\n##F\nY##\nGHI\n#JK\n##L\nZ##\nMNO\n#PQ\n##R\n\"\nX &lt;- grid::textGrob(\"Species 1\")\nt2 &lt;- grid::textGrob(\"Species 2\")\nt3 &lt;- grid::textGrob(\"Species 3\")\n\nout &lt;- wrap_plots(\n  X , A, B = p2, C = p3, D = p4, E = p5, F = p6, Y = t2,\n  G = p7, H = p8, I = p9, J = p10, K = p11, L = p12, Z = t3,\n  M = p13, N = p14, O = p15, P = p16, Q = p17, R = p18,\n  design = layout\n) +\n  plot_layout(\n    guides = \"collect\",\n    axis_titles = \"collect\"\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    legend.direction = \"horizontal\",\n    text = element_text(size = 8)\n  )\n\nout\n\n\n5 References\nprincipal components analysis\nAutomating exploratory plots with ggplot2 and purrr\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2024,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Working Example for Generating Multiple Plots Inside a Map2\n    Call},\n  date = {2024-02-23},\n  url = {https://focusonr.org/posts/plots_from_purrr},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2024. “Working Example for Generating\nMultiple Plots Inside a Map2 Call.” February 23, 2024. https://focusonr.org/posts/plots_from_purrr."
  },
  {
    "objectID": "posts/dockerize_simple/index.html",
    "href": "posts/dockerize_simple/index.html",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "",
    "text": "Photo by Nathan Waters on Unsplash"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#pre-launch-tasks",
    "href": "posts/dockerize_simple/index.html#pre-launch-tasks",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.1 Pre-launch tasks",
    "text": "3.1 Pre-launch tasks\nSelect a hosting service\nThere are a number of cloud based server options: Microsoft Azure, Oracle, Google Cloud, Amazon AWS EC2, Digital Ocean and Hetzner to name a few. Each has their own approach to setting up a custom virtual server. Several have free or low-cost service tiers available.\nAn overview of the process with AWS EC2 follows. (Detailed instructions for setting up a virtual server on EC2 both through the EC2 console and the command line interface were described in earlier posts: here and here.\nThe first step is to create an AWS account or sign in to an existing account and navigate to the EC2 dashboard.\nBefore launching the server instance itself we need to define a working environment within EC2. That is, we need to do the following:\n\ngenerate secure shell (ssh) key-pair\nconfigure a firewall.\nobtain a static IP.\nobtain a domain name.\n\nThe configuration has three components:\n\nselect an instance operating system (ubuntu) and\nselect an instance type (t2-micro)\ndetermine the size of the storage space.\n\nOnce the environment and configuration is set up we can launch the server.\nWhen the server is available we can connect via ssh.\nLastly associate the IP address with the domain name.\nssh -i \"~/.ssh/power1_app.pem\"  ubuntu@rgtlab.org\nor using the config setup described in Tip 1 at the end of this post.\nssh rgtlab.org\nThe only software tools necessary to install are Docker and Caddy. If you followed the CLI or console based instructions to set up a virtual server here or here Docker and Caddy will be pre-installed.\nOtherwise you can install them with the following commands:\nsudo apt update\nsudo apt install docker.io -y\nsudo apt install -y curl debian-keyring debian-archive-keyring apt-transport-https\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | \\\nsudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg\ncurl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | \\\nsudo tee /etc/apt/sources.list.d/caddy-stable.list\nsudo apt update\nsudo apt install caddy -y\nAt this point we have a customized virtual server with a static IP address, unique domain name and a firewall in place. In other words, items 1, 2, 3, and 4 from our ‘hosting’ list above are taken care of."
  },
  {
    "objectID": "posts/dockerize_simple/index.html#post-launch-steps-on-local-workstation",
    "href": "posts/dockerize_simple/index.html#post-launch-steps-on-local-workstation",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.2 Post-Launch steps on local workstation",
    "text": "3.2 Post-Launch steps on local workstation\nTo run and host our Shiny app online we need to add a few configuration files to our power1_app development directory."
  },
  {
    "objectID": "posts/dockerize_simple/index.html#we-want-to-containerize-our-app.",
    "href": "posts/dockerize_simple/index.html#we-want-to-containerize-our-app.",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.3 We want to containerize our app.",
    "text": "3.3 We want to containerize our app.\nBy dockerizing the Shiny app we can assure that whenever its run all the required software and the right versions are ava\nThe first configuation file is:"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#docker",
    "href": "posts/dockerize_simple/index.html#docker",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.4 Docker",
    "text": "3.4 Docker\n\na Docker configuration file (default name Dockerfile)\n\n\n\n  Photo by Ian Taylor on Unsplash \nWe’ll use docker to access R and Shiny. Here is our minimal dockerfile:\n\nDockerfile: Show the code\nFROM rocker/shiny:4.2.0\n# there are a bunch of files in /srv/shiny-server. delete them\nRUN rm -rf /srv/shiny-server\nCOPY /power1_shiny/* /srv/shiny-server/\n# rocker/shiny adds a user named shiny\nUSER shiny\nCMD [\"/usr/bin/shiny-server\"]\n\nThis file in just a few lines instructs Docker to build a new container based on a Rocker/Shiny image (which is a ubuntu image with R and Shiny installed) and layered with the addition of our Shiny code launch Shiny server listening on (default) port 3838.\nNote: We placed the power1_shiny/app.R code in the default location /srv/shiny-server so we only need to start the Shiny server and it will find the shiny program\nWe’ll use Caddy as our web server. Caddy is an open-source tool that has the very useful feature of automating the acquiring and installing of an SSL certificate. (An SSL cert is required by most browsers to use the encrypted communication protocol https.)\nTo configure the web server we need to add a Caddy configuration file (default name Caddyfile) to the power1_app directory.\nThe Caddy configuration file specifies three critical things.\n\nthe site domain name.\nthe authentication pair login/hash-password, for each user and\nthe ‘reverse proxy’ map that redirects requests to port 443 (ssl port) onto port 3838 (Shiny port) in the docker container.\n\nOur barebones Caddyfile looks like this:\n\nCaddyfile: Show the code\nrgtlab.org {\n    basicauth * /power1_shiny/* {\n        bob $2a$14$pYWd5O7JqNeGLS4m4CKkzemM2pq5ezn9bcTDowofZTl5wRVl8NTJm\n    }\n    root * /var/www/html\n    handle_path /power1_shiny/* {\n            reverse_proxy 0.0.0.0:3838\n    }\n    file_server\n}\n\nWe can accomplish what we need for items 4, 5, 6 and 7 through the Caddyfile.\nNote:\n\nrgtlab.org is our domain name\nthe basicauth directive specifies login credentials for user bob (password: vanilla47)\nhandle_path maps all https requests to port 3838 where Shiny is listening.\nroot directive tells Caddy where to look for the index.html file.\n\nProviding our servers domain name, rgtlab.org is sufficient to initiate an exchange with the letsencrypt service to generate an SSL certificate.\nLastly, we need an index.html file to provide a launch page for the app.\n\nindex.html: Show the code\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;body&gt;\n    &lt;h1&gt;Power1 app&lt;/h1&gt;\n    &lt;ul&gt;\n      &lt;li&gt;&lt;a href=\"./power1_shiny/\"&gt;Power1 app&lt;/a&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n\nOnce the config files, the index.html file and the Shiny code directory are in place copy we the entire power1_app directory to the server rgtlab.org with the secure copy command:\nscp -i \"~/.ssh/power1_app.pem\" -r ~/prj/power1_app/  ubuntu@rgtlab.org:~"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#post-launch-steps-on-remote-server",
    "href": "posts/dockerize_simple/index.html#post-launch-steps-on-remote-server",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.5 Post-Launch steps on remote server",
    "text": "3.5 Post-Launch steps on remote server\nUse ssh to login to the server and cd to power1_app directory\nBuild and run the Docker container (using the docker approach allows us to avoid installing both R and Shiny on the virtual server rgtlab.org).\ndocker build -t power1_image .\nrun container\ndocker run -d --name=power1_shiny -p 3838:3838 --restart=always power1_image\nNext copy the Caddyfile to the location caddy expects to find it in the /etc/caddy directory\nsudo cp ./Caddyfile /etc/caddy/\ncopy index.html to location Caddy expects to find it in the /var/www/html directory\ncp  ./index.html /var/www/html/\nLastly, run the following command to restart Caddy\nsudo systemctl reload caddy\nThe App launch page will now be available at https://rgtlab.org.\nand you’re good to go!"
  },
  {
    "objectID": "posts/dockerize_simple/index.html#tip-construct-ssh-config-file.",
    "href": "posts/dockerize_simple/index.html#tip-construct-ssh-config-file.",
    "title": "A simple process to get your Shiny app online (securely).",
    "section": "3.6 Tip construct ssh config file.",
    "text": "3.6 Tip construct ssh config file.\nFor convenience, construct a config file in ~/.ssh as:\nHost rgtlab.org\nHostName 13.57.139.31 # static IP\nStrictHostKeyChecking no  #avoid known host file error message\nUser ubuntu # default user on ubuntu server\nPort 22  # the default port ssh uses\nIdentityFile ~/.ssh/power1_app.pem\nthen you can ssh into the new server with\nsh&gt; ssh rgtlab.org"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "",
    "text": "chatGPT"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#section",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#section",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.1 ",
    "text": "1.1 \nchatGPT Prompts:\n“I want to use the Palmer Penguin dataset to create a Shiny app for data exploration.”\n“Update shiny app. Add a dropdown menu to select categorical variables, sex, species or island. Also add a dropdown menu to select continuouse variables Use selected categorical variable as a grouping variable in side-by-side boxplots of selected continuouse variables.”\n“add a second interactive plot to app.R code to provide scatterplots of 2 selected continuous variables. The two cont. vars are selected from drop down menus.”"
  },
  {
    "objectID": "posts/simple_shiny_app_with_chatgpt/index.html#r-code-to-launch.",
    "href": "posts/simple_shiny_app_with_chatgpt/index.html#r-code-to-launch.",
    "title": "A simple shiny app to explore Palmer Penguin data using ChatGPT to prototype.",
    "section": "1.2 R code to launch.",
    "text": "1.2 R code to launch.\nFrom inside R.\n    shiny::runApp(\"app.R\", launch.browser = TRUE)\nFrom shell.\n    R -e \"shiny::runApp('app.R', launch.browser=T)\"\n\nlibrary(shiny)\nlibrary(bslib)\nlibrary(bsicons)\nlibrary(palmerpenguins)\nlibrary(ggplot2)\nlibrary(corrgram)\nlibrary(dplyr)\n\n# Load the dataset\ndata &lt;- na.omit(penguins) # Remove rows with NA for simplicity\n\n# Helper function for tooltip\nadd_tooltip &lt;- function(input_ui, tooltip_text) {\n  input_ui$children[[1]] &lt;- div(\n    input_ui$children[[1]], # Original label\n    span(\n      bs_icon(\"info-circle-fill\"),\n      class = \"tooltip-icon ms-2\",\n      `data-bs-toggle` = \"tooltip\",\n      `data-bs-placement` = \"right\",\n      title = tooltip_text\n    ),\n    style = \"display: flex; align-items: center;\"\n  )\n  input_ui\n}\n\n# Module for inputs\ninputsUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  tagList(\n    h4(\"Boxplot Controls\"),\n    add_tooltip(\n      selectInput(\n        ns(\"xvar\"),\n        \"Continuous Variable for Boxplot:\",\n        choices = names(data)[3:6]\n      ),\n      \"Select a continuous variable to display on the Y-axis of the boxplot.\"\n    ),\n    add_tooltip(\n      selectInput(\n        ns(\"groupvar\"),\n        \"Group by (Categorical Variable):\",\n        choices = c(\"species\", \"sex\", \"island\"),\n        selected = \"species\"\n      ),\n      \"Select a categorical variable to group data in the boxplot.\"\n    ),\n    hr(),\n    h4(\"Scatterplot Controls\"),\n    add_tooltip(\n      selectInput(\n        ns(\"scatter_x\"),\n        \"X-axis for Scatterplot:\",\n        choices = names(data)[3:6]\n      ),\n      \"Select a variable for the X-axis of the scatterplot.\"\n    ),\n    add_tooltip(\n      selectInput(\n        ns(\"scatter_y\"),\n        \"Y-axis for Scatterplot:\",\n        choices = names(data)[3:6]\n      ),\n      \"Select a variable for the Y-axis of the scatterplot.\"\n    ),\n    add_tooltip(\n      selectInput(\n        ns(\"groupvar_scatter\"),\n        \"Group by (Scatterplot):\",\n        choices = c(\"species\", \"sex\", \"island\"),\n        selected = \"species\"\n      ),\n      \"Select a variable to group points in the scatterplot by color.\"\n    )\n  )\n}\n\ninputsServer &lt;- function(id) {\n  moduleServer(id, function(input, output, session) {\n    reactive(input)\n  })\n}\n\n# Module for boxplot\nboxplotUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  plotOutput(ns(\"boxPlot\"), height = \"400px\")\n}\n\nboxplotServer &lt;- function(id, data, inputs) {\n  moduleServer(id, function(input, output, session) {\n    output$boxPlot &lt;- renderPlot({\n      req(data(), inputs())\n      ggplot(\n        data(),\n        aes(\n          x = .data[[inputs()$groupvar]],\n          y = .data[[inputs()$xvar]],\n          fill = .data[[inputs()$groupvar]]\n        )\n      ) +\n        geom_boxplot(alpha = 0.7) +\n        theme_minimal() +\n        labs(\n          x = inputs()$groupvar,\n          y = inputs()$xvar,\n          fill = inputs()$groupvar\n        ) +\n        theme(legend.position = \"bottom\")\n    })\n  })\n}\n\n# Module for scatterplot\nscatterplotUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  plotOutput(ns(\"scatterPlot\"), height = \"400px\")\n}\n\nscatterplotServer &lt;- function(id, data, inputs) {\n  moduleServer(id, function(input, output, session) {\n    output$scatterPlot &lt;- renderPlot({\n      req(data(), inputs())\n      ggplot(\n        data(),\n        aes(\n          x = .data[[inputs()$scatter_x]],\n          y = .data[[inputs()$scatter_y]],\n          color = .data[[inputs()$groupvar_scatter]]\n        )\n      ) +\n        geom_point(alpha = 0.7, size = 2) +\n        geom_smooth(\n          method = \"lm\",\n          se = FALSE,\n          aes(group = 1),\n          color = \"black\",\n          linetype = \"dashed\"\n        ) +\n        geom_smooth(method = \"lm\", se = FALSE) +\n        theme_minimal() +\n        labs(\n          x = inputs()$scatter_x,\n          y = inputs()$scatter_y,\n          color = inputs()$groupvar_scatter\n        ) +\n        theme(legend.position = \"bottom\")\n    })\n  })\n}\n\n# Module for correlation matrix\ncorrelationUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  plotOutput(ns(\"correlationMatrix\"), height = \"400px\")\n}\n\ncorrelationServer &lt;- function(id, data) {\n  moduleServer(id, function(input, output, session) {\n    output$correlationMatrix &lt;- renderPlot({\n      req(data())\n      numericData &lt;- data()[, sapply(data(), is.numeric)]\n      corrgram(\n        numericData,\n        order = TRUE,\n        lower.panel = panel.shade,\n        upper.panel = panel.pie,\n        text.panel = panel.txt,\n        main = \"Correlation Matrix\"\n      )\n    })\n  })\n}\n\n# Main UI and server\nui &lt;- fluidPage(\n  theme = bs_theme(bootswatch = \"litera\"), # Use a bslib theme\n  titlePanel(\"Palmer Penguins Explorer\"),\n  fluidRow(\n    column(3, inputsUI(\"inputs\"), \n       style = \"overflow-y: auto; max-height: 600px;\"),\n    column(\n      6,\n      fluidRow(\n        column(12, h4(\"Boxplot\"), boxplotUI(\"boxplot\"), style = \"height: 50%;\"),\n        column(12, h4(\"Scatterplot\"), scatterplotUI(\"scatterplot\"), \n           style = \"height: 50%;\")\n      ),\n      style = \"overflow-y: auto;\"\n    ),\n    column(3, h4(\"Correlation Matrix\"), correlationUI(\"correlation\"))\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  # Reactive dataset\n  filteredData &lt;- reactive({\n    data\n  })\n  \n  # Call modules\n  inputs &lt;- inputsServer(\"inputs\")\n  boxplotServer(\"boxplot\", filteredData, inputs)\n  scatterplotServer(\"scatterplot\", filteredData, inputs)\n  correlationServer(\"correlation\", filteredData)\n}\n\nshinyApp(ui, server)"
  },
  {
    "objectID": "posts/donna/index.html",
    "href": "posts/donna/index.html",
    "title": "Donna Brogan problem",
    "section": "",
    "text": "quarto\n\n\n\n1 Introduction\nThe question arises as to whether in the case of two treatment groups and two timepoints does MMRM reduce exactly to ANCOVA.\n\nDoes if matter if the analysis is adjusting for baseline (i.e. not including baseline in MMRM response.).\nDoes it matter if response is observed value or is a change score? Consider the article by Brogan and Kutner [@Brogan1980] Here are all the responses bundled into a single markdown code block:\n\nI'll explain the key differences between using a linear model and a random effects model for your clinical trial scenario.\n\nLinear Model (e.g., ANCOVA):\nIn a linear model, you would typically analyze the post-treatment measurements as your dependent variable, with treatment group as a predictor and pre-treatment measurements as a covariate. This approach:\n- Treats all observations as independent\n- Handles missing post-treatment data through complete case analysis (dropping those cases)\n- Assumes the relationship between pre and post measurements is the same for all subjects\n- Same error variance for all observations\n\nRandom Effects Model (Mixed Model):\nThis approach would model both time points together and account for the fact that measurements from the same person are correlated. Key features:\n- Includes subject-specific random effects to account for individual differences\n- Can handle missing data more efficiently (uses all available data)\n- Allows for different variances at different time points\n- Models the correlation between repeated measurements within subjects\n\nFor your specific case, the random effects model has several advantages:\n1. It can use all available data, including subjects who only have pre-treatment measurements\n2. It accounts for the correlation between pre and post measurements from the same person\n3. It provides more accurate standard errors by modeling the dependency structure\n\nThe basic random effects model for your case might look like this in R:\n```r\nlmer(outcome ~ time * treatment + (1|subject))\nWould you like me to elaborate on any of these points or provide more specific guidance for your analysis?\n\nYes, the linear model can be seen as a special case of the random effects model where the random effects variance components are set to zero. This means:\n\nIn mathematical terms, if we write a random effects model as: y = Xβ + Zu + ε where:\n\nXβ represents the fixed effects\nZu represents the random effects\nε is the error term\n\nWhen we set Var(u) = 0, the random effects term Zu disappears, and we’re left with: y = Xβ + ε which is the standard linear model\nThis relationship is why random effects models are sometimes called “mixed models” - they mix both fixed effects (like your linear model) and random effects together. The fixed effects portion is essentially the same as what you’d have in a linear model.\nYou can actually test this relationship formally using a likelihood ratio test comparing the models, though there are some technical considerations since you’re testing on the boundary of the parameter space (variance can’t be negative).\n\nThis hierarchical relationship between the models is one reason why random effects models are so flexible - they can “collapse” down to simpler models when the data suggest that’s appropriate. Would you like me to explain more about how this relationship plays out in practice with your clinical trial data? ``` \n\n\n2 Methods\nSet up the model, no covariates, in both settings with 3 observations per group. Work out analytic formula\n\nRepeat for unequal variances\nRepeat w covariates\n\n\n\n3 Methods\n\n\n4 Results\n\n\n5 Code\n\n\n\n6 References\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy)_glenn_thomas2025,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Donna {Brogan} Problem},\n  date = {2025-01-31},\n  url = {https://focusonr.org/posts/donna/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. 2025. “Donna Brogan Problem.”\nJanuary 31, 2025. https://focusonr.org/posts/donna/."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Vim is a powerful and efficient text editor that, with the right setup, can serve as a productive environment for data science work in Python, Julia, and R. This guide will walk you through the essential plugins and configurations to transform Vim into a fully functional IDE for data science.\n\n\n\nLightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage.\n\n\n\n\nA plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins.\n\n\n\nPlug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim\n\n\n\nPlug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']\n\n\n\nPlug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle\n\n\n\n\nPlug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1\n\n\n\nPlug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline.\n\n\n\nPlug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code.\n\n\n\nPlug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets.\n\n\n\nPlug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R.\n\n\n\nPlug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode\n\n\n\n\nScreenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science.\n\n\n\n\nWith this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!\n\n\n\n\n\n\nHow to Exit Vim"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#why-use-vim-for-data-science",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Lightweight & Fast: Vim is optimized for speed, making it ideal for large datasets and remote work.\nHighly Customizable: You can tailor Vim to your workflow using plugins.\nKeyboard-Driven Efficiency: Eliminates the need for excessive mouse usage."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#getting-started-package-management",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "A plugin manager is essential for maintaining and updating plugins. Popular choices include:\n\nvim-plug: A minimalist and fast plugin manager.\nVundle: An alternative with similar capabilities.\nPathogen: Loads plugins automatically from a directory.\n\nTo install vim-plug, add the following to your .vimrc:\ncall plug#begin('~/.vim/plugged')\n\n\" Add plugins here\n\ncall plug#end()\nRun :PlugInstall after adding plugins."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#enhancing-syntax-highlighting-language-support",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sheerun/vim-polyglot' \" Syntax highlighting for multiple languages\nPlug 'vim-python/python-syntax' \" Improved Python syntax highlighting\nPlug 'JuliaEditorSupport/julia-vim' \" Julia support\nPlug 'jalvesaq/Nvim-R' \" R support for Vim"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-completion-linting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'neoclide/coc.nvim', {'branch': 'release'} \" LSP support\nPlug 'dense-analysis/ale' \" Linter for multiple languages\nInstall language servers:\npip install python-lsp-server\njulia -e 'using Pkg; Pkg.add(\"LanguageServer\")'\nR -e 'install.packages(\"languageserver\")'\nConfigure CoC in .vimrc:\nlet g:coc_global_extensions = ['coc-pyright', 'coc-julia', 'coc-r-lsp']"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#navigating-code-files",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'junegunn/fzf', { 'do': { -&gt; fzf#install() } }\nPlug 'junegunn/fzf.vim' \" Fuzzy file searching\nPlug 'preservim/tagbar' \" Code structure browser\nPlug 'scrooloose/nerdtree' \" File explorer\n\nOpen NERDTree with :NERDTreeToggle\nOpen Tagbar with :TagbarToggle"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#interactive-execution-repl-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'jpalardy/vim-slime' \" Send code to a REPL\nPlug 'hkupty/iron.nvim' \" Interactive REPL support\nConfigure Vim-Slime:\nlet g:slime_target = 'tmux'\nlet g:slime_python_ipython = 1"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#version-control-integration",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-fugitive' \" Git commands in Vim\nPlug 'airblade/vim-gitgutter' \" Show git diff in sign column\nUse :Git for Git commands and :GitGutterToggle to view changes inline."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#code-formatting-auto-indentation",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'psf/black', { 'for': 'python' } \" Black formatter for Python\nPlug 'mhartington/formatter.nvim' \" General-purpose formatter\nConfigure formatter.nvim for Julia and R:\nrequire('formatter').setup({\n  filetype = {\n    python = {require('formatter.filetypes.python').black},\n    julia = {require('formatter.filetypes.julia').default},\n    r = {require('formatter.filetypes.r').styler}\n  }\n})\nUse :Format to auto-format code."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#snippet-support-for-faster-coding",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'sirver/ultisnips' \" Snippet engine\nPlug 'honza/vim-snippets' \" Collection of snippets\nUse &lt;Tab&gt; to expand snippets."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#debugging-tools",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'puremourning/vimspector' \" Multi-language debugger\nFollow the setup guide for debugging Python, Julia, and R."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#additional-productivity-plugins",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Plug 'tpope/vim-surround' \" Quick surround modifications\nPlug 'tpope/vim-commentary' \" Easy commenting\nPlug 'junegunn/goyo.vim' \" Distraction-free mode"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#visual-aids-accessibility",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "Screenshots & Diagrams: Use images to demonstrate concepts.\nCode Blocks: Ensure syntax highlighting for better readability.\nSEO Optimization: Use keywords like Vim plugins for data science."
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#conclusion",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "With this setup, Vim becomes a powerful tool for data science work, supporting Python, Julia, and R. Whether you need syntax highlighting, REPL integration, or debugging, these plugins will help you create an efficient workflow.\nWhat are your favorite Vim plugins for data science? Share your thoughts in the comments!"
  },
  {
    "objectID": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "href": "posts/configure_vim_for_r/chat_blog_draft.html#exiting",
    "title": "Setting Up a Vim Environment for Data Science Work",
    "section": "",
    "text": "How to Exit Vim"
  },
  {
    "objectID": "posts/research_management/research_workflow_local.html",
    "href": "posts/research_management/research_workflow_local.html",
    "title": "Streamlining Your Research Workflow on Mac with ChatGPT",
    "section": "",
    "text": "Tracking daily research progress can quickly become overwhelming without a structured workflow. This guide outlines an efficient system using a well-organized directory structure, automated logging, ChatGPT for dictation and summarization, and Git for version control. By implementing this workflow, you can maintain clear, searchable research logs while reducing manual overhead.\n\n\n\nResearch Workflow Overview"
  },
  {
    "objectID": "posts/research_management/research_workflow_local.html#step-3.1-preparing-a-dictation-prompt",
    "href": "posts/research_management/research_workflow_local.html#step-3.1-preparing-a-dictation-prompt",
    "title": "Streamlining Your Research Workflow on Mac with ChatGPT",
    "section": "4.1 Step 3.1: Preparing a Dictation Prompt",
    "text": "4.1 Step 3.1: Preparing a Dictation Prompt\nUse this Bash script to copy a structured prompt to your clipboard:\n#!/bin/bash\n\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\ncurrent_dir=$(basename \"$PWD\")\n\nprompt=\"I'm about to dictate research experiment notes.\\nWhen I'm done, provide a concise summary that includes:\\n1. The date and time of dictation ($current_time).\\n2. The name of the current research project directory ($current_dir).\\n3. Each line of the summary should begin with \\\"$current_dir:\\\" so that it can be extracted using grep.\\nThe notes start here: \"\n\necho -n \"$prompt\" | pbcopy\necho \"Research prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\nMac Dictation Feature"
  },
  {
    "objectID": "posts/research_management/research_workflow_local.html#step-3.2-dictating-notes",
    "href": "posts/research_management/research_workflow_local.html#step-3.2-dictating-notes",
    "title": "Streamlining Your Research Workflow on Mac with ChatGPT",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nEnable Mac’s dictation by pressing Control twice.\nDictate your research notes.\nCopy and paste the generated summary into your daily log."
  },
  {
    "objectID": "posts/research_management/research_workflow_local.html#step-3.3-automate-log-updates",
    "href": "posts/research_management/research_workflow_local.html#step-3.3-automate-log-updates",
    "title": "Streamlining Your Research Workflow on Mac with ChatGPT",
    "section": "4.3 Step 3.3: Automate Log Updates",
    "text": "4.3 Step 3.3: Automate Log Updates\nTo append the summarized notes to your daily log, use the following script:\n#!/bin/bash\n\nclipboard_content=$(pbpaste)\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"Update appended to daily_log.md.\""
  },
  {
    "objectID": "posts/research_management/research_workflow_local.html#automate-daily-git-commits",
    "href": "posts/research_management/research_workflow_local.html#automate-daily-git-commits",
    "title": "Streamlining Your Research Workflow on Mac with ChatGPT",
    "section": "5.1 Automate Daily Git Commits",
    "text": "5.1 Automate Daily Git Commits\nSchedule an automatic commit every night using crontab:\n0 23 * * * cd ~/prj/research_update && git add . && git commit -m \"Daily log $(date)\" && git push"
  },
  {
    "objectID": "posts/research_management/research_workflow_local.html#research-workflow-overview",
    "href": "posts/research_management/research_workflow_local.html#research-workflow-overview",
    "title": "Streamlining Your Research Workflow on Mac with ChatGPT",
    "section": "",
    "text": "ResearchWorkflow\n\n\n\nstart\n\nStart Research Day\n\n\n\nsetup\n\nSet up Project\nStructure\n\n\n\nstart-&gt;setup\n\n\n\n\n\nend\n\nEnd Research Day\n\n\n\nlog\n\nInitialize Daily Log\n\n\n\nsetup-&gt;log\n\n\n\n\n\ndict\n\nEnable Mac Dictation\n\n\n\nlog-&gt;dict\n\n\n\n\n\nnotes\n\nDictate Research Notes\n\n\n\ndict-&gt;notes\n\n\n\n\n\ngpt\n\nChatGPT Summarization\n\n\n\nnotes-&gt;gpt\n\n\n\n\n\nupdate\n\nUpdate Daily Log\n\n\n\ngpt-&gt;update\n\n\n\n\n\ngit\n\nGit Operations\n\n\n\nupdate-&gt;git\n\n\n\n\n\nmanual\n\nManual Commit\n\n\n\ngit-&gt;manual\n\n\n\n\n\nauto\n\nAuto Commit\n\n\n\ngit-&gt;auto\n\n\n\n\n\nsync\n\nSync Across Devices\n\n\n\nmanual-&gt;sync\n\n\n\n\n\nauto-&gt;sync\n\n\n\n\n\ncloud\n\nChoose Sync Method\n\n\n\nsync-&gt;cloud\n\n\n\n\n\nicloud\n\niCloud Drive\n\n\n\ncloud-&gt;icloud\n\n\n\n\n\ndropbox\n\nDropbox\n\n\n\ncloud-&gt;dropbox\n\n\n\n\n\ngithub\n\nGitHub\n\n\n\ncloud-&gt;github\n\n\n\n\n\nsearch\n\nSearch & Retrieve\nPast Notes\n\n\n\nicloud-&gt;search\n\n\n\n\n\ndropbox-&gt;search\n\n\n\n\n\ngithub-&gt;search\n\n\n\n\n\nsearch-&gt;end\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ngraph TD\n    Start([Start Research Day]) --&gt; Setup[Set up Project Structure]\n    Setup --&gt; Log[Initialize Daily Log]\n    Log --&gt; Dict[Enable Mac Dictation]\n    Dict --&gt; Notes[Dictate Research Notes]\n    Notes --&gt; GPT[Send to ChatGPT for Summarization]\n    GPT --&gt; Update[Update Daily Log File]\n    \n    Update --&gt; Git{Git Operations}\n    Git --&gt;|Automatic| AutoCommit[Schedule Daily Commits]\n    Git --&gt;|Manual| ManualCommit[Manual Commits]\n    \n    AutoCommit --&gt; Sync[Sync Across Devices]\n    ManualCommit --&gt; Sync\n    \n    Sync --&gt; Cloud{Choose Sync Method}\n    Cloud --&gt;|Option 1| iCloud[iCloud Drive]\n    Cloud --&gt;|Option 2| Dropbox[Dropbox]\n    Cloud --&gt;|Option 3| GitHub[GitHub]\n    \n    iCloud --&gt; Search[Search & Retrieve Past Notes]\n    Dropbox --&gt; Search\n    GitHub --&gt; Search\n    \n    Search --&gt; End([End Research Day])\n    \n    style Start fill:#f9f,stroke:#333\n    style End fill:#f9f,stroke:#333\n    style Git fill:#bbf,stroke:#333\n    style Cloud fill:#bbf,stroke:#333\n# Step 1: Organize Your Research Folder Structure\nA structured directory keeps your research files easily accessible and prevents clutter. Use the following command to create a research workspace:\n\n```sh\nmkdir -p ~/prj/research_update ~/prj/{X1,X2,X3,X4,X5,X6,X7,X8,X9,X10}\n\n\n\n\n\n\nEach project folder should contain: - notes.md – Running log of project progress - references.bib – Citation management - data/ – Datasets and related files - coding/ – Code and analyses - figures/ – Graphs and visualizations - tables/ – Data summaries - archive/ – Storage for non-current files\n\n\n\nFolder Structure Example"
  },
  {
    "objectID": "posts/research_management/test.html",
    "href": "posts/research_management/test.html",
    "title": "Mermaid Version Test",
    "section": "",
    "text": "graph TD\n    A[Start] --&gt; B[Test]\n    B --&gt; C[End]\n\n\n\n\ngraph TD\n    A[Start] --&gt; B[Test]\n    B --&gt; C[End]\n\n\n\n\n\n\n\n\n\nReuseCC BY 4.0CitationBibTeX citation:@online{(ryy) glenn thomas,\n  author = {(Ryy) Glenn Thomas, Ronald},\n  title = {Mermaid {Version} {Test}},\n  url = {https://focusonr.org/posts/research_management/test.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n(Ryy) Glenn Thomas, Ronald. n.d. “Mermaid Version Test.” https://focusonr.org/posts/research_management/test.html."
  },
  {
    "objectID": "posts/research_management/test.html#my-workflow",
    "href": "posts/research_management/test.html#my-workflow",
    "title": "My Blog Post",
    "section": "",
    "text": "Here’s a visualization of our process:\n\nflowchart LR\n    A[Write Code] --&gt; B[Test]\n    B --&gt; C[Deploy]\n    C --&gt; D[Monitor]\n\n\n\n\nflowchart LR\n    A[Write Code] --&gt; B[Test]\n    B --&gt; C[Deploy]\n    C --&gt; D[Monitor]\n\n\n\n\n\n\nThe diagram above shows our deployment pipeline."
  },
  {
    "objectID": "posts/research_management/test.html#test-1-basic-debug-info",
    "href": "posts/research_management/test.html#test-1-basic-debug-info",
    "title": "Mermaid Version Test",
    "section": "",
    "text": "%%{init: {'logLevel': 'debug'}}%%\ngraph TD\n    A[Start] --&gt; B[End]\n\n\n\n\n%%{init: {'logLevel': 'debug'}}%%\ngraph TD\n    A[Start] --&gt; B[End]"
  },
  {
    "objectID": "posts/research_management/test.html#test-2-version-with-config",
    "href": "posts/research_management/test.html#test-2-version-with-config",
    "title": "Mermaid Version Test",
    "section": "2 Test 2: Version with Config",
    "text": "2 Test 2: Version with Config\n\n%%{init: {\n  'theme': 'default',\n  'logLevel': 'debug'\n}}%%\nflowchart TD\n    A[Version] --&gt; B[Test]\n\n\n\n\n%%{init: {\n  'theme': 'default',\n  'logLevel': 'debug'\n}}%%\nflowchart TD\n    A[Version] --&gt; B[Test]"
  },
  {
    "objectID": "posts/research_management/index.html",
    "href": "posts/research_management/index.html",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "",
    "text": "quarto"
  },
  {
    "objectID": "posts/research_management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "href": "posts/research_management/index.html#step-3.1-initialize-a-chatgpt-dictation-prompt-by",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by",
    "text": "4.1 Step 3.1: Initialize a chatGPT dictation prompt by\nrunning this bash script to copy a prelude to the chatGPT prompt to your clipboard: Call it dp (dictation prompt).\n#!/bin/bash\n\n# Get current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Define the prompt with explicit instructions\nprompt=\"I'm an academic biostatistician. I'm working on a data analysis project.\nI'm about to dictate daily research progress notes.  \nWhen I'm done, provide a concise summary that includes:  \n\n1. The date  and time of dictation ($current_time).  The line with date and time\nshould be the second line of the summary. The first line should be blank. The\ndate and time line shound be enclosed in a box of ascii characters to set it apart.\n2. The name of the current research project directory ($current_dir).  \n3. Each line of the summary including the blank line and the date and time line\nand enclosing box lines should begin with \\\"$current_dir:\\\" so that it can be\nextracted using ripgrep.  \n\nThe notes start here: \"\n\n# Copy the prompt to clipboard (MacOS pbcopy)\necho -n \"$prompt\" | pbcopy\n\n# Notify the user\necho \"Prompt copied to clipboard. Paste it into ChatGPT when ready.\"\n\n\n\n\n\nworkflow"
  },
  {
    "objectID": "posts/research_management/index.html#step-3.2-dictating-notes",
    "href": "posts/research_management/index.html#step-3.2-dictating-notes",
    "title": "Mac Workflow for Tracking Daily Research Progress",
    "section": "4.2 Step 3.2: Dictating Notes",
    "text": "4.2 Step 3.2: Dictating Notes\n\nOpen ChatGPT (done automatically by “dp” script) and follow these steps:\ncopy text from clipboard into the prompt box.\nsubmit prompt to prep chatGPT for summarization.\nClick chatGPT microphone and Dictate your research notes.\nWhen finished dictating submit prompt to ChatGPT for summarization.\nCopy and generated summary onto the clipboard.\n\nUse the following script to append the summary to your daily log: and push the changes to daily_log.md to the remote repository on GitHub.\n#!/bin/bash\n\n# Get the current directory name\ncurrent_dir=$(basename \"$PWD\")\n\n# Get the current date and time\ncurrent_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n\n# Get the clipboard content (MacOS pbpaste)\nclipboard_content=$(pbpaste)\n\n# Echo the output\n#\necho \"$clipboard_content\" &gt;&gt; ~/prj/research_update/daily_log.md\necho \"\" &gt;&gt; ~/prj/research_update/daily_log.md\n\n# Confirm success\necho \"Update for $current_dir appended to daily_log.md in ~/prj/research_update\"\ncd ~/prj/research_update\n  git add .\n    git commit -a -m \"Daily log update $(date +'%Y-%m-%d')\"\n    git push"
  }
]